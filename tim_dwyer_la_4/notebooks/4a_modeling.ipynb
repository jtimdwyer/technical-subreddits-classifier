{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posts that beat the median\n",
    "We're going to process our data a bit more so that we can build some models that will try to answer the following question:\n",
    "\n",
    "> Q: For a given post, does this post have more than the median score or not?\n",
    "\n",
    "The this end we'll transform our text data into numerical data that we can work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/csv/all_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>over_18</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>is_self</th>\n",
       "      <th>higher_than_median</th>\n",
       "      <th>num_comments_log1p</th>\n",
       "      <th>title_len_log1p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dave Bautista has achieved full Drax.</td>\n",
       "      <td>22715.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>funny</td>\n",
       "      <td>1.527526e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.802118</td>\n",
       "      <td>3.637586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not even safe in Super Mario 64...</td>\n",
       "      <td>36365.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>gaming</td>\n",
       "      <td>1.527525e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.135565</td>\n",
       "      <td>3.555348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rapid-fire cigar box juggling (sort of looks l...</td>\n",
       "      <td>56601.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>gifs</td>\n",
       "      <td>1.527522e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.461468</td>\n",
       "      <td>4.174387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very true</td>\n",
       "      <td>43332.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pics</td>\n",
       "      <td>1.527526e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.870166</td>\n",
       "      <td>2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Couple with Down's syndrome celebrate 22 years...</td>\n",
       "      <td>27582.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>aww</td>\n",
       "      <td>1.527525e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.431331</td>\n",
       "      <td>4.094345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title    score  over_18  \\\n",
       "0              Dave Bautista has achieved full Drax.  22715.0      0.0   \n",
       "1                 Not even safe in Super Mario 64...  36365.0      0.0   \n",
       "2  rapid-fire cigar box juggling (sort of looks l...  56601.0      0.0   \n",
       "3                                          Very true  43332.0      0.0   \n",
       "4  Couple with Down's syndrome celebrate 22 years...  27582.0      0.0   \n",
       "\n",
       "  subreddit   created_utc  is_self  higher_than_median  num_comments_log1p  \\\n",
       "0     funny  1.527526e+09      0.0                 1.0            5.802118   \n",
       "1    gaming  1.527525e+09      0.0                 1.0            6.135565   \n",
       "2      gifs  1.527522e+09      0.0                 1.0            6.461468   \n",
       "3      pics  1.527526e+09      0.0                 1.0            7.870166   \n",
       "4       aww  1.527525e+09      0.0                 1.0            6.431331   \n",
       "\n",
       "   title_len_log1p  \n",
       "0         3.637586  \n",
       "1         3.555348  \n",
       "2         4.174387  \n",
       "3         2.302585  \n",
       "4         4.094345  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_feats = ['title', 'selftext']\n",
    "num_and_bool_feats = [col for col in df.columns if col not in text_feats + ['subreddit']]\n",
    "df[num_and_bool_feats] = df[num_and_bool_feats].copy().astype(float)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only remaining preprocessing is in tokenizing the titles. We can just do this in a pipeline without too much difficulty after we split everything into training and testing sets, so let's do that now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['higher_than_median'],1)\n",
    "y = df['higher_than_median']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Text as Numerical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some explanation for NLP and feature extraction for text.\n",
    "\n",
    "\n",
    "As a warm up we will encode the subreddit name as a collection of dummy variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dum_train = pd.get_dummies(X_train['subreddit'])\n",
    "X_dum_test = pd.get_dummies(X_test['subreddit'])\n",
    "\n",
    "for col in X_dum_test:\n",
    "    if col not in X_dum_train.columns:\n",
    "        X_dum_test.drop(col, 1, inplace=True)\n",
    "\n",
    "for col in X_dum_train:\n",
    "    if col not in X_dum_test.columns:\n",
    "        X_dum_test[col] = pd.Series([0 for _ in X_dum_test.index], index=X_dum_test.index)\n",
    "\n",
    "X_train = X_train.join(X_dum_train)\n",
    "X_train.drop('subreddit', 1, inplace=True)\n",
    "\n",
    "X_test = X_test.join(X_dum_test)\n",
    "X_test.drop('subreddit', 1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to want to use a tf-idf tokenizer on the `title` feature, but to do this with a pipeline object from SKLearn, we can define a custom transformer that will only affect the `title`. This is not built in complete generality, so I make no promise that it will work without modification to a different data structure (i.e. if you're using different matrix encodings). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "class Tfidf_Col(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, cols=[]):\n",
    "        self.cols = cols\n",
    "        self.vects = {col:TfidfVectorizer() for col in cols}\n",
    "        \n",
    "    def transform(self, X, *_):\n",
    "        X = X.copy()\n",
    "        transformed = []\n",
    "        for col in self.cols:\n",
    "            tmp = self.vects[col].transform(X.loc[:,col])\n",
    "            transformed.append(tmp)\n",
    "            X.drop(col, 1, inplace=True)\n",
    "            \n",
    "        X = scipy.sparse.csr_matrix(X.values)\n",
    "        transformed.append(X)\n",
    "        X = scipy.sparse.hstack(transformed)\n",
    "        return X\n",
    "        \n",
    "    def fit(self, X, *_):\n",
    "        for col in self.cols:\n",
    "            self.vects[col].fit(X.loc[:,col])\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('tfidf', Tfidf_Col(cols=['title'])), ('ss', StandardScaler(copy=True, with_mean=False, with_std=True)), ('logreg', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'logreg__C': array([ 1.25462])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl = [\n",
    "    ('tfidf', Tfidf_Col(['title'])),\n",
    "    ('ss', StandardScaler(with_mean=False)),\n",
    "    ('logreg', LogisticRegression()),\n",
    "]\n",
    "\n",
    "np.random.seed(41)\n",
    "\n",
    "my_params = {\n",
    "    'logreg__C':np.random.uniform(0,5,1),\n",
    "#     'logreg__penalty':['l1', 'l2'],\n",
    "}\n",
    "\n",
    "pipe = Pipeline(pl)\n",
    "logreg = GridSearchCV(pipe, param_grid=my_params)\n",
    "\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99537944553346402"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64804703905921879"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('tfidf', Tfidf_Col(cols=['title'])), ('ss', StandardScaler(copy=True, with_mean=False, with_std=True)), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'knn__n_neighbors': range(3, 4)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl = [\n",
    "    ('tfidf', Tfidf_Col(['title'])),\n",
    "    ('ss', StandardScaler(with_mean=False)),\n",
    "    ('knn', KNeighborsClassifier()),\n",
    "]\n",
    "\n",
    "np.random.seed(41)\n",
    "\n",
    "my_params = {\n",
    "    'knn__n_neighbors':range(3,4)\n",
    "}\n",
    "\n",
    "pipe = Pipeline(pl)\n",
    "knn = GridSearchCV(pipe, param_grid=my_params)\n",
    "\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70799999999999996"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice_index = X_train.index[:2000]\n",
    "slice_X = X_train.loc[[*slice_index], :]\n",
    "slice_y = y_train[slice_index]\n",
    "knn.score(slice_X, slice_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72950000000000004"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice_index = X_train.index[2000:4000]\n",
    "slice_X = X_train.loc[[*slice_index], :]\n",
    "slice_y = y_train[slice_index]\n",
    "knn.score(slice_X, slice_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70973901973265441"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice_index = X_train.index[4000:]\n",
    "slice_X = X_train.loc[[*slice_index], :]\n",
    "slice_y = y_train[slice_index]\n",
    "knn.score(slice_X, slice_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51658966820663588"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too big to score on the training set!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('tfidf', Tfidf_Col(cols=['title'])), ('ss', StandardScaler(copy=True, with_mean=False, with_std=True)), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_...     min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'))]),\n",
       "       fit_params=None, iid=True, n_jobs=1, param_grid={},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl = [\n",
    "    ('tfidf', Tfidf_Col(['title'])),\n",
    "    ('ss', StandardScaler(with_mean=False)),\n",
    "    ('dt', DecisionTreeClassifier()),\n",
    "]\n",
    "\n",
    "np.random.seed(41)\n",
    "\n",
    "my_params = {\n",
    "    \n",
    "}\n",
    "\n",
    "pipe = Pipeline(pl)\n",
    "dt = GridSearchCV(pipe, param_grid=my_params)\n",
    "\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('tfidf', Tfidf_Col(cols=['title'])), ('ss', StandardScaler(copy=True, with_mean=False, with_std=True)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1, param_grid={},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl = [\n",
    "    ('tfidf', Tfidf_Col(['title'])),\n",
    "    ('ss', StandardScaler(with_mean=False)),\n",
    "    ('rf', RandomForestClassifier()),\n",
    "]\n",
    "\n",
    "np.random.seed(41)\n",
    "\n",
    "my_params = {\n",
    "    {'rf__n_estimators'}:range(6,14),\n",
    "}\n",
    "\n",
    "pipe = Pipeline(pl)\n",
    "rf = GridSearchCV(pipe, param_grid=my_params)\n",
    "\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9878202435951281"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
