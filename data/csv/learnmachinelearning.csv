title,num_comments,score,over_18,locked,stickied,subreddit,created_utc,is_self,selftext
Need advice for predicting likes with ML,3,0,False,False,False,learnmachinelearning,1483285897,True,"I want to predict if a post will result in many likes. I'm fine using a regression to predict the exact number or classifier to determine if the result will be above some threshold. 

Two questions: 

1) Given I could use a regression or classifier, which is best at discriminating those with a high number of likes from those with a low number?

2) I thought about using naive Bayes to classify based on high performing words, but I also have extra info like time of day for the post. How does one combine something solely text based, like naive Bayes, with numeric covariates?"
Thorough Deep Learning Course (~ 18 hours),0,1,False,False,False,learnmachinelearning,1483289181,False, 
Multi-layer neural network implementation in Python,0,2,False,False,False,learnmachinelearning,1483315770,True,[deleted]
Neural Network - number of hidden NEURONS and number of hidden LAYERS,2,7,False,False,False,learnmachinelearning,1483347147,True,"tl;dr How are number of hidden neurons in a hidden layer and number of hidden layers related to the performance of a neural network?

Hello, 
I'm currently a student who's been self teaching machine learning; I realized I didn't really understand how number of hidden layers in a neural net affects its performance and how number of neurons in a hidden layer affects it. For example, what makes a DNN significantly different from a network with one hidden layer, perhaps with many hidden neurons? "
Deep Learning in Android?,4,4,False,False,False,learnmachinelearning,1483371213,True,Is there any benchmark for Deep Learning frameworks running in android? Which is the typical performance we ca expect from a smartphone? 
What is the best course to learn deep learning in practice using tensorflow or such except Udacity which I am taking already?,11,5,False,False,False,learnmachinelearning,1483407033,True, 
There exists a world for Machine Learning beyond R and Python!,0,1,False,False,False,learnmachinelearning,1483424628,False,[deleted]
TIL (Today I Learned) Tuesday - Share something new that you have learned today!,2,1,False,False,False,learnmachinelearning,1483427230,True,"It doesn't matter if it's something trivial. As long as it's new information you didn't know until today, feel free to share!
"
There exists a world for Machine Learning beyond R and Python!,0,1,False,False,False,learnmachinelearning,1483428540,False, 
Multi-Objective Problems: Introduction,1,1,False,False,False,learnmachinelearning,1483462923,False,[deleted]
Material after Andrew Ng's Introduction to Machine Learning on Coursera?,1,6,False,False,False,learnmachinelearning,1483484689,True, 
ELI5 about Independent component analysis (ICA).,2,1,False,False,False,learnmachinelearning,1483492794,True,"I know it is for dimensionality reduction, and also it assumes vectors are independent of each other unlike PCA. Can someone give a complete explanation of ICA?"
How to force XGBoost to learn multiple trees?,1,2,False,False,False,learnmachinelearning,1483502833,True,"Currently, no matter how big of n_estimators I set, xgboost always end up with a tree with just one root. So my question is how is n_estimator really interpreted here? Isn't it suppose to be number of trees? Thanks!"
Sharing a small Guide to help you Get Started with Machine Learning on Linux,0,17,False,False,False,learnmachinelearning,1483520908,False, 
Summary/generalist book on ML ?,6,7,False,False,False,learnmachinelearning,1483530464,True,"Hello all, 

I'm looking for a book explaining the different methods  in machine learning. I would like something giving an overview of the diverse methods (ie not focused on a specific topic like deep learning or even neural network). I'm interested in knowing what method exists, understanding broadly how they function, what are their domain of application/validity/limits. I'm not too much interested on the precise and technical details of the mathematics underlying (some mathematics of course are unavoidable) and even less on how to implement them.

The ultimate goal would be to get a basic understandings, in order to know when I have a problem if ML would be a interesting solution, and if yes which method would be the most interesting to apply.


Thanks for you advice"
What I Learned Implementing a Classifier from Scratch in Python,0,19,False,False,False,learnmachinelearning,1483530989,False, 
Question : Self taught machine learning possible?,1,2,False,False,False,learnmachinelearning,1483532781,True,"As the question suggests, I'm planning to learn about machine learning (Python background- self taught) , is it currently possible to get a job in ML by being self taught? I only ask because i do not have any interaction with other such people. Thank you"
What are harmonic embeddings,0,1,False,False,False,learnmachinelearning,1483551242,True,"I went through the recent [facenet paper](https://arxiv.org/abs/1503.03832) that discussed harmonic triplet loss and harmonic embeddings. I understand the loss aspect of it, but I can't grasp what the harmonic embeddings mean? Can anyone ELI5?"
How does include machine learning in a browser extension?,1,3,False,False,False,learnmachinelearning,1483552802,True,"Can anyone point me to links detailing how to build a browser extension that makes use of a pre-made machine learning model? For example, say I develop a model in Python to detect faces in an image. How could I then use this model in building an extension to detect faces on a webpage?"
Recommendations for paid MOOC/Specialization (with certification if possible) for Machine Learning,1,1,False,False,False,learnmachinelearning,1483566653,True,"I work for an IT giant in India, and we can opt for a paid course (certification preferred) that the company will pay. I want to take a course in the field of machine learning to improve my knowledge. I am comfortable with the basic concepts of ML, and I think this is a good opportunity for me to invest in something serious. I considered the Udacity ML Nanodegree and a couple of ML specializations on Coursera (there are quite a few). What would be recommended?

Any help will be appreciated.

Thank you."
Looking for any opinions you may have on these free books on machine learning.,5,1,False,False,False,learnmachinelearning,1483567299,True,"I recently found [this list of free books on machine learning](https://github.com/josephmisiti/awesome-machine-learning/blob/master/books.md) and was curious to find out if anyone has used any of them and if they could suggest I read or avoid certain ones.

 I also will gladly take recommendations for any other books (payed or free), I just wanna see if I could learn something for cheap first :D

I should also say that I would prefer python books, but want to learn in anyway!"
Tutorial: Creating Data Visualizations in Matplotlib,0,2,False,False,False,learnmachinelearning,1483568647,False, 
Machine Learning Curriculum; The ultimate list,0,1,False,False,False,learnmachinelearning,1483576062,False, 
Help choosing math courses,3,2,False,False,False,learnmachinelearning,1483585423,True,"Hey all, a math institute in my city is offering a few 2 months long courses starting this week. I'm looking for something that will help me with Deep Learning, so I'm looking for a few suggestions.

The courses are:

-Markov Chains

-Combinatorics

-Fundamental Group

-Statistical Mechanics

-Number Theory

-Singularity Theory: Combinatorics, Topology and Algebra

-Functional Analysis

-Clifford Algebras, Spinors and Applications

-Lie Algebras

-Algebric Theory of Numbers

-Differential Topology

Any help is appreciated."
How do you know which Machine Learning Algorithm you should use?,11,15,False,False,False,learnmachinelearning,1483613356,True,I want to create a bot which learns from my actions on social media. But I am not sure which Algorithm I should use? Any help/examples would be appreciated. 
How do I apply Machine Learning at my company?,2,0,False,False,False,learnmachinelearning,1483638891,True,"I am working at an Automotive Company in IT. How do I apply machine learning at my company? I want to show some output, some kind of application or input/output based stuff."
Object Detection (Robotics),0,1,False,False,False,learnmachinelearning,1483642084,True,"I'm hoping to use a live camera feed focused on multiple robots that watches if they are going to hit each other, and if so, issues a ""stop"" command to the appropriate robots. I have no experience with machine learning, but I was wondering if a classifer trained to identify each robot would be a good / fun solution. I know there's a steep learning curve. Is this a reasonable 4 month project (~10 hours per week)?"
Short-ish Deep Learning Tutorial? [Please read comments],4,8,False,False,False,learnmachinelearning,1483664732,True,"I understand SVMs, Random Forests, and unsupervised learning. Is there a deep learning tutorial that I can get through in a few days?"
Can I use an ID as a feature?,3,1,False,False,False,learnmachinelearning,1483669527,True,"*I am very new to ML and I post this question in a different sub, but didn't get an answer.  I hope you can help!*

For my ML project, I have an array of motion sensors and I would like to use a history of those sensors as a feature. 

For example, I have motion sensors with IDs 1-3.  And these sensors are tripped in this order: 3, 1, 2.  So my history looks like this:  

Order | ID
---|---
1st | 3
2nd | 1
3rd | 2

The sensor's ID has nothing to do with its position (ex: 1 is not 'closer' and 3 is not 'further').  

**Is it possible to use the ID as a feature?  Will the algorithm be confused since the size of the number is meaningless?**

As an alternative, I could make ""seconds since tripped"" a feature and have a feature for each sensor.  But I was worried that this would make it more difficult to add more sensors later, as the number of features would change. (vs. always showing to ID of 1st 2nd and 3rd, which can be scaled to more than 3 sensors.)
"
Cross Validation with Neural Networks?,2,1,False,False,False,learnmachinelearning,1483670565,True,Does anyone have any resources related to this? tutorials related tensorflow.
It seems that Keras shows more overfitting results than Torch's one,4,4,False,False,False,learnmachinelearning,1483695347,True,"Hi, reddit!
I have been struggled to build a rnn-based structure for human action recognition from human joint skeleton data. Recently, I moved torch to keras (tensorflow backend), because it utilizes gpu automatically for me.

Anyway, with same structure including dropout or others, keras gives me more overfitting results than torch's one. For simple datasets like mnist or one-variant time series prediction data, keras works fine. But with more sophisticated data (Two-Person-Interaction Data and MSRAction3D Data), the results are seemed highly overfitted. For example, torch showed 0.9 and 0.8 classification accuracy for TPI data, but keras showed 1.0 and 0.6 classification accuracy. Any suggestion or have any similar symptoms with keras? Thanks. "
Is a VAE inherently tolerant (to a certain degree) to overfitting compared to a traditional AE? [x-post from /r/MLQuestions],0,1,False,False,False,learnmachinelearning,1483704838,True,"The overfitting might be calculated as a measure of reconstruction capability on testing data corrupted with artificial noise.

I have noticed that an AE with large bottleneck and large hidden layers is prone to this kind of overfitting producing the typical ""bouncing"" testing RMSE curve. Conversely, a VAE with exactly the same dimensionalities of bottleneck and hidden layers had its minimum testing error slightly higher than the traditional AE, but did not bounce. By the way, only the mu of the decoder has been taken into account to calculate the testing RMSE.

Any thoughts about this phenomenon? Might it be the stochastic sampling (reparameterization trick) that acts like regularizing noise? Or maybe is it the prior on the latent variables? Does this mean that the capacity of a VAE (expressed in terms of bottleneck size and hidden layers size) can be way larger than a traditional AE?
"
Need some basic Neural Network coding advice,3,2,False,False,False,learnmachinelearning,1483711925,True,[deleted]
A Multilayer Neural Net implementation in numpy to learn basics.,1,13,False,False,False,learnmachinelearning,1483717199,False, 
"NLP, python. Any way to get ""most similar"" words based only one one text?",6,5,False,False,False,learnmachinelearning,1483721036,True,"Hello!

I'm quite new to machine learning and NLP and I have the following question.

Word2Vec and some other tools are trained on big amounts of data and they are able to provide ""most similar"" words to almost any word and ""word algebra"" (as in an old example of ""king - man + woman = queen""). Is it possible to get something similar on a custom text?

For example I take one novel ~300k words. I tried to train word2vec on it, but it seems that this text is too small - for any term in vocab similarity was almost 100%. For example:

    >>>>model.most_similar('hundred')
    [('rather', 0.9997420310974121),
    ('future', 0.999687910079956),
    ('living', 0.9996793270111084),
    ('path', 0.999663770198822),
    ('offering', 0.9996454119682312),
    ('complete', 0.999616801738739),
    ('perhaps', 0.9996157884597778),
    ('rest', 0.9996148347854614),
    ('foreign', 0.999613344669342),
    ('passed', 0.999611496925354)]

So is there any way to get similar words based on a custom text? Or texts with millions of words are necessary for this?


**UPD**
By the way, if anyone is interested, I was able to find a similar functionality in NLTK.

    from nltk.text import Text
    #""text_tokens"" - is a list of tokens
    t = Text(text_tokens)
    t.similar(term)

Not very precise, but better than nothing"
"Scrum Saturday - Share your progress, your goals, and whatever is stopping you from achieving those goals!",2,8,False,False,False,learnmachinelearning,1483772597,True,"Let's have a scrum meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
My Learning Path for Machine Learning with Python,0,1,False,False,False,learnmachinelearning,1483773675,True,[removed]
Is a udacity nanodegree worth it?,9,10,False,False,False,learnmachinelearning,1483786652,True,"Hey everyone,
I currently study computer science and my next semester break will be arround 8 weeks long. As I don't want to wast all this time I was thinking about taking some online courses on AI and/or ML. I discovered th udacity nanodegrees and they look really polished and have some good reviews. However thy have the potential to become fairly expensive.


So I have so questions. Did anyone of you already take the nanodegrees for ML , if so how good are those?

How many months does the course take at least? It's like 200$/month with 50% chashback if you finish within in a year (I think).


I already took 2 courses on AI, algebra and calculus each and my programming skills are pretty good. Any estimationes on how long it would take me to finisch the nanodegree?


And my last question is, is a udacity nanodegree something that's worth it to show case on your resume?

Greetings
Panzki"
Is the plot of training/testing error vs model capacity conceptually related to plots of training/testing error vs epochs?,1,2,False,False,False,learnmachinelearning,1483804886,True,"Hi,

while I was reading Bengio's (et al.) book on deep learning, I was intrigued by the plot on page 115 describing the relationship between model complexity (for example width of layers in a neural network) and generalization. The plot is similar to [this one](https://qph.ec.quoracdn.net/main-qimg-6f4f40ac0fb1b33d17760d104f6c0864?convert_to_webp=true) and [this one](http://img.blog.csdn.net/20150926135014879).


I noticed that the shapes of the curves in that plot are very similar to those of training and validation/testing error vs epochs in a high-capacity model, such as [this one](https://i.stack.imgur.com/I7LiT.png).

Even if the two plots describe two different phenomena, I think it might be interesting to ponder about how they might be linked.

Is the concept of model capacity related to the concept of exposure (learning) of a model to data?

Maybe a model can *express* it's capacity trough learning, hence there might be a ""learned"" capacity that is high-bounded by the ""official"" capacity and is progressively increased trough iterations on the data. 

To prove this, just think at the learning in a neural network: maybe at the earliest epochs some units are still configured randomly and just in later epochs they end up being able to extract specific useful features. Hence, the ""learned"" capacity would be calculated as the amount of units that actually represent something useful. This amount is always a quantity that is inferior or equal to the total number of nodes in that neural network and increases over the epochs.

Would thinking in these terms make sense? What are your thoughts on this?"
Multi-agent Q learning?,1,1,False,False,False,learnmachinelearning,1483823432,True,"Hi there. I'm pretty new to machine learning, but I'm trying to create an AI to play board games. I came across the project [qlearning4k](https://github.com/farizrahman4u/qlearning4k) which seems like a way to generalize tensorflow Q learning on single player games.

Is there a way to adapt this approach to multiplayer games? Or is there a better option for this sort of thing?

Thanks!"
Learn Data Science and Machine Learning in 2017,0,1,False,False,False,learnmachinelearning,1483824914,False, 
11 of the best machine learning books,3,36,False,False,False,learnmachinelearning,1483829128,False, 
How to tell your RNN or LSTM information about your sequence?,4,1,False,False,False,learnmachinelearning,1483948356,True,"I was wondering how I could 'prime' a RNN with information about the sequence its about to take in. For instance if I wanted to tell the rnn the text is from a mystery novel as opposed to a romance novel. How would one go about doing that?

The only way I've thought to do it is by treating that info as the beginning of your sequence every time, and have the model learn it that way. But I'm not sure if that would break any rules as I have a very poor understanding of neural networks.

Any help would be much appreciated"
LSTM/RNN where time between inputs is variable.,2,2,False,False,False,learnmachinelearning,1483965412,True,"I have a dataset where i want to do classification. The data is sequential, where the sequential dimension is temporal. The temporal span between my inputs varies alot. That is, a sequence might look something like this.

Input1 <1sec> Input2 <5sec> Input3 <30sec> Input4 <10days> Input5 <10sec> Input5

That is, <> indicates the temporal time between inputs. When using LSTM for something like text, the implicit ""distance"" between inputs will not vary.

From a practial point of view, i see various ways of handling this. One could create a variable with ""time since last input"", or some variable ""total time"" such a UNIX time stamp. My question is however more so theoretical, as in is there any research into how modelling variable time between inputs in RNNs is done in the best way?

"
How to do feature selection using univariate filters in Caret?,2,3,False,False,False,learnmachinelearning,1483975212,True,"Hi all,

I recently started looking into the Caret package in R to wrap feature selection from univariate filters within cross-validation (this [Stack Exchange CrossValidated post](http://stats.stackexchange.com/questions/158238/feature-selection-classification-in-caret) does a good job explaining what I want to do):

1. Split data into *n* folds 
2. Select features using *n - 1* folds 
3. Train model on the same *n - 1* folds and feature subset from step 2
4. Evaluate performance on held-out fold
5. Repeat steps 2-4 over all folds

My main question: during this process, what does the `caretSBF` function actually do? I can't find it anywhere in the [caret online manual](http://topepo.github.io/caret/index.html) and in the [documentation](https://rdrr.io/cran/caret/man/caretSBF.html), it's listed along with `anovaScores` and `gamScores`. How is it different than those two functions? 

Any help would be appreciated."
Why are the softmax and softplus functions named this way?,5,1,False,False,False,learnmachinelearning,1483991931,True,"e.g. ""plus"" is a function that takes two arguments, whereas ""softplus"" is a function that takes one argument.  What is the motivation for using the prefix ""soft""?  And how are these functions related to the regular ""max"" and ""plus"" functions?"
Microsoft made a free introductory course for machine learning on edX. It's called 'Principles of Machine Learning',4,18,False,False,False,learnmachinelearning,1483995036,True,"https://courses.edx.org/courses/course-v1:Microsoft+DAT203.2x+1T2017/info

Is anyone enrolled from this sub? Is it a good starting point if you aren't interested in microsoft machine learning tools? I just skimmed it and I haven't see anything yet..."
Predicting success vs. failure of a certain action,0,0,False,False,False,learnmachinelearning,1483995769,True,"I'm new to machine learning and was presented with a problem at work that I think machine learning might be able to solve. We have a study with thousands of participants whom we need to call several times over the life of the study. What I want to do is to see if we can figure out better times and days of the week to call each participant based on our previous calls to that participant in particular as well as our calls in general. Or if calling doesn't work at all for those people, I want to know that so we can get in contact with them using an alternative method.

We log these calls in a table so we have a large table where each call is a row with:

The participant's unique ID

Success or failure of the call (i.e. did we reach the participant?)

Date of call

Time of call

I've started with the basics: graphing success rate by time of day and day of the week, seeing how many unique values we have for each participant (ranges between 2 and 40), etc. But I'm not quite sure where to go from here to actually setup some sort of machine learning process that results in what I need. I'm using R. Any help/guidance/examples would be appreciated.
"
Beginner - Udemy or Packt books?,4,2,False,False,False,learnmachinelearning,1484002061,True,"Hi!

I'd like to start exploring Machine Learning quite quickly. I've made a few projects in Python and I'd like to learn R. In March I'm starting new studies connected with Machine Learning.

I have 3 books available thanks to Packt free ebooks:
Python Machine Learning - Sebastian Raschka 
Building Machine Learning Systems with Python - Willi Richert, Luis Pedro Coelho
R Machine Learning Essentials - Michele Usuelli

Recently I also saw a bargain on Udemy (https://www.udemy.com/machinelearning/ - Machine Learning A-Z™: Hands-On Python & R In Data Science) with quite high revievs.

What can you recommed? What course is worthwhile? Maybe I should try another book/course?

Thank you for responses!"
"Post-Beginner courses that delve into making more complex machine learning systems (computer vision, genetic algorithms, text/image generation).",0,14,False,False,False,learnmachinelearning,1484031761,True,"I took an ML course in college that covered basically the same stuff as Andrew Ng's Coursera course (but also included a little more math and proofs than Ng's course). I just took Ng's course as a refresher and now I don't know where to go. 

I would like to learn to do cool stuff like make a model which learns to play a video game by itself. I find genetic algorithms really interesting but have zero clue how they work. For instance this video i keep coming back to these videos and wondering how it works.

[Genetic Algorithm Learns to fight](https://www.youtube.com/watch?v=u2t77mQmJiY)

[MarI/O neural network playing videogame](https://www.youtube.com/watch?v=qv6UVOQ0F44)

The other thing that interests me is computer vision and natural language stuff. The Recurrent Neural Network that learns to make [new magic cards by itself is really amazing to me](http://www.escapistmagazine.com/articles/view/scienceandtech/14276-Magic-The-Gathering-Cards-Made-by-Artificial-Intelligence).

But both the video game genetic algorithms and recurrent neural networks sound way to complicated. In addition i don't have an ultra-powerful computer to train a model on and i also don't know where to get the data to train.

Basically i am wondering how to learn these more advanced topics and how people come up with them."
How to concatenate filters in Inception module with pooling layer reducing output size?,0,1,False,False,False,learnmachinelearning,1484050105,True,I'm trying to do [this](https://hijeffery-prml.rhcloud.com/wp-content/uploads/2014/09/Inception-Module.png) but get stuck on how to concatenate the filters because the max pooling reduces height/width. How do I perform the pooling so that its output has the same size as the convolutions? Is zero padding expected?
"What's the 1 doing in this flow chart? (From Raschka's Python Machine Learning, Chapter 2 - Perceptron)",1,1,False,False,False,learnmachinelearning,1484062951,False, 
Scheduled Dropout?,0,2,False,False,False,learnmachinelearning,1484066354,True,"Could it be useful to reduce the dropout rate during training?  My logic was that a high dropout rate in the beginning of training would help the hidden layers learn good higher-order representations.  But then once the weights had reached a good region in parameter space, reducing the dropout rate would give the algorithm more information to work with to do its final tunings.  Has anybody tried this?"
"What constitutes ""long"" vs ""short"" text?",2,2,False,False,False,learnmachinelearning,1484069136,True,"In a number of the deep learning NLP papers, the consideration is specifically regarding ""short"" text - which I would clearly gather being tweets, typical forum posts, a few sentences.  But what is the threshold between ""long"" and ""short"" text - Would ten typical length sentences be considered long?  500 words?  

I realize that the answer is not going to be so cut and dry, but is there a typical rule of thumb that exists?"
What does the 1 mean in this flow chart (from Raschka's Python Machine Learning)?,0,1,False,False,False,learnmachinelearning,1484080802,False,[deleted]
What is the 1 for in this Perceptron flow chart mean?,4,2,False,False,False,learnmachinelearning,1484081423,True,"Hello r/learnmachinelearning

I'm currently trying to learn Linear Algebra and read Raschka's Python Machine Learning at the same time. In the book, in the second chapter, there is [this chart](http://imgur.com/RXI37Sd) showing the flow of the algorithm.

It is my understanding that *x* subscript 1 to *x* subscript m is each feature vector. I am basing this on an earlier part of the book which gave a quick rundown of linear algebra conventions where *x* had j subscript with j being an index for one of the features.

So, I think I understand what the circles with the *x*s are. I think *w* subscript m are the weights that each of the *x*s are dot-multiplied.

I get that after these are calculated the results go into the input and activation functions.

My problem is that I have no idea why there is a 1 in the top left of the diagram. Why is it being weighted? Where does the one come from?

Any help would be appreciated!"
"Gradient descent with univariate linear regression , parameters run off to become Nan?",0,1,False,False,False,learnmachinelearning,1484114523,True,"as the title suggests , can somebody help me understand why my code makes the nan's ? i assume it is because they become too large , but then can someone tell me how my implementation is wrong ? code with message --> http://pastebin.com/1KfZLAcy"
TIL (Today I Learned) Tuesday - Share something new that you have learned today!,0,6,False,False,False,learnmachinelearning,1484118202,True,"It doesn't matter if it's something trivial. As long as it's new information you didn't know until today, feel free to share!
"
ELI5 (Explain Like I am Five) Friday!,2,1,False,False,False,learnmachinelearning,1484118210,True,[removed]
Analysis of Dropout,2,14,False,False,False,learnmachinelearning,1484125829,False, 
Help getting started with parsing news stories,2,5,False,False,False,learnmachinelearning,1484178671,True,"Hi,

I am a web developer by skill, but am growing increasingly interested in trying out small bits of machine learning.

I currently run http://2017.sucks which is a collation of news articles over 2017 that ""suck"" (represent a bad event).

I am looking for assistance in where I should start looking in trying to get a system that can determine whether a news article is about a good, bad or neutral event.

What technologies and guides are there out there that would get me started in this direction?

Thanks,
Alex."
ML Workflow with cloud instances,2,3,False,False,False,learnmachinelearning,1484215959,True,"Hi, I'm currently implementing some proof-of-concept ML solutions (Tensorflow image retraining), and feel that I am wasting a lot of my time switching environments, as none quite do everything I would like.  

I currently have access to:

* Work PC (Win10, no GPU, running Anaconda)
* Laptop (Ubuntu, no GPU, running Anaconda)
* Azure NC6 instance (K80 GPU, CLI only, about 80hrs free per month with my MSDN licence)

I'm more comfortable working in code rather than notebooks, and have been editing in VS Code, running small samples and tutorials locally (slow!), and then uploading some to Azure (much quicker!).

However, I feel that I would be better if I could somehow edit the code locally in VS Code, but have my command prompt running in Azure, and the code automagically syncing between them.

Is there any way to do this, or does anyone have examples of their workflow that may help?

Thanks!
"
What algorithm would best fit my needs?,1,5,False,False,False,learnmachinelearning,1484229997,True,"I'm currently trying to find if there are any meaningful relationships between an email's subject line, and a variety of data points from the mailing.

I've been playing around with Weka, and I'm unsure which algorithm I should start with. Each instance has the following data points:

* subject line length
* total unique clicks
* total opens
* total sent
* percent open
* percent unique click
* percent click
* unsubscribes
* unsubscribes to open ratio

I've been using smaller data sets (~10k instances), however I have access to about 500k instances, if that affects the algorithm choice.

I was thinking of using a clustering algorithm, since the data set seems to fit the parameters for an unsupervised learning task.

I've also tried converting the subject line length to a nominal data set, then used Weka's J48 algorithm, but I had very poor accuracy.

Hypothesis: Using the data points above, there exists an optimal range of characters for a subject line to maximize one's open rate."
Can anyone explain what distributed here means ? I am new to ML. Im finding it hard to understand this thing.,3,1,False,False,False,learnmachinelearning,1484230506,False, 
Learn Random Forest for machine learning in R,3,8,False,False,False,learnmachinelearning,1484234885,False, 
Basic machine learning question,2,9,False,False,False,learnmachinelearning,1484238183,True,"I'm new to Machine Learning and am fairly unsure about the process and algorithms to use.  
  
The project I have started is as follows: I want to use a scientists rate of tumor growth, modeled graphically, paired with actual cancer patient info from the National Cancer Institutes Genomic Data Commons, to create an adjusted growth rate based on actual data. The end goal is for a user to be able to enter their age, gender, and cancer stage at diagnoses and have the program generate a growth rate based on the graph's info combined with the patient data.  

What would be the best way to go about this? Preferably using Java, as I am the most comfortable with it. Thanks. "
Network expansion on need!,0,1,False,False,False,learnmachinelearning,1484245485,True,"I have an idea but I am not sure if other mechanisms (which i might not be aware of) would already do a similar thing.
Lets assume we have a classification task on images;
 
Now after a few batches, when the first 1 or first 2 layers have settled to some sensible features, we could expand all the higher layers.


For example, I would add 100 more neurons to each layer, and have a special learning rate schedule for them. I would set their learning rate to some very high value - hoping they would almost immediately absorb **new** information - then decrease the learning rate over the next few mini-batches.

When the next expansion is scheduled (when the training nearly done with the current batch) I would first try to remove *""unnecessary""* (explaination below) neurons, and then just expand again; so new, relevant, information is retained and neurons that did not contribute to the improvement are removed.


Now, how to figure out which of the new neurons are ""unnecessary"": One could of course naively try to remove a single neuron and then re-evaluate all inputs of the last batch, checking if the average loss becomes worse...

Another idea would be to check each of the new neurons connections and search for another neuron in the old set that has the same input weights to the layer below. (basically check if we just made a copy of a neuron that already exists in the non-expanded set).

Would expanding a network while training make sense to quickly assimilate new information? If not, why?
"
RNN predicting constant values when given more data.,1,1,False,False,False,learnmachinelearning,1484263360,True,"I have some economic data - so very interdependent and complicated - from worldbank. It also has a lot of missing values. I normalized it so all features are approximately normal, zero centered and with variance of 1. I then filled the missing values with zeros - I tried some different ways of imputation, but that one works almost the best and is very simple. The data is 25 dimensions, 60 timesteps, and for ~200 countries. 

Then, I fit an RNN which would predict all 25 variables one step ahead. Here is the problem:
I first left out the years 2013-2016 as validation, and the model predicted very reasonable figures for 2013-2026, which trends and so on - [image here](http://imgur.com/eGera6D). Note that the first years there is no data, and this is how the zero-fill looks. I then fit the exact same model, only with no validation data - so with data up to 2016. This time the predictions were almost exactly constants - [see here](http://imgur.com/MWQTQX1). It seems the model is predicting values that are very close to zero. 

The code was exactly the same, I'll include it in a comment to not clutter the post. Why is this happening?"
How to proceed with Natural Language Processing in python ?,0,1,False,False,False,learnmachinelearning,1484273825,True,[removed]
Suggest me any good book on NLP ?,0,1,False,False,False,learnmachinelearning,1484275406,True,[removed]
"Ng's ML Coursera Class, Udacity's intro to ML course, or another MOOC?",12,8,False,False,False,learnmachinelearning,1484281510,True,"Hey everyone, I'm a recently fresh CS undergrad who just started work, but would like to move to a position in the field of ML. I have no prior ML course experience, but have taken university level math as well as Linear Algebra (although that was a while back). Would Ng's ML Course be the best starting point for me? Is there a possibility that some of the information from that class is outdated? Would love some input/recommendations! Thanks in advance!"
Kaggle PC Build,15,4,False,False,False,learnmachinelearning,1484286933,True,"Quick Question,

Do you guys recommend the 7700K or the 6850k for a deep learning pc build?

I don't plan on getting more than 2x 1080 TI's for it but I'm wondering if running both at PCIe-16X is worth it with the 6850k or not since it has 40x PCIe lanes. 

edit: does ram speed matter at all? would it be worth it getting 3200 mhz ram over 2400 mhz ram?"
Show-off Sunday!,0,2,False,False,False,learnmachinelearning,1484291337,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
Neural networks for Machine Learning in 5 mins by practice in R,0,1,False,False,False,learnmachinelearning,1484299110,False, 
Using Machine Learning to flag high-risk accounts?,7,7,False,False,False,learnmachinelearning,1484345319,True,"Let me preface the following by saying I have very little knowledge of the ins and outs of machine learning. 

I am working on a project that considers multiple variables to help predict whether an ID is ""high-risk"" that is, a high chance they will terminate their contract with us. 

Is this something machine learning could solve? I have read and watched a few videos on Support Vector Machines and they seem to be a possible solution, but again I don't know if I'm just force-fitting SVMs into my project. 

Assuming ML is the correct approach, how do I go about the system recognizing a high-risk, not yet terminated ID? Do I load the data of IDs that have already terminated and once it understands the variables that contribute it can then predict for the ones that aren't yet terminated? 

In my head I have this idea of the model being able to take all variables, spit out a single value indicating the likelihood of termination so that we can then target those to retain. 

Examples/key words to search for/YouTube links are all appreciated. My main problem at this point is I don't know what to even search for."
Recurrent Attention Model Paper Doubts,0,1,False,False,False,learnmachinelearning,1484374892,True,"Hi, 
I was reading the RAM paper.
I had the few following questions.
1.Does the rnn network output the action at ever point of time or at only last time instance say k(if we k sized memory for the rnn).I do understand that rnn network has to output the location at each step but does it also has to do that with the action(i am thinking in the object classification sense)
2.Why do we need to backpropogate through the glimpse network. To be honest i didn't quite understand the need for a glimpse network as neural network. What are we trying to learn there."
"Scrum Saturday - Share your progress, your goals, and whatever is stopping you from achieving those goals!",1,1,False,False,False,learnmachinelearning,1484377632,True,"Let's have a scrum meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
"How do I split my time amongst these topics: Statistical learning theory, Deep Learning and classic algorithms?",1,10,False,False,False,learnmachinelearning,1484400511,True,"I’ve completed the ML course on Coursera and I’ve read [Introduction to Machine Learning with Python](http://shop.oreilly.com/product/0636920030515.do)

I want to specialize in building text-mining applications. I’m building a news classifier app, and I’m unable to debug issues. So I figured I need a deeper understanding."
K-means Clustering.Open your R console and begin learning :),0,1,False,False,False,learnmachinelearning,1484402437,False, 
Is there an image classification CNN model that works on icon sized line drawings?,11,1,False,False,False,learnmachinelearning,1484406334,True,"I'm working on a project with a goal of classifying tens of thousands of small black and white icons.

I tried using TensorFlow to classify the icons, but it only seemed to work with photo-realistic images.  I'm new to computer vision and ML and wondering if there is an obvious solution.

examples similar to what I want to classify:

http://imgur.com/LkfHte6.png

"
Learning more about Machine Learning,3,1,False,False,False,learnmachinelearning,1484425995,True,[deleted]
"If I know how to implement a 1 layer neural net that can recognize digits in the MNIST database, is that enough to get me some kind of entry level job?",9,8,False,False,False,learnmachinelearning,1484435251,True,"I should say I've been a C#/Javascript developer for five years.

According to the [tensorflow tutorial](https://www.tensorflow.org/tutorials/mnist/beginners/) classifying digits is the Hello World of machine learning. I've been doing the Andrew NG course and I completely understand the math of a basic neural net that can classify digits in the MNIST.

I just realized that today and was like, wow. I haven't been planning on making a move towards ""data science"" until I was much more knowledgeable. But realizing you could put me on a desert island with a computer and a generator and enough gas to run it and the MNIST database that I could write a program from scratch to do it, I feel like I've made it beyond the level of total ignorance.

What would you do if you were me?"
Free and good Internеt dаting with manу girls. Мy rеаl advicе for you guуs,0,0,False,False,False,learnmachinelearning,1484462224,True,[removed]
What exactly does regularization do to neural network parameters?,10,6,False,False,False,learnmachinelearning,1484474141,True,"Does it set (some of) the weights equal to 1? Is that how it ""removes"" parameters? And what about biases, does it set those to zero?

Update/edit: You guys are wonderful, thank you!"
Which ML model for classification on sparse data?,1,1,False,False,False,learnmachinelearning,1484514033,True,[deleted]
Signed up for the January Start (Ng course),2,5,False,False,False,learnmachinelearning,1484535287,True,"So I signed up for the January Start course, anything I should be looking forward to?"
Looking for example code of back propagation of convolution layers in a neural network.,5,1,False,False,False,learnmachinelearning,1484543263,True,"I'm trying to really understand how back propagation works in a convolution layer.  I'd love to see some code that doesn't just dedicate training to an ml library.  something like what this book does with the fully connected layers would be great 

https://www.amazon.com/Make-Your-Own-Neural-Network-ebook/dp/B01EER4Z4G/ref=sr_1_1?s=books&ie=UTF8&qid=1484543240&sr=1-1&keywords=make+your+own+neural+network"
Best Tensorflow+Deep Learning tutorials on YouTube,2,22,False,False,False,learnmachinelearning,1484548190,False, 
27[M4F] Sеx-оn-thе-First-Dаte,1,0,False,False,False,learnmachinelearning,1484591195,True,[removed]
Logits: One Weird Trick to Predict Practically Everything,0,4,False,False,False,learnmachinelearning,1484594091,False, 
Explain this excerpt from Bishop's machine learning book,2,2,False,False,False,learnmachinelearning,1484600917,True,"I took this text from the chapter of Bayesian graphical model.

> ""More generally, if we have M discrete variables x1, . . . , xM, we can model
the joint distribution using a directed graph with one variable corresponding to each
node. The conditional distribution at each node is given by a set of nonnegative parameters
subject to the usual normalization constraint.""

What does this line say?

> "" The conditional distribution at each node is given by a set of nonnegative parameters
subject to the usual normalization constraint.""

Every node in the graphical model has conditional probability table which sums to one?"
Learning Artificial Intelligence: Frequently Asked Questions,15,16,False,False,False,learnmachinelearning,1484609433,False, 
Recommender system neural networks?,3,4,False,False,False,learnmachinelearning,1484647370,True,"What is the general approach when developing NN models for recommender systems?

Is there a big model, that works for all users, or the apps develop a model for each user?"
is this a useful course,2,3,False,False,False,learnmachinelearning,1484688177,True,"[shift key is broken on this laptop hence no decent formatting or punctuation]

hi machine learners, as someone interested in the topic, i was wondering if any of you thought this course package [https://shop.theawesomer.com/sales/the-complete-machine-learning-bundle] was of any value, or are the free resources out there good enough/more than enough, or are there much more productive ways i could spend my money/"
Creating abstract images with an untrained network,0,6,False,False,False,learnmachinelearning,1484691057,False, 
[FRЕE] Sex оn thе First Dаtе,0,1,False,False,False,learnmachinelearning,1484708513,True,[removed]
"Python, NLP. Need advice about gensim Phrases/Phraser.",3,5,False,False,False,learnmachinelearning,1484717719,True,"Asked this question on [/r/MLQuestions](https://www.reddit.com/r/MLQuestions), got no answer, maybe I'll have more luck here.


I need an advice about gensim phrases extraction.

I wrote the following code:

    sentence_stream = [[i for i in word_tokenize(sent) if i not in punctuations and i not in stop] for sent in sent_tokenize(text)]
    bigram = Phrases(sentence_stream, min_count=3, threshold=3, delimiter=b' ')
    tokens_ = bigram[sentence_stream]

It works well and very fast, but I receive the following warning:

    D:\Programs\Anaconda3\lib\site-packages\gensim\models\phrases.py:248: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class
  warnings.warn(""For a faster implementation, use the gensim.models.phrases.Phraser class"")

I tried to google examples of using Phraser, but found nothing (except description in documentation). Could you give me an example of using it? Or at least a way to hide these warnings.


**UPD** Solved, here is the result:

	sentence_stream = [[i for i in word_tokenize(sent) if i not in punctuations and i not in stop] for sent in sents]
	bigram = Phrases(sentence_stream, min_count=2, threshold=2, delimiter=b' ')
	bigram_phraser = Phraser(bigram)
	tokens_ = bigram_phraser[sentence_stream]
	trigram = Phrases(tokens_, min_count=2, threshold=2, delimiter=b' ')
	trigram_phraser = Phraser(trigram)
	tokens__ = trigram_phraser[tokens_]
	all_words = [i for j in tokens__ for i in j
	all_words

This takes a list of sentences as input and returns a list of tokens (bi- and trigrams)."
TIL (Today I Learned) Tuesday - Share something new that you have learned today!,1,3,False,False,False,learnmachinelearning,1484723277,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until today, feel free to share!
"
Any Graduate Level ML Textbook Recommendations,5,9,False,False,False,learnmachinelearning,1484725122,True,"Hey all-

I recently dove quite deep into machine learning and am looking for resources to take me beyond the undergraduate level. I've taken the Ng course as well as an undergraduate course in ML. I have a math background, so I'm very comfortable with proof-based approaches and the various types of math that I image pop-up at the graduate level (linear algebra, graph theory, statistics, etc). Also, I'd be comfortable coding in Java, c++, python, matlab/octave, or Mathematica, but have a preference towards python.

Given this background, I was wondering if anybody had recommendations for textbooks that may be used in a graduate level ML class? Given how new the field is- there unfortunately isn't many suggestions I could find by a simple Google search.

For example - I saw that these schools use these textbooks:

Princeton - Foundations of Machine Learning by Mehryar Mohri

CMU -  David Mackay's Information Theory, Inference, and Learning Algorithms   

UCI - Bishop's Pattern Recognition and Machine Learning

Berkeley - Gareth Jame's An Introduction to Statistical Learning with Applications in R"
13 Free Training Courses on Machine Learning and Artificial Intelligence,0,1,False,False,False,learnmachinelearning,1484726677,False, 
How to fine tune an image net model?,1,1,False,False,False,learnmachinelearning,1484726877,True,"Hi, I would like to fine tune one of the image net models for classifying pictures for different categories. Where can I  find tutorials for that and which DL library is the best for this task?"
Best courses for Data science and Machine Learning beginners from top universities,1,0,False,False,False,learnmachinelearning,1484736668,False,[deleted]
Where can I find a list of exercises in machine learning and their solutions?,3,9,False,False,False,learnmachinelearning,1484746629,True,"I have a lot of experience with python. Recently I decided to start learning machine learning, and I read some theory about it.

From experience, I learn best from exercises (preferably, for start, very simple ones) and their solutions. Could you recommend me a good place to find such?"
Is there any way to comfortable work with ~2Gb csv files in Python [suspicious test task in order to get a vacancy]?,16,6,False,False,False,learnmachinelearning,1484759453,True,"Hello!

I'm quite new to machine learning (several months of learning by myself) and currently looking for a job as data analyst/scientist. Today I was offered to do a test task in order to apply for a vacancy; it involves analysis with big csv files (300Mb and 2Gb).

My PC has ~8Gb RAM and it proved to be not enough to work with 2Gb file in pandas. I thought to try using sqlalchemy to create a local database, but I'll still have to load this data in memory to work with it.

Is there any way to work with such big files on a home PC (without servers)?

And to me this task seems to be suspicious: I need to analyse the data, give a solution to a question and prepare a presentation. The question is quite precise: the hypothesis is that company loses customers and revenue due to bad work of customer support, prove or disprove; if prove - show the losses in customers and revenue.
If the data was smaller, I'd think that this is simply a test task. But with this amount of data it seems to be a real work task, which a company wants to be done for free.

**UPD** I wrote a letter, explaining that the dataset seems too big for a test task. They acknowledged it and said that they will decrease the volume of data in the test task in several weeks."
[FRЕЕ JОIN] 100% Frеe-Sех-Dаting-Websitе. Our girls аre lооking for just frеe-sех. Меmbеrs аrе from all over thе world.,0,0,False,False,False,learnmachinelearning,1484825901,True,[removed]
Whether a student in photo's wearing a uniform.,2,1,False,False,False,learnmachinelearning,1484874089,True,"I am familiar with .NET programming but don't know much about machine learning.
Can somebody guide me to begin with this field.
I have a task to write a program to just determine whether a student in (front facing) photo wears a uniform.

I think what I need to learn are

1. Detect a face in photo and determine its size to crop & scale for better further comparison

2. Find the way distinguish shape & color of clothes in picture and train the AI

But I don't know exactly how those techniques are called.
Please recommend me resources, tools and steps to accomplish this.

Thank you all.

P.S. Languages other than .NET are fine for me."
Could machine learning be used to make a high resolution 3D scanner from a low resolution range finder?,2,7,False,False,False,learnmachinelearning,1484874244,True, 
Show-off Sunday!,1,7,False,False,False,learnmachinelearning,1484896147,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
(X-post from r/MLQuestions) Seeking help for my first NN Project on Keyword Identification,0,2,False,False,False,learnmachinelearning,1484916669,False, 
Seeking advise on chapters to skim on Neural Networks by Hatkins,5,6,False,False,False,learnmachinelearning,1484925438,True,"I am studying neural networks and I was suggested to read the classic by Hatkins on Neural Networks. However, it was really written before deep learning came onto the scene. Thus, was advised to consider it a introductory book on neural networks. 

My question is, I don't want to read the whole book back to front and was wondering if anyone familiar with the title or contents would be willing to suggest what the 'essential' chapters for this book might be? The table of contents are below:

* Chapter 1: Rosenblatts Perceptron 
* Chapter 2: Model Building through Regression 
* Chapter 3: The Least-Mean-Square Algorithm 
* Chapter 4: Multilayer Perceptron 
* Chapter 5: Kernel Methods and Radial Basis Function Networks 
* Chapter 6: Support Vector Machines 
* Chapter 7: Regularization Theory
* Chapter 8: Principal Component Analysis 
* Chapter 9: Self-Organizing Maps 
* Chapter 10: Information-Theoretic Learning Models 
* Chapter 11: Stochastic Methods Rooted in Statistical Mechanics 
* Chapter 12: Dynamic Programming 
* Chapter 13: Neurodynamics 
* Chapter 14: Bayesian Filtering for State Estimation of Dynamic Systems 
* Chapter 15: Dynamically Driven Recurrent Networks 


I am thinking chapters 1 through 4, and chapter 15 seem to be the most focused on neural networks and the other chapters seem focused on alternative machine learning approaches? 
Thoughts? "
27[М4F] Sex-оn-the-First-Datе,0,1,False,False,False,learnmachinelearning,1484936749,True,[removed]
Google's 43 Practical Rules of Machine Learning in Industry [Github Mirror],2,21,False,False,False,learnmachinelearning,1484971597,False, 
"Scrum Saturday - Share your progress, your goals, and whatever is stopping you from achieving those goals!",0,1,False,False,False,learnmachinelearning,1484982445,True,"Let's have a scrum meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
My real storу аbout 3 times with 3 diffеrent girls fоr guys,1,0,False,False,False,learnmachinelearning,1484988497,True,[removed]
Looking for regression problems,0,1,False,False,False,learnmachinelearning,1485007088,True,[deleted]
Validation-Set and Test-Set - Which is which?,1,1,False,False,False,learnmachinelearning,1485016775,True,"In every article or paper I read, Validation- and Test-Set are used differently. Is there a ""correct"" definition, where most of scientist agree on? It's very confusing to be honest..."
I put together a curated list of Machine Learning resources separated by category and difficulty level. Hover over Free Lectures.,5,57,False,False,False,learnmachinelearning,1485024238,False, 
"Sеx with 3 diffеrеnt girls, 3 times for 1 month. Sex Dating Wеbsitе which found оnly seх relаtions without money",0,0,False,False,False,learnmachinelearning,1485028647,True,[removed]
What does Deep Mind think of HTMs?,0,0,False,False,False,learnmachinelearning,1485032939,True, 
Introductory resources for application side of ML/AI?,0,2,False,False,False,learnmachinelearning,1485037146,True,"I am looking for a resource (papers/books) for the application side of ML/AI, not how to implement or do ML. Ideally, it should present the advantages and disadvantages of various machine learning approaches as well as potential future developments. The technical details are lower priority, but it should show enough to be able to understand the advantages/disadvantages for applications."
"CS 294 Deep Reinforcement Learning, Spring 2017 [follow @ r/berkeleydeeprlcourse]",1,2,False,False,False,learnmachinelearning,1485041725,False, 
Beginning of a PyTorch tutorial series: Classifying Names with a Character-Level RNN,0,3,False,False,False,learnmachinelearning,1485057687,False, 
How do you combine domain knowledge directly with a neural net?,0,1,False,False,False,learnmachinelearning,1485058616,True,"So, let's say you're building a recurrant neural net that looks at source code and you have the BNF for the language you're examining. How do you take advantage of this extra information, so the RNN doesn't have to spend training time learning the basic grammar, and can focus on higher-level stuff?

My first thought was looking at binary-encoded parse trees, but that seems like a pretty ugly approach."
why do we need training accuracy?,3,3,False,False,False,learnmachinelearning,1485058715,True,"Help me I'm confuse, what is training accuracy and why do we need it? Based on [here](http://community.rapidminer.com/t5/RapidMiner-Studio/what-is-training-accuracy-testing-accuracy/td-p/32499), training accuracy is when model used in the training data. From what I understand, we use testing data to test the model built on a new and unseen data (different from we use in training). But if we apply the model in training isn't the answer pretty obvious because the model have seen the data during training phase, and the accuracy will always be 100%? "
Keyword-based email categorization and recipient assignment,0,2,False,False,False,learnmachinelearning,1485061776,True,"I'm working on a class project, but I have minimal experience with machine learning.


(TL;DR I need a model that inputs an email body and determines who best to send it to from a dynamic list. It would need to support iterative training and a dynamic categories list)


Problem:
an email server receives IT Helpdesk-esc questions and is tasked with automatically forwarding the email to the correct technician (aka ""manager"") based on the contents of the email. For now, I'm focusing on the body and keywords therein.
I want it to work like this: a model that takes in the message, processes keywords, and returns a manager's email address.
At first, it would classify the address randomly. The model would iteratively train only when the email is re-forwarded by the recipient.

The tricky part:
The managers are constantly changing (I.e. Quitting and being hired), which means non-constant categories. Also, I want it to be able to catch on to new terms and use those for classification. (I.e. Be able to work for years down the road with emerging technologies)

So far:
I'm aware of bag-of-words and TF-IDF for keyword processing, but I don't know how to expand the corpus dynamically (a hashing trick, maybe?)

I'm also at a loss for a machine learning algorithm, which needs to:
- iteratively train
- accept changes in categories/classifications

(I'm using Weka, but might be switching over to TensorFlow or scikit-learn if they would serve me better)



Literally anything you can say to me would be awesome, especially if you could tell me how you would personally approach the problem."
"What the difference between ""evaluative feedback"" and ""instructive feedback """,2,2,False,False,False,learnmachinelearning,1485094950,True,"Recently, i am reading the book ""reinfocelearning learning An introduction"" Chapter 2, I am confuse about  ""evaluative feedback"" and ""instructive feedback "",how to understand it ?

""In their pure forms, these two kinds of feedback are quite distinct: evaluative feedback depends entirely on the action taken, whereas instructive feedback is independent of the action taken. There are also interesting intermediate cases in which evaluation and instruction blend together."""
Which book did you find helped most with your understanding of ML?,10,17,False,False,False,learnmachinelearning,1485103454,True,Question in title.
Recommendation: ML-Books for Math major with optimization background,4,3,False,False,False,learnmachinelearning,1485105402,True,Are there books around that introduces the key algorithms of Machine Learning including the mathematical background and ideas? I can find many resources for rather high level explanations for Machine Learning algorithms but I kind of want the technical background behind these.
Му sexy stоrу abоut frеe dаting wеbsite,0,1,False,False,False,learnmachinelearning,1485142281,True,[removed]
Are MOOCs/books sufficient for getting a job in applied ML?,1,1,False,False,False,learnmachinelearning,1485144910,True,[deleted]
How to Find the Distribution of Discrete Sequential Data?,4,3,False,False,False,learnmachinelearning,1485145868,True,"It's been a while since I did any work with stats and I'm having a tough time understanding how a sequence can be described by a distribution. 

It seems like each element could be described by a distribution. Then, that sequence of distributions itself can be described by a distribution. Is there a term for this?

Given a sequence of discrete values with a fixed length, how can I visualize or find out if the data can be described by a specific family of distributions such as Gaussian? 

"
Explanation of maximum likelihood,1,3,False,False,False,learnmachinelearning,1485160012,True,"While revisiting [maximum likelihood notes](http://cseweb.ucsd.edu/~elkan/250B/logreg.pdf) i got confused about maximum likelihood and probability density function.

It is saying that 

We assume that the examples are independent, so the probability of the set is
the product of the probabilities of the individual examples:

$$
f(x_1,...x_n;\theta)=\prod\limits_{j} f_\theta(x_j;\theta)\\
$$

The notation above makes us think of the distribution $\theta$ as fixed and the examples
$ x_j $ as unknown, or varying. However, we can think of the training data as fixed
and consider alternative parameter values. This is the point of view behind the
definition of the likelihood function:

$$L(\theta;x_1,...x_n) = f(x_1,...x_n;\theta)$$

Note that 

* if $ f(x; \theta) $ is a probability mass function, then the likelihood is always
less than one. 

* if $ f(x; \theta) $ is a probability density function, then the likelihood
can be greater than one, since densities can be greater than one.

Can someone explain if $ f(x; \theta)$  is a probability density function then how likelihood can be greater than one ? **

"
The internet seх dating wеbsite found 3 girls fоr Seх,0,0,False,False,False,learnmachinelearning,1485173980,True,[removed]
AI Toolbox - Searchable Directory of Open Source AI Libraries (xpost from r/machinelearning),2,12,False,False,False,learnmachinelearning,1485185790,False, 
Question regarding In/Out vectors in Neural Nets,0,0,False,False,False,learnmachinelearning,1485191158,True,[deleted]
Feature Engineering: Introduction to Geospatial Data with Python,0,9,False,False,False,learnmachinelearning,1485191843,False, 
What are the approaches to use Google Maps Timeline Data?,1,1,False,False,False,learnmachinelearning,1485210003,True,"I plan to work on using Machine Learning on my Google Maps Timeline Data. I have the locations(latitude,longitude,timestamp) ready in CSV format. What approach should I use to determine a pattern from the data. A pattern something like home to work and work to home.

I posted this on /r/MLQuestions but couldn't get any help. So thought of asking this here."
Free and well trusted Intеrnet seх dаting website with a lоt of girls. Мy rеal stоrу fоr guys,0,0,False,False,False,learnmachinelearning,1485215881,True,[removed]
"Learn TensorFlow and deep learning, without a Ph.D",2,40,False,False,False,learnmachinelearning,1485230473,False, 
Any resources where I can get voice samples recorded by different people?,1,3,False,False,False,learnmachinelearning,1485253624,True,I'm looking into problem of recognition by voice and want to practice getting and preparing data for classification. Later I want to actually run several algorithms to see how they work and how preparation workflow affects the results. But I have problem finding raw data on the internet. Can someone point me to the places where I can get samples if there are any?
How would you accomplish this with machine learning?,5,1,False,False,False,learnmachinelearning,1485274698,True,"Say you have a large database, where each object has a bunch of boolean properties.

Given two arbitrary objects in the database, assign the pair a rating of how similar they are, based on their boolean properties. 

Is there some approach/algorithm in machine learning that would suit this sort of problem? Apologies if this is a really nooby question."
Can you confirm my hypothesis on this youtube video?,7,1,False,False,False,learnmachinelearning,1485276523,True,"Hey guys,    
I am currently learning SOMs and I've stumbled across [this beautiful video](https://www.youtube.com/watch?v=zyYZuAQZWTM).    
I'd like you to criticize my hypothesis on what is happening:    
*There is a 32 x 32 grid. Each point (let's call these x) of this map has a two-dimensional weight vector. These weight vectors are uninitialised at the beginning. Iteratively, data points (let's call these y) appear on the map in one of the four colors. Whenever a 'y' appears, the (Euclidean) distance between itself and every weight vector of the 'x's' is computed. The minimum (when more than 1 are minimal, take randomly) is taken and the neighbor function is applied (the BMU and its neighbourhood is adjusted towards the 'y'). The next 'y' will compute its Euclidean distance between itself and the updated weight vectors of the 'x's'.*    
    
    

**Just to be safe: There is no classical dimensional reduction, am I right? The given 32 x 32 map has two dimensions (represented by the weight vectors of its 'x's') and the appearing data points, 'y', have only two dimensions as well.**"
Should LayerNorm be used before or after the activation function?,3,1,False,False,False,learnmachinelearning,1485277297,True,Should LayerNorm be used before or after the activation function?
"Explain this part, please.",5,1,False,False,False,learnmachinelearning,1485278819,True,"http://imgur.com/a/2USpU

This is from Bishop's machine learning book.

I don't understand the integration part, where integration removes the dependency.
This is a graphical model question.

EDIT: Got answer from Quora https://www.quora.com/ELI5-Can-someone-explain-this-question-based-on-Bayesian-Network-from-Bishop%E2%80%99s-Machine-Learning-Book"
Explanation Request esp last three lines.,0,1,False,False,False,learnmachinelearning,1485285454,True,"> If we are given a labelled training set, comprising inputs {x1, . . . , xN} together
with their class labels, then we can fit the naive Bayes model to the training data using maximum likelihood assuming that the data are drawn independently from
the model. The solution is obtained by fitting the model for each class separately
using the correspondingly labelled data. As an example, suppose that the probability
density within each class is chosen to be Gaussian. In this case, the naive Bayes
assumption then implies that the covariance matrix for each Gaussian is diagonal,
and the contours of constant density within each class will be axis-aligned ellipsoids.
The marginal density, however, is given by a superposition of diagonal Gaussians
(with weighting coefficients given by the class priors) and so will no longer factorize
with respect to its components.

I can't understand this part

> The marginal density, however, is given by a superposition of diagonal Gaussians
(with weighting coefficients given by the class priors) and so will no longer factorize
with respect to its components."
how to cleanup imagenet?,1,4,False,False,False,learnmachinelearning,1485290471,True,"I am using imagenet to train food classifier. The problem the I found is that a lot of images are  ""this photo is no longer availabe"" or other blank pictures. Is there anyway how could I remove these images from dataset with python?"
Introduction to Natural Language Processing,0,2,False,False,False,learnmachinelearning,1485295708,False, 
"What are ""exploratory"" ML techniques to use when confronted with a new dataset (and you know little about it)?",2,15,False,False,False,learnmachinelearning,1485302482,True,"I have dataset in dataframe form, shaped (2700, 155). Out of the 155 columns, only 4 are categorical values; the others are measurements.

What are some ""exploratory"" ML techniques to use when confronted with a dataset which you know little about? My mind races to t-SNE, or perhaps types of classification.

What other methods could I use to see ""what's there"" and help give me some direction?"
Looking for project guidance - detecting air planes in satellite imagery,0,1,False,False,False,learnmachinelearning,1485315108,True,"I'm interested in learning more about machine learning and decided on a project I wanted to tackle to jump into the subject. 

I'd like to develop a machine learning algorithm that can detect the locations of airplanes in an overhead satellite image. For example, the input would be an image of an [entire airport](http://imgur.com/COTWE2j) and the output would be the number of airplanes detected in the image and their pixel locations. 

This problem may have been solved before but I'd like to take a stab at my own solution to get some experience. 

For training data I can get many examples of planes from similar images. I'm using image data from [Planet](http://www.planet.com), so I can write a script that automatically pulls out small image chips centered on airport terminals, and then label the chips if they contain a plane or not. Example data would look like: http://imgur.com/N0bfR4G, http://imgur.com/Z6btN55,  and http://imgur.com/W9PCW6Y . 

My questions about training data are: 

- Would all the labeled training image chips need to be the same size? For example, would they all have to be, say, 30x30 pixels? Or could they all be in a range of sizes like 25x25 - 35x35 pixels. 

I ask this question because they only image classification work I'm familiar with now is the TensorFlow tutorial using the MNIST training data, where all the data were exactly 28x28 pixels, and size of the tensor depended on that. 

- What is the best method for gathering training data that is labeled 'not plane' - sample image chips that don't contain a plane at all. Would I just take random image chips out of the larger satellite image that I know don't contain any planes and use that? 

- Any insight into how much training data would be needed? Thousands of samples? Tens of thousands? 

Just beginning to start the data gathering part of this project, so any input would be helpful. Thanks!"
"Given a t-SNE plot, how can I infer the ""most correct"" labels? How does one understand its structure?",1,1,False,False,False,learnmachinelearning,1485316467,True,"Let's say I begin with an exceptionally large dataframe. Several of these columns are categorical labels. 

(As a more concrete example, let's imagine a group of students in a school district, pre-school to high-school). 

Now, I begin using sklearn and instantiate a t-SNE model, similar to the example here:

http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html

     import numpy as np
     from sklearn.manifold import TSNE
     X  # my data
     model = TSNE(n_components=2, random_state=0)
     np.set_printoptions(suppress=True)
     model.fit_transform(X) 

and then we plot this. The plot might look something like this: http://imgur.com/a/3amkJ

Here's my problem: with real datasets, after using t-sne to learn/cluster, you will have a number of ""clusters"". Then, using the categorical labels, I try to go through each of these, and try to figure out what structure the t-SNE plot is giving me. 

For our school example, I'd get the t-SNE output, then I would label the datapoints. (Let's assume that the clusters are actually representative of age/classroom, e.g. the first-graders group together, the second-graders are a group, etc.)

If I try to color this plot with ""grades"", I'll see that the grades does not really explain the structure of this plot. (Why? Because every class-level has students with As, Bs, Cs, etc.) Then I might try height...that does pretty good (because there's a correlation between short students--> pre-school, tall students --> high school seniors). 

How does one use a t-SNE plot to infer the ""most correct"" labels of the data? How does one use t-SNE plots to explain (and further explore) the plot structure? 
"
I don't know what I don't know. Help me get started in ML,3,4,False,False,False,learnmachinelearning,1485318981,True,"I am a mechanical engineer, and I've been thrust into project a where I'm working with many people on huge (and growing) data sets where we are trying to optimize for particular manufacturing parameters. The problem is we have no good way of processing this data. I know *of* machine learning, but to be honest, I don't really understand how it works...

A little bit about me: Mechanical engineer. I have the math and stats aspect of machine learning in hand, but with very little formal programming experience. I do consider myself a very good excel user (proficient in VBA with the help of my good friend google), and I have a fair bit of experience in Access and slowly picking up more SQL.

My question is this: is there a way to *use* machine learning without having to *learn* machine learning? Much like I can use MS Access without knowing SQL, is there a tool or program I can use to launch me into data processing without the prerequisite background?

I've tried the coursera Machine Learning course, I've looked into the Udacity ML ""nano degree"", but frankly, I'm already overworked and overwhelmed, and I can't imagine trying to fit that into my life. I work with a bunch of old farts that haven't even figured out that they can drag and drop attachements into email, and I **KNOW** there is a better way to process this data in front of me, but I don't have the time or resources to learn the skills myself.

So, is there a cheat sheet for skipping to the front of the line? Or is that too optimistic of me?"
TIL (Today I Learned) Tuesday - Share something new that you have learned today!,0,3,False,False,False,learnmachinelearning,1485328053,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until today, feel free to share!
"
Extracting Names using RNNs - PyData Singapore,0,3,False,False,False,learnmachinelearning,1485335041,False, 
Ubuntu or Arch Linux for Machine Learning ??,4,0,False,False,False,learnmachinelearning,1485356446,True,[deleted]
Orange: GUI based machine learning,6,14,False,False,False,learnmachinelearning,1485360074,False, 
Need advice on content-based and content-aware recommendation systems.,0,1,False,False,False,learnmachinelearning,1485429237,True,"Hello!
I'm studying recommender systems and have questions about content-based and content-aware recommenders.

1. Usually examples are the following: there is a database of movies, where genres are assigned to each movie and users rate the movies. Then item-profile and item-profile are created (usually with tf-idf or something similar) and predictions are made based on this. But what if there are several ""parameters"". For example there are restaurants with parameters: cuisine (where restaurants provide several types of cuisine and customers may like several types of cuisine) and a lot of parameters with discrete values - allow/prohibit smoking, parking, dress code and so on. How parameters with discrete values can be used - simply filtering hotels before/after prediction?

2. Suppose there is more information about customers - age, race, weight etc. What is a good way to use it? Use this information as features for classification?"
"LayerNorm before final activation, should it be avoided like for BatchNorm?",5,1,False,False,False,learnmachinelearning,1485432117,True,"For classification problems with deep neural nets, I've heard it's a bad idea to use BatchNorm before the final activation function (though I haven't fully grasped why yet) so I'm curious whether it's a bad idea to place a LayerNorm before the final output activation as well. Is it? It doesn't feel like it should be a problem because the normalization is done per sample, so the number of samples belonging to a class doesn't matter, does it?"
Question about Keras,4,2,False,False,False,learnmachinelearning,1485435206,True,"If I specify a batch-size of 32 while training a Keras model, does it load 32 examples, it makes predictions in parallel and runs backprop once with mini-batch gradient descent... Correct? 


Is this valid during test time? Can I load 32 data points and have Keras automatically make predictions in parallel on all of them? "
How to start with making a program learn how to play a simple game I created?,3,13,False,False,False,learnmachinelearning,1485441065,True,Let's say I have a very small simple game ( ala flappy bird) and I want to apply an algorithm like NEAT to make it learn how to play the game. How do I go about doing this? What data do I need to extract from the game to feed into the neural network? How do I extract that data? Write it into a file and have the neural network read from there? Use multiple threads? I've seen many implementations of NEAT on flappy bird but I don't know how to start making sense of it. 
Gradientzoo: get pre-trained models from here,0,6,False,False,False,learnmachinelearning,1485442877,False, 
Help me understand this training history!,7,3,False,False,False,learnmachinelearning,1485447863,True,"Hi r/learnmachinelearning !

 

I'm trying to use deep learning (*Keras*) for a classification problem. Currently my knowledge can be summarised as ""None"", as I'm toying around to see how deep learning works.

I'm running three very simple models (respectively one, two, three hidden layers) on an array of size [100000 x 15], where the goal is to guess the 15th variable (a boolean) out of the first 14 ones. Data is split 25/25/50 between training/validating/testing. 

What I have trouble understanding is the behaviour of my three-layers model. [Here is a plot](http://i.imgur.com/o2fUfNM.png) where I ran the learning 10 times and plotted the learning history. As you can see, the accuracy oscillates significantly between each epoch, until one point where it suddenly falls to 60-65% and stops changing. 

As a comparison, the two simpler models show ([1](http://i.imgur.com/ofIQc8n.png), [2](http://i.imgur.com/KnUGZAj.png)) a much ""flatter"" history: no oscillation, no big change.

The only idea I have is that I'm facing over-fitting ... but I'm far from being confident on that.

 

If that helps, [here](http://i.imgur.com/8oAsdzg.png) are the three very simple models I'm using."
First AI course,3,6,False,False,False,learnmachinelearning,1485460746,True,"Hello, I am planning to take my first course in AI to explore the field.

I am stuck between 3 choices -
* UC Berkeley's CS188 by Dan Klein and Peter Abbeel
* MIT OCW's 6.034 by Patrick Henry Winston, and 
* edX's new course as a part of their MicroMasters program ColumbiaX's CSMM.101x by Ansaf Salleb-Aouissi. 

Almost everywhere I read says the Berkeley's is the best, while I have also read reviews saying MIT's is pretty good too. The edX's is good in regard that it just began this month, so I can follow along with the assignments as well. I don't know if I sound very confused, but that's probably because I am. Could anyone please guide me?

Any help will be appreciated. Thank you in advance."
MLP Implementation for MNIST,0,2,False,False,False,learnmachinelearning,1485464498,True,[deleted]
Show-off Sunday!,3,7,False,False,False,learnmachinelearning,1485500940,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
Му gооd lifе stоrу. I didn’t undеrstаnd thаt wеbsitе саn hеlр mе tо find thе truе girl fоr sех,0,0,False,False,False,learnmachinelearning,1485508881,True,[removed]
Looking for a critique/feedback to my ML approach to this finance problem!,0,3,False,False,False,learnmachinelearning,1485540765,True,"Hi Everyone,

I know that this is relatively simple probably, but I am still relatively new, so I am looking for some feedback on how to best tackle this problem using ml/scikit-learn. This is my first ""real life"" usage case. Here's the issue:

I have a ton of invoices created and a ton of payments to a bank account. I need to match payments made to the bank account to the invoices generated. My features are:

Invoice: Id#, date, description, dollar amount
Payments: PaymentID, date, description, dollar amount

Payments don't always reference an invoice number in a description, and right now I have to do all matching manually.

I have a dataset of 4000 or so payments matched to invoices to train. This is my approach, would this be the ""right way"" of tackling this problem? THANK YOU!

1. tf-idf vectorize the text data for payment description, invoice description etc. 
2. Split the data into 70/30 for training and testing after randomizing my data 
3. Should I use something like PCA or any other feature scaling here?
3. Pass the data into an algorithm SVM/NB/ DT etc and then...
4. Evaluate performance (F1 score etc) using sklearn.metrics. Once settled on an algorithm, refine using gridsearch CV etc.

Anyways, this is my first foray into it after taking some MOOCs. Any feedback you have is GREATLY  appreciated. 

Thanks!"
Machine Learning for Everyone - Part 2: Spotting anomalous data,0,8,False,False,False,learnmachinelearning,1485552904,False, 
3 timеs with diffеrеnt girls оr mу rеаl stоrу hоw I fоund girls fоr 1 mоnth,0,1,False,False,False,learnmachinelearning,1485553937,True,[removed]
[Project] Clickbait detection using Deep Learning (Github); X-post from /r/MachineLearning,3,16,False,False,False,learnmachinelearning,1485578360,False, 
"Scrum Saturday - Share your progress, your goals, and whatever is stopping you from achieving those goals!",2,6,False,False,False,learnmachinelearning,1485587205,True,"Let's have a scrum meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
"Fuck with 3 girls, 3 times for month. Site which helped to find only sex relation without charge",0,0,False,False,False,learnmachinelearning,1485600524,True,[removed]
Foundations of Machine Learning Boot Camp by Simons Institute with lectures on machine learning and deep learning.,0,20,False,False,False,learnmachinelearning,1485606804,False, 
Deep Learning on Heroku tutorial (Iris classification),0,3,False,False,False,learnmachinelearning,1485620553,False, 
What should I learn to solve this problem?,4,4,False,False,False,learnmachinelearning,1485633206,True,"Here's what I have:

* However much understanding of statistics comes with an engineering undergrad.
* Decent programming skills.
* Basic understanding of iterative problem solving.

Here's the problem I want to solve:

A common issue in acoustics is predicting the transmission loss (TL) of a partition (wall) design. There is currently [a popular program named Insul](http://www.insul.co.nz/) that does this *analytically*, based on the research done on this topic in the last few decades. Insul works *pretty good*, but it does have some real limitations that require the user to make a lot of assumptions. I think I can do better.

A partition is made up of one to many components. It might be as simple as a single layer of wood or wallboard, or it might be complex with as many as 3 different stud rows and 10 layers of wallboard, wood, plus special acoustical components like resilient mounts and layers of special glue.

Each component will have a type, and then by type there'll be properties. For example, a substrate layer, like wood or wallboard, will have weight and stiffness, while a stud-row will have a layout and a thickness.

There are test reports available for many different partitions, but certainly not all. And there are test reports available for partitions that include every component I'd want to be able to model.

What I'd like to build is a system that will predict the performance with any realistic combination and arrangement of components. I can train it with hundreds of test reports that will collectively include every possible component in at least a few partition configuration.

So what do I need to learn to be able to solve this problem?"
Looking for a mentor/tutor,4,2,False,False,False,learnmachinelearning,1485633222,True,I have good programming experience but I'm completely new to ML so I don't really know anything beyond the most basic terminology. I am looking for a kind soul that would be willing to spend a few hours per week providing some critique and guidance. I have a specific problem that I want to tackle but I feel like I know way too little about ML to even know where to begin with this.
How can I use a trained Tensorflow model to predict from a C# application on Windows?,4,5,False,False,False,learnmachinelearning,1485637342,True,"So I have a trained tensorflow model and I would like to use it in my C# application on Windows.

How can I do that? For example the console application would ask for the image filepath and than the script would process it and return the prediction to the C# application."
Let’s make a DQN: Game bot in OpenAI's Gym,1,2,False,False,False,learnmachinelearning,1485652151,False, 
"I’ve registered for many of sex dating, but they asled me money for using. I’ve found free and well trusted dating website which helped me to find girls for sex",0,1,False,False,False,learnmachinelearning,1485652193,True,[removed]
Нi,0,0,False,False,False,learnmachinelearning,1485664101,True,[removed]
Machine Learning with Python course 92% off ($49) - Worth it?,1,1,False,False,False,learnmachinelearning,1485669896,False, 
Learnt HOG and SVM. Tried implementing it with OpenCV and Tensorflow.,2,0,False,False,False,learnmachinelearning,1485704684,False, 
Looking for help with youtube likes prediction?,3,4,False,False,False,learnmachinelearning,1485706551,True,"HI, I'm fairly new to machine learning and I'm trying to predict the number of likes a youtube video receives based on around 20 or so numerical and other parameters available through the youtube API.  Could you point me into the right direction for the type of techniques that I should use for this or any other helpful reources/ projects. The data source can be fairly large as the number of youtube videos."
1_mоnth_I’m_using_this_Frее_аnd_gооd_dаting_sitе__–_I’vе_fоund_3_diffеtеnt_girls_whо_аgrееd_fоr_sех_with_mе_3_timеs,0,0,False,False,False,learnmachinelearning,1485722968,True,[removed]
Not sure if naivety is causing backprop problem,7,1,False,False,False,learnmachinelearning,1485773658,True,"So I'm training a simple DNN which I can choose to have n layers and a user specified number of neurons in each layer. I use pure backprop with no momentum or stochastic variation because I want to get  simple implementation working first.  

So what I'm doing is feeding my network weather data, like ground temperature, rain, radiance and I ask it to output what it thinks the air temperature should be. To do this I try classification.  
I have an target set of temperatures and say there are m neurons in the last layer. Each neuron represents a ""range of temperature"" evenly spaced between Tmin and Tmax. Hence the number of neurons in the last layer determines resolution. The program finds out which neuron (temperature range) is the closest to the correct temperature and sets the target to be unity for that neuron while setting the target to be zero for the rest. This idea is what came naturally to me, but maybe it is flawed because my network mostly only finds that the same one neuron matches each input example.

Is there an approach to classification that I should be taking instead? Also I will provide data and Python code if necessary."
Frее_Intеrnеt_sех_dаting_wеbsitе_with_mаnу_girls,0,0,False,False,False,learnmachinelearning,1485776096,True,[removed]
Question about estimating classification error in R,0,1,False,False,False,learnmachinelearning,1485788418,True,"Hello - I just started a masters program in business analytics and am currently taking a class on machine learning. I have a couple questions about estimating error in the R software.

We are learning how to use various classification algorithms including the J48 decision tree, K-NN, and Naive Bayes. 

Specifically, using the J48 decision tree algorithm (using the 'caret' package), our instructor wants us to experiment estimating error. The two methods he wants us to use for checking model error are the following:

* Create a data partition to create a Test and Train subset
* Use cross validation and bootstrap. 

My question is: These are both separate ways to test for error, correct? You would not use these both together would you? Our instructor has not been quite clear on this yet, and I have not had a chance to ask questions. 

The second part of the assignment is to then tweak the confidence parameters of the J48 decision tree. I think I understand this aspect. 

Finally, he wants us to try estimating the error and tweaking parameters for a KNN and Naive Bayes (also using the 'caret' package). However, he has not given us any info on how to test for error or tweak parameter in either of these algorithms.

Any help is greatly appreciated. Even just getting a dialogue going would probably help me out. There are a lot of things I know that I don't know yet.

Cheers."
GitHub - DenseInL2/SimpleXOR : For understanding basics of neural network,1,4,False,False,False,learnmachinelearning,1485788657,False, 
Local vs Cloud/Hardware Advice,0,1,False,False,False,learnmachinelearning,1485800211,True,[removed]
Learning about Machine Learning/Artificial Intelligence,2,5,False,False,False,learnmachinelearning,1485808509,True,"Hey, guys. I'm a college student and I'm taking my masters in computer engineering, and I wanted to learn more about ML and AI. I have experience in lots of languages like Java, C, C++, Python, Web, ... So I wanted books/websites that teach us what it is and give us practical examples so I can train, I would rather Python but any language is Ok. Thanks in advance
"
Difference between exogenous/endogenous variables vs independent/dependent variables in a causal system?,0,1,False,False,False,learnmachinelearning,1485817863,True,[deleted]
ML for web scraped e-commerce data,7,5,False,False,False,learnmachinelearning,1485820783,True,"I have several data sets that include product level transaction data for a large e-commerce website collected through web scraping. I have data including item IDs, titles, prices, quantity sold of the item, the item's category, and pretty much anything else that you might find on a product listing on an e-commerce website.

The data is scraped on a regular basis such that I have a time series for the items.

I'd like to use machine learning to build a data product using this data and would be interested in hearing what ideas this group may have."
Build an Image Recognition Web App w/Pre-Trained VGG-16,0,3,False,False,False,learnmachinelearning,1485829312,False, 
Weekly email newsletter with TensorFlow tutorials and articles,0,9,False,False,False,learnmachinelearning,1485830192,False, 
Му rеаl ехреriеnсе fоr уоu guуs,0,0,False,False,False,learnmachinelearning,1485857975,True,[removed]
Is it viable to use CNN on a small dataset(~800 images/ class)?,6,1,False,False,False,learnmachinelearning,1485861254,True,"Hi, 
I am working on detecting specific facial features and classifying the images with 1 or 0 labels. Each class consists of ~ 800 images augmented with random rotation and translation. I am thinking of using VGG16 Faces and fine-tuning it for my task. 


Can this solved using a deep learning model or should I implement SVM for classification. 

Thanks."
TensorFLow classification wothout training data?,6,1,False,False,False,learnmachinelearning,1485870069,True,"Hi,
I have a (propably naive) question about TensorFlow.
Is it possible to use TensorFlow as classifier without prior knowledge about the identity of the class of the individual datapoints? I have a complex 2D dataset that I basically want to cluster into n classes without generating a training set? I'd asume the optimization step during learning needs some kind of feedback from the training set to evaluate accuracy. I was just wondering if there is a way around that by looking e.g. for self similiarity within the clusters?"
Getting into a top MS program,0,1,False,False,False,learnmachinelearning,1485885058,True,[deleted]
Introduction to Correlation,0,1,False,False,False,learnmachinelearning,1485909544,False, 
Cost function for neural networks,3,3,False,False,False,learnmachinelearning,1485910645,True,"It is recommended that one use a cross entropy loss as cost function when softmax function is used as the activation function in a neural network, instead of the mean squared error.

We observed a increased speed in learning (plus a slight increase in accuracy)  when we changed the cost function to cross entropy loss.

Why is it better?"
TIL (Today I Learned) Tuesday - Share something new that you have learned today!,2,7,False,False,False,learnmachinelearning,1485932848,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until today, feel free to share!
"
То mу mind,0,0,False,False,False,learnmachinelearning,1485938910,True,[removed]
Weights initialisation for NN and bootstrap,1,2,False,False,False,learnmachinelearning,1485942341,True,"Hi, I'm relatively new to neural networks, and I'm struggling with the generalization of the winning model :

After having constructed and chosen a neural network through validation and test samples (with other algorithm families), I would like to estimate the performances of the model with bootstrap samples (and get an AUC range with 95% confidence for example). But for each bootstrap sample, I can't decide whether I should keep the random seed to set the initial weights found when I was constructing the NN, find a new local optimum (thus new weight initialization), or let randomness operate magically...

More generally, are the initial random parameters of any converging algorithm part and parcel of the model ? I'm also looking for some literature about that subject."
Question about cross validation,8,3,False,False,False,learnmachinelearning,1485972230,True,"How does cross validation reflect the accuracy of initial training/test splits?

I'm assuming at first the model is trained a certain test/train split, then that same model is trained on another train/test split.  So wouldn't the model have a higher accuracy inherently on the second train/test split, and even higher accuracy as you train on further train/test splits?

So what purpose does averaging the accuracy of these train/test splits serve?"
Could a NN compile source code into machine code?,10,1,False,False,False,learnmachinelearning,1485973800,True,"So... this is a question that I've been pondering, I'm new to ML stuff.  I have no idea how to research any of this, unless I say... take 4 years out of my life and just read everything until I stumble upon the information.  I'm hoping to start a bit of a conversation, Imagine we're just drinking a few beers, and you want me to learn ML...

So, onto compiling source code.

The input and output seem very deterministic.  Let's say for fixed set of command line arguments, use something like libTCC for x86 and 1000 sample functions and we just feed code in and expect machine code out

This thesis lead me down a thought path, and now I'm just super curious..

I compared this very deterministic input -> output  to that of logic gates.

I can pass in a number for function to use, the two inputs, and pass fail it on the wrong output. for that function category....

    def logic_gate(type, a, b):
        ...

So I know this could get trained, and I'm assuming after training that it would be 100% correct forver.  A nice logic_gate *black box*.

In order for this to work - I'd assume you'd have to have at least a 1:1 representation within the neural network of... I don't know what to call it... ""logical elements""....  for each effective ""transistor"" you'd have to represent that choice (or mathematical function) in at least one element in your network.  (right?)

And if that's true, (I'm assuming) - How would you choose the NN size?

And that would be for IDEAL networks!

Would you need more nodes to over-represent the logic elements within NN, at a higher ratio like 2:1 or 10:1 to train it and get output that doesn't get stuck in local minimums or local maximums while training.
Or maybe I'm misunderstanding the training step and this small contrived example will converge in an idyllic network quickly, if it has the right number of nodes because it's not a ""generational evolutionary model"", it's a back calculated model driven from math back up the series of nodes)

OKAY, so what is my above paragraph called, when talking about NN ... and problem complexity to we consider the 'complexity' at all or is it something more like 'we just pick a number and increase it if the model isn't getting trained appropriately)

Because if we underrepresent the number of logical elements then it seems obvious to me that some information decimation will take place.  And our black box won't be accurate to the function tested

... okay so that round about brings me back to this NN compiler question...  If it is possible and reasonable, then how do we start to cut up the input and turn it into vectors for the system to be trained by.  AND more interestingly could... we do that thing that google translate does and  code -> (code idea) -> (machine code compiler)  where the compiler is various outputs.

And then NEXT, could we possibly use a NN to decompile source code for security research?

phew, thank you for your time."
Question about contextual usage between continuous and discrete action spaces in reinforcement learning,0,3,False,False,False,learnmachinelearning,1485977949,True,"Hi everyone, I'm a Computer Science student working on implementing an agent to complete a wide variety of web browser tasks on [Mini World of Bits](http://alpha.openai.com/miniwob/index.html). Our group is looking into various approaches on how the agent would take actions and assess the discounted future reward function. However, due to the nature of the environments, we are unsure whether or not we should take a discrete or continuous approach to the action spaces.

Regarding the continuous approach, we've read a few papers (notably [this one](https://arxiv.org/pdf/1509.02971v5.pdf) ) which mention the usage of DDPG (Deep Deterministic Policy Gradient, a combination of the actor-critic method from DQN and DPG) which can learn competitive policies for tasks using low-dimensional observations (e.g. cartesian coordinates).

However, we are also unsure whether it would be viable to implement this agent using a discrete action space, e.g perform discrete actions of moving the cursor left by a pixel, clicking the mouse, and then assessing reward.

Just wondering if anyone with more expertise (we are quite new to this area) could give an insight into which methodology would be appropriate to implement the agent in this case? Thanks!"
Соuld уоu hеlр mе fоr а sесоnd?,0,2,False,False,False,learnmachinelearning,1485998106,True,[removed]
First time using anaconda for a machine learning course and need to use Scikit-learn for a question.. how?,3,1,False,False,False,learnmachinelearning,1486008104,True,"I know this is a stupid-person question.. but I missed the first couple weeks of class so I don't know anyone in it yet and the prof takes days to answer an email.. how do I use Scikit-learn? I have anaconda navigator and we've been using Jupyter notebooks for the assignments, is Scikit-learn accessible from Jupyter? Or do I find it in the navigator app? I have a very slow old Mac and I've only used Matlab and octave before so I'm used to opening the app and have a GUI in front of me to work with. 

Any tips would be appreciated, thanks "
Machine learning basics?,4,11,False,False,False,learnmachinelearning,1486032158,True,"Hello, i am currently looking for a tutorial/video-course about the basics of machine-learning. BUT WAIT there is a catch... I'd like to know the basics, and the thoughts behind the procedures, and not just *mindlessly* learn a framework. 

Maybe there are courses/pages explaining it in this way, but so far i haven't seen any.

If you do know a great source, please do share it with me!

(BTW the problem with learning a certain framework of ML at the very beginning is that i understand that i can write a *really* simple ML program with it, but i don't *exactly* know what does procedures do....)

(Also as a sidenote: I'm more interested in unsupervised learning than in supervised learning)
"
If уоu аsk mе,0,0,False,False,False,learnmachinelearning,1486032553,True,[removed]
Why does ResNet modules have two layers per skip connection and not just one?,2,4,False,False,False,learnmachinelearning,1486042799,True,"[Schematic](http://imgur.com/a/CjmFw).

How come there are two weight layers per skip connection instead of one each? Is there a particular reasoning behind this? Would it work as effectively to add the respective output after each layer (like a RNN)? It feels like the two-layer stacking is inspired by VGG topologies where there's always two convolution layers before each pooling. Why do people do that?"
Looking for a comprehensive resource on Restricted Boltzmann Machines,2,3,False,False,False,learnmachinelearning,1486047663,True,"Hi,

I am learning Restricted Boltzmann Machines. Unfortunately what I am finding online, and even in the books I am reading ([Murphy's ML Probabilistic Perspective](https://www.cs.ubc.ca/~murphyk/MLbook/)) the topic is treated in a maximum of 20 pages. Some tutorial and articles cover the subject by different perspectives, and scientific articles are a bit too technical and sometimes of dubious usefulness. Do you have any suggestion for a comprehensive text on Restricted Boltzmann Machines?"
Make prediction with Tf with a model made in Keras,0,5,False,False,False,learnmachinelearning,1486054984,True,"I trained a model in Keras with Tensorflow backend and now I would like to use it.
Can I use **ONLY** Tensorflow  to load the model and to predict?

(like in Keras, `predict_proba`)"
"Cutoff level for an adaptive threshold set dependent on test set performance, validity of results?",0,1,False,False,False,learnmachinelearning,1486080870,True,"For a binary classification problem on aerial photography, suppose the decision function were an adaptive threshold which received information from the test set (i.e. the threshold was altered multiple times until the test set performance was high). Would the results on the test set then be invalid?

The problem is that ""validity"" gets muddied a bit when you compare to other methods (e.g. SVM) where hyperparameters are tuned contingent on test set performance. I'm specifically looking for a concise explanation of why the results do or do not become invalid in the adaptive threshold case vs. the SVM case, for the sake of explaining this concept to others."
Show-off Sunday!,0,1,False,False,False,learnmachinelearning,1486105695,True,[removed]
[META-DISCUSSION] How about making the sub itself an ML project?,3,4,False,False,False,learnmachinelearning,1486112994,True,"The idea is pretty simple. There are a number of moderation tasks and sub features that could benefit from ML (and NLP). I was thinking you could pick a specific tool or task and have subreddit members collaborate on implementing it. 

Some possible subreddit projects.

* Automatic post tagging
* Automatic spam filtering
* Automatic answer suggestions for FAQ 

Some of these things probably already exist, but it would be cool to do r/learnmachinelearning specific implementations for learning. 

What do we think?"
Can I аsk а favour?,0,0,False,False,False,learnmachinelearning,1486113122,True,[removed]
Using same dataset for both training and validation,0,1,False,False,False,learnmachinelearning,1486149622,True,[deleted]
Regression Parameters for Fantasy Hockey,4,2,False,False,False,learnmachinelearning,1486154683,True,"I'm trying to use Linear Regression on a set of fantasy hockey data for individual players and I'm not sure if I need to eliminate some parameters for this to work.  I have Date, PlayerID, TeamID, Home/Away, OppTeamID, and Line#.  I'm trying to predict fantasy points based of off these but I know PlayerID, TeamID and OppTeamID aren't linear as I'm just numbering them 1-numPlayers and 1-numTeams respectively. If I want to use these data points should I use another method besides linear regression? If I stick with linear regression what are my options?

"
Can You Help?,0,1,False,False,False,learnmachinelearning,1486170144,True,[removed]
"Scrum Saturday - Share your progress, your goals, and whatever is stopping you from achieving those goals!",1,4,False,False,False,learnmachinelearning,1486191979,True,"Let's have a scrum meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
Hadamard product in OpenBLAS,1,2,False,False,False,learnmachinelearning,1486208979,True,"Does it exist?
In MKL its v*mul, in cuBLAS its SHAD/DHAD, I think...

http://netlib.org/blas/"
From my point of view,0,0,False,False,False,learnmachinelearning,1486215532,True,[removed]
This is a really basic neural network for linear regression trying to learn the simplest function possible and yet something's going wrong. Could someone take a look?,10,3,False,False,False,learnmachinelearning,1486239010,True,"EDIT: **SOLVED!** Thanks for the help.

This program is just generating a two-column list of random numbers and asking the simple one-hidden-layer neural network to learn how to add the two numbers in each row together. Both the random numbers and the ground truth (easily calculated) are passed to the Feed_Forward model, the model is trained and then it's asked to make a prediction on a different set of random numbers.

But the problem is that the loss is increasing rather than decreasing and for the life of me I can't find the bug that's causing it. If you have any idea I'd love to hear it. Thanks.

    import numpy as np
	import matplotlib.pyplot as plt

	class FullyConnected():

		# input and output should be numpy arrays
		def __init__(self, input, output):
			self.input = input
			self.M, self.N = input.shape
			__, self.out_size = np.atleast_2d(output).T.shape
			self.hidden_size = 10
			self.input2 = None
			self.weights1 = None
			self.weights2 = None
			self.bias1 = None
			self.bias2 = None
			self.ground_truth = np.atleast_2d(output).T
			self.predictions = None
			self.loss = None
			self.epochs = 0
			self.learning_rate = .0001
			self.initialize()

		def initialize(self):

			self.weights1 = (np.random.randn(self.N, self.hidden_size))
			self.bias1 = np.zeros((self.hidden_size, 1))
			self.weights2 = (np.random.randn(self.hidden_size, self.out_size))
			self.bias2 = np.zeros((self.out_size, 1))


		def train(self, passes):

			while (self.epochs < passes):

				# forward pass
				self.forward_pass()
				# calculate loss
				self.calculate_loss()
				# backward pass
				self.backward_pass()


		def forward_pass(self):

			# Hidden layer
			self.input2 = np.dot(self.input, self.weights1) + self.bias1.T

			# Sigmoid activation function
			self.input2 = 1.0 / (1 + np.exp(-self.input2))

			# Output layer
			self.predictions = np.dot(self.input2, self.weights2) + self.bias2

		def calculate_loss(self):

			# Mean squared error
			self.loss = np.asscalar((np.sum(self.ground_truth - self.predictions) ** 2) / (2*self.M))
			self.epochs += 1
			print (""Loss after %d epochs is %d"" % (self.epochs, self.loss))

		def backward_pass(self):

			# Loss gradient
			temp_grads = ((self.predictions - self.ground_truth) / self.M)

			# Output layer update #
			#######################

			# Bias gradients update
			self.bias2 -= self.learning_rate*np.sum(temp_grads)

			# Weights gradients update
			temp_weight_grads = np.dot(self.input2.T, temp_grads)

			self.weights2 -= self.learning_rate * temp_weight_grads

			input_grads = np.dot(temp_grads, self.weights2.T)

			# Hidden layer update #
			#######################

			# sigmoid gradients
			sig = self.input2 * (1.0 - self.input2)
			temp_grads_hidden = input_grads * sig
			# temp_grads_hidden = input_grads

			temp_bias_grads = np.atleast_2d(np.sum(temp_grads_hidden, axis=0))

			# Hidden bias gradients update
			self.bias1 -= self.learning_rate*temp_bias_grads.T

			# Hidden weight gradients update
			temp_weight1_grads = np.dot(self.input.T, temp_grads_hidden)

			self.weights1 -= self.learning_rate * temp_weight1_grads



		def predict(self, new_input):

			self.input = new_input
			self.M, self.N = new_input.shape
			self.forward_pass()
			return self.predictions


	def main():

		# Setup input and ground truth for addition problem
		X = 100 * np.random.randn(10, 2)
		Y = X[:, 0] + X[:, 1]
		my_model = FullyConnected(X, Y)
		my_model.train(200)

		test_data = 10 * np.random.randn(100, 2)
		answers = test_data[:, 0] + test_data[:, 1]

		predictions = my_model.predict(test_data)

		test_answers = test_data[:,0] + test_data[:,1]

		print (""predictions: "", predictions[:5]
        print (""actual answers: "", test_answers[:5])






	if __name__ == ""__main__"":
		main()


EDIT: By the way, I've fooled around with the learning rate ad nauseam -- that's not it. And you can easily run this code yourself. It will just print out the loss after each epoch and then it will compare the first five predictions against the actual sums.

EDIT2:
The problem was that the ratio of input numbers to weight initialization was too extreme. With smaller numbers as inputs it worked."
The way I see it,0,1,False,False,False,learnmachinelearning,1486246536,True,[removed]
Help with finding a first project,2,2,False,False,False,learnmachinelearning,1486249132,True,"I've been watching many YouTube videos from sentdex, Google, Data School, and others.  At the same time I've been readind some books as well.  As per my usual way of doing things in life, I have a good theoretical base from which to start a machine learning project, but I have absolutely no idea what kind of task I want to undertake first.  Does anyone have any homework assignments that I can use to start that would produce a ""fun"" or interesting start?  Alternatively, are there any resources that provide machine learning goals for beginners that don't give out the solutions?  I feel that if I can start with something on my own, I can better jump into other projects of my own design.  Thanks!"
Machine Learning at Berkeley's Introductory ML Tutorial Series: Neural Networks and Backprop,0,1,False,False,False,learnmachinelearning,1486254501,False, 
How the heck does the backpropagation works in neural network?,12,10,False,False,False,learnmachinelearning,1486264196,True,"I am trying to understand the very basics of neural network. I made this [simplest neural network](https://gist.github.com/anonymous/b2dd3c9aa57849aaae46e544f193d41a) in which it trains  only with a XOR input [1,0] and output [1]. I used this [tutorial](http://python3.codes/neural-network-python-part-1-sigmoid-function-gradient-descent-backpropagation/) but didnt used any arrays because I want to understand neural networks from its foundation. I successfully wrote the feed forwarding steps of this neural network but its in the backprop that I got stuck. Truthfully I dont know how the heck it works. How should I backprop my neural networks and update the weights?

After searching I found this website http://www.cse.unsw.edu.au/~cs9417ml/MLP2/ in this I am scratching how to implement this [equation](http://www.cse.unsw.edu.au/~cs9417ml/MLP2/Equation7.jpg) in my code

      lr is the learning rate which i kept 0.01
      delta K is my dZ
      Xk I am not sure should I take one input i1, i2 or both
      deltaWk(j,k) how to calculate?"
Spеaking for mуsеlf,0,0,False,False,False,learnmachinelearning,1486291894,True,[removed]
[Project] happy-and-you-know-it: Facial Emotion Recognition using deep residual learning. (demo at https://happy-and-you-know-it.herokuapp.com/); X-post from r/MachineLearning/,0,4,False,False,False,learnmachinelearning,1486298102,False, 
"Sorrу to intеrruрt, but",0,0,False,False,False,learnmachinelearning,1486309204,True,[removed]
Machine Learning advice for Event Labeling Problem I am having,1,8,False,False,False,learnmachinelearning,1486325127,True,"Hi Learnmachinelearning community,

I am relatively new to Machine Learning and am currently doing my final year project for a Computer Science course at college. The project I am doing is creating a chatbot to allow users to manage their calendar by letting them book events, view their schedule and interact with their calendar through a chat interface.


I currently have a ML problem that I am looking for advice with:

For my app, I want to be able to classify an event that the user wants to add to their calendar as either 'business' or 'personal / leisure'. Business events would be things like team meetings at work, or other work events and 'personal / leisure' events would be things that users would do in their free time.


The data that would be passed into the app would be something like this: 'add team meeting for tomorrow' or 'add the cinema for tomorrow evening'


I would then use the personal / business prediction to suggest a time for the event, either within the users' work hours or outside them if they don't provide a time when booking the event.
I have 2 questions here:

1) Are there any good datasets out there that have a large library of event types labelled with 'personal' / 'business', or how would I go about getting data for this?

2) What type of algorithm would be good for this problem? Essentially the data would just be the event eg: team meeting or cinema from the above examples, so how would I go about predicting a label for this type of data?

I know there is a lot of information here, so sorry about that. I would welcome any responses here, as it is a problem I have been thinking about for the last few weeks and am still unsure with how to proceed."
Can I learn probability and statistics on the go?,0,1,False,False,False,learnmachinelearning,1486327362,True,[removed]
Hеllо thеrе!,0,1,False,False,False,learnmachinelearning,1486329752,True,[removed]
A neural net for regression and not classification,10,8,False,False,False,learnmachinelearning,1486347429,True,"I've been using R for over a year now to build statistical learning predictors for regression. I say statistical learning because I've mostly relied on random forests for prediction and its worked really well. However, I want to compare them to more algorithms and techniques.  

I recently switched to python (all of my team's code can be in the same language) and I'm having trouble with making a neural net predictor using sci kit learn. There is a lot of overwhelming information out there with Keras, tensorflow, deep learning etc. 

My main aim is to use the neural net algorithm to make the best predictor I can for forecasting time series data with 5 predictors. Can someone help me how to go about this. 

Once this is complete, I want to compare how different algorithms work in predicting my response. I want to try and see if deep learning will help me make a better predictor. What I'm confused about is : all the applications for neural nets and deep learning seem to be in classification and aren't geared towards regression. 

Can someone help me get started with deep learning for regression. What's the simplest way to implement a deep neural net in python. I've read that keras is a good place to start.

Let me know if what I'm asking is clear. I'm happy provide more details if I've been incoherent. Thanks in advance ! "
https://youtu.be/63HHmjlh794,0,1,False,False,False,learnmachinelearning,1486395707,False,[deleted]
[Resource] - Can a Chess Piece Explain Markov Chains?,0,5,False,False,False,learnmachinelearning,1486396386,False, 
How do you decide which classification ML method to use on Test set?,0,1,False,False,False,learnmachinelearning,1486396437,True,[removed]
HDBSCAN cluster: still unclear to me how to chose 'min_cluster_size`,1,3,False,False,False,learnmachinelearning,1486401796,True,"Hdbscan is an excellent technique to find the ""optimal"" number of clusters within your data when you have little a priori idea how many clusters should exist. This makes the method great for exploratory analysis:

http://hdbscan.readthedocs.io/en/latest/comparing_clustering_algorithms.html

Here's my problem: All results using hdbscan with the python implement in the link above rely on the crucial min_cluster_size http://hdbscan.readthedocs.io/en/latest/parameter_selection.html
How do users normally chose this? It's unclear to me how this is done, especially given how drastically different the clusters are given this input."
"Deep Learning & Parameter Tuning with MXnet, H2o Package in R",0,1,False,False,False,learnmachinelearning,1486444994,False, 
Simplest back propagation neural network for self learning?,0,3,False,False,False,learnmachinelearning,1486454790,True,"For me back propagation in neural network was some *black magic trick* which when applied to a forwarded neural network allows it to learn. But for the past few weeks I want to understand this *black magic trick* and posted some questions in the reddit itself [[1]](https://www.reddit.com/r/MLQuestions/comments/5q2jb9/can_anyone_share_a_simplest_neural_network_from/) [[2]](https://www.reddit.com/r/learnmachinelearning/comments/5s5a7y/how_the_heck_does_the_backpropagation_works_in/). Many redditors gave their valuable advises and codes which helped me to understand a little bit more about backprop (still some confusions are there :) )

In the end I had made a simple neural network which helped me understand back prop in neural networks a little more. This neural network only take one input (i=1) to predict one output (o=1) with only one hidden node and no bias nodes. I have followed [mattmazur's ](https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/) for starting but I made some stupid mistakes in my codes which gave wrong result.  I am very thankful to [kosmoi](http://python3.codes/neural-network-python-part-1-sigmoid-function-gradient-descent-backpropagation/ ) who helped me to find and debug the error code which resulted in the successful run of the neural network. 

This is the full  code and I also tried to comment Latex equation  (hyper link) to  the corresponding codes for reference.

       Input layer=1 --> Hidden layer=1 --> Ouptut layer=1
https://gist.github.com/anonymous/e83ca9b0ed99db66079a3930dba605d9

       Input layer=1 --> Hidden layer=2 --> Ouptut layer=1
https://gist.github.com/anonymous/748ad2cd48ff1779e4fff6d3f84902c1

*Note: This code is just for understating backprop and I am not guaranteeing any efficiency or accuracy*"
I wondеr if уоu соuld hеlp mе with this?,0,0,False,False,False,learnmachinelearning,1486465546,True,[removed]
"Complement your ML learning at AI With The Best, the global online tech conference 29/30 April featuring Ian Goodfellow, Yoshua Bengio and Geoffrey Hinton. 100 speakers to inspire you with interactive tech talks :D",0,1,False,False,False,learnmachinelearning,1486491357,False, 
What are the best techniques for using clustering for exploratory data analysis (EDA)? Exploring structure of data,5,2,False,False,False,learnmachinelearning,1486499948,True,"This topic came up in this thread:

https://www.reddit.com/r/datascience/comments/5sfj0y/hdbscan_cluster_still_unclear_to_me_how_to_chose/

Let's consider a concrete example. You're given a dataset: 
Let's say I have measured ~1000 features of students in a given public school district, 5000 students: kindergarten through senior high school students. The features include grades, height, age, ethnicity, list of extracurricular activities, number of credits per semester, etc.

Now, there are several ""clusters"" here will fit the data better than the alternatives. As an example, I would expect to see a cluster for the grade level.

How does the ""data scientist"" with no priori knowledge of these data use clustering to learn about the dataset's structure?

For certain datasets, your data scientist will know absolutely nothing about how ""well"" clusters fit the data----what methods should one use to investigate the structure of the data? "
question about deep learning/clustering?,4,3,False,False,False,learnmachinelearning,1486511567,True,Say I want something more powerful than k-means and would like to use deep learning. What is the correct way to go about grouping this unlabeled data? Say I have 300 faces that are smiling and 300 that are frowning but I would like to have these be grouped without me labeling each item one by one. What would be the best way to go about this from a high level? 
MachineLearning / AI Workbooks?,5,1,False,False,False,learnmachinelearning,1486513541,True,"Have you found any workbooks or problem/solution books on ML helpful?

Are there any repositories of online questions for learning ML?

I'm interested in creating some resources, if there are none. If you'd like to be involved in reviewing what I create or testing it out, please let me know!
"
TIL (Today I Learned) Tuesday - Share something new that you have learned today!,0,4,False,False,False,learnmachinelearning,1486537629,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until today, feel free to share!
"
[FREE-JOIN] 100% Free_Sex_Dаting_Website,0,0,False,False,False,learnmachinelearning,1486549956,True,[removed]
Neural net input sensitivity analysis,0,6,False,False,False,learnmachinelearning,1486553621,True,"Hi,

if we have something like a vanilla feedforward densely connected neural net with continuous valued output (so, for regression), what approaches are available for understanding the marginal effect each input dimension has on the output? So consider for example the kind of visualisations that random forests/gradient boosting models permit with partial dependence plots - is this possible with a neural net? A naive approach would be to do something like set each input feature to its mean, then linearly vary your feature of interest over its domain, and plot the results (or do this for 2 features and get a contour map). It's not clear to me if this is going to be valid in general, though. 

If we think of the neural net as some kind of continuous, differentiable function, then we'd expect that it would be also possible to construct a locally-valid linear approximation to the function surface in some small neighbourhood of an output point of interest, so it should be possible to at least understand the effect of inputs near a point, but harder to do in general. Is there any literature discussing this, or offering practical implementation advice?

Cheers!

"
Is this the right way to optimize neural network weights?,0,1,False,False,False,learnmachinelearning,1486558931,True,"This is the continuation of my past [questions](https://www.reddit.com/r/learnmachinelearning/comments/5sk774/simplest_back_propagation_neural_network_for_self/). For the past few days I am trying to understand the nuts and bolts of neural networks and back propagation. In order to understand the fundamental structure and signal processing in neural networks, I have made some neural networks without any arrays. Those neural networks used a single input and output for training; to up the ante I have made a XOR neural network.

I have used *for loops* to fetch the input output values from the XOR arrays and then feed that to the neural network. All seems to work fine.

https://gist.github.com/anonymous/5b1dd09ed65ddb9ec8edda0624bb9a05

I dont know whether I am optimizing  weights correctly? Can some body look into my codes and share your opinion regarding it?

*Note: This code is just for understating backprop and I am not guaranteeing any efficiency or accuracy*"
"Detailed Solution Manual of ""Machine Learning: A Probabilistic Perspective""",0,31,False,False,False,learnmachinelearning,1486562664,True,"Hey, I started a solution manual on Murphy' ML Book. My proposal is not only solve the exercises, but also give an introduction to get a feeling about the problem and make some remarks after the solution. 
I hope this can help people which are not so familiar with the math level required by the book to have a better comprehension of it. Currently, I have chapter 2 finished and I am starting chapter 3.
GitHub page:
https://github.com/ArthurZC23/Machine-Learning-A-Probabilistic-Perspective-Solutions"
Introduction to Naive Bayes Classification Algorithm in Python and R,0,1,False,False,False,learnmachinelearning,1486624518,False, 
What does a classification prediction look like?,3,1,False,False,False,learnmachinelearning,1486633622,True,[deleted]
[FREE] Free Sex Dаting Website,0,0,False,False,False,learnmachinelearning,1486634756,True,[removed]
Particle Swarm Optimization and Weights Update,10,2,False,False,False,learnmachinelearning,1486648696,True,"Hi,
So I have been trying to build a Neural Network with PSO as the training algorithm. So far, I've understood the basics of PSO and ANN as separate subjects. But, how would it relates back to each other?
I understand that the Position of the particle represents the fitness function, which we are trying to reduce. But how will the new weights be calculated once we obtained the new position of the particle?
More specifically, how does the new weights get calculated and updated?"
TensorFlow howto: a universal approximator inside a neural net,6,10,False,False,False,learnmachinelearning,1486659362,False, 
Show-off Sunday!,0,1,False,False,False,learnmachinelearning,1486710511,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
"13 Free Self-Study Books on Mathematics, Machine Learning & Deep Learning",0,1,False,False,False,learnmachinelearning,1486710659,False, 
Can you give me a hand with this?,0,1,False,False,False,learnmachinelearning,1486721255,True,[removed]
"Hello, I'm a beginner and I recently made the connection between CNNs and normal NNs. I wrote a visual guide about what I learned. I'm looking for feedback (especially about errors!) and I hope you gain something from the guide.",0,1,False,False,False,learnmachinelearning,1486767617,False,[deleted]
CNNs from different viewpoints (a visual guide for beginners),4,13,False,False,False,learnmachinelearning,1486768307,False, 
Will you let me speak?,0,1,False,False,False,learnmachinelearning,1486772629,True,[removed]
"I have cs background, but no machine learning experience. Is my understanding accurate?",11,8,False,False,False,learnmachinelearning,1486773732,True,"In my head, machine learning systems are trained by feeding them with tons of training data so that when they take new input, they can ""guess"" about said input.  

As a hobby project, I would like to learn machine learning and make a chess playing system that, instead of using brute force, learns from chess games databases which moves are good in a given situation and uses this to play.  

My basic idea is that first I need a way to rate how good a move is in a given board position.  Then I can use it to analyze moves from chess databases and feed this to my system.  

Am I understanding right? Is this the right way to approach this problem? Would it be feasible to do this? Assuming I have good computer science and math/statistics background, how much stuff do I need to learn in order to be good enough at this to actually accomplish this goal?
What are some of the most important top I should cover if I aim to do this?"
Is TensorFlow the best and most widely used environment for coding things in the Machine Learning area?,3,5,False,False,False,learnmachinelearning,1486779352,True, 
"Scrum Saturday - Share your progress, your goals, and whatever is stopping you from achieving those goals!",0,7,False,False,False,learnmachinelearning,1486796779,True,"Let's have a scrum meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
Question Regarding Yoshua Bengio's DeepLearningBook Quote,3,3,False,False,False,learnmachinelearning,1486798947,True,"""Unfortunately, mean squared error and mean absolute error often lead to poor results when used with gradient-based optimization. Some output units that saturate produce very small gradients when combined with these cost functions.""

How is MSE going to produce saturated gradients? I understand sigmoid producing small gradients, but MSE objective, ||y-f(x)||^2, is a parabolic bowl with very nice gradient qualities, not to mention it has a closed form.

What is Yoshua Bengio referring to here?"
You want me?,0,0,False,False,False,learnmachinelearning,1486806230,False, 
Density Estimators: Is the average test set log-likelihood really adequate to assess model performance? Why isn't negative/noise data used to ensure that generalization has been achieved? [x-post from /r/MLQuestions],2,1,False,False,False,learnmachinelearning,1486821206,True,"Hi,

reading [NADE papers](https://arxiv.org/abs/1605.02226), I noticed that the average (negative) log-likelihood is often used to assess the accuracy of the density estimation model.

At the beginning this made sense to me, but then I thought at an overfitting simple ""model"" in which binary input units are directly connected to output units. Each of these output units would represent a probability specific for its input unit. For example, NADE models the outputs as representing conditional probabilities of a specific input variable given all the previous in a pre-determined ordering of input variables.

In such a simple toy model, the binary inputs are connected with constant weights set at one to the outputs, and there is no learning, also because the gradients would be always be 0 as there is no ""error"" in estimating the probability.

This ""model"" would always estimate a probability 1 for all the dataset samples that are given to him. It would also return a probability of 1 for unseen samples from a test set, and it would always return 1 from noise.

If the NADE can be interpreted as an autoencoder, then I think that it learns to generalize to the correct probability distribution via a sufficiently narrow latent-code/hidden layer. If the hidden layer is not sufficiently narrow, then an autoencoder might learn the identity function, and the same might happen with the simple case of bernoulli probabilities on binary-valued input vectors. Measurement of this phenomenon is not taken into account in the average log-likelihood measure.

As noise or negative samples are not used in order to make sure that their probabilities returned would be around 0, how can the training dataset (or test set) log-likelihood be considered as a serious quality measure?
"
Monthly ELI5 (Explain Like I am Five) Thread,19,17,False,False,False,learnmachinelearning,1486855012,True,"Top comments need to be in the format of: `ELI5 $CONCEPT_NAME` and the replies should provide a clear explanation in a layman's term.
Here are the relevant rules from /r/explainlikeimfive breaking down the meaning of ""ELI5"":

- E is for Explain - merely answering a question is not enough.

- LI5 means friendly, simplified and layman-accessible explanations - not responses aimed at literal five-year-olds.
"
"Lecture notes, videos and exercises+solutions from Prof. Laurenz Wiskott",0,10,False,False,False,learnmachinelearning,1486899121,False, 
Couple of questions on CNN,7,6,False,False,False,learnmachinelearning,1486908335,True,"So I have a project for school where I need to be able to recognize signs from images. Kinda like traffic signs. I decided to use convolutional neural network because of personal interest and it seems to be effective methode for this problem. I understand how normal neural network works but I have a couple of questions conserning this.

1. How big can the image be. Most examples have used small 32x32x3 images but I don't know if this is because of it's an example or because there is some limit.

2. Am I supposed to choose the kernels my self or does the machine learning figure them out itself.

3. Do the convoluted images mix with one another in the convolution phase  or do I just keep convoluting them over and over until I reach the fully connected layers.

4. Can anyone suggest an easy training problem and a dataset for it. I have to collect the dataset for my own project by hand so it would be nice to test the algorithm with a proper dataset so I know if the problems are in the algorithm or data.

Thanks for any answers."
Neural Net?,5,2,False,False,False,learnmachinelearning,1486928970,True,"Which is the best beginners resource to study the mathematics as well as overall of neural net 

"
If you had to recommend ONE book for mathematical background?,8,25,False,False,False,learnmachinelearning,1486946417,True,"TL;DR Somewhat experienced practitioner looking for graduate level treatment of topics in math/stats used in ML. 

Hi,

I have a CS background, so sometimes I find myself lacking the math/stats knowledge to understand certain topics.

I'm looking for a book to learn things at the graduate/PhD level in these topics:

- Statistics
- Calculus
- Optimization
- Linear algebra

Is there ONE book that is along the lines of ""necessary mathematical background for ML"" kind of thing?

I build complex NN's in the ML research department of one of the big-4 tech companies. I give my background to clarify that I am not looking for a book to teach me what Gaussian is, how to apply Bayes rule, or how backpropagation works. 

To give a few examples, my hope is to gain enough background knowledge to comfortably understand topics such as:

- Statistical learning theory
- VC dimensions and SVMs
- Proof of expressiveness of neural networks.
- Optimization procedures such as conjugate gradient methods
- Eigenvalues/vectors deeply and intuitively.

Thanks!
"
When should we use Relu (or something from the Relu family) and when shouldn't we?,3,15,False,False,False,learnmachinelearning,1486985758,True,"Clearly Relu and its ilk are the go-to choice for CNNs.

At the same time, RNNs, specifically LSTMs make thorough use of sigmoids and tanhs and that practice seems pretty widespread.

What about just linear regression? Is Relu better for straight linear regression too?

What about GANs?

Autoencoders?"
New podcast on ML basics,15,17,False,False,False,learnmachinelearning,1487016223,True,"I'm creating a podcast - [Machine Learning Guide](http://ocdevel.com/podcasts/machine-learning) - on the basics of ML. Audio is an inferior medium to task - but with so much chores/commute/exercise time, there's _hours_ every day one could spend learning - so count this supplementary. I aim to be super high-level and 101, so this is for newbies and unconfidents. 

One goal of the podcast is to be a syllabus, where in each episode I recommend ""required readings"" resources - books/textbooks/courses/etc that I've boiled down from the most common recommendations from around the web. So anyone asking ""which maths should I learn? which textbooks would you recommend? which language is best?"" - this is for you.

Hope y'all find it useful, tell me if it's crap!"
What's the difference between a neural net that can do MNIST and a neural net that can recognize adorable kittens?,2,2,False,False,False,learnmachinelearning,1487023334,True,"A related question is if you take a neural net that can do MNIST and give it more nodes and layers could you train it to recognize cats? Obviously I am assuming you have 5 million images of cats (from my Aunt Kathy, you know what I'm saying). If not, what are the primary differences between the two types of neural networks? Does the cat neural net receive pixels as its input features or do you have to massage the input data somehow?"
Advice on my study plan please.,1,0,False,False,False,learnmachinelearning,1487073082,True,"Hello redditors,

I'm a current first year undergrad student in mathematics/statistics and computer science. At 24 reading about the developments of machine learning in terms of alphago, autonomous vehicles, and most recently Liberatus, the poker AI, has been the spur I needed to get me back to uni after dropping out after my first year of engineering straight out of high school.

Obviously I want to start playing around with algorithms myself though I realise I need to learn the fundamentals first. We will be introduced to linear algebra this semester but being keen to get started in the field, I was just hoping for some advice regarding where to start my personal studies.

I have been ticking away at [Learn Python The Hard Way](https://learnpythonthehardway.org/book/) which came in handy when we worked with matlab last year.

For the mathematics side I was looking to follow the [MIT Linear Algebra lectures](https://www.youtube.com/watch?v=ZK3O402wf1c) on youtube by Gilbert Strang.

Following that I was hoping to try my hand at [Sentdex's Python Machine learning with SKLearn Tutorial for Investing](https://www.youtube.com/watch?list=PLQVvvaa0QuDd0flgGphKCej-9jp-QdzZ3&v=URTZ2jKCgBc).

Just after any recommendations on this plan of attack, possibly further python or maths resources.

Kind regards."
Classify a pattern using multiple inputs(rows) and predict that pattern,4,5,False,False,False,learnmachinelearning,1487079364,True,"I have a dataset which contains a timestamp and a response time.
I want to recognize current patterns in the dataset with labelled learning or something like that. I've been looking at multi-class classification but that only takes 1 input/row and outputs a class which it things it belongs to.

The algorithm should look at the surrounding previous data to check the correct pattern the newest input value is in. 

[Example](http://imgur.com/a/bvX0Y)

A single input could be 45ms but you wouldn't know which pattern it belongs to unless you check all recent inputs. When it gives the class prediction a score of 0.75 or higher I can check the previous down time of the same class and give a prediction as to when the service is going down. Would be nice if 1 type of machine learning could do this all but I'm currently looking for a pattern classification algorithm.

Any help is greatly appreciated."
24_Bailey_( ͡° ͜ʖ ͡°),0,0,False,False,False,learnmachinelearning,1487098491,False, 
A Brief Introduction To Artificial Neural Networks,0,23,False,False,False,learnmachinelearning,1487098825,False, 
Top 100 Deep Learning Papers (2012~2016),2,7,False,False,False,learnmachinelearning,1487105334,False, 
Haiku - Start Coding on a Cloud ML Stack in Seconds,1,3,False,False,False,learnmachinelearning,1487112374,False, 
"[Data] Spanner, the Google Database That Mastered Time, Is Now Open to Everyone",0,1,False,False,False,learnmachinelearning,1487141606,False, 
TIL (Today I Learned) Tuesday - Share something new that you have learned today!,0,6,False,False,False,learnmachinelearning,1487142417,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until today, feel free to share!
"
Possible to directly get p(X = x) from VAE? [xpost /r/MLQuestions],0,1,False,False,False,learnmachinelearning,1487154670,True,"So a VAE tries to maximize the log likelihood of the data (`log p(x)`) as per my understanding:

    log p(x) - KL[ Q(Z | X) || P(Z | X) ] = E_{z ~ Q(Z | X)} [log p(x|z)] - KL [ Q(Z | X) || P(Z) ] 


Is there any way to get an evaluation of of the probability for a single sample from this model? My thoughts are bayes rule:

    p(X=x) = p(X | Z=z) p(Z=z) / p(Z | X=x)

Since we have all these terms: i.e:

    p(Z | X=x) --> the output of the encoder of the VAE
    p(X | Z=z) --> the output of the decoder of the VAE
    p(Z=z)      --> the assumed prior, N (0, I)

However, if `P(X | Z)` is a bernouilli dist I guess analytically this becomes:  
    `bernouilli * N(0, I) / N(mu, sigma)`

Is this solvable analytically?  Empirically when we train VAE's I see the error not bounded in [0, 1] which I would expect for a pmf. Is this because we drop the ` KL[ Q(Z | X) || P(Z | X) ] ` term on the LHS of the first equation above?"
How much data should I use?,2,1,False,False,False,learnmachinelearning,1487158399,True,"For my final year project at uni I am trying to build a model for sarcasm using CNN's. I was wondering how many sarcastric and non-sarcastic sentences I should have, as there is obviously more non-sarcastic sentences. Is there a ratio that is generally known? e.g, 1:1 or 1:2"
How to win Machine Learning Competitions ?,0,12,False,False,False,learnmachinelearning,1487170880,False, 
[Webinar]: Machine Learning in a Live Production Environment,0,1,False,False,False,learnmachinelearning,1487176126,False, 
Scikit learn?,2,0,False,False,False,learnmachinelearning,1487185597,True,"Complete tutorial on scikit learn? 
I'm now taking this one
 https://youtu.be/OB1reY6IX-o
 any more else videos I should take? "
Introduction to Anomaly Detection,0,8,False,False,False,learnmachinelearning,1487210080,False, 
Notes or articles related to Bayesian Networks and belief propagation?,2,1,False,False,False,learnmachinelearning,1487229110,True,"I am struggling to understand the concept of belief propagation in bayesian networks, can anyone point me to a good resource? Thanks! "
Components and implementations of Natural Language Processing,0,1,False,False,False,learnmachinelearning,1487238715,False, 
My crazy story about Sex with 3 different girls,0,0,False,False,False,learnmachinelearning,1487240333,True,[removed]
Let's make an A3C: Theory - Introduction into Policy Gradient Methods,0,1,False,False,False,learnmachinelearning,1487241910,False,[deleted]
Trying to train a classifier that predicts the gender of of a reddit user,23,8,False,False,False,learnmachinelearning,1487253542,True,"I have mined about 1500 male and female usernames and dumped about 10 comments from each username into text files. I will be using bag of words as features along with the user's activity in subreddits. After researching I have come to the conclusion that SVM works best for classifying text data.

My questions are:

1) Would PCA be useful for this limited amount of data? I have also considered using LDA but I feel I have too less data.

2) More importantly, I'll be using BOW as features along with activity in subreddits. Is scaling required, if so why? Won't the basis parameters adjust themselves anyway in neural nets and SVM's and assign the actual significance to each feature?

3) Is the amount of data I have enough for about 70% accuracy? If not, should I go for 100 comments per username? Due to reddit's pinging rules, it takes a lot of time to mine stuff, so I was wondering if it would be worth it.

4) Should I use BOW or tf-idf? Also, if I use BOW and then remove features with low variance, isn't that similar to just doing tf-idf?

Edit: After using SVM classifier and no PCA or LDA, I have got 76%. Is it any good? Also I'm pretty sure scikit-learn has done a shitty job at tokenizing the words. Am now trying to use NLTK to tokenize."
What is the best way to predict if an event will happen within a certain time horizon or within multiple time horizons? Using time series data,1,9,False,False,False,learnmachinelearning,1487254477,True, 
Does mini batch gradient descent (b>1) converge faster than stochastic gradient descent(b=1)? (x-post on /r/MLQuestions),3,3,False,False,False,learnmachinelearning,1487260381,True,"My reasoning is that you're computing a larger fraction of the parameters, theta, per update of theta values, you're less likely to descend in the wrong direction (assuming you randomized your input first)

sorry about the x-post, not sure which subreddit to ask"
[Project] Attempting to perform face recognition on LFW dataset. Approach?,0,1,False,False,False,learnmachinelearning,1487261133,True,[deleted]
"Using a generator, does it matter how many steps per epoch i take?",9,2,False,False,False,learnmachinelearning,1487286028,True,I am using a generator to input my data to tf.  Does it matter how many steps per epoch i take?  Should I pick something that is representative of the size of my dataset (its very large)? 
Show-off Sunday!,1,1,False,False,False,learnmachinelearning,1487315397,True,[removed]
Let's make an A3C: Theory - Introduction into Policy Gradient Methods,0,3,False,False,False,learnmachinelearning,1487320292,False, 
"Is there an Atlas of deep learning models, learning algorithms, initializations, etc.",1,8,False,False,False,learnmachinelearning,1487334778,True,"I mean a guide that explains the relationships between current state of the art DNN models, initialization functions for different layers, training methods, data preprocessing, different normalization approaches etc. organized by properties of your dataset, the kind of task you are trying to do (such as classification, generation, prediction, sequence to sequence conversion, etc.).

I feel like I should be able to navigate the existing state of the art before trying to reinvent the wheel and fail."
"Looking for advice, C# non-fixed topology neural network activations",0,2,False,False,False,learnmachinelearning,1487362453,True,"Preface, this is my first post in this sub. I apologize if I misuse terminology as I don't have a strong academic background and have been learning these topic on my own.

As part of a side project I'm using c# to evolve a population of non-fixed topology neural networks (inspired by NEAT and HyperNEAT) to accomplish a learning based task. For context, the networks are compositional pattern producing networks (cppns) and I'm using them to attempt to solve a rubics cube. The details of the project design are a bit lengthy to put here, but if anyone is interested I'm happy to share in the comments. Also, I'm trying to self implement as much of the code as possible to get a deeper understanding of using HyperNEAT algorithms to solve a problem. As such I'm currently not using any machine learning libraries.

My application runs fine but I'm running into performance issues when measuring the fitness of my networks once they become pretty sizable. Altering the toplogy doesn't take long, but activating the networks takes a long time considering I need to activate each cppn network ~1000+ times each evolution cycle (per the needs of measuring 'progress' at solving a rubics cube). This results in evolution cycles eventually taking around half a minute+ at a few hundred generations, granted a lot of that is based off my topology mutation rates and hardware. I've squeezed as much performance as I can out of my own coding methods and tricks (caching past network activations, multi-threading, 'flattening' each networks structure ahead of time, ect.)

**My specifc question is, has anyone come across any c# libraries or code bases that deal with performance orientated graph topology for non rigid neural networks? Or maybe seen some good examples of in other languages?**

I've glanced at the HyperNEAT portion of the sharpneat library on github but that thing is a beast. If all else fails I can sink a few days into studying how they handle maintaining and activating their network toplogy.

I'd appreciate anyone's thoughts on the subject- or just sharing their own experiences they feel relate to the topics touched on above. Thanks for any thoughts :)"
How does TensorFlow update the weights in NNs?,5,5,False,False,False,learnmachinelearning,1487367184,True,"I'm doing some research as a student on how to improve the performance of NNs with TensorFlow by using some alternative mathematical functions. For example...

    X = tf.placeholder(...) # Data
    W1_0 = tf.Variable(...)
    B1_0 = tf.Variable(...)
    W1_1 = tf.Variable(...)
    B1_1 = tf.Variable(...)
       ⋮
    W1_n = tf.Variable(...)
    B1_n = tf.Variable(...)
    
    Y1 = tf.nn.relu(personal_math_function(X, W1_0, W1_1, ..., W1_n, B1_0, B1_1, ..., B1_n))


That would be the activation function applied to a single layer in my NN as an example. The `personal_math_function` will return the appropriate tensor and shape of `Y1` based on the mathematics performed in the function.

For each session run, does TF look at the variable requirements for that layer and then alter those values, or does it do something else? I'm attempting to implement the weight matrices as a special type of matrices, so the `tf.matmul` function needs to be redefined for my case. I'm just not 100% sure how to go about updating the weight values, or if TF will do that for me. And I cannot find anything on this topic.

Yes, I know I can pass a list or a vector of `W1`'s and `B1`'s, but this made it easier to visualize what my requirements are. 

Also, I am aware of the requirement to use something such as `softmax` to get the values if classifying and multiple values, session running to train, etc, this is specifically for a **single layer** in my NN and how TF decides to update the values in my `W1`'s and `B1`'s."
Cool summer courses/internships in California?,0,1,False,False,False,learnmachinelearning,1487374655,True,[removed]
"Weekly Scrum Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",3,2,False,False,False,learnmachinelearning,1487401635,True,"Let's have a scrum meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
Collaborative Filtering/Matrix vectorization,5,3,False,False,False,learnmachinelearning,1487410048,True,So currently I'm working on SVD and learned that the algorithm maps the items and the users to a joint latent space of dimension f. How do I figure out what Dimension f is exactly? Is it user defined? And if so how do I figure out what works best? 
How do you decide when to give up?,8,5,False,False,False,learnmachinelearning,1487423731,True,"I have a domain specific curated (911) dataset of 25M records.   Among other data I have date/time of event, age/sex of patient, and a one hot array of dispatch labels (seizure, diabetic, diff breathing, etc).   From my experience and from summary statistics, I know that there are seasonal variations (lots more diff breathing in winter) and daily variations of certain types of emergencies.

My hypothesis is that I might construct a supervised nn with date/time, age, sex as inputs, and 34 diagnoses as output labels.  Since I'm not following a tutorial I'm writing everything from scratch (keras).   I have no experience or intuition about any of my hyperparameters.   I don't really know how many layers I should use (most attempts I used 2), or how many nodes per layer (I've tried 50 to 80), or which loss function (mostly categorical_crossentropy), which optimizer (mostly sgd and I varied the learning rate by at least 4 orders of magnitude).   There are lots of knobs to fiddle.

So after hundreds of runs, with no indications of any successful training (training accuracy under 0.2) it is now 3AM.  I thought I'd be able to discover something in my data, and I'm just assuming I'm doing something wrong.   How do you convince yourself to stop?   How do you convince yourself that it's not that your model is shit, it's that your hypothesis is wrong?

"
Trouble installing Tensorflow,5,5,False,False,False,learnmachinelearning,1487437146,True,"Would appreciate any help with my issue.  I am trying to install the new Tensorflow 1.0.  I currently have Windows 10 and Python 3.6 and corresponding pip 9.0.1.  When I follow the instruction on <https://www.tensorflow.org/install/install_windows#installing_with_native_pip> with the command ""pip3 install --upgrade tensorflow"" and get the error
""Could not find a version that satisfies the requirement tensorflow (from versions: )
No matching distribution found for tensorflow""

I would prefer the native installation over the Anaconda version if I can.  I'm not sure what I'm doing wrong.  Thank you in advance for the help!"
I know nothing,2,0,False,False,False,learnmachinelearning,1487449736,True,"I know nothing, how can I just download a premade network and give it some images to teach it to do stuff, like to give it many picture to tell it if a picture is ugly or not, and then see if it can say which picture is ugly and which not"
How to Program Least Squares / Gradient Descent from Andrew Ng's 2nd Lecture?,4,2,False,False,False,learnmachinelearning,1487485358,True,"I'm a software engineer trying to learn Machine Learning. I picked up Neural Networks pretty easily, but pretty much everything else is alluding me.

I'm trying to start at square one, but there seems to be a step between Least Squares and Gradient Descent that I can't grasp.

It seems to me that the problem is clearly defined: Given a set of points that seems to trend along a line of some path, find the line that best fits through those points. I know that algorithms exist to find this line, but I want to find it with ML to really grasp how it works.

I've started several ML books and articles, and this is usually the first example. It seems like Least Squares is clearly the algorithm you use to measure the errors / cost of your current hypothesized line. And it seems like Gradient Descent is the algorithm that helps you creep closer toward the ideal line.

First of all, is that right?

Secondly, if it is, writing a function to measure the Least Squares from two lines was pretty easy for me. How to apply Gradient Descent is where I'm lost.

Given that a line's equation is y = Mx + B -- my understanding is that Gradient Descent could help me find M and B (or the weights).

Andrew Ng does a bunch of math I don't really understand to reach an equation for Gradient Descent. But it's not clear to me exactly how this equation is used.

My understanding is that in say a for loop, 1000 times, I would change the values of M and B by a set value (step_size). On each iteration, I would measure the Least Squares and if it is less (since my goal is to minimize it), I would change the values of M and B correspondingly.

It's just a little unclear to me how exactly this for loop works.

    var points = [[1, 2], [2, 3], [3, 4]]; // ...
    var inputs = [0, 0]; // M & B.
    var step_size = 0.001;
    var steps = 1000;
    var error = least_squares(inputs, points);

    for (var i = 0; i < steps; i++) {
        var new_input = gradient_descent(); // unsure what the params are -- probably input, points, and step_size.
        var output = least_squares(new_input, points);
        if (output < error) {
            error = output;
            input = new_input;
        }
    }

Am I on the right track? Am I even right about what Gradient Descent actually does? Appreciate any tips.

Thanks!"
Fuck me in the ass,0,1,False,False,False,learnmachinelearning,1487508029,True,[removed]
Good online resources,1,1,False,False,False,learnmachinelearning,1487510028,True,"Hi,

First of all some quick background: I am 19, beggining my MEng in Computer Science at the University of Leeds(UK) in September and have been dabbling in programming in high-level OOP languages since I was 14 or so. I've written some basic programs like chat applications, a brute-forcer (it sucked), an FTP client and Minecraft mods but haven't made anything in over a year. 

I becmae really bored of programming, making applications that just does 'stuff' bores me, I haven't been interested in a long time but recently stumbled across AI. data science and machine learning. This field genuinely interests me to the point where I obtained a book (AI a Modern Approach by S.Russell and P.Norvig). I really want to get started to learn this field but am clueless as to where to start.

I am generally OK with Java and C# and can use Python rather well too, the problem isn't the programming it's knowing where to look to apply it to machine learning. I was wondering if there are any known online tutorials, courses, e-books or even normal books I can buy to help me? I've seen the data science course on Coursera which starts by teaching you 'R' and am not sure if dat science is a relevant subject to learn if I wish to move onto machine learning in the future. Can anyone help me here?

TIA. "
number of neurons vs. performance of the network,7,2,False,False,False,learnmachinelearning,1487523630,True,"I was thinking that in MNIST, each image has 28x28 pixels. So let's say if the images are binarized, I should be able to map the relationships between pixels and its class (10 classes) by using a single layer of 784 neurons. Furthermore, if images are greyscale, 784x100 neurons should be able to map the relationship well. 

However, the existing MLPs generally have more than 300,000 neurons. So 1) is there anything wrong with my rationale above? And 2) Is there any relationship between dimension in input data and the number of neurons in a good performance neural nets?"
"Do my data have to be restricted to an interval such as [0, 1] or [-1, 1] when using ANNs",3,3,False,False,False,learnmachinelearning,1487543415,True,"My data is normally distributed around zero and most of the points are in the [-1, 1] interval, but since I have a lot of samples there are some outliers. If I scale the data by its maximum absolute value most of the points come extremely close to zero, and most of the interval stays completely empty.

So my question is: would it be OK if I use ReLU activation function at hidden units and linear activation at the output? Do I loose representational power if I don't use a non-linear activation at the output?"
What kind of neural net is this?,7,5,False,False,False,learnmachinelearning,1487555884,False, 
Classifying based on group of observations,0,1,False,False,False,learnmachinelearning,1487562892,True,[removed]
Deciding between ISL and ESL books,2,3,False,False,False,learnmachinelearning,1487566220,True,"Hi everyone! Turns out I still have money to spare for the month. My question is: what would you recommend between ""Introduction to Statistical Learning"" and ""Elements of Statistical Learning"" as my first printed ML book?

My background: first year grad student with a decent mathematics knowledge. Finished Andrew Ng's course a month ago and currently doing Stanford's CS229 (the assignments are very challenging for me). I ""skimmed"" both ISL and ESL pdfs and my first impression is that ESL is more mathematically-involved (I may be wrong). Planning to work in the industry with an ML-related career after Masters. Might pursue a PhD (but everything is still in the clouds)

I just want to buy Printed Books because reading on the computer strains my eyes so fast and I'm someone who loves annotating books with sticky notes, highlighters and stuff.

So which one of the two is a good first printed book investment? Or are there any other choices?

Thank you so much!"
Supercharge your datasets with features based on trending concepts for Nasdaq & NYSE stocks,5,8,False,False,False,learnmachinelearning,1487569725,False, 
My real stories for you guys,0,0,False,False,False,learnmachinelearning,1487588821,True,[removed]
ML weekend project,2,5,False,False,False,learnmachinelearning,1487616729,True,"I am a beginner in machine learning and have been studying Supervised, Unsupervised learning and Neutral networks for a while . But I can't figure out a small project to implement that I've learned. Can anyone please suggest me with some idea kinda weekend project to do? "
Finetune image classifier models with different image size (Keras),2,1,False,False,False,learnmachinelearning,1487616859,True,"I would like to fine tune  for example InceptionV3 but I only have `1x56x56` images. Can I fine tune it, and if yes than how?"
Tips on building new ML desktop for multiple runs?,12,4,False,False,False,learnmachinelearning,1487616974,True,"Hi, I want to build a new computer for doing multiple simultaneous neural network simulations, and so I'm considering multiple GPUs or..maybe an Intel Xeon PHI.  Budget is $2500+ (no monitor/keyboard/mouse), but that's somewhat adjustable.    Any tips/suggestions?   

Backstory:
I've got a pretty sweet desktop with a GTX1080 I built last fall for ~$2000, that I've used to get some encouraging results in my machine learning research.  But I can really only run one parameter set at a time, whereas I'd prefer to be doing multiple runs at once to find the best network architecture & parameters more efficiently.

I'm ready to ""scale up"", and...for some reason...the finance-bureaucracy at my workplace makes it vastly easier for us to buy a new desktop than to simply rent time on a cloud service like AWS. (?? I know...)  

Ideas: Is it possible to run four GTX1070's in one box? I don't require that they be able to ""talk to each other"" so SLI wasn't on my mind.  (Pardon my ignorance.)  Someone said I should check out the Intel Xeon Phi instead, but it's so ""new"" I don't know...that's why I'm posting here.  

(Seems like, if the code I'm using is already CUDA-enabled --which it is--, then the Phi is an expensive alternative whose main selling point -- i.e., writing non-CUDA code --  I don't need.)"
Looking for a collection of ipython notebook doing a dataset (in depth) anaylsis.,3,5,False,False,False,learnmachinelearning,1487623054,True,"So I found this two on the internet

* https://github.com/agconti/US_Dollar_Vehicle_Currency/blob/master/US_Dollar_Vehicle_Currency.ipynb

* https://github.com/agconti/kaggle-titanic/blob/master/Titanic.ipynb

I am looking for many  (advanced) analysis like this. If you did something on your own and you could share, that would be great."
Sentiment analysis of financial articles in Polish,4,3,False,False,False,learnmachinelearning,1487645112,True,"Hey guys, I'm undertaking what starts to look like a mammooth project for me. For my bachelor thesis I will be attempting to do sentiment analysis of articles from polish financial newspaper. Currently I'm at about 50% of scraping those articles for my DB. So it's time to start answering the question on how will I attempt the sentiment analysis. 

There are some hurdles from the very start - it doesn't seem there is freely available general sentiment word list, nevermind the dream of a one optimized for financial vocabulary. So dictionary method is off for a bad start - should I pursue it I would need to build the word lists myself. What would be a good way to approach that so that the lists are reasonably built?

If not dictionary method then what? Naive Bayes? How many articles should I get manually classified for the train set? What would be the best practice in manual classification of articles. Random sample of articles for each person that will be marking them + maybe some additional ones that were already classified to see if people agree on their classifications? 

I have tons of questions and probably don't even know what should I be asking and thinking about so if any of you could provide some guidance I would be grateful."
1 month I’m using this proven dating website – I’ve found 3 diffetent girls who agreed for sex with me,0,0,False,False,False,learnmachinelearning,1487647246,True,[removed]
Simple Tutorial on SVM and Parameter Tuning in Python and R,0,3,False,False,False,learnmachinelearning,1487661878,False, 
Looking for a accountability partner / learning buddy to stay on track.,1,2,False,False,False,learnmachinelearning,1487668619,True,[deleted]
Worst Theano performance pitfalls,4,3,False,False,False,learnmachinelearning,1487682786,True,"Hi,

I'm currently working on a highly specialised architecture in Lasagne/Theano. Without going into too much detail the architecture relies heavily on upsampling feature maps from multiple layers and hypercolumns.

One of the biggest issues I'm facing is the performance of the architecture.

I was wondering if anyone had any tips about what things in Theano specifically are known to degrade performance, or what can be done to identify the less performant parts of the network.

Thanks in advance."
Can anyone point out to me resources for learning linear algebra/Probability/information theory for machine learning?,3,5,False,False,False,learnmachinelearning,1487688867,True,Its not like i don't no these subjects but i always feel that i don't know them at a level on which i ll feel confident about them. Are there some books/MOOCs that cover these concepts for machine learning? I tried the deep learning book by ian goodfellow but it ran through these concepts too fast and i had to individually google a lot of things..
"ELI5: ""Training RBM with maximum likelihood""",0,5,False,False,False,learnmachinelearning,1487692375,True,"I understand maximum likelihood, but don't we commonly use CD to train RBM? How do we train RBM with maximum likelihood? Not looking for proof but a simple explanation."
Dimensions: vis x hid or hid x vis?,1,0,False,False,False,learnmachinelearning,1487713428,True,"Assume:

vis - input size

hid - output size

k - mini batch size

 
  
Let's ignore bias for a second. I have noticed that in all tutorials I have come over, the following is used:

W(hid * vis) x(vis * k) = y(hid*k)

 
  
In Tensorflow it's:

x(k * vis) W(vis * hid) = y(k * hid)

 

Does it have something to do with how matrices are stored (column-major/row-major) or does it not matter?

What is standard?

What do you use?"
"Using ML for Classification Problems, understanding results from Azure ML Studio",0,1,False,False,False,learnmachinelearning,1487724901,True,"Hello all,

I recently started playing with Azure ML Studio as a means to try and develop an understanding of basic machine learning concepts and how they worked. I captured some network traffic on one of my lab networks and I than modified the capture file with false traffic that was intended to be obviously bad data. (different subnet) Using several of the tutorials Azure ML studio provided I was able to create two different experiments, one that leveraged Tuned Hyperparameters and one that did not. Once I ran my experiment and reviewed the results, I have struggled making sense of them. Could anyone share some insight into what I'm looking at?

A quick overview of my experiment in Azure ML Studio:  
* PCAP capture converted to CSV as input data, column created to host a label where I provided the value ""1"" to good data and ""2"" to bad data  
* 75-25 stratified split on the labeled data  
* Normalized data fed into ""Tune Model Hyperparameters"" module or directly into ""Train Anomaly Detection Model"" module for the experiment not using ""Tune Model Hyperparameters""
* Output of the ""Train Anomaly Detection Model"" feeding into a ""Score Model""  
* Output of both ""Score Model"" modules (one for One-Class SVM Vector Model and the other for PCA-Based Anomaly Detection Model) feeding into an ""Evaluate Model""  
* Pictures are the output of the ""Evaluate Model"" for each experiment  
  
Experiment results in question
http://imgur.com/a/q3JkP

Thanks in advance!"
TWIL (This Week I Learned) - Share something new that you have learned this week!,0,3,False,False,False,learnmachinelearning,1487747681,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
Trying to implement a breadth first search into my genetic algorithm,14,2,False,False,False,learnmachinelearning,1487773168,True,"So my final year project is due on Friday and I am really stuck on a problem I can't overcome. I have been learning about machine learning (genetic algorithms) for the last year on my own for my thesis. I took code from a book I have been reading and the last step I am trying to complete is implementing a BFS into my fitness function to make the rockets smarter and be able to find the way around the obstacles I have been building. Would someone be able to have a look at my Github repository and be able to give me any guidance? I have been trying to add the code from the BFS method in the Rockets to the Fitness function but I'm not sure if I am going about it the right way?

https://github.com/keithmadden/thesis

Any help would be very grateful "
Great course I just took on Unsupervised Learning in Python - highly recommend!,5,12,False,False,False,learnmachinelearning,1487778724,False, 
How unacceptable is it to select a random branch in Decision Tree prediction if a new attribute value is encountered.,4,2,False,False,False,learnmachinelearning,1487786149,True,"I am writing a decision tree trained with the ID3 algorithm from scratch. I wanted to be able to train on and classify continuous data, so I implemented k-means clustering and reduced the range of values of any input training or predicting data.

However, I ran into the problem where an attribute value that was not encountered during training, in a deep node somewhere in the tree, but that exists further up was encountered. All data points with this specific attribute value probably ended up on a different branch of the tree.

So to 'solve' this, whenever an unknown attribute value is encountered for a node, I sent it down a random existing branch.

I get 95.45% accuracy using randomly split 85%-15% training-test data with iris.

Is this an acceptable approach to take or have I gotten something wrong here?

Here's the code: https://github.com/jamalmoir/ml_components/blob/master/ml_components/models/decision_tree.py

Thanks"
"Help me figure out if my project is reasonably doable, and if so, where to begin? (xpost from /r/computervision)",0,1,False,False,False,learnmachinelearning,1487798405,True,[removed]
[Meta] Does anyone else have trouble finding coworkers who are interested in machine learning?,1,2,False,False,False,learnmachinelearning,1487808553,True,"None of my coworkers (~10 ASP.NET/JavaScript devs) have any interest in machine learning. I've tried coaxing them into it but they don't seem to care. Talking about neural nets, to them, sounds like you're trying to talk about quantum physics or something. They have zero interest in machine learning. I believe their plan is to keep making websites until they retire. That seems really strange to me."
"[Webinar]: Machine Learning in a Live Production Environment by Matthew Kirk, author of Thoughtful Machine Learning with Python",0,12,False,False,False,learnmachinelearning,1487845025,False, 
How much difference does CUDA compute capability 3.5 vs 6.1 make when learning RNN's?,0,0,False,False,False,learnmachinelearning,1487862617,True, 
What is the difference between Octave and scikit-learn?,4,7,False,False,False,learnmachinelearning,1487895556,True,"I am new to the realm of machine learning, and from my understanding I will be using these two programs in the near future. Although I have looked up the description for each program, I am still confused as to what the main differences between the two are."
Should we complete the programming assignments in Andrew Ng's ML Course?,11,1,False,False,False,learnmachinelearning,1487902790,True,"Is it really useful because almost nobody uses octave for ml nowadays. 
Most use tensorflow which abstracts all the complex mathematics.
What is the point of doing those assignments?"
Weekly Show-off!,3,6,False,False,False,learnmachinelearning,1487920857,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
Linear Regression: Hypothesis Visualization for more than 2 variables,5,3,False,False,False,learnmachinelearning,1487933061,True,"When there's a single variable x, we can visualize the hypothesis in an X-Y plane (using X axis and Y axis).

When there are 2 variables X1 and X2, we can visualize the hypothesis in a 3D plane (X,Y,Z axis)

What happens when there are more than 3 variables? How can one visualize it?"
Sigmoid function,4,6,False,False,False,learnmachinelearning,1487946315,True,what is the e? and what is the t? in Sigmoid function?
What are some features for reddit posts?,11,0,False,False,False,learnmachinelearning,1487973271,True,"I want to build a shill classifier inspired by this:

https://www.reddit.com/r/technology/comments/5vxxyh/reddit_is_being_regularly_manipulated_by_large/

Would it be possible to classify a post as a shill post?

Based on the andrew ng test of, ""would an expert be able to do this?"" I honestly don't think it's possible, and I'm nearly certain that I would have to build the data set myself, since crowdsourcing it would most likely lead to political bias unless I got an unbiased, large amount of participants and used some sort of context tree-esque scoring system.

thanks everyone :)"
"Weekly Scrum Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",4,5,False,False,False,learnmachinelearning,1488006847,True,"Let's have a scrum meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
Avery,0,0,False,False,False,learnmachinelearning,1488019333,False, 
Some doubts about GMM clustering for Speaker Recognition [Noob],5,1,False,False,False,learnmachinelearning,1488050495,True,"I am a newb to Machine Learning and have taken up a Speaker Recognition project for this semester (and deadlines are fast approaching eek). I am currently using Gaussian Mixture Model from sklearn to fit the MFCCs I have extracted from some audio dataset that I found online. 

[1]. What do ""components"" mean in a GMM? I understand that it means the number of Gaussian distributions that make up a GMM but how is that applicable to clustering?

[2]. How do I decide the number of components for a model I want to fit? And how should the co-variance matrix be (full, diag etc)? Is this trial and error? 

[3]. What exactly is the output for the GMM predict function using sklearn? I'm getting a component number as the output but I have no idea how to interpret it. 

Please help :]"
How one should read Deep Learning by Ian Goodfellow ?,0,1,False,False,False,learnmachinelearning,1488052477,True,[removed]
How to display a sequence of up to 5 digits?,0,1,False,False,False,learnmachinelearning,1488054301,True,[removed]
Have I used RNN-LSTM model correctly?,2,0,False,False,False,learnmachinelearning,1488065867,True,"Hi,

I would like to validate that my use of an RNN-LSTM model is correct. I am new to RNN and am still not confident with its application.

I have a Jupyter notebook on GitHub here -> https://github.com/ReeceRobinson/datascience/blob/master/notebooks/Audio%20Detection/9%20-%20RNN%20Analysis.ipynb

This notebook includes all my work and explanation of what I am trying to achieve. To summarise I want to train a model to detect a time-series of 4kHz beeps that my washing machine emits when it has completed a cycle. I want to use that detection in my home control system for alerting etc.

My trained model appears to work but I am suspicious that I may have made an error.

Can someone please verify I have not made a mistake in my approach or point out the obvious error(s) if any in my assumptions on how RNNs work?

Cheers
Reece"
Proper Normalization for Test Data?,1,5,False,False,False,learnmachinelearning,1488072515,True,"What is the proper way to normalize data for a neural network?

I typically do the following:

    training_data -= mean(training_data)
    training_data /= std(training_data)

    test_data -= mean(training_data)
    test_data /= std(training_data)

The important parts being that I am reusing the mean, and standard deviation from the training set. This seems like the right way to do it, as we are assuming that the test and training data are from the same distribution.

I realized that I just do this as a kind of convention, because I learned it in a class, and I don't really know the theoretical basis for it. Searching has only really given blog posts and other non-rigorous sources.

No one ever really mentions their data preprocessing in papers I read either, which I find odd as it makes it difficult to reproduce results.

So, first, am I normalizing my data correctly? And second where can I find a rigorous treatment of this topic?
"
Can the size of a Neural Networks training data cause it to fail to complete training?,11,3,False,False,False,learnmachinelearning,1488075991,True,"Hello, I don't know if this kinda of post is welcome here but I couldn't really find a concrete answer on google, and I am very new to machine learning in general so if this is a dumb question I apologize.
I am a 17 (not very good) coder and I finished construction of my first neural network yesterday, its goal is to play tic-tac-toe, and I think that it is working somewhat. Basically, it runs through its training data and fairly quickly reaches 50-55 percent proficiency on the training data. The data is structured as a variety of board layouts with the best move for that layout being the expected result that is thrown into the backpropigation function.
However, it basically hangs at this number forever. I am using a Sigmoid activation function with a cost function to match, and I am 99.99% sure that those are working correctly. My learning constant is 0.001. The network has 9 neurons in each of its three layers.
I only have 85 training examples for the program, could this be what is causing the network to fail during training? Sorry if I sound like an absolute troglodyte, I self taught most of this and my understanding is more than a little bit spotty."
The 4 Steps of Machine Learning Source: Udacity,0,1,False,False,False,learnmachinelearning,1488084960,False,[deleted]
The 4 stages in Machine Learning (Source: Udacity),16,57,False,False,False,learnmachinelearning,1488085719,False, 
How reliable are CIFAR-10 results for generalization?,2,0,False,False,False,learnmachinelearning,1488109967,True,"I am pretty new to machine learning -- so far I have only followed the Caltech course, which I liked a lot.

I have seen the CIFAR-10 datasets used in a lot of places as a benchmark for how well different learning algorithms perform image recognition. However what I'm confused about is whether we can be sure that these algorithms will generalize well from these results? In the Caltech course the lecturer puts a lot of emphasis on data snooping and the requirement to take it into account.

Here are my thoughts/assumptions:

* CIFAR-10 includes a test-set that is used to benchmark how good a model is
* Initial CIFAR-10 results were not very good, and the models were very simple (but our in-sample error would generalize to out-of-sample with high probability)
* As research progressed more and more complex models were tried which improved in-sample error significantly and gave good results on the test-set
* However, to improve the results on the test-set we explored a lot of models. And these models were explored based on the error on the test-set of previous models.

Does this not mean that we have effectively been data snooping by trying so many different models with a ton of different parameters, and basing our choices on the test-set error? How do we know that new model results will generalize well when they have been picked like this?

Thanks in advance!"
What are the mathematical concept should I learn to get a good hold in Machine Learning and AI??,4,1,False,False,False,learnmachinelearning,1488113825,True,"Hi all I don't know whether I'm posting this in a correct sub, but I'm really want to learn machine learning since I want to get into AI eventually. I know to understand the underpinnings of ML one has to be strong in few maths fundamentals, so what are they ??? Is it Linear Algebra, Integral Calculus or Differentiation ? Please suggest me ???"
Understanding style transfer art with neural networks,0,1,False,False,False,learnmachinelearning,1488166140,False, 
Is there a structure that concatenates features from ALL conv layers in the last hidden layer?,6,0,False,False,False,learnmachinelearning,1488169615,True,"I'm working on a structure as in the title. I apply average pooling on all conv layers, concatenate them, and connect it to the output layer. There are some reasons in the domain knowledge (music) to support this structure and it's working well. I'm wondering if I'm missing some previous paper to cite. "
"[Stupid Math Question] Activation Functions introduce non-linearity, but is ReLU a linear of nonlinear function in itself?",11,1,False,False,False,learnmachinelearning,1488176019,True,"**Typo in title:** a linear OR nonlinear function

Can't edit the title. 

I am for some reason confusing what a linear function is. Go easy on my stupidity please. As per http://cs231n.github.io/neural-networks-1/#actfun it's defined as f(x) = max(0, x)"
Outlier Detection in High-Dimensional Time Series,3,3,False,False,False,learnmachinelearning,1488177586,True,"Since big data is all the rage these days, I've been asked at work to help develop an outlier detection system for streams of environmental data coming from a variety of sensors. Right now we're doing USL/LSL monitoring, but the goal is to capture multi-dimensional outliers and anomalous sequences that nonetheless may be within the normal bounds. The data consists of time-series measurements from T=0 to T=Tmax over a machine cycle, where Tmax is not guaranteed to be consistent from cycle to cycle. The sample period is fairly regular, but some data may be missing.


Time (ms) | V1 | V2 | ... | P1 | P2 | ...
----------|----|----|-----|----|----|----
2 | 0.4 | 0.8 | ... | NULL | NULL | ...
101 | 0.6 | 1.1 | ... | 0.5 | 0.6 | ...
199 | 0.9 | NULL | ... | 0.5 | 0.64 | ...
... | ... | ... | ... | ... | ... | ... 
Tmax | V1(Tmax) | V2(Tmax) | ... | P1(Tmax) | P2(Tmax)


I've spent the past few days taking a deep dive into machine learning literature, and I think I have an understanding of the high-level steps I need to take, but the sheer variety of approaches for each step is a little overwhelming. Right now, my concerns are mainly focused around two steps:

1\. Transform time-series data into point-space data

  * It appears that there are a variety of methods here: DFT, LSSA, wavelet decomposition, polynomial regression, etc. I know that the best way to choose is to evaluate performance against actual data, but is there a recommended ""standard"" method to start with?
    
  * How is correlation between decomposed vectors usually handled? For example, if take a matrix of 3-dimensions x 10000 samples, and decompose each dimension into 20 frequency components, so that the transformed data is a single 60-dimensional vector, is there anything special that needs to be done to account for the fact that each group of 20 dimensions isn't independent?
    
  * How should Tmax be handled? Should it be included as its own dimension? If so, how should it be weighted against the other dimensions?

2\. Identify outliers, and most-significant dimensions

  * From what I can tell, two major approaches seem to be Local Outlier Factor (LOF) and Isolation Forests

  * I have three reservations about the LOF method 1) some sort of dimensionality reduction will be required to avoid the ""curse of dimensionality"". I found a paper on the PINN method [1], which seems promising, but there don't seem to be any implementations that I can find 2) some sort of normalisation will be required to prevent the axis scale from dominating distance calculations, but how do I evaluate what counts as ""dominating""? 3) The LOF seems to be highly dependent on the distance metric chosen. Most implentations seem to use Euclidean distance. However, if spectral analysis is performed in step 1, is Euclidean distance an accurate distance metric in the frequency domain? Is it worth looking for an implentation that uses log-spectral distance?

  * From my limited understanding, the two major advantages of isolation forests are that 1) they have a certain degree of scale invariance because they don't use a distance metric for classification and 2) they have dimensionality reduction ""built-in"" because each tree is constructed from a random sample of dimensions. Is this an accurate characterisation?

  * The largest challenge that I see is identification of which dimensions contributed the most to a datum being considered an outlier. This seems like it potentially would be easier with the LOF method (do an O(n) search in the k-neighborhood of an outlier, projecting each n-vector into (n-1) space and rank dimensions based on which causes the greatest change to the LOF score), but the couple of tools that I've found so far don't support this out-of-the-box. I'm not sure how to even approach this problem with the isolation forest method, which is why I'm still considering LOF as an option.

    I'm also having trouble finding any literature on this problem. The closest I've found is [2], which only discusses anomalies in sequences of discrete symbols. I know it's possible to map continuous data to symbolic data [3], but I'm not sure how it would be applied to multi-dimensional data, or how the performance compares to LOF or isolation forests.

  * Another random thought I had was using either an N-order Markov Model, or an LSTM autoencoder/decoder to calculate the prediction error for each time step, but I am not sure how to account for the variable sampling intervals, the variable sequence length, or the continuous multivariate aspect of the data.

If anyone could point me in the right direction for researching methods, or if anyone has any suggested implementations (I'm sure this is far from a unique problem), that would be very much appreciated. So far I've looked at scikit-learn and Jubatus. I know R is popular for data analysis, but I'm not familiar with the language or with its libraries. I know Amazon offers anomaly detection through [AWS](http://docs.aws.amazon.com/kinesisanalytics/latest/sqlref/random-cut-forest.html), but I need something on-premise (besides the fact that it doesn't analyse which dimensions are anomalous).

Sorry for the long post, but I had a bunch of related questions and didn't want to split them all up individually.

**tl;dr**

* Doing outlier detection for high-dimensional time series data

* What are current state-of-the-art methods for time-series compression/regression?

* What are current state-of-the-art methods for outlier detection, including detecting which dimensions are anomalous?

Thanks in advance.

**Refs**

1\. Finding Local Anomalies in Very High Dimensional Space (de Vries, Chawla, Houle, 2010)
    
2\. Anomaly Detection in Large Sets of High-Dimensional Symbol Sequences (Budalakoti, Srivastava, et al., 2006)

3\. A Symbolic Representation of Time Series, with Implications for Streaming Algorithms (Lin, Keogh, et al., 2003)"
Free eBook: Machine Learning with R - Second Edition [PDF/ePub/Mobi],0,3,False,False,False,learnmachinelearning,1488186222,False, 
[Short Post] Eyes Open: My first 4 months in an ML product team,7,44,False,False,False,learnmachinelearning,1488190627,True,"Hey r/learnmachinelearning

I'm writing this short post in response to [this infographic post](https://www.reddit.com/r/learnmachinelearning/comments/5w8lsf/the_4_stages_in_machine_learning_source_udacity/), *The 4 Stages of Machine Learning*. I basically [replied to it](https://www.reddit.com/r/learnmachinelearning/comments/5w8lsf/the_4_stages_in_machine_learning_source_udacity/de8c4g7/) saying that it encapsulates reasonably well ML in a research context, but not so much the greater problem of production ML systems. People asked me to expand on that so here it is. 

What's my experience with production ML? Pretty limited, but my very short time in it has been eye-opening. I started a year long data engineering internship with Zendesk's ML product team in November 2016. It's the team that posted [*Serving Tensorflow in Production at Zendesk*](https://www.reddit.com/r/MachineLearning/comments/5w64uo/p_serving_tensorflow_in_production_at_zendesk/) recently. Our product is [*Automatic Answers*](https://www.zendesk.com/automatic-answers/). 

#### Getting XX.XX% on a dataset vs. creating a product for users

Perhaps the most important difference between the ML most people here know and production ML at Zendesk is that Zendesk's ML must have *business value*, which means it must offer *value to customers*. Zendesk has a product model, and Automatic Answers must fit into that and drive the companie's growth. Sure ML and AI are really cool, but if you can't get it to be useful to a user then you have nothing. Before Zendesk, I saw ML as ""how can I get this damn network to train and perform on this dataset? The pros have achieved 9X.XX% accuracy."" Now 'doing ML' for the team includes: 

* Managing customer expectations
* Debugging problems end-users face with how the model behaves
* Serving 1000s of models and their predictions on demand to thousands of people
* So. much. UX.

I can't tell you how influential UX seems to be to the success of real-software systems. Your model can be awesome, but your ML system (in a production context) really includes everything the *product* relies on, from the data ingestion system to the end-user UX. If those fail you your model is pointless and your ML system is crippled.


#### more about ML in the real world (again, from what *I've* seen)

Just as it's known that Data Science is really around 20% research and 80% data stewardship, being an ML engineer in production means that your responsibilities extend beyond training models on ready-to-go datasets. You're going to be using them, so capabilities with AWS/GCP, Hadoop/Spark, Tensorflow Serving, Pachyderm, Docker, Data Visualisation, SQL are all very handy. Also, all of a sudden your work becomes part of a wider team, product, and company so it must actually be *reproducible*, *implementable*, *bug-free*, *documented*.  Those four things don't really constrain researchers and at-home ML hobbyists. 

#### Eyes Open 

Realistically, the world of 'open-source and MOOC' ML consists *mostly* of 3 kinds of ML work:

1. Tutorials
2. Implementing ML research papers
3. Personal Projects

Of these, the first two are basically 'follow the steps'. It's certainly not easy but it's not like what's done in industry. The third may or may not involve real end-users and production-ready ML engineering, most don't. You can go along and learn a bunch about ML through doing the above things and still be wholly unsuccessful at production ML engineering, which really does require you put on different hats (product management, data engineer, reliability engineer, OPS, Tester, etc). 

#### What's heartening to me

I should remind that I am not an *ML* Engineering Intern, I'm a Data Engineering intern. Though part of my work is solving problems peculiarly associated with and created by ML systems, and it's pretty awesome. Though I'm not sitting there with IPython and Tensorboard open, my work falls within what I would call *ML Engineering*. It's a much broader problem than the already massive problem that is Machine Learning research, and it stands on its own as a pretty great (under-exposed) area of software engineering. I likely could not have gained an internship in ML research as an undergrad, but being a data engineer in an ML team is pretty much the next best thing. Further, it seems the norm amongst ML teams to encourage cross-fertilisation of skills so if you're in the ML team you're bound to be up-skilling in ML. **If you don't have/want-to-get a PHD, but love ML, seriously consider shaping yourself as a Data/ML engineer. You'll be in high-demand.**

#### Learn more about real-world ML

There really isn't enough material out there on 'real-world ML'. The field is still quite new, and people are still finding their feet. Most of the good ML engineering stuff comes, unsurprisingly, out of Google. They've been doing ML in production for a long time now and on a massive scale, so they've come face to face with it's unique challenges. 

Properly explaining how big the problem of production ML is would take more than a few books, and so far no one's even written one book on it. Nevertheless, here are some things I've read which give at least some insight into production ML and its teams.

* [Google's M. Zinkevich's ""Rules of Machine Learning""](https://github.com/thundergolfer/google-rules-of-machine-learning)
* [Hidden Technical Debt in Machine Learning - Google](https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf)
* [Google's hybrid approach to research - P. Norvig](http://norvig.com/cacm-hybrid.html)
* [Detecting Adversarial Advertisements in the Wild - Google](https://www.eecs.tufts.edu/~dsculley/papers/adversarial-ads.pdf)
* [Scaling Big Data Infrastructure: The Twitter Experience](http://www.datascienceassn.org/sites/default/files/Scaling%20Big%20Data%20Mining%20Infrastructure%20-%20The%20Twitter%20Experience.pdf)
"
Visualising a 3D classifier in Python,1,0,False,False,False,learnmachinelearning,1488194371,True,"I have a neural net doing classification with 3D inputs, I'd like to visualise it somehow on a 2D plane. Are there any standard methods/libraries to deal with this? I was thinking about averaging over one of the parameters and plotting decision boundaries with mlxtend, but it seems to be extremely computationally expensive."
Neural Net learning difference between 1 and 0? Check. Neural Net learning to recognise handwritten digits? No... No check at all.,11,3,False,False,False,learnmachinelearning,1488210201,True,"Hey guys, first time poster here. I was trying to learn the back propagation algorithm to train a basic feed forward neural network recently, and that ended in me making my own little library for neural networks. I did this solely for practice and to better my understanding of machine learning, and so the code sacrifices performance for readability and simplicity (based on my view at least). To get this far I’ve heavily utilized Matt Mazur’s example found in this link: 
https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/

I have also tested my neural network with his example and it works just like his. Additionally I used this library to teach an ANN how to play Tic Tac Toe, and got questionable results, however it was clear that the network was learning something. For example the network did try to win, and definitely knew that it needs to get 3 in a row to do so, however sometimes it places an O on a spot that was already taken…

Now I am trying to get a neural network to recognize hand written digits using the mnist dataset. So I downloaded the dataset in this link:
http://deeplearning.net/tutorial/gettingstarted.html
(mnist.pkl.gz)
and am currently trying to teach my neural network to recognize these digits.
My network has an input layer of 784 neurons (one for each pixel), a hidden layer of 800 neurons, and an output layer of 10 neurons, one for each number. The issue I’m having is that no matter how much I train it, the output of each neuron is always 1.0.

The reason I told you guys about Matt Mazur’s example and the Tic Tac Toe bot was to prove that it works, at least somewhat. However those are all very small neural nets that are easy to fit. Clearly my code breaks down as soon as you get into larger ones, with hundreds of neurons per layer.

The GitHub repo with all of the code for the library and my version of Matt Mazur’s example can be found here: https://github.com/Shoop123/neural_network_library
I have also commented the back propagation method in the neural_net.py file so that its easier to look at for anyone.

Here is the structure of the library (please let me know if I’m using any terms incorrectly):

(the library basically consists of 3 files: neuron.py, layer.py, neural_net.py)

1) Neuron class (neuron.py) that has weights for that neuron (with the logistic activation function since so far there is no support for any other one)

2) Layer class (layer.py) that has a list of neurons for that layer and a bias neuron (for now, each layer can have only one bias)

3) NeuralNetwork (neural_net.py) class that randomizes the weights for each neuron and creates them, assigning each neuron to its layer

4) The “train” method in the NeuralNetwork class goes through each training case once and performs stochastic gradient descent; the “train_batch” does the same but with full-batch gradient descent, and the “train_mini_batch” does the same but with mini-batch gradient descent.

5) The “run” method just does a forward pass through the neural net.

Let me know if you have any more questions about the code!
Thanks in advance for reading all of this!"
Is this how you set up Multi-label classification?,0,0,False,False,False,learnmachinelearning,1488223455,True,[deleted]
Question regarding linear SVM and iris data set,1,1,False,False,False,learnmachinelearning,1488227371,True,"The iris data set contains three species of the iris flower. I am given to understand that a linear SVM can be applied to this dataset to classify the three species.

But I was under the impression that the linear SVM method simply took the training set, classified into TWO categories (not three, like the iris set), and finds a separating hyperplace between these sets (or a best approximation).

Where is my confusion? How can a linear SVM be used on the iris set?

Thanks!"
Maximize your Learning— How to Apply Machine Learning Practices into your own life.,1,27,False,False,False,learnmachinelearning,1488239282,False, 
Machine Learning From Scratch: Bare bones implementations in Python,7,31,False,False,False,learnmachinelearning,1488243893,False, 
Statistical test that data is modelable?,2,3,False,False,False,learnmachinelearning,1488294524,True,"I have input and output data y(x), where x and y are vectors. I am trying to determine if the information in x is incomplete and thus cannot be used to model y. My idea is that x is complete if I show that there is a correlation between similarity in x samples and similarity in y samples. I think I can do this by calculating RMSE between random pairs of x and their corresponding y, and then measuring the Pearson correlation coefficient of the RMSE pairs. Correlation in this case would mean that if two x vectors are similar, then their corresponding y vectors also tend to be similar. Is this a good way to go about this? Is there a general way to determine that data is modelable?"
How do you solve this problem detects and corrects incorrect usage of English articles in a given text?,3,2,False,False,False,learnmachinelearning,1488296304,True,I am looking for the approach you would use to solve this problem.
"I seem to be having a strange problem with my network, could anyone test this data for a similar outcome?",1,1,False,False,False,learnmachinelearning,1488338057,True,"Hello! I constructed my first little network based on this guide here:

https://www.doc.ic.ac.uk/~sgc/teaching/pre2012/v231/lecture13.html

Now, when I do a single run of the data from this article, inputting 10,30,20 into the network and checking to see how my weights have changed, my network matched up perfectly with the table provided and I went out upon my way attempting to build a more advanced network based on what I learned. However, recently I went back to run the test data again and I encounter a strange problem, and I don't know if it is the data, or my network that is acting up.

If I have the network run infinity with the same input (10,30,20), I assumed that eventually the first output nodes output would approach one and the second would approach zero ad-infinitum, since there is only one ""training example"" and it would be reasonable to conclude it would behave that way...at least I think?

What actually happens is that the first 20-odd cycles of the network behave as expected, and then, within one cycle, both output nodes rapidly drop to a value slightly above 0.5 and decrease by minuscule amounts seemingly forever. I have no idea why. Have I designed my network wrong or is this simply a result of the data? "
New NLP Project - Should I scrap sites or manually build my corpus to start?,1,6,False,False,False,learnmachinelearning,1488343097,True,"I am new to Machine Learning and am reasonably skilled at Python.  I decided to start with one of my first learning projects being a NLP project.  The idea is I would be looking at a variety of blog posts both to classify them and determine their content, but also to determine their similarity to other existing articles.  I have an idea where to start, but I was curious as to which approach might be better from a learning perspective.  

Option 1: Spend time learning to build web crawlers to get data from multiple sites? 

Option 2: Spend several hours downloading and formatting content and building individual text files (probably still less time then it would take to do the scraping).  

The idea of trying to figure out how to scrap data from dozens of different sites seems very daunting right now, but I was curious if I might find it is a lot easier than I think and be a great learning experience.  Or just get the data I need and start digging into NLP right away? "
"Hi,",2,1,False,False,False,learnmachinelearning,1488344870,True,"My model using convolution neural net with data augmentation and batch normalization is giving pretty good result (accuracy over 90) but same exact model on CIFAR-10 gives poor accuracy ~76%. Any idea? Is it that my model is overfitting on MNIST data?



"
TWIL (This Week I Learned) - Share something new that you have learned this week!,1,4,False,False,False,learnmachinelearning,1488352075,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
"When using a network pretrained in ImageNet, is it better to reshape images, or pad them with zeros?",2,1,False,False,False,learnmachinelearning,1488405628,True,"I have images of different sizes, with width and height of maximum 256 pixels. Is it a better idea to reshape everything to (256, 256), or to pad the smaller images with zeros? Some of those images are as small as (256, 60) / (60, 256), so I'm afraid that reshaping will completely destroy any structure.

I'm using Inception V3 / ResNet50

**Edit: the title should be: ""...using a network pretrained ON ImageNet...""**"
Bias-Variance Tradeoff in Machine Learning,5,18,False,False,False,learnmachinelearning,1488409198,False, 
First-time Access to an Asset - Is it Risky or Not?: A Machine Learning Question ·,0,1,False,False,False,learnmachinelearning,1488414824,False, 
What are the differences between Batch Renormalization and Streaming Normalization in Neural Networks?,0,2,False,False,False,learnmachinelearning,1488415759,False, 
Two basic approaches to building a model - which is more useful?,0,1,False,False,False,learnmachinelearning,1488418607,True,"I have a problem where I have to take a complex multivariate function and, using randomized algorithms, try to build a basic predictive model for it. In general, there seem to be two schools of thought for how to go about doing this:

1. Do an initial trial with white noise, and see how well your trial performs. Then, ditch all but ""the best"" results. Then, try to reverse-engineer a model from that. Then try another test. Then, try to reverse-engineer a model from that. Repeat until you're happy.

2. Don't ever try to figure out ""why,"" or generate any hypotheses. Instead, generate a bunch of candidate models using a bunch of random methods -- possibly using recursion if need be, meaning you end up generating a bunch of random model-generating methods, random model-generating-method-generators, and so on. Then, go do a trial and see which ones perform the best.

I'm wondering how well these two approaches work in practice. The first one involves an analysis step where you try to figure out ""why"" things work, the second involves a tower of recursion in which you just try out like a billion ways of doing things. Is there a name for these two approaches?"
"Getting started with Machine Learning for a ""battle royale"" betting game",2,2,False,False,False,learnmachinelearning,1488419605,True,"I'm fairly new to ML, having gone through Andrew Ng's Coursera course. I'd like to apply what I've learned to a ""battle royale"" kind of betting game.

The idea is that you pit 4 fighters, each with different stats (strength, defense, luck, etc...) against each other in a Roman Colosseum-like arena. Each fighter is assigned odds of winning (like in horse betting) at the start, which change throughout the day.

There are 3 arena matches going in simultaneously, each with different fighters.

Spectators may bet on 1 fighter per arena, so one might bet on ""Jack"" in Arena 1, ""Gladius"" in Arena 2, and not bet on Arena 3. This counts as one ""betting set"". They can make up to 5 ""betting sets"" per event.

**If I wanted to have an ML algorithm try to predict the 5 ""betting sets"" that result in the highest profit, where would I start?**

If my understanding is correct, this would be some sort of multi-class classification problem(?)

Which algorithms would be a good start to look at? Neural nets? SVM?

***
Edit - A small example:

Suppose a battle royale event is being held. The arenas have the following fights, with fighters and their starting odds ((n) meaning they have a n-to-1 chance of winning) :

* Arena 1: Jack (3) vs Caesar (2) vs Brute (3) vs Locke (8)
* Arena 2: Gladius (2) vs Luna (10) vs Sera (15) vs Leon (6)
* Arena 3: Theo (4) vs Dragar (2) vs Ironhead (2) vs Clegor (10)

A spectator can make up to 5 betting sets per royale. For example:

1. Jack + Gladius + Ironhead (3\*2*2 = 12-to-1 total odds)
2. Jack + Gladius + Dragar (3\*2*2 = 12)
3. Jack + Dragar (3*2 = 6)
4. Jack + Luna (3*10 = 30)
5. Caesar + Sera + Dragar (2\*15*2 = 60)

Suppose the actual winners are Jack, Gladius, and Dragar. That means the spectator correctly predicted the winners on betting sets 2 and 3, and so their total winnings is 12+6 = 18 times their bet.

I have about 2000 training examples from past royales to use as data. Is there a ML algorithm that can pick the 5 betting sets in a way that will lead to a higher profit in the long run?"
How to change careers and become a data scientist - one quant's experience,5,19,False,False,False,learnmachinelearning,1488422462,False, 
"I've started a blog about ML and music. The first post ""MNIST – the totally non-clickbait beginnings""",5,11,False,False,False,learnmachinelearning,1488451723,False, 
[Webinar]: 'How to Win Machine Learning Competitions?' by Marios Michailidis (Former Kaggle #1),0,20,False,False,False,learnmachinelearning,1488461618,False, 
https://blog.metaflow.fr/tensorflow-how-to-optimise-your-input-pipeline-with-queues-and-multi-threading-e7c3874157e0#.gwpgs7m3w,1,1,False,False,False,learnmachinelearning,1488473877,False, 
Help to compare and find patterns in data,0,1,False,False,False,learnmachinelearning,1488484396,True,[removed]
The Challenges of Building a Predictive Churn Model,0,5,False,False,False,learnmachinelearning,1488499572,False, 
How to avoid network becoming painstakingly slow as it comes closer to convergence?,6,3,False,False,False,learnmachinelearning,1488513106,True,"Hello, I am new to the machine learning field and I am far from being fluent in this practice so please forgive any blatant stupidity. Anyways, I've been working on my first feedforward neural network for a while now but I seem to have run into a problem.

My network is a standard feedforward network with three layers each with nine nodes, using Sigmoid activation (I tried softmax but it didn't seem to work out very well.) The networks goal is to play tic-tac-toe and makes its move based on whichever output node throws the highest Sigmoid value. It is fed training examples that are randomly shuffled, each example is a board state with X=1,O=-1, and a blank space being zero. The expected value that is fed into back-propigation is an array with every expected value being zero except for the intended move, which is one. 

The problem I encounter is that the neural networks train time screeches to a halt as it gets closer to its intended output. At around 40-50 percent efficiency with the training examples, the error becomes far to small and the weight adjustments shrink to the point where I can run it all night and it will hardly advance. The mean squared error is dropping, it is just dropping so, so slowly that it takes hours for anything to actually change in how the network plays. I tried implementing a crude form of momentum but it didn't seem to help much. How do I avoid this problem? "
Weekly Show-off!,1,4,False,False,False,learnmachinelearning,1488524933,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
Minimal neural networks library developed for educational purposes,3,19,False,False,False,learnmachinelearning,1488549464,True,"I am developing a pure Python and NumPy implementation of a neural networks library for educational purposes.

It focuses on readability rather than speed and thus aims at providing an easily understandable toy code, as opposed to the real production grade libraries.

https://github.com/inejc/nnlib"
Implementing batches in tensorflow question,1,5,False,False,False,learnmachinelearning,1488583147,True,"I'm pretty new to using tensorflow, and I'm having a difficult time figuring out how to implement mini-batch training into my convolutional network. I have 7500 training images (80x240) and 2500 testing images. When I try to train on my CPU, my comp freezes up to the point where I cannot even move my mouse. When I try to train on my GPU, I eventually get this error:

    ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[7500,40,120,32]
         [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](_recv_Placeholder_0/_3, weights_0/read)]]

So I looked back into my notes (from Udacity) and decided to try and implement this function:

    def batches(batch_size, features, labels):
        X_batch = []
        y_batch = []
    
        sample_size = len(features)
        for start_i in range(0, sample_size, batch_size):
            end_i = start_i + batch_size
            batchX = features[start_i:end_i]
            batchy = labels[start_i:end_i]
            X_batch.append(batchX)
            y_batch.append(batchy)
        return X_batch, y_batch

However, when I go to run the session in tensorflow, I get this error:

    InvalidArgumentError (see above for traceback): Incompatible shapes: [32,20] vs. [128,20]
         [[Node: mean_squared_error/Sub = Sub[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""](Relu_4, _recv_Placeholder_1_0/_1)]]

I experimented with different batch_size parameters. Right now, it's set at 128. When I change it to 100, for example, the error changes to this:

    InvalidArgumentError (see above for traceback): Incompatible shapes: [25,20] vs. [100,20]
         [[Node: mean_squared_error/Sub = Sub[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""](Relu_4, _recv_Placeholder_1_0/_1)]]

Any thoughts on how I can get batches working in tensorflow? Below is my entire section of code. Note that loc_X_test and loc_y_test are my testing examples, and loc_X_train and loc_y_train are my training examples. The x's are 80x240 images, and the y's are arrays of 20 (location data from where digits are in some picture).

Any help is appreciated. Thanks!

    def batches(batch_size, features, labels):
        X_batch = []
        y_batch = []
    
        sample_size = len(features)
        for start_i in range(0, sample_size, batch_size):
            end_i = start_i + batch_size
            batchX = features[start_i:end_i]
            batchy = labels[start_i:end_i]
            X_batch.append(batchX)
            y_batch.append(batchy)
        return X_batch, y_batch
    
    loc_X_train = count_X_train.reshape(7500, 80, 240, 1)
    loc_X_test = count_X_test.reshape(2500, 80, 240, 1)
    
    
    #first mnist tf network for the simple 28x28 images
    tf.reset_default_graph()
    
    learning_rate = 0.01
    epochs = 10
    batch_size = 100
    test_valid_size = 128
    n_input = 19200
    n_classes = 20
    n_hidden_layer = 250
    n_hidden_layer_2 = 200
    dropout = 0.75
    
    from time import perf_counter as timer
    start1 = timer()
    
    with tf.device('/gpu:0'):
        weights = {""conv_layer"":tf.Variable(tf.random_normal([5, 5, 1, 32]), name = ""weights_0""), #[filter height, filter width, color channels, k_output]
                   ""conv_layer_2"": tf.Variable(tf.random_normal([5, 5, 32, 64]), name = ""weights_1""),
                   ""dense_layer"":tf.Variable(tf.random_normal([20*60*64 ,1024]), name = ""weights_2""),
                   ""hidden_layer"":tf.Variable(tf.truncated_normal([1024, n_hidden_layer_2]), name = ""weights_3""), 
                   ""output_layer"":tf.Variable(tf.truncated_normal([n_hidden_layer_2, n_classes]), name = ""weights_4"")}
    
        biases = {""conv_layer"":tf.Variable(tf.random_normal([32]), name = ""bias_0""), 
                  ""conv_layer_2"": tf.Variable(tf.random_normal([64]), name = ""bias_1""),
                  ""dense_layer"": tf.Variable(tf.random_normal([1024]), name = ""bias_2""),
                  ""hidden_layer"":tf.Variable(tf.zeros(n_hidden_layer_2), name = ""bias_3""), 
                  ""output_layer"":tf.Variable(tf.zeros(n_classes), name = ""bias_4"")}
    
        x = tf.placeholder(""float"", [None, 80, 240, 1])
        print(x)
        y = tf.placeholder(""float"", [None, n_classes])
        print(y)
        keep_prob = tf.placeholder(tf.float32, shape = ())
        print(keep_prob)
    
        #_x = tf.reshape(x, [-1, 80, 240, 1])
    
        conv_layer = tf.nn.conv2d(x, weights[""conv_layer""], strides = [1, 2, 2, 1], padding = ""SAME"")
        conv_layer = tf.nn.bias_add(conv_layer, biases[""conv_layer""])
        conv_layer = tf.nn.relu(conv_layer)
        conv_layer = tf.nn.max_pool(conv_layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding = ""SAME"") #ksize --> size of the filter
        print(conv_layer)
    
        conv_layer_2 = tf.nn.conv2d(conv_layer, weights[""conv_layer_2""], strides = [1, 1, 1, 1], padding = ""SAME"")
        conv_layer_2 = tf.nn.bias_add(conv_layer_2, biases[""conv_layer_2""])
        conv_layer_2 = tf.nn.relu(conv_layer_2)
        conv_layer_2 = tf.nn.max_pool(conv_layer_2, ksize=[1, 2, 2, 1], strides = [1, 2, 2, 1], padding = ""SAME"")
        print(conv_layer_2)
    
        dense_layer = tf.reshape(conv_layer_2, [-1, weights[""dense_layer""].get_shape().as_list()[0]])
        dense_layer = tf.nn.relu(tf.add(tf.matmul(dense_layer, weights[""dense_layer""]), biases[""dense_layer""]))
        dense_layer = tf.nn.dropout(dense_layer, keep_prob)
        print(dense_layer)
    
        #fully connected relu layer
        layer_1 = tf.add(tf.matmul(dense_layer, weights[""hidden_layer""]), biases[""hidden_layer""])
        layer_1 = tf.nn.relu(layer_1)
        print(layer_1)
    
        layer_2 = tf.add(tf.matmul(layer_1, weights[""output_layer""]), biases[""output_layer""])
        layer_2 = tf.nn.relu(layer_2)
        print(layer_2)
    
        #loss and optimizer
        cost = tf.losses.mean_squared_error(predictions = layer_2, labels = y)
        optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cost)
    
        #accuracy
        correct_prediction = tf.equal(tf.argmax(layer_2, 1), tf.argmax(y, 1))
        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
    
    
    #print results
    init = tf.global_variables_initializer()
    
    save_file3 = './train_model3.ckpt'
    saver = tf.train.Saver()
    
    config = tf.ConfigProto()
    config.gpu_options.allow_growth = True
    
    with tf.Session(config = config) as sess:
        sess.run(init)
    
        for epoch in range(epochs):
            total_batch = int(7500/batch_size)
            X_batch, y_batch = batches(batch_size, loc_X_test, loc_y_test)
            for i in range(total_batch):
                sess.run(optimizer, feed_dict = {x: X_batch[i], y:y_batch[i], keep_prob:dropout})
    
            #sess.run(optimizer, feed_dict = {x: loc_X_train, y:loc_y_train, keep_prob: dropout})
    
        saver.save(sess, save_file3)
        print("""")
        print(""trained model saved"")
    
        #calculate test accuracy
        test_accuracy = sess.run(accuracy, feed_dict = {x:loc_X_test[:test_valid_size],
                                                       y:loc_y_test[:test_valid_size], keep_prob:1.})
    
    
    
        print("""")
        print(""testing accuracy: {}"".format(test_accuracy))
    
    end1 = timer()
    print(end1 - start1)"
"Weekly Scrum Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",2,2,False,False,False,learnmachinelearning,1488611213,True,"Let's have a scrum meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
help with python Recommender System,5,8,False,False,False,learnmachinelearning,1488623922,True,"Hello everybody,

I'm trying to apply the methods taught by Andrew Ng in Machine learning Course using python (I acquire the python version of the exercises https://github.com/kaleko/CourseraML), to a different dataset. Specifically I'm trying to build a Recommender System for books based on the Book-Crossing Dataset (http://www2.informatik.uni-freiburg.de/~cziegler/BX/). One of the hold-backs in this process is the size of the data set. Even after some exploratory data analysis (EDA), it is still almost too much for the computational power I posses. How can one tackle this kind of problems?  Another thing is that I 'm not sure if I have implemented the commands in the best possible way for speed and accuracy.Finally I would appreciate an overall review and suggestions of what I'm doing wrong and how can I improve the system and my skills. 

You can get the code here ' https://github.com/PascPeli/BooksRecommender.git '. Thank you in advance for your time!
"
"A comprehensive list of pytorch related content on Github, such as different models, implementations, helper libraries, tutorials etc.",0,21,False,False,False,learnmachinelearning,1488649974,False, 
"Using memory from humans playing to ""bootstrap"" DQN networks memory?",1,4,False,False,False,learnmachinelearning,1488700955,True,"Hopefully this makes some sense, but I'm wondering if anyone has any experience using human playthroughs to prefill part of a DQN networks memory in order to sort of push it in a successful direction faster

For example have someone play a basic game of breakout a few times, fill the memory with those frames, run experience replay on that, then train the network as you normally would

Any thoughts on this would be really appreciated, thank you!"
[CNNs] Speeding up convergence,4,3,False,False,False,learnmachinelearning,1488705780,True,"Hello :)
I am currently trying to use CNNs on my GTX1060. The problem is now that while my networks converge and are not yet overfitting, it takes quite some time to learn. (I only train for 10 hours at a time right now, because I want to try many different prototypes)
Now what are current techniques for speeding up learning/convergence. I would not matter to me, if validation becomes worse as I do not overfit at all right now.
For reference: I am speaking about CNNs with 5 - 20 layers and between 10 and 100 million learnable paramters. 

I already tried batch normalization which helped. Also a big impact was using residual units, but mainly at the beginning of training. The loss would become good very fast, but further learning would be as slow as a network without res-units.

Are there more techniques or a guideline how to speed up learning?"
Changing activation function ruins my recognization rate - please help me,0,1,False,False,False,learnmachinelearning,1488729608,True,[removed]
Help understanding CNN,0,1,False,False,False,learnmachinelearning,1488740320,True,[removed]
Learning From Scratch,10,16,False,False,False,learnmachinelearning,1488740723,True,[deleted]
Splitting the dataset into batches with tensorflow/python,1,2,False,False,False,learnmachinelearning,1488746710,True,"I have a dataset of images as a Numpy array. (Number of images, length, width, colour range) I would like to split it to batches and feed to tensorflow. What is the good way to do it?"
Siamese cnn to get similair fashion apparels,11,6,False,False,False,learnmachinelearning,1488792999,True,"Hi,

I am working at a fashion webshop as a back-end programmer, the webshop has around 150k different products all related to fashion.
My boss asked me to look into a search function with images. So I have read some papers on comparing images to images and I have found a lot of AI approaches which got me interested, currently the most prommising one is a siamese neural net that can find a similair image with only 3-4 images per product.

But I am a bit lost on where to start and how long this would take me as I am someone who is not that great with maths and machine learning for that matter, can you guys give me some pointers on where to go?

Current idea is to go with TensorFlow or Caffe to build a siamese neural net to one shot recognize fashion apparels.

What my boss wants in the end is that a user can upload an image to our website which then gets the exact or similair products from our database.
What would be the best AI solution for this? we have about 2-5 images per product.

Thank you."
How to encode an ip address and user agent as a feature?,7,3,False,False,False,learnmachinelearning,1488818332,True,"Firstly, I'm new to playing with ML, so please let me know if I'm off with anything :)

I'm trying to build a model that can detect irregular download activity of a bunch of files.

Considering that a download can either be regular or not regular, I'm looking to use a classification model (Any suggestions for which one? I have a bit over 1 million pieces of training data to use).

Features to use

* Time since last download (from the same ip address in seconds) (an integer, easy).

* ip address - convert to an integer? What kind of range is practical though to have any meaning?

* User agent - Some kind of tokenisation??

Thanks for all your help!"
Using machine learning to generate design documents,6,3,False,False,False,learnmachinelearning,1488821433,True,"Beginner here. How would I go about using machine learning to generate a simple set of design documents (pdfs) from a set of values in a spreadsheet? I already have hundreds of sets of documents and their corresponding spreadsheet values, how would I go about ""showing"" the computer what a set of values should translate into (such as the address value should go in a specific spot in the title block)?"
"Training/Validation loss at nan, Validation accuracy at 0.00015",1,6,False,False,False,learnmachinelearning,1488823786,True,[deleted]
Trouble getting a basic value network working,1,5,False,False,False,learnmachinelearning,1488829481,True,"Hey all, so I'm trying to make a simple network to predict the value at each tile for a 4x4 tile game. Right now I'm just trying to train it so that the first tile has a value of 1 and the rest have a value of 0, however when I try to train it the network has the same value for every tile

My network in Keras

    model = Sequential()
        model.add(Dense(164, input_shape=(input_size,), activation='relu'))
        model.add(Dense(150, activation='relu'))
        model.add(Dense(1, activation='linear'))
        model.compile(loss='mse',
                      optimizer=SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True))

And the simple code I'm using to zero it out and then try to train it so that the first tile has a value of one

    print ""Zeroing...""
    for y in range(0,200):
        for x in range(1,17):
            tempstate = to_onehot(input_size, x-1)
            tempstate = np.reshape(tempstate, [1, input_size])
            agent.critic_model.fit(tempstate, np.reshape(0, [1, 1]), nb_epoch=1, verbose=0)
    for x in range(1,17):
        tempstate = to_onehot(input_size, x-1)
        tempstate = np.reshape(tempstate, [1, input_size])
        print(""{0:.3f}"".format(agent.critic_predict(tempstate)[0][0])),
        if x%4 == 0:
            print
    print ""Testing...""
    for y in range(0,200):
        for x in range(1,17):
            tempstate = to_onehot(input_size, x-1)
            tempstate = np.reshape(tempstate, [1, input_size])
            reward = 0
            if x == 1:
                reward = 1
            agent.critic_model.fit(tempstate, np.reshape(reward, [1, 1]), nb_epoch=1, verbose=0)
    for x in range(1,17):
        tempstate = to_onehot(input_size, x-1)
        tempstate = np.reshape(tempstate, [1, input_size])
        print(""{0:.3f}"".format(agent.critic_predict(tempstate)[0][0])),
        if x%4 == 0:
            print

The zeroing works fine, however after trying to train it so that the first tile has a value of one it believes that every tile has the value `0.042`

I'm a bit of a noob at this so any and all help is hugely appreciated, thank you!"
Need tips on buying a gpu,8,5,False,False,False,learnmachinelearning,1488837145,True,"I want to buy a GPU to do deep learning experiments.

I'm particularly enthused with the Atari Deep Mind paper.

I'm thinking what I want is an 8GB Cuda-compatible GPU. I read a blog post that said a lot of memory is required to hold training data... But I've done some searching and it was suggested that maybe I want a multi-GPU setup instead?

Like perhaps 3x 2GB Cuda-compatible GPUS, which I think I could get for a comparable price (?), so I can run multiple experiments at once and get a quicker grasp or something.

This is a slight aside, though it might be helpful for you to know about who I am:

I'm a Math and CS graduate (as in Bachelor's degrees) looking for a new job, are there any decent jobs out there for people like me? How can I tailor my Deep Learning research/experience to help me get a job in this exciting field? Does it require a PhD like every job posting says? Will I just have to wait until I get there?"
Simple Lasso Regression Question,4,3,False,False,False,learnmachinelearning,1488863982,True,"Hello, I'm pretty new to understanding statistics in the context of machine learning and computational statistics and was wondering if someone could help me with a simple question.

How does the choice of the regularization parameter affect the result of Lasso regression? 

I don't think I'm following the material here and every google search I try leads to various methods for choosing the regularization parameter and how those methods differ, but nothing explaining the impacts of the parameter itself."
Toy data set for ConvNets ? (for teaching),6,6,False,False,False,learnmachinelearning,1488878933,True,"Hi Reddit,
I am looking for a simple data set (eventually synthetic) to be used in a ML class. The idea is to find an as-simple-as-possible data set that a MLP would fail to classify but a ConvNet would succeed. By simple I mean with a low number of classes (2 ?). Ideally the ConvNet would be also simple i.e. composed of a low number of filters that once learned would be easy to interpret by students.
I am looking for an equivalent of the 2-spirals problem (that demonstrates the capability of a MLP) but for a ConvNet.    "
Developing a Model for Mass Spectrometry. Several Questions,3,2,False,False,False,learnmachinelearning,1488890711,True,"Hi guys. This seems to be a bit too long for ELI5, but I bet someone could help me out.

For my bachelor thesis I have to build a deep NN, that trains plots of mass spectrometry as seen [here](https://www.pic-upload.de/view-32784808/index.png.html) as the green plot (200 Datapoints saved into `train_x` and `train_y`). Eventually it will have trained for several different substances and has to calculate the ratio between two or more substances out of one plot.

Since I'm fairly new to ML I'm getting confused rather quickly by the vast amount of information available. 
I figured since I'm trying to train a plotted function (i.e. gaussian function or muliple gauss functions overlapping) my problem is of a linear regression one.

I am working with Python 3.5 with the lib Theano where I mostly build symbolic expressions to construct the NN almost from scratch. Assume I have a single hidden layer with 6 hidden units. My cost function is the regular:

    cost = ((self.linearRegression.output - y) ** 2).sum()

with

    self.linearRegression.output = T.dot(hidLayer.out, W) + b
    hidLayer.out = T.tanh(T.dot(input_x, W) + b

*linearRegression and hidLayer are seperate objects and have their own W & b.*

I will list some problems I'm having but I don't expect everything answered :)

* Since I'm trying to understand as much as possible the training only consists of feeding the [previous plot](https://www.pic-upload.de/view-32784808/index.png.html) into the NN. Would this plot (`train_x, train_y`) be a mini-batch or just a sample? My thought would be that several training plots would be my mini-batches (which I didn't implement yet).

* If I put the whole dataset as training input, after a few epochs the output looks like the blue plot. After 100 epochs the plot almost looks like the original data with a cost heading zero very fast, which seems like *overfitting* to me.

So my next thought was, since linear Regression demands a scalar output and not a vector, I will use scalar input aswell. So I loop over the whole function - training point by point. But this ends in a rather [unimpressive result](https://www.pic-upload.de/view-32785110/lin1.png.html). After that point I doubted that I grasp the fundamentals of the whole Machine Learning thing.

I tried another approach where instead of my `linearRegression.output` being a linear combination as above would be

    for k in range(kernel_number):
        i = (k+1)*3
        outputtemp = outputtemp + T.dot(self.W[i-3]*input[0][i-3],(T.exp( -(T.sqr(input_dir-W[i-2]*input[0][i-2]) / T.sqr(2*input[0][i-1])))))
    self.output = outputtemp + self.b

which builds overlapping gaussian functions depending on the previous hiddenLayer and uses the currently training `train_x` as `input_dir`.
After several epochs, the output-plot resembles the training plot quiete nicely. [Here is an example](https://www.pic-upload.de/view-32785257/gauss54.png.html) what it looks like after 54 epochs. The red dot is marking the current position of training, since I'm looping over the several data points as mentioned before. The amount of hidden units is set by the amount of gaussian kernels I want to use times three (one parameter for the amplitude, one for the mean and one for variance)

Here I am standing in front of several problems again:

* Is this the correct way to implement 'kernel regression' (if this even is the correct term)?

* If I put more than one kernel, it seems to prioritize one single kernel and 'eliminates' the others. Is this just a initializing problem or is my whole approach incorrect?

* I still think it's rather weird, that I need to index and loop over the whole data instead of putting it whole into training as a vector (But this doesn't work with my kind of code), since it could take up to a minute just to train for *one* epoch! To the contrary - My approach I mentioned in Question #2 only takes a few seconds for 100 epochs and fits perfectly over my training data (which isn't what I want. I want a smooth gauss plot).

Even if you can't explain any of my questions, maybe you know some literature or tutorials I can check out so I could understand my kind of problem better.

I learned most of insights from [Nando de Freitas](https://www.youtube.com/channel/UC0z_jCi0XWqI8awUuQRFnyw) on Youtube and coding from [deeplearning.net](http://deeplearning.net/tutorial/) and they use the MNIST digit classification and solve it by Logistic Regression. I know most of the problems are classification ones, but I find it difficult to look for tutorials based on linear regression. Do you think it would help me to do the online course by Andrew Ng? *(Note: I only have two months left to finish. I need to keep that in mind)*

Sorry for the massive text-wall. I would really appreciate any thought on in!"
Need help in Project,1,1,False,False,False,learnmachinelearning,1488896848,True,"i am working on something called collaborative filtering for online recommendation in e-commerce.

I want to predict or recommend item based on user search. and user is completely anonymous to us. I am thinking to use k mean clustering for similar user based on search. i need dataset of users and their search. can anyone help me in that ??"
How do I update the weights for a Softmax gradient Neural Network?,0,1,False,False,False,learnmachinelearning,1488902386,True,"So I've been working on learning how softmax works, it's been a challenge since I have essentially zero calculus knowledge beyond what I've told myself. I'm using the equations provided via standfords tutorial on softmax regression, so, I can calculate the error gradient for a set dataset, which if I understand correctly, is a matrix the size of the number of classes by the number of examples (correct me if I'm wrong) and I can also calculate the overall cost for every example. So...how do I use this information to update the weights? I cannot work it out myself I'm afraid."
Training trouble (NN),2,2,False,False,False,learnmachinelearning,1488902849,True,"Hello! I've been exploring the wonderful world of machine learning and I've been trying to train an NN to recognise whenever the input picture is a picture of a fish. Simple as that. No further classification, simply a fish or not a fish and after few days where I tried different approaches I'm left with no progress. 

Now I don't know what should I try. My NN is a 5 layer network which takes in a 32x32 picture, with layer sizes of 1024,3000,2000,800,1 (1024 nodes for input layer and 1 node output. Should I increase the number of output nodes?) and a learning rate 0.09. Should I perhaps change the layer sizes? Could it be learning rate being too small or too big? Or is my approach totally wrong?


Now I guess I should mention how I actually did the training.

First training I forgot to teach it anything other than fish. Which unexpectedly resulted in it claiming everything is a fish. I was amused but not in any way closer to being correct.

Later I tried teaching it a few random images from the CIFAR dataset (200 pictures total 50/50 fish/notFish) and once again I was unsuccessful.

The last and most time-consuming thing I tried was increasing the size of the dataset to 4400 pictures from each category (4400 fishes and 4400 not fishes) and once again no progress.

I assume the NN is working correctly as I've successfully trained it to perform simple logic https://bitbucket.org/FishFishFish/logic-gates-neural-network"
"Too many courses, confusing terminology! Where to begin with NLP?!",9,6,False,False,False,learnmachinelearning,1488905267,True,"**Problem**

I want to learn Machine Learning, specifically NLP (Natural Language Processing) for a news analysis project I am working on. 

For a person with intermediate programming knowledge and basic knowledge of working with databases, what would be the correct beginning point? There are so many courses available online on different platforms that it's confusing to identify where I should begin. 

**Existing Skill**

I learned programming through the [Python specialization on Coursera](https://www.coursera.org/specializations/python) which taught me about data structures, extracting data from the web, analyzing it and visualizing it. The course established a pretty strong programming foundation but left much to desire when it came to analysis... There was little to nothing about statistics, and from what I've come to know till now Machine Learning requires one to have solid basics in Statistics. 

To give you a more granular idea of my current skill level, here's the paper I wrote for my capstone project: https://paper.dropbox.com/doc/News-Analysis-Methodology-fXyowV7zSRAxKA70kxAwP

**Options**

I am currently looking at [Udacity](https://www.udacity.com/) to further my skill but I am getting confused by their different courses on [Data Science](https://www.udacity.com/course/data-analyst-nanodegree--nd002), [Machine Learning](https://www.udacity.com/course/machine-learning-engineer-nanodegree--nd009), [Deep Learning](https://in.udacity.com/course/deep-learning-nanodegree-foundation--nd101/) and [Artificial Intelligence](https://www.udacity.com/course/artificial-intelligence-nanodegree--nd889). There appears to be so much overlap in these courses that it's hard for me to decide what exactly I need. 

I don't want to waste time going down the wrong path.
"
"Learn-blog: A blog simplifying the concepts of machine learning with examples, comics, and decoded vocabulary. (X-Post /r/MachineLearning)",7,25,False,False,False,learnmachinelearning,1488909571,True,"**tl;dr**: I study and work in machine learning, and with the help of another machine learning student we made a blog that decodes and simplifies the concepts. We call it [learn-blog](https://ironman5366.github.io/learn-blog)


Longer version:


I've been studying the field of machine learning for awhile now, and what struck me most about the field is that it's not nearly as hard as it seems to be, but a lot of the terminology is needlessly confusing.

I posted about this on devrant and a lot of people there encouraged me to make learn-blog. So, working with /u/thejohnhoffer we made it.

In each lesson, we address common misconceptions and decode confusingly termed topics into understandable concepts. 

We also provide examples of how to make neural networks using [keras](https://keras.io), assuming only a rudamentary understanding of Python.

- [The site](https://ironman5366.github.io/learn-blog)

- [Lesson 1 - ""Neurons""](https://ironman5366.github.io/learn-blog/2017/02/26/Lesson01-Neurons.html)
- [Lesson 2 - A basic example](https://ironman5366.github.io/learn-blog/2017/03/02/Lesson02-NeuralExample.html)"
Playbooks Centralize Educational Resources for Predictive Modeling,0,1,False,False,False,learnmachinelearning,1488910193,False, 
TWIL (This Week I Learned) - Share something new that you have learned this week!,2,5,False,False,False,learnmachinelearning,1488956852,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
Starting out,16,10,False,False,False,learnmachinelearning,1488988535,True,"Hello there!  
  
I'm still in high school, but as my interest in shaping the course of our future is obsessive I couldn't stop myself from getting into Machine Learning.  
  
I finished an ""Intro to Machine Learning"" course on Udacity and I've been watching many YouTube videos on the topic (including some university lectures) and I think I'm slowly getting a clearer picture of this field (in large). (And I've played with and tested some algorithms and techniques in sklearn)  

However, everyone who's working in this field will understand how difficult it can be for someone of my age to do this on my own, so I would like to ask you for advice.  
  
There is much of it online, but it focuses on books and courses and not on the general course one should take.  
I don't know whether I should focus on Neural Nets or, perhaps, some tools for financial m.l. or even some third thing...  
It surely depends on my interests, so I would like to specify that I'm interested in things that will really have a large effect on the future, that are scientific, but not too complex for me to at least grasp.  
  
Thank you for taking your time to read this.  
It really means a lot to me."
Looking for a metric (like AUC) to optimize for the top N,4,1,False,False,False,learnmachinelearning,1488992702,True,"Hi,

I often build predictive models where I only care about the top N predictions. For example, I may want to target 1000 customers, or replace 100 sensors...

Knowing in advance that I only care about the very beggining of the ROC curve means AUC is not a perfect choice of metric for me.

**Is there a better metric in this case, or should I write a custom metric?**

Thanks"
Resources on Bayesian Optimization,1,3,False,False,False,learnmachinelearning,1488992957,True,"I'm a grad student dipping his feet into the more theoretical aspects of ML, and I'm really fascinated by the idea of Bayesian Optimization, even though I'm not able to firmly grasp some of the key concepts.

Does anybody have links to courses, books, etc. that would help? Any help would be much appreciated!"
Google is reportedly buying data science community Kaggle,0,13,False,False,False,learnmachinelearning,1488996442,False, 
How long does it take to learn machine learning?,2,5,False,False,False,learnmachinelearning,1489023021,True,"I took computer science classes for two years in high school...15 years ago. Starting today, how long would it take to....

1. Get an entry level job in the field? (I've heard anywhere from 1-3 years of study to get to this level, data scientist??)
2. Get hired as a machine learning engineer? (3-5 years? Not even sure if that is the right title)
3. Become a machine learning expert? (10 years?)

I understand the answer is, it depends, but I am just looking for a general approximation of how long it would take for a motivated quick learner?"
[Keras] Is there a layer to go from 3D to 4D tensor ?,2,2,False,False,False,learnmachinelearning,1489053807,True,"Hi, I'm working for the first time on a machine learning project using Keras and Tensorflow.

I have some trouble to compose my model to fit my input and my output dimensions. My input shape is `(<batch_size>, 9)` (2D) and my output is `(<batch_size>, 90, 107, 154)`(4D).  I think I've got a way to go from 2D to 3D with a `RepeatVector` but how can get from 3D to 4D ? 

Here's my code, I spared you data preprocessing :


    # Create first network with Keras
    from keras.models import Sequential
    from keras.layers import *
    import numpy as np

    # fix random seed for reproducibility
    seed = 7
    np.random.seed(seed)

    X = loadX(""../index.tsv"") # I spare you the content of these
    Y = loadY(""../index.tsv"") #

    print(""INPUTS:  "" + str(X.shape)) # (16, 9)
    print(""OUTPUTS: "" + str(Y.shape)) # (16, 90, 107, 154)


    # create model
    model = Sequential()
    # input.shape = (*, 9)
    model.add(Dense(32, input_dim=9, init='uniform', activation='relu'))
    # shape = (*, 32)
    model.add(RepeatVector(4))
    # shape = (*, 4, 32) 
    model.add(Reshape((8,16)))
    # shape = (*, 4, 32) 
    #model.add(RepeatVector3D(4)) # <- made up layer, is there a layer that can take 3D and output 4D ?
    # shape = (*, 4, 4, 32) ?
    #model.add(Dense(64))
    # shape ??

    # Compile model
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    # Fit the model
    # 
    model.fit(X, Y, nb_epoch=150, batch_size=16,  verbose=2)

    # calculate predictions (not yet there)
    a_chair = model.predict(np.array([[2015,40,3,9,400,6,4,1,0]]))


At the moment I'm not interested in the quality of my model, I will fiddle around that when I will have figured basics dimensional manipulations (and when my dataset will be complete).

Am I delusional to hope that a NeuralNet can handle this kind of data augmentation ? 

Thanks in advance

(edit: delirium)"
How to advocate posterior inference instead of MAP for latent feature learning? [x-post from /r/MLQuestions],0,6,False,False,False,learnmachinelearning,1489068100,True,"Hi,

At my company I am going to give a presentation on feature learning. Contextually, I will also describe a classification model that I have been developing using Variational Autoencoders for feature learning. Apart from the quality of the learned representation, that was very satisfactory and leading to good classification scores, I have to defend the decision of using a Variational Autoencoder instead of a regular autoencoder.

I am planning to argument posterior inference vs MAP. What are the most convincing arguments in the context of feature extraction? This, considering the fact that only the modes of the learned posterior distribution might be used (the z's mu of the variational autoencoder).

I think that one of the most convincing arguments is that in posterior inference, being stuck to local minima is less likely: when a good posterior distribution is being found the various minima might correspond to various modes of the distribution.

In the variational autoencoder, two different modes of the true posterior might be included in the high-density area of a simple diagonal-covariance matrix gaussian, so samples might be drawn from that area encompassing both local minima.

Any other nice explanation for an audience that has some average background in statistics, machine learning and mathematics?

thanks!
"
Help in understanding what values are in the kernel matrix for convolutions in CNNs (tensorflow)?,5,1,False,False,False,learnmachinelearning,1489077577,True,"Hi all,

Say I have a convolutional layer in a CNN that will make 64 filters using a 3x3 kernel. 

I'm a bit confused for how tensorflow will make 64 filters. We are not specifying the kernel matrix. Is tensorflow using 64 different kernel matrices for the operation? How is it deciding what values to put into the kernel matrix?"
"[X-Post MLquestions] Completely uneducated, but that won't stop me (text processing)",5,1,False,False,False,learnmachinelearning,1489084306,True,"I have a data set of text names, maybe even some dollar figures for transactions attached, from a csv/xls* file. What I need to accomplish is I need to build and train a machine learning model to take names like ""IBM corp"", ""I.B.M."", ""IBMinc"" and maybe even ""International Buisness Machine"" and group them under IBM. Maybe even taking a look at it and summing the transaction amounts under that umbrella as well.

Starting small at the moment with only 100 data points.

Chosen tools and languages: TensorFlow and Python

My question is what kind of algorithms/packages should I be looking at to accomplish this?

Hopefully I used the terminology correctly, as I said, I don't know much but I'm trying."
Has anyone recreated the results from PathNet yet?,0,16,False,False,False,learnmachinelearning,1489086895,True,"https://arxiv.org/abs/1701.08734

Paper that I'm referencing. I'm curious if anyone has recreated the results or if there have been any efforts to that are public"
Difference between a Dueling Q Network and a Actor-Critic Network,3,5,False,False,False,learnmachinelearning,1489091729,True,"So I've been getting into reinforcement learning and I've come across both actor-critic and dueling q networks as next steps from regular regular DQN's.

My question is, what are the differences between them? From what I gather, actor-critic splits the network up into value and policy functions, and dueling splits it up into state value and action utility networks. Is there any difference between these or are they just different terms for the same type of networks?

Any and all help is appreciated, thank you!"
What is the best approach for determining whether an imagine has one or more features?,0,0,False,False,False,learnmachinelearning,1489113496,True,"Say you want to determine whether an imagine contains a face with blue eyes and/or if the image contains a face with a beard. I want to train the data with supervised learning, so I have a dataset that contains information about whether the image contains these True/False features. Now I want to submit an image and have it return to me the likelihood that the imagine contains the features. What is the methodology to best implement this? (For example, is there an approach to extract this info out at once or should I be running multiple tests with a simpler true/false classification?)"
How do Generic Algorithms Work? - Unity,2,25,False,False,False,learnmachinelearning,1489115057,False, 
Struggling with finding feature maps of kernels.,0,3,False,False,False,learnmachinelearning,1489120937,True,"I'm currently learning about kernel functions, but I am really struggling with understanding how to find a kernel function's corresponding feature map. I get the basic idea, but when given certain kernel functions--such as K(x,x') = min(x,x')--I am completely lost. Can someone please give me some advice or point me somewhere? Thank you!"
Weekly Show-off!,0,2,False,False,False,learnmachinelearning,1489129752,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
Computer evolves to generate baroque music!,0,0,False,False,False,learnmachinelearning,1489129821,False,[deleted]
Whats it called to finish learning one vector (and never go back to relearn) before starting learning the next?,1,1,False,False,False,learnmachinelearning,1489154362,True,"Online Learning appears to mean updating the weights after learning a vector but looping over all vectors multiple times. Batch learning is updating the weights at the end of each loop. This would be a subset of Online Learning.

I want to know what to look up. Even if it doesnt exist, there must be some theory about it that I could base experiments on."
Looking for an implementation-focused paper appropriate for an undergrad,1,2,False,False,False,learnmachinelearning,1489154432,True,"Hello,

I'm working on a class project, requiring that I implement a machine learning technique as it's described in a paper. I'm having trouble finding papers that aren't primarily theory based though. Would anyone be able to point me in the right direction?

Cheers!"
Looking for resources on feature learning (or representation learning),0,2,False,False,False,learnmachinelearning,1489155029,True,"Hi,

I'm interested in feature learning, mostly supervised techniques, and I'd like a good resource to start with.

To my knowledge, the most efficient techniques involve extracting the first part of a neural network, or extracting partial decision trees. But maybe there are other techniques ?

Anyways, I'm interested in general purpose techniques, nothing specific to image / sound / text analysis. Thanks !"
"When initializing weights in Tensorflow using truncated_normal, should the standard deviation always be a very low value, or is it dependent on the activation function?",0,9,False,False,False,learnmachinelearning,1489196102,True,Taking a course in which it's recommended the stddev be set to 0.1 or less. Should that be the case all the time?
How to implement paper X using framework Y?,4,3,False,False,False,learnmachinelearning,1489213656,True,"What's the process that goes into implementing a research paper in an ML/DL framework?

I see a lot of projects like [these](https://github.com/jcjohnson/neural-style) and wish to know how I can learn to do this myself."
"Weekly Scrum Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",1,3,False,False,False,learnmachinelearning,1489216013,True,"Let's have a scrum meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
How do we choose alpha and gamma in Q learning?,3,7,False,False,False,learnmachinelearning,1489238262,True,i want to know on what basis an agent should change its alpha and gamma value rather than hard coding it.
very basic neural net question,8,3,False,False,False,learnmachinelearning,1489264531,True,"Hi everyone, I'm trying to implement a NN from scratch for fun. My math background isn't the strongest so I apologize in advance if these questions are elementary.

For backpropagation, I have this collection of equations [here](http://imgur.com/siICX6w). This is from http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/.

1. Is y_hat the **probability** of class y being predicted, or the actual predicted class? For example if I have class 0 = 30% , class 1 = 10% and class 2 = 60% with the correct class being 1, is delta_3 = 10% - 1? Or is it 2-1? (since the predicted class here would be 2) Does it matter that I have a class that's zero? Would this mess up error/log loss calculations?
 
2. What is the clear circle operator for delta_2? Is that a product?

 Thank you"
Genetic CNN: CNN architecture exploration using Genetic Algorithm,0,5,False,False,False,learnmachinelearning,1489271458,False, 
Introduction To Convolutional Neural Networks,0,26,False,False,False,learnmachinelearning,1489273612,False, 
Monthly ELI5 (Explain Like I am Five) Thread,24,6,False,False,False,learnmachinelearning,1489274228,True,"Top comments need to be in the format of: `ELI5 $CONCEPT_NAME` and the replies should provide a clear explanation in a layman's term.
Here are the relevant rules from /r/explainlikeimfive breaking down the meaning of ""ELI5"":

- E is for Explain - merely answering a question is not enough.

- LI5 means friendly, simplified and layman-accessible explanations - not responses aimed at literal five-year-olds.
"
Backgammon Doubling Cube Project,0,1,False,False,False,learnmachinelearning,1489277559,True,[deleted]
[Request] Resources for learning Genetic Algorithms,0,3,False,False,False,learnmachinelearning,1489277999,True,"Hi,

can anybody recommend reading material, good github repos, or anything else for learning genetic algorithms? I'm interested specifically in their applications to feature selection and genetic exploration of neural net topologies. My preference is for materials which lean more on the applied side of things (rather than hard theory), so programming implementations is of interest aswell.

Thank you!"
I’m at university again!,6,7,False,False,False,learnmachinelearning,1489315018,False, 
Explain expectation-maximisation algorithm.,5,7,False,False,False,learnmachinelearning,1489320307,True,"I am trying to make sense of the E-M algorithm in order to understand the Gaussian Mixture Model. Can anyone throw light on this, showing all the solved steps for a simple application. Thanks in advance.  "
Which of the courses in Machine Learning have the best assignments and are available on the web for free?,10,23,False,False,False,learnmachinelearning,1489325229,True,"By best I mean:- 
1) Intermediate to advanced level rigor(no beginner stuff needed) 2) Cover wide variety of algorithms and have solutions available on the web.
If you know any such courses, please post the link below. Thanks in advance!"
My first simple project. Need feedback.,4,5,False,False,False,learnmachinelearning,1489328199,True,"So, last week I just began my journey in ML. I came across this simple project for beginners (Source: Machine Learning Mastery) and tried it out myself.

Here's the GitHub link: https://github.com/bensooraj/Making-predictions-on-the-Iris-Dataset

I do not understand everything that I've done, but it did help get a grip on a very high-level.

Any suggestions(Pull Requests)/feedback to improve the comments are really welcome. It can help me or anyone else who are just starting off."
I edited David Silver - RL Lecture 10 so the slides are now visible,3,27,False,False,False,learnmachinelearning,1489354260,False, 
Looking for an hybrid algorithm that creates tree-based features and fits them into a logistic regression,6,9,False,False,False,learnmachinelearning,1489401447,True,"Hi,

I've heard about a technique that combines the strengths of logistic regression with those of decision trees. The idea is to create features based on decision trees and then use these features to fit a logistic regression model.

Do you have a link / paper / lib / anything really :)

Thank you

/e : Finally found the answer. This technique is called [rulefit](https://www.r-bloggers.com/rulefit-when-disassembled-trees-meet-lasso/) !"
How would you classify tree data structure using ML ? (Way to represent the structure or algorithms handling this kind of sequentiality),6,9,False,False,False,learnmachinelearning,1489417475,True,"Hi guys,
I'm facing a binary classification problem where my data is represented as multidimensional (64 dim per node) tree of events. The size of tree can be random but limited by a max depth (about 50) and max number of leafs per node (let's say 10). 
I'm looking for either a smart way to present the structure into a classic algorithm or an algorithm capable of handling this kind of sequentiality.

Any idea ?

Thanks a lot,"
How can I choose the number of hidden layers/units in a DNNClassifier?,0,4,False,False,False,learnmachinelearning,1489423688,True,"I've trained a model with XGBoost with 0.85 gini in some train data. However, I cannot seem to choose the right number of hidden layers/units when trying to train a DNN Classifier in the same data. (I'm using TFLearn's DNNClassifier as follows):

classifier = learn.DNNClassifier(
  feature_columns=learn.infer_real_valued_columns_from_input(X_train),
  hidden_units=[100, 200, 300, 400, 500, 400, 300, 200, 100],
  n_classes=2)

I've tried different combinations of hidden units, but I never get higher than 0.55 gini. I've searched for info about how to choose the number of hidden layers and units, but I haven't found any.

Can anyone point me to some info about how to choose the number of layers/units? Thanks in advance.
"
"Why do we use softmax to calculate probabilities, instead of diving number by the sum in the sample.",7,7,False,False,False,learnmachinelearning,1489429759,True, 
Question About Adding New Features w/ No Historical Data in NN (Time-Series),2,2,False,False,False,learnmachinelearning,1489439037,True,"I'm still relatively new to working with neural networks and I was wondering what the best practice is for adding in features which you don't have historical data for (when you do have it for all other features) in a time-series model.

Specifically:

As a learning exercise, I'm creating a neural network (basic for now, recurrent in the future) which predicts the price of a stock / index (original, I know). I can get historic data for most things except Twitter, which I've found to be very difficult to get historic data (past what the API allows) at scale (unless you're willing to spend +$10k).

With that said, how would adding in the twitter data affect things if it starts a year or two after all the other data starts? Is this less of an issue in a recurrent model?"
What to start studying RL for participating in General AI Challenge?,8,3,False,False,False,learnmachinelearning,1489440888,True,"I am looking into [General AI Challenge](https://www.general-ai-challenge.org/active-rounds), which for it's first round uses facebook's [Comm AI Env](https://github.com/facebookresearch/CommAI-env) to train and test dialog based tasks. What are the good introductory and hands-on tutorials I should be looking at to learn RL with respect to chatbots and have a modest attempt at this challenge?"
Train Record Linkage and generate predictions on test set?,0,2,False,False,False,learnmachinelearning,1489467067,True,"I can't give away the full details, but my goal is match each of the invoices created to each payment made. So for example, if I have a set of invoices:

    InvoiceDate InvoiceAmount InvoiceCategory
    02/21/2016  46.53             Amazon 
    08/17/2016  36.53             BestBuy
    08/17/2016  26.53             Amazon
    08/21/2016  16.53             BestBuy

and a set of payments:

    PaymentDate PaymentAmount PaymentCategory
    03/1/2016     45.00           Paypal
    9/1/2016      41.14           Credit
    9/2/2016      20.14           Paypal
    8/29/2016     20.14           Check

Then each invoice must match the correct payment. To make the matches, the `InvoiceDate` and `PaymentDate` must be fairly close. For example, for the invoice `02/21/2016  46.53             Amazon`, `03/1/2016  45.00 Paypal` is probably the better match than `9/21/2016  15.14 Check` because its date and amount is closer to the invoice

Moreover, for the invoice `08/21/2016  16.53 BestBuy`, although `9/2/2016      20.14 Paypal` and `8/29/2016     20.14 Check` have similar dates and payment amounts, the latter is the correct match because `BestBuy` accepts check payment but not Paypal

So the correct output should look like

    InvoiceDate InvoiceAmount InvoiceCategory PaymentDate PaymentAmount PaymentCategory
    02/21/2016  46.53             Amazon      03/1/2016     45.00             Paypal
    08/17/2016  36.53             BestBuy     9/1/2016      41.14             Credit
    08/17/2016  26.53             Amazon      9/2/2016      20.14             Paypal
    08/21/2016  16.53             BestBuy     8/29/2016     20.14             Check

If the above is my training set, I would like to train a model on it and then generate predictions on a test set. 

I'm aware of the that record linkage/fuzzy matching can match data sets like this. I read about the`recordlinkage` and `fuzzywuzzy` Python packages. But from what I've learned about them, they can't train on a training set and then predict a test set

Anyone know how I can proceed with this problem?
"
Twitter List: Deep Learning Loop,1,16,False,False,False,learnmachinelearning,1489474592,False, 
How to weight features in a feature vector when they have different domains?,0,3,False,False,False,learnmachinelearning,1489506637,True,"Please consider the following scenario: 

After feature selection, I still have 11 features left in my feature vectors. Ten of these are # occurrences of words, the other one is a special attribute which holds a rating on 10.

Now, a first logical step might be to rescale them all (for the words using td-idf, for the special attribute bringing it back to a 0..1 scale).

But after that, I have the feeling that simply using this vector as is won't be beneficial. I would want to automatically weight them, in such a way that the potential information gain is highest.

[For example, if (I do not know this!) the rating was as important as all the other features together, I'd want the system to automatically assign weights 10x0.05 and 1x0.5]

Now, my questions:

1. Is this possible with some sort of general algorithm, that given a labeled dataset determines optimal weights within your vector?

2. Is this even 'useful'? I'm no real expert in ML, so I might be missing something here. Maybe this weighting step is somehow already done when I use a certain classifier (SVM?), because it takes into account which features are more information-containing than others and assigns greater importance to these? 

I ask the question because I know that for e.g. a simple kNN-approach, not weighting them obviously gives wildly inferior results than weighting them. 

For clarity: I know *how* to weight features, I just need to know how to determine the weights in a general way (if at all necessary).

Thanks for your thoughts!


"
TWIL (This Week I Learned) - Share something new that you have learned this week!,2,8,False,False,False,learnmachinelearning,1489561661,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
What statistics skills and knowledge do we need to perform ML in reality?,2,4,False,False,False,learnmachinelearning,1489563023,True,"I'm a beginner to ML and have played with toy datasets. Data collected in reality may not fit with algorithms in textbooks and papers. I guess some maths or statistics skills are required. What are they?

(Edit: missing word added)"
"What techniques are good for text ""pattern matching""",0,0,False,False,False,learnmachinelearning,1489569226,True,"Given a text where I need to extract some dates, numbers, maybe some identifiers.

I can do this with a convoluted set of regexps, but which machine learning techniques would be good for this?"
Convolutional neural network as a feature extractor for autonomous driving.,0,7,False,False,False,learnmachinelearning,1489588759,False, 
What do you wish you knew when you started learning ML?,5,25,False,False,False,learnmachinelearning,1489588833,True,"hi everyone!
This year I'll be doing my thesis in machine learning applied to recognized failures in machines and structures in a more automatic way (hopefully hehe).

I'm just starting to learn machine learning, so I think that is a good idea to ask the more experienced people out there what they wish they knew when they start.

Thanks in advance!"
"""Embeddings"" vs ""Representations"" in NLP",1,5,False,False,False,learnmachinelearning,1489591212,True,"I was going through [this](https://engineering.quora.com/Semantic-Question-Matching-with-Deep-Learning) blog post on Quora's approach to finding semantically similar sentences/questions.

In all their approaches, they claim to generate sentence vectors from word vectors, and then feeding the sentence embeddings into a ""representation"" layer (see fig. 1). Can anyone shed any light on what the representation layer might be and how it might differ from an embedding layer.

Thank you!"
SVM theory question,1,1,False,False,False,learnmachinelearning,1489592711,True,[deleted]
"Having problems getting multitask learning to work on CIFAR, would appreciate some advice.",0,1,False,False,False,learnmachinelearning,1489593910,True,"Inspired by this paper by Teterwak et al. [http://www.cs.dartmouth.edu/reports/TR2014-762.pdf], I'm trying to get multitask learning (MTL) to work on CIFAR-100 (if you haven't seen MTL before, I'd recommend having a read of the intro to Caruana's thesis [http://www.cs.cornell.edu/~caruana/mlj97.pdf]). The idea being to learn a 100-class classification task in parallel with a 20-superclass classification task. The CIFAR-100 dataset comes with 20 coarse labels which partition the 100 labels, so the choice of hierarchies is a natural one. In Teterwak et al.'s paper they show marked improvements over their baseline but I can't seem to beat mine. 

Could anyone suggest something to try? My current model is as follows (any criticism, related to MTL or not, appreciated): 

4 convolution layers of dimension [64, 128, 256, 512].
Strides of 1.
No FC layers.
2x2 Max pooling after each layer, except third.
Local response normalisation after each layer.
Batch norm after each layer.
Filter size of 5 throughout.
Adam optimiser with 0.9, 0.999 momentum coefficients and a learning rate of 2e-4.
Dropout.
L2 regularisation. 
Data augmentation - random cropping and flipping of images.
Batch size of 128.
Relu throughout.

To implement MTL, I bifurcated the model, different bifurcation points were tested. So up until the bifurcation layer, all weights were shared. After the bifurcation point, each branch had the same architecture as the baselines, except in the output layer where there was either a size of 20 or 100 for the softmax layer. With each step in training, the model was given a batch of inputs then the joint loss of both outputs together was minimised. In the original paper, the learning rate up until bifurcation is halved to keep learning consistent throughout the layers, I haven't implemented this but I didn't think that would make much of a difference? 

Thanks"
Initiating multiple tensorflow sessions,0,1,False,False,False,learnmachinelearning,1489595574,True,"I have a question regarding implementing TF sessions in my code. I'm currently experimenting with a new implementation of neural networks, which require a different evaluation function. This leads me to having to do the following evaluation

    Y1 = tf.nn.relu(My_Function(XX) + B1)

Where `B1` is the offsets, and `XX` is the training/test set (dimensions: batch_size * n_features). The problem is in `My_Function()`, which returns a tensorflow tensor.

In order to do the calculation, the math operations have to be defined differently as the tensor is stored in a different format. Therefore, the *easiest* way is to create a tensor of zeros to store the results. This is done with `tf.zeros([batch_size, layer1_neurons], dtype=tf.float32)`. However, I need these to be zeroed out each time `My_Function()` is called, and I'm unsure how to do this. The test set has a batch_size of 10,000, while the training batch size is 100. 

The evaluation in `My_Function` has the following format:

    sess = tf.Session()
    result = tf.zeros([batch_size, n_features], dtype=tf.float32)
    for xyz in tensor:
        # do computations
        delta = tf.SparseTensor(indices, values, shapes) # Stores the indices and values to update/add to result
        result += tf.sparse_tensor_to_dense(delta)
    init = tf.global_variables_initializer()
    sess.run(init)
    return result

What I need to do is initialize only `result` everytime `My_Function()` is called. However I cannot find a way to do this in TF. Does anyone have any suggestions? In the current format, when running the code, it runs the training set fine `dim(train) = (100, 28, 28, 1)` but then complains about it not being able to fit the test data into `result` as `dim(test) = (10000, 28, 28, 1)`.

Essentially `batch_size` changes between the test and training sets, so `result` should be recreated/zeroed with each function call. However, as it doesn't seem to be changing on the batch_size, I am suspicious to if it's actually zeroing out `result` with each function call as well."
Understanding training a recurrent neural network,2,1,False,False,False,learnmachinelearning,1489614351,True,"I have successfully trained a standard feedforward neural network.  It was simple enough: you have your input data with the expected outcomes, apply backpropagation to correct errors, and run through it several times.

Now what about the recurrent neural network, whose state changes because of the previous input.  Am I correct in assuming that there is only input data, and no separate expected data?  If *input[i]* is the input data at iteration *i*, then *input[i+1]* should be the expected outcome at iteration *i*?  Does that means the network will always continue to move forward then?

Edit: To clarify a bit, I am referring to Elman's recurrent neural network where each node in the hidden layer carries the previous state."
What beginner tutorial do you recomend?,9,9,False,False,False,learnmachinelearning,1489619371,True,"I tried to learn naural networks a few times and it always ended the same way - I gave up because it was either too advanced or had no real coding examples. I though I might ask here. I'm not looking for any magical neurtal network in an hour toutorial. Everything I want is basic form start to end tutorial at the end of which I will have done something - not a bunch of random examples, but something that really works."
Do I need to be good at math to enjoy ML?,2,1,False,False,False,learnmachinelearning,1489625492,True,"Hey there, I'm a freshman in CS. ML really intrigues me, but I'm honestly not that great in Linear Algebra ( i do enjoy it to a certain extent, but i'm not naturally good at it ) . So would I enjoy ML? I don't know if I want to pursue it further or not!"
NakedTensor: Super simple TensorFlow examples,0,14,False,False,False,learnmachinelearning,1489627745,False, 
ProjectSub-par results when training any neural network library on Iris datasets,3,1,False,False,False,learnmachinelearning,1489628326,True,"I've tried a tonne (10+ in this case) of different py libraries which can all handle MNIST fine and produce around 95-97% classification accuracy. But when I try the Iris data set I get results similar to random guessing (33% correct). Not sure why either - I've tried various combinations of hyperparameters.

Is there potentially something I'm missing here? Is it really that difficult a data set to classify?

I'm currently running the library from this repo:

`git clone https://github.com/mnielsen/neural-networks-and-deep-learning.git`

Training using 4, 8, 8, 3 (input, hidden 1, hidden 2, output - 1 hot vectors). Learning rate of 1.2, 100-50 train/test split, 3000 epochs and minibatch size of 16. This gives around 18-20/50 correct classifications post-'learning'.

I'd be grateful for any guidance here!"
Top Machine Learning Trends To See In 2017,0,1,False,False,False,learnmachinelearning,1489644449,False, 
[P] DyTB: don't waste your time writing boilerplate code. Let DyTB do it for you.,4,2,False,False,False,learnmachinelearning,1489658316,False, 
"Looking to implement pre-trained CNN, what math do I have to know?",5,2,False,False,False,learnmachinelearning,1489673542,True,"So I am working on a project that need to implement a ImageNet trained CNN. I saw there's a few pre-trained network called Inception  from the tensorflow library.

What are some maths I need to know in order to know how to implement it? 

What math do I need to know in order to have a basic understanding to know how it works underneath the hood? (enough so I can write something up)

Thanks in advance"
Multiple Outputs Algorithm?,1,3,False,False,False,learnmachinelearning,1489686049,True,"So, I've been studying machine learning for a while, and now started to tinker with some data. I'm trying now to develop my first model to predict the future sales of each product based on a set of past features. 

So, my question is the following: Since I have multiple products, how I could train the data in a manner that would output multiple variables (one for each product)? I was thinking about maybe a neural network with multiple, or one algorithm per product , but that probably would be the wrong approach :P

Thanks in advance!"
Where to begin,2,2,False,False,False,learnmachinelearning,1489688104,True,"I am interested to relearn or probably start to learn properly machine learning with its prerequisites. I heard about kaggle and datacamp(only names) in the machine learning Reddit page. So I would like take up a course from datacamp. Need some guidance there.
PS: my interest is to learn machine learning and apply it for solving discrete problems "
Finding the dual optimisation problem of an SVM,0,2,False,False,False,learnmachinelearning,1489699326,True,[deleted]
How to use batch_sequences_with_states in tensorflow?,0,1,False,False,False,learnmachinelearning,1489699606,True,"[This example](https://www.tensorflow.org/versions/master/api_docs/python/contrib.training/splitting_sequence_inputs_into_minibatches_with_state_saving) in the documentation does not work and all the other bits and pieces required to use this method are scattered around tests, examples, comments inside the repository. I have preprocessed data of different lengths. They are currently stored as a list of numpy arrays of shape `(time, features)`. How should I format this list in order to be able to use `batch_sequences_with_states` method?"
Dealing with a very sparse dataset for multi-label classification. What best practices should I do first?,2,5,False,False,False,learnmachinelearning,1489731868,True,"Hi everyone, 

I was given a dataset of gene annotations, and I noticed that the data is very sparse (24801x4021 binary matrix {0,1}. The number of 1s range from 2 to 5 per row). And I need to perform multi-label classification.

I am thinking of feeding this data into an auto-encoder to reduce dimensions, then use the resulting features for my classifier (but I might sacrifice interpretability, etc.). Do you think it's a good idea? 

What do you think should I do? If possible, can you please point me to nice papers that has dealt with high-dimensional, high-sparsity data?

Thank you so much!"
Weekly Show-off!,0,6,False,False,False,learnmachinelearning,1489734524,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
SVM theory question,0,3,False,False,False,learnmachinelearning,1489738536,True,[deleted]
Questions on Regularization [xpost r/mlquestions],1,3,False,False,False,learnmachinelearning,1489741050,True,"I am reading about regularization [from this link](http://cs231n.github.io/linear-classify/#svm) and I cannot understand how I should correlate this particular concept to penalization.

>There is one bug with the loss function we presented above. Suppose that we have a dataset and a set of parameters W that correctly classify every example (i.e. all scores are so that all the margins are met, and Li=0Li=0 for all i). The issue is that this set of W is not necessarily unique: there might be many similar W that correctly classify the examples. One easy way to see this is that if some parameters W correctly classify all examples (so loss is zero for each example), then any multiple of these parameters λW where λ>1 will also give zero loss because this transformation uniformly stretches all score magnitudes and hence also their absolute differences. 

I'm guessing I can visualize this as multiplying the coefficients of a straight line equation in 2D and satisfying the equation despite the multiplied coefficients. Or is there a better way to think about it?

>For example, if the difference in scores between a correct class and a nearest incorrect class was 15, then multiplying all elements of W by 2 would make the new difference 30.

>In other words, we wish to encode some preference for a certain set of weights W over others to remove this ambiguity. >

I don't understand this statement. Am I correct in understanding that a unique set of weights/parameters is desirable (but why?)?

>We can do so by extending the loss function with a regularization penalty R(W). The most common regularization penalty is the L2 norm that discourages large weights through an elementwise quadratic penalty over all parameters:

>R(W) = \sum_k\sum_l W_{k,l}^2

Why are large weights discouraged?

"
R or python for random forest or xgboost?,1,1,False,False,False,learnmachinelearning,1489750318,True,"I am about to undertake a project in which I need to build both a random forest and xgboost model on the same dataset. I am unsure as to which language has the best advantages for this task.

I know that R has a 'factor' variable type which is good for modelling character variables, python doesn't have this so I have had to do things like one hot encoding in the past. I am looking for advice on other differences like this?

It is worth noting that my modelling set will be large, in the region of 3 million rows (could be more) and 300 variables (might have to be cut down).

I am better versed in python but very willing to improve my R to the same standard if it is going to be preferable. Can someone convince me as to which direction is best?"
Brilliant breakthrough of neural nets for absolute beginners,2,1,False,False,False,learnmachinelearning,1489754892,False,[deleted]
Brilliant walkthrough of neural nets for absolute beginners,7,64,False,False,False,learnmachinelearning,1489754997,False, 
"When creating your ensemble model and creating a ""new"" data set with predictions from your first model as features, do you use the predicts or predict_probas?",2,2,False,False,False,learnmachinelearning,1489760163,True,"Basically the title. When you're creating your ""new"" data set to train on for your ensemble model, do you want to use JUST the predictions from the initial models or would you use the probabilities? The latter of course makes the ""new"" data set bigger as there are roughly M times more features, where M is the number of target classes. 

What is the difference between the two? Is there anywhere I can read more about this?"
Where to find video lectures for Stanfords undergraduate CV class?,4,3,False,False,False,learnmachinelearning,1489815209,True,Specifically vids for CS131 that corresponds to [this](http://vision.stanford.edu/teaching/cs131_fall1617/schedule.html)
"Weekly Scrum Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",4,2,False,False,False,learnmachinelearning,1489820811,True,"Let's have a scrum meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
Do you need regularization terms when you have a large training sample set and are doing testing and cross validation?,8,5,False,False,False,learnmachinelearning,1489856712,True,"I can't find an answer on Google so I'd thought I'd try here.

I'm trying to make a Neural Net for digit recognization, and not sure if I should have regularization terms when calculating the (cross-entropy) loss and when doing backprop. I have a very large training set and am doing cross validation. Is that enough to prevent over fitting, or should I also have regularization terms in as well? TIA"
How to approach find duplicates in a taxanomy of trees data?,0,3,False,False,False,learnmachinelearning,1489858826,True,"I have certain taxanomy of trees data containing leaves,for example sample data    

    Clothing & Accessories > Men > Socks > Casual Socks
    Shoes > Related Accessories > Socks > Men > Casual Socks

Both leafs intent is same,hence they are duplicate.This is the only example i have,how can i classify which leaf is duplicate using machine learning.How to approach ?"
Courses/Tutorials with example codes for beginner?,0,0,False,False,False,learnmachinelearning,1489872936,True,[deleted]
[D] A Super Harsh Guide to Machine Learning • r/MachineLearning,0,20,False,False,False,learnmachinelearning,1489877265,False, 
What format does my data need to be in to put into the tensorflow mnist example code?,1,3,False,False,False,learnmachinelearning,1489878264,True,"I have been slowly picking up machine learning and have been toying with tensorflow and built my own dataset that I would like to have classified by the same process as used in the [MNIST example code for tensorflow](https://www.tensorflow.org/get_started/mnist/beginners)

In their example they pull the mnist training data from some files and it isnt clear what the structure is. right now I have my data in this format

data = [ [ [feature, feature, feature, feature], [label] ], [ [feature, feature, feature, feature], [label] ] ]

so it is a list of lists with each internal list being a datapoint which contains one list for the features and another list for the labels which are one-hot. It seems like this should work because in their code they take batch[0] as the data and batch[1] as the label so I thought that my data might be able to match up but I am getting some errors.

Do I have to convert to an array or what is the best way to reorganize my data so that I can throw it into their code? I have already corrected the various dimensions to handle my data with the neural network, I simply do not know what format it needs to be to get it to a working training step. Even if anyone could guide me to the relevant documentation that would be a great help. "
Learning To See [Part 1: Introduction],0,42,False,False,False,learnmachinelearning,1489890582,False, 
Good RMSE Value,6,2,False,False,False,learnmachinelearning,1489918835,True,"Must an RMSE value be below one to be considered good enough for regression?

My regression model output an RMSE value of 0.00073121 for the training set and 7.947 for the testing set. My first instinct was that it was overfitting but then it got me wondering how much differences between the training RMSE and testing RMSE is considered acceptable.

Edit: below zero to below one. "
Created a RNN to predict AQI in Beijing. Help me better understand the results and how I can improve. Results and graphs inside,7,9,False,False,False,learnmachinelearning,1489920796,True,"**Preamble**

I live and study in Beijing. It can sometimes get pretty polluted here so I decided that I wanted to take everything I've been learning in ML and Neural networks to build a model that can predict the AQI hopefully at least 12 hours in the the future. 

After some research and asking around I figured that the best NN for the job would be a RNN. Below I have results, Architecture, Data structure, and how I want to improve it.

**Graphs of outputs**

[Graphs!](http://imgur.com/a/SoWyA)

Orange is prediction and blue is actual data. This is not data I used to train this is from the validation set.

I'm hoping that you guys can help me understand my results better and help me explore how to make it a future version of this RNN better at predicting AQI further out in to the future.


6 hour prediction:

- Train Score: 0.05 RMSE

- Test Score: 0.05 RMSE

12 hour prediction:

- Train Score: 0.06 RMSE

- Test Score: 0.06 RMSE


24 hour prediction:

- Train Score: 0.07 RMSE

- Test Score: 0.08 RMSE



**Architecture**

On the architecture front I sort of tried the first thing that occurred to me and did not do much in the way of optimization. What are some ways I can attack the problem more effectively then just spray and pray.

I used an RNN with:

- 10 LSTM input dim

- 60 Dropout units with .5 drop out rate

- 1 Dense unit that had my final output


below is the actual code

    with tf.device('/gpu:0'):
        model = Sequential()
        model.add(LSTM(10, input_shape=(1, 10)))
        model.add(Dropout(.5, input_shape=(60,)))
        model.add(Dense(1))
        model.compile(loss='mean_squared_error', optimizer='adam')
        model.fit(trainCurrent, trainFutureAQI, epochs=10, 
    batch_size=12, verbose=2)

**Data Structure**

The input consisted of 10 data points. I decided on these because I thought this was the minimum you would need to actually see some predictive power. It turned out to work better then I thought it would just on this

I have hourly data from 2011-1-1 to 2017-1-31. 

- Year
- Month
- Day
- Hour
- Current AQI
- Temp (C)
- Relative Humidity
- Wind Speed (Knots)
- Wind Direction (Degrees)
- Wind Gusts (Knots)

**Going Forward**

There are a few things I would like to try in the future to make this better. I'd love to get some feed back on what you think might or might not work.

- I want to try outputting the three predictions at once from the RNN. Right now it only outputs 6, 12, or 24 and I have to retrain every time I switch it.

- When It comes to predicting past 24 hours It is clear I will need more data. My thoughts are right now I will need weather and AQI data from the surrounding cities.

- I want to also include data on weather there are important government meetings. The city usually shuts down the factories for these government meetings

**Things I wish I knew before I started**

I wish knew about numpy and how it can be used to easily read and clean large data sets. It took me a while to take care of the data I scrapped from the internet

Let me Know what you guys think"
"What's the first step in order, to create a simple machine learning algorithm",5,1,False,False,False,learnmachinelearning,1489921764,True, 
Some questions regarding building a recommender system,3,2,False,False,False,learnmachinelearning,1489922074,True,"So I'm a total noob in machine learning. I signed up for GaTech's unsupervised learning course on udacity because it had a fun movie recommendation system project in the end. The project instructions said to implement the recommendation system by using k-means clustering and Pearson Correlation Similarity Measure. I did a bit more googling and came across people using matrix factorization to improve their systems.

I'll be using the movielens 100k dataset and python and it's scikit-learn library for it.

So here's is what I understand what I am supposed to do-
1. Dimensionality Reduction
2. Clustering
3. PCSM
Is this order correct?

Here are some questions that are confusing me a lot-
1. Sorry if I sound stupid but my biggest question is what are the ""features"" in this context. I saw AndrewNg's course slides on recommender systems and understand the concept of features but not able to figure out what they are here. Are they the movie genres in the dataset? Or is it something the algorithm will figure out on it's own? What kind of features will PCA and KMeans be using?

2. SVD vs PCA for dimensionality reduction. Scikit-learn's PCA documentation states that it uses SVD for PCA. So I'm a bit confused here. I read that PCA is like a double-edged sword so first try to run your project without using it. I'll definitely following that. Just wanted to clear all my doubts right now.

I also plan on creating a simple front end with signup/sign-in option. Plan on using flask for it."
Can someone give me some pointers on how to learn Self-Organizing Map (SOM)?,3,4,False,False,False,learnmachinelearning,1489922707,True,"I am trying to learn kohonan SOM, read some books and watched some YouTube videos but still can't get the basic of it. It's like I don't know where to start. Does someone here have any good reference for me to start learning? 

EDIT: Sorry for being unclear. I actually have learned about it when I took data mining class last year, but I wasn't clear enough. From reading and watching some materials on the internet, I got that it's actually like an ANN, so it's got some nodes and weight. First, you assign weights with random values to the nodes and start from there. I got it so far, but then got confused. The next thing is you treat it like K-Means clustering, am I right? You then try to find the centroid (or reference vector in SOM term) like in K-Means, by determining the closest object to the centroid. And then you update the centroid. Do I get it right so far? 

Basically all I need is step by step explanation on how the algorithm works. "
Confused about Deconvolution,3,2,False,False,False,learnmachinelearning,1489965853,True,"I don't understand why there is only very little documentation on deconvolution. I kind of get it but not completely.

Let say I have 3 conv layers in this format

Conv1->pool->Conv2->pool->Conv3->pool

so if I want to upsample, then I should take the output from the last step and do
->deconv3->deconv2->deconv1->output image 

is this correct?"
Easy (silly) Machine Learning Algorithm Question,4,3,False,False,False,learnmachinelearning,1489967908,True,"Okay... So I am new the ML ... and want to start off with something simple.


Here's the context. If you plays game that involves overalls (NBA2k, NHL, FIFA)... one thing I want to find out ... is what is the formula to calculate this. (If its a simple average... I wouldnt be asking here but it isnt).


So... what I want to do for my first exercise size is ... provide a dataset of attributes of specific player and their end results and have my ML to train/predict for any set of attribute to give them.


What's a good ML to use? (For example.. I looked into Decision Tree, but it doesnt work || Linear Regression doesnt work because I have 2 variables)
Thanks alot!"
Advice for undergrad in ML,6,4,False,False,False,learnmachinelearning,1489984023,True,"Hey, so I'm a junior in college right now working on my BS in Computer Science. I was wondering if you guys could give me some advice involving how to get involved in undergraduate research for machine learning. I'm mostly self taught, but have a decent amount of knowledge in the area. My problem is that although my school has a research group for ML, it is heavily focused on grads and phd students, and they have completely ignored me despite several attempts towards getting involved. Should I just try to find a research lab at another nearby school and hope they do ML as well? It's kind of irritating, I just want to get involved in the academic community. 

Thanks!"
What machine learning algorithm should I apply ?,5,1,False,False,False,learnmachinelearning,1489995172,True,"I have the following problem and I cannot find in the literature the typical algorithm to apply, could you help me ?

I have a cost function c : AxB -> R and I try to approximate φ (with a neural network ?) such as ∀a∈A ∀b∈B c(a,φ(a)) ≤ c(a,b).

I can generate as many a∈A as I want but it takes a bit of time (around 5s), I can compute c(a,φ(a)) fairly fast (around 0.2s) but c does not have gradient (so no easy back-propagation).

I thought about using reinforcement learning but it seems to be difficult when having continuous state and infinite possibilities. Besides, it is a 1 action to immediate reward (it is not a game where multiple actions are required). 

Any ideas ?

EDIT : Corrected a mistake in the problem formulation"
What's the best way to get up to speed on the math needed for basic machine learning?,6,9,False,False,False,learnmachinelearning,1490030351,True,"I want to get into machine learning, but not sure if I have enough of the prerequisite math experience. I took calculus in college and am familiar with basic stats, but that's about it. 

I'm guessing I probably need a calculus refresher and exposure to linear algebra. I'm starting with Khan Academy, which seems decent, but any other suggestions would be appreciated!

(Or maybe I don't need to learn the math first? http://machinelearningmastery.com/techniques-to-understand-machine-learning-algorithms-without-the-background-in-mathematics/) "
Looking for an internship in machine learning.,12,0,False,False,False,learnmachinelearning,1490030873,True,"Hey, I've been with fascinated by Machine learning specifically deep learning and I don't completely  understand the place where it would go but I have an idea.

I've been using tensorflow and I love it's documentation, it's very lucid and user friendly.

But I've been looking for an internship (even unpaid) so that I can validate my skills. I do think sometimes I suffer with imposter syndrome, so yeah maybe some random project would be great experience."
How can I improve my RBM autoencoder for MNIST? (Tensorflow),4,3,False,False,False,learnmachinelearning,1490041322,True,[deleted]
"Is there a way to measure how long an epoch should be taking, because I feel like my network is taking unreasonably long to cycle each epoch.",1,2,False,False,False,learnmachinelearning,1490044267,True,"So, I'm implementing this network from scratch with basically no prior experience, as sort of a personal challenge. After getting my networks basic structure to work by teaching it to play tic-tac-toe, I decided I would begin messing around with 3x3 rubixs cubes.

I currently have 50 thousand training examples, and the network is fairly ""deep"", I dunno how else to describe that, it has 3 hidden layers with 56,40 and 36 nodes in each, with 54 inputs, one for each sticker, and 12 outputs for each (non-slice) way to turn a rubixs cube.

My training examples are generated via scrambling a cube and then undoing the scramble within a certain number of moves, and then putting each ""state"" of the cube, IE which stickers are where, as inputs with the correct turn to move towards the solution as the intended output.

The network is written in python, no NN modals, from scratch using numpy and basically no other outside tools beyond GUI stuff. It takes my network nearly one and a half *hours* to cycle a single epoch. I feel like this is grossly unreasonable but I just can't tell how long it *should* be taking on code that actually doesn't suck, so I don't know how bad mine is.

I don't know if multithreding would help, or using a different language, does anyone have a way of estimating this type of stuff?"
Linear algebra cheat sheet for deep learning,2,62,False,False,False,learnmachinelearning,1490045885,False, 
Which machine learning algorithm to apply and how to implement?,2,2,False,False,False,learnmachinelearning,1490047853,True,"https://www.hackerearth.com/challenge/competitive/machine-learning-challenge-one/machine-learning/bank-fears-loanliness/
This is the question. How to approach this? So far I used logistic regression, polynomial regression but didn't get any good results."
Is this book good for learning tensorflow?,2,7,False,False,False,learnmachinelearning,1490075476,True,https://www.amazon.com/gp/product/1786462168/ref=ox_sc_act_title_2?ie=UTF8&psc=1&smid=ATVPDKIKX0DER
MIT 6.S191 Lecture 6: Deep Reinforcement Learning,0,13,False,False,False,learnmachinelearning,1490084778,False, 
Help with Skip-Gram and Teseorflow needed,0,1,False,False,False,learnmachinelearning,1490092956,True,[deleted]
Help with Skip-Gram and Tensorflow needed,5,3,False,False,False,learnmachinelearning,1490094009,True,"Ok so I'm working on a skip-gram model with tensorflow.

I haven't worked with tensorflow before so I'm really confused how I have to shape my input for it to work. So in a Skip-Gram model with a word window of 1 I have a sentences as following for example:

""Sentence number one"" -> (sentence, number), (number, sentence), (number, one), (one, number)

""Another sentence here"" -> (another, sentence), (sentence, another), (sentence, here), (here, sentence)

My question now is, how do I use these tuples now? In my understanding I let the neural network learn the connection for a word (x) by its context words (y). So if x would be ""number"" then y would be ""sentence"" and ""one"".

But what about if x is ""sentence""? Do I process each document (here each sentence) after one each other or do I process them together?

So x is ""sentence"":

y= ""number""

or

y=""number"", ""another"", ""here""

Basically do I learn each document separately or can I learn them together.

My second question then is: how can tensorflow read my data. I suppose I have to convert them to integers somehow. Does tensorflow already have the means to do that or do I have to find my own solution for that.

As you can see I'm fairly new to all that so any help would be appreciated.
"
Question on one-to-many sequence to sequence model,1,1,False,False,False,learnmachinelearning,1490099450,True,"Hi! 

I'm trying to write a model, that predicts the most suitable answer to a question based on a set of 20 answers. One of the answers comes from the original thread the question was posted, while the remaining 19 comes are random replies from different threads.
My dataset consists of 5000 questions and 5000 answers, one answer per question. 
During training I want to just map one question to an answer using RNNs, CNNs or a combination, while during testing have the model predict the best answer out of 20 possibilities. 

As for now, I'm thinking about either using some sort of seq2seq model, but I'm at a loss regarding how to represent the output classes this way. , or calculating a sentence vector for the input and the outputs, and choosing the output with the closest euclidean distance. 
Have any of you done anything similar, read/heard about a similar type of project or have any pointers? 

I have looked at seq2seq models, http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf, but it seems that this approach generates answers instead of picking from a list. 

This paper: https://www.aclweb.org/anthology/P/P15/P15-1152.pdf is a bit closer to what I'm looking for, but I still feel a bit lost when thinking about how to approach the task. 

I'm currently using Keras for other tasks related to the dataset, and would like to continue using Keras as much as possible. 

"
Reading DeepLearningBook.org and came across a surprising generalization. Anyone have research to back it up,3,7,False,False,False,learnmachinelearning,1490104455,True,"""As of 2016, a rough rule of thumb is that a supervised deep learning algorithm will generally achieve acceptable performance with around 5,000 labeled examples per category, and will match or exceed human performance when trained with a data set containing at least 10 million labeled examples.""


I am tempted to take this at face value coming from such a good source but I wish I new more about where this assertion is actually coming from. Is there data or papers to back this up?"
Carnegie Mellon machine learning program,0,2,False,False,False,learnmachinelearning,1490110491,True,I've been exploring potential careers and I'm currently interested in machine learning. Carnegie Mellon appears to have a great program for it but I'm currently in the University of Pittsburgh and it does not offer a machine learning undergraduate like Carnegie does. Would a computer science undergraduate degree with an artificial intelligence concentration combined with coursera and Udacity be sufficient to counter this disadvantage?
Best AI and chatbot conferences in 2017,0,8,False,False,False,learnmachinelearning,1490110883,False, 
What is TensorFlow NoOp on GPU?,0,2,False,False,False,learnmachinelearning,1490115991,True,"I'm profiling ops on a GPU. What is going on behind the NoOp? My guess is a data transfer is occurring between CPU and GPU, since TopKV2 does not have a GPU kernel. 

[screenshot](https://unsee.cc/bisozeda/) 
"
Semi-supervised learning : beyond self training,1,2,False,False,False,learnmachinelearning,1490121231,True,"Hi,

I'm looking for content (papers / tutorials / libraries / anything) about semi-supervised learning (using unlabeled data + labelled data to predict better than with labelled data alone).  

Atm, I've found a few links ([here](https://mitpress.mit.edu/sites/default/files/titles/content/9780262033589_sch_0001.pdf), [here](http://pages.cs.wisc.edu/~jerryzhu/pub/sslicml07.pdf), [here](http://rinuboney.github.io/2016/01/19/ladder-network.html)) that are helpful, but I'm still looking for someting more convincing.  

What I've learned so far :  
>- SSL can be achieved by using your model to predict labels and then using these labels to learn better. This is called self training.  
>- There are also models dedicated to the task. There are very different approaches like graph-based oned, generative ones, etc...  
>- There is a neural-net approach inspired by self learning called [pseudo-label](http://deeplearning.net/wp-content/uploads/2013/03/pseudo_label_final.pdf)  
>- There is also a thing called [ladder networks](https://arxiv.org/pdf/1507.02672.pdf) that I have yet to understand  

I still can't answer questions like :  
>- What is the state of the art ? For image SSL ? For text SSL ? For structured data SSL ?  
>- What do neural nets do that other algorithms don't ?  
>- Isn't there an approach based on autoencoders, where you'd learn an unsupervised representation of the manifold and then use it to predict ?  
>- How can I implement this in R, python or a reasonably common language ?  

Thanks !"
NN works with sigmoid but not with tanh activation function - help me please,4,1,False,False,False,learnmachinelearning,1490128996,True,"Hi,

I am learning about neural networks. Therefore i bought the book ""Make your own neural network"" (https://github.com/makeyourownneuralnetwork/makeyourownneuralnetwork/blob/master/part2_neural_network_mnist_data.ipynb). This is quite good but the code example only supported the sig moid activation function. I modified the code to also work with tanh - but the performance drops to about 20 % when using tanh against 95% when using sigmoid... Could you please help me to find out where my mistake is?

To try the sigmoid version you have to comment the lines in activation function and derivativeActivationFunction and the lines at the end that have comments that say which line is for the required activation function.

Thank you for your time and your help. The code is here: 

    import numpy
    import scipy.special
    import matplotlib.pyplot
    %matplotlib inline
    
    def activationFunction(x):
        #return sigmoid(x)
        return tangensHyperbolicus(x);
    
    def sigmoid(x):
        return scipy.special.expit(x)
    
    def derivativeSigmoid(x):
        return sigmoid(x) * (1.0 - sigmoid(x))
    
    def derivativeActivationFunction(x):
        #return derivativeSigmoid(x)
        return derivativeTanH(x)
    
    def tangensHyperbolicus(x):
        return numpy.tanh(x)
    
    def derivativeTanH(x):
        hyperTangensResult = tangensHyperbolicus(x);
        return 1.0 - (hyperTangensResult * hyperTangensResult);
    
    class neuralNetwork:
        
        def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):
            self.inodes = inputnodes
            self.hnodes = hiddennodes
            self.onodes = outputnodes
             
            self.wih = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.hnodes, self.inodes))
            self.who = numpy.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes))
    
            self.lr = learningrate        
            pass
    
        
        def train(self, inputs_list, targets_list):
            inputs = numpy.array(inputs_list, ndmin=2).T
            targets = numpy.array(targets_list, ndmin=2).T
            
            hidden_inputs = numpy.dot(self.wih, inputs)
            hidden_outputs = activationFunction(hidden_inputs)
            
            final_inputs = numpy.dot(self.who, hidden_outputs)
            final_outputs = activationFunction(final_inputs)
            
            output_errors = targets - final_outputs
            hidden_errors = numpy.dot(self.who.T, output_errors) 
            
            deriv1 = derivativeActivationFunction(final_inputs)
            self.who += self.lr * numpy.dot((output_errors * deriv1), numpy.transpose(hidden_outputs))
            
            deriv2 = derivativeActivationFunction(hidden_inputs)
            self.wih += self.lr * numpy.dot((hidden_errors * deriv2), numpy.transpose(inputs))
            
            pass
    
        
        def query(self, inputs_list):
            inputs = numpy.array(inputs_list, ndmin=2).T
            hidden_inputs = numpy.dot(self.wih, inputs)
            hidden_outputs = activationFunction(hidden_inputs)
            
            final_inputs = numpy.dot(self.who, hidden_outputs)
            final_outputs = activationFunction(final_inputs)
            
            return final_outputs
    
    input_nodes = 784
    hidden_nodes = 200
    output_nodes = 10
    
    learning_rate = 0.1
    
    n = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)
    
    training_data_file = open(""mnist_dataset/mnist_train.csv"", 'r')
    training_data_list = training_data_file.readlines()
    training_data_file.close()
    
    epochs = 5
    
    for e in range(epochs):
        print(e)
        for record in training_data_list:
            all_values = record.split(',')
            #for sigmoid:
            #inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01
            
            #for tanh:
            inputs = ((numpy.asfarray(all_values[1:]) / 255.0 * 2.0) -1.0) * 0.99
            #targets = numpy.zeros(output_nodes) + 0.01
            targets = numpy.zeros(output_nodes) - 0.99
            targets[int(all_values[0])] = 0.99
            n.train(inputs, targets);
            pass
        pass
    
    test_data_file = open(""mnist_dataset/mnist_test.csv"", 'r')
    test_data_list = test_data_file.readlines()
    test_data_file.close()
    
    
    scorecard = []
    print(""Checking score"")
    for record in test_data_list:
        all_values = record.split(',')
        correct_label = int(all_values[0])
        #for sigmoid:
        #inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01
        
        #for tanh:
        inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 2.0) -1.0
        outputs = n.query(inputs)
        label = numpy.argmax(outputs)
        if (label == correct_label):
            scorecard.append(1)
        else:
            scorecard.append(0)
            pass
        
        pass
    
    scorecard_array = numpy.asarray(scorecard)
    print (""performance = "", scorecard_array.sum() / scorecard_array.size)"
Mining build log,0,1,False,False,False,learnmachinelearning,1490130198,True,"I have about ten years of build logs for the legacy product I work on.  The test suite has some at times surprising relationships mapping test cases to the code under test.  I would like to able to when I receive a new build failure email evaluate the commits and determine the change that is most likely the source.  

I am a run of the mill enterprise java developer so I do not really stay up on data science-y things.  Is this a reasonable goal?  I can imagine picking features such as class name, package, edit distance of class name and test name and coming up with some statistics.  If I go through one of the online machine learning or data science classes will I be equipped with the knowledge to take on this task? "
Need some help to understand The Elements of Statistical Learning.,9,4,False,False,False,learnmachinelearning,1490131176,True,"I've read 20 pages of Hastie's 'The Elements of Statistical Learning' and I'm overwhelmed by the equations (like 2.9 what 'E' stands for; 2.11 ??)

Can you recommend some Book, Course, whatever to help me understand it?"
LSTM and Reinforcement Learning,0,5,False,False,False,learnmachinelearning,1490145316,True,"I am currently working on an implementation of Deep Recurrent Q-Learning, but I seem to be having some trouble understanding the LSTM layer that I need.

The implementation is based off of the paper [Deep Recurrent Q-Learning for Partially Observable MDPs](https://arxiv.org/abs/1507.06527) which is a modification of the paper [Playing Atari with Deep Reinforcement Learning](https://arxiv.org/abs/1312.5602). 

For the most part I understand everything related to the Atari paper. I have implemented my own version using Keras and tested it on the OpenAI Gym module with good enough results.

However, now I'm trying to modify my previous code to have an LSTM recurrent layer. I managed to get that working and have been running tests, however, I haven't been able to achieve the optimal scores in the Gym tests.

I should note, I am currently testing on a modified version of CartPole where the velocity observations have been removed. The project is to see if the LSTM can figure out velocities by ""remembering"" the positions. The authors of the Deep Recurrent paper had good results on images, so I figure this simple problem should have decent results.

I believe my understanding of the LSTM internal state may be the problem, so I was hoping someone could answer a few questions on it.

1) So, the LSTM starts with a zeroed/blank/empty state when created, lets call it S0.

2) The network is given the observations and it outputs the action to use in Gym. The internal state is advanced to S1. 

3) The training function now uses the prediction to get the Q values for calculations done later. This advances the internal state to S2.

4) Next, training is done on the training data. If the internal state isn't reset, the first training example begins at S2 and progresses from there.

5) The internal state is reset to S0 after training.

6) We now pass a new set of observations into the network and get the next action (like in step 2). But, since the state was reset after training, we are starting from S0, but perhaps it should be S1 since it's the action after the initial action?

I've also done some other testing with some toy code, and I'm not sure my above explanation is correct or not. If I predicted an example that was the last in the sequence, I would get a good value. If I next predicted the first example in the sequence without resetting the state, it would be off by a little but not an extreme amount. But the sequences that followed seemed to slowly correct themselves to the correct value.

So, could someone clear up the LSTM internal state issue for me? I'm a little confused.

Thanks."
Learning path for machine learning,6,7,False,False,False,learnmachinelearning,1490145976,True,"I am interested in machine learning, my background is from java. So picked up python (learn a second language and also read from blogs its good for machine learning). 

subscribed to \u\sentdex youtube channel. Also looked at this course from edx Microsoft's Introduction to Python for Data Science. 

My question is how do i proceed after this, doing a google search shows alogrithms, deeplearning, keras, scikit tensor flow. is there any particular order through which i can progress completing one after another. Which i should complete first. please can some one point to me to on the correct approach  (i dont want to overload/overboard and get slowed down)"
TWIL (This Week I Learned) - Share something new that you have learned this week!,0,1,False,False,False,learnmachinelearning,1490166474,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
"TensorFlow and Deep Learning without a PhD, Part 1 (Google Cloud Next '17)",3,52,False,False,False,learnmachinelearning,1490175339,False, 
Looking for outlier detection implementations in R language,0,1,False,False,False,learnmachinelearning,1490194663,True,"Hi,

I'm disappointed. It looks like R's algorithms for outlier detection are outdated, slow or both. It must be that I haven't found the best ones.

So far, I've considered the following algorithms : IsolationForests, HighDimOut, abodOutlier. They work, but I think I need something better.

Note that I'm not set on which approach would work for my problem, so any algorithm is welcome, being density-based, graph-based, angle or distance-based, AE-based...

Thanks !

Note : Do you know something better. My dataset consistst of 500k rows and 200 columns."
Looking for a tutorial I can't find anymore,1,3,False,False,False,learnmachinelearning,1490202655,True,"Hi everyone!

I'm looking for a machine learning introduction that I think I originally came across on HackerNews a few years ago. The tutorial was very unique: AIRC it involved stop-motion type animations, with someone writing on sticky notes to show a basic neural network setup. Does this ring a bell with anyone? I've done dozens of google searches with no useful results."
Getting job ready in Machine Learning,1,2,False,False,False,learnmachinelearning,1490207830,True,"I worked in BI for couple of years and with the goal of moving into ML, I started taking Prof Ng's course in Coursera and I am half way through. What should I do next to become job ready in the field of ML (I am more interested in NLP/Image recognition)in next 6 months? 6 months is the timeline goal that I've set myself to equip myself with the required skills (atleast enough for a entry level position.)


Appreciate the help and God Bless Prof. Ng :) "
"Thoughts on Fast.ai? And also, when do I transition to ML/AI/data science career?",0,3,False,False,False,learnmachinelearning,1490210849,True,"Nowadays there are so many ML programs and quite a lot of them - I suspect - are fad-following rehashes.

I came across Fast.ai, which promotes itself as practical, jump-and-swim type of learning, which a seamless transition to Kaggle.

What are your thoughts on this?

I feel like I could start Fast.ai and accompany the theory part with Ng's ML course in Coursera. Once I'm done, I'll test myself with Kaggle competitions.

Is that a solid plan to learn ML?

My last question is: When do I transition to a data science/ML career? If I set my goal to be in top 20 of a Kaggle competition, would that be a moment in my career to transition into a more data science-type of a field?

Quick background:
I work as an app developer, and have domain specific knowledge of medicine.
"
Iterating over TensorFlow Dimension of type 'None',1,1,False,False,False,learnmachinelearning,1490214736,True,"I'm implementing a new variation of a NN where I need to define certain mathematical functions in TensorFlow. However, I am getting a placeholder error with the following function. This function is replacing the `tf.matmul()` function, where `self` would be the hidden layer and `A` would be your input layer. I have extracted the problem lines to recreate it. For my code to work, it _must_ be in this format. Unless someone can help me reformulate it. The problem arises on the definition of `idx`

    def My_Function(self, A):
        with tf.Session() as sess:
            result = tf.zeros_like(A)
            tf.reshape(result, [tf.shape(A)[0], self.m])
            idx = [[i] for i in sess.run(tf.range(0, tf.shape(result)[0]))] # Problem is this line


As `My_Function` replaces the `tf.matmul` function, the dimensions of `A` are not known until run time. This function is defined in my activation function of the form `tf.nn.relu(h.My_Function(A) + B)` where `A` is my input and `B` is biases. Therefore, when defining the layer, this is before run/training time, so the ""official"" dimensions of `A` by this point are `[None, 28, 28, 1]`. 

The error that I get at run time when defining the layer is 

 


    InvalidArgumentError: You must feed a value for placeholder tensor 'Placeholder' with dtype float
	 [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

    Caused by op 'Placeholder', defined at:
      File ""/home/christopher/anaconda3/lib/python3.5/runpy.py"", line 184, in _run_module_as_main
    ""__main__"", mod_spec)
      File ""/home/christopher/anaconda3/lib/python3.5/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
      File ""/home/christopher/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py"", line 3, in <module>
    app.launch_new_instance()
      File ""/home/christopher/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py"", line 653, in launch_instance
        app.start()
      File ""/home/christopher/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py"", line 474, in start
    ioloop.IOLoop.instance().start()
      File ""/home/christopher/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py"", line 162, in start
        super(ZMQIOLoop, self).start()
      File ""/home/christopher/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py"", line 887, in start
    handler_func(fd_obj, events)
      File ""/home/christopher/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py"", line 275, in null_wrapper
        return fn(*args, **kwargs)
      File ""/home/christopher/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py"", line 440, in _handle_events
        self._handle_recv()
      File ""/home/christopher/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py"", line 472, in _handle_recv
        self._run_callback(callback, msg)
      File ""/home/christopher/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py"", line 414, in _run_callback
        callback(*args, **kwargs)
      File ""/home/christopher/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py"", line 275, in null_wrapper
        return fn(*args, **kwargs)
       File ""/home/christopher/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py"", line 276, in dispatcher
        return self.dispatch_shell(stream, msg)
      File ""/home/christopher/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py"", line 228, in dispatch_shell
        handler(stream, idents, msg)
      File ""/home/christopher/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py"", line 390, in execute_request
        user_expressions, allow_stdin)
      File ""/home/christopher/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py"", line 196, in do_execute
        res = shell.run_cell(code, store_history=store_history, silent=silent)
       File ""/home/christopher/anaconda3/lib/python3.5/site-packages/ipykernel/zmqshell.py"", line 501, in run_cell
        return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
      File ""/home/christopher/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2717, in run_cell
        interactivity=interactivity, compiler=compiler, result=result)
      File ""/home/christopher/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2821, in run_ast_nodes
        if self.run_code(code, result):
      File ""/home/christopher/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2881, in run_code
        exec(code_obj, self.user_global_ns, self.user_ns)
      File ""<ipython-input-4-8452266bec9e>"", line 3, in <module>
        X = tf.placeholder(tf.float32, [None, 28, 28, 1])
      File ""/home/christopher/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py"", line 1587, in placeholder
    name=name)
      File ""/home/christopher/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 2043, in _placeholder
    name=name)
      File ""/home/christopher/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 759, in apply_op
        op_def=op_def)
      File ""/home/christopher/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2240, in create_op
    original_op=self._default_original_op, op_def=op_def)
      File ""/home/christopher/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1128, in __init__
        self._traceback = _extract_stack()

    InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype float
	     [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

 

Does anyone have any suggestions on how to resolve this error? `idx` is certain indices of `result` as I need to perform some generic arithmetic operation on them. The full form has a list of both `i` and `j`, but that would reproduce the same error more than likely so I reduced it down to just the basics"
Extrapolation of Neural Network,1,2,False,False,False,learnmachinelearning,1490217039,True,"Imagine we input some numbers into our Neural Network and teach it to perform some operation, e.g. add them all together or calculate arithmetic mean or root mean square. So far we taught it to perform on a bounded amount of numbers. And my question is, are there techniques to extrapolate a NN to an arbitrary amount of input variables?

Notice that all my examples are symmetric functions. But I believe with enough advancement something similar could be done with functions with more complex input.

"
Where do you get your ML News from? Post listing different sources,0,9,False,False,False,learnmachinelearning,1490237981,False, 
Tensor-flow training error: InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype float,2,2,False,False,False,learnmachinelearning,1490259407,True,"I am learning to write my first tensor-flow neural network. I used videos and other web articles to learn myself tensorflow. I wrote this simple neural network for iris data set classification .

https://gist.github.com/anonymous/77f951cf6d914875259539fbe92752b4

But its showing this error 

>InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype float

Any idea why its happening and how to solve it

EDIT1: I have removed the bug and its running fine can any one check my code and tell me whether my implementation is correct or not.
https://gist.github.com/anonymous/1f12142139b7e3e91ce8b764492a423e"
game2vec - game embeddings,0,1,False,False,False,learnmachinelearning,1490263196,False, 
[N] 4 week's ML camp in Korea in July (sponsored by Google & Kakao),1,6,False,False,False,learnmachinelearning,1490265516,True,"[Link] https://github.com/TensorFlowKR/MLJejuCamp

Call for application for Machine Learning Camp Jeju 2017

If you have studied machine learning/deep learning and TensorFlow, you probably want to implement a non-trivial and large-scale system for real use. We invite you to the month-long Machine Learning Camp Jeju 2017, where you can make that dream a reality.

For a full month in beautiful Jeju Island, you and other participants will train a deep learning model using TensorFlow from start-to-finish. Jeff Dean (Google Senior Fellow via Hangout), and Rajat Monga (Google/TensorFlow Director (TBC)) will give us keynote talks. Plus, you will have access to experienced mentors including Namju Kim (Head of Research for Kakao Brain), Lucy Park (TF-KR), Sung Kim (TF-KR), Donghyun Kwak (TF-KR), Terry Taewoong Um (TF-KR), and many more. We hope you take advantage of this wonderful opportunity.

Those selected as participants will be provided with one (1) round-trip airfare (up to 300 USD) to Jeju Island (South Korea), room and board at Jeju National University, USD 1,000 in stipends and USD 500 to 1,000 in Google Cloud Credit. In addition to these benefits, participants will gain valuable and practical experience in the field of deep learning. We look forward to your application!

Mentor Recruitment: If you’re interested in sharing your experiences and expertise with the camp, please contact us at mljejucamp@googlegroups.com. You will serve as personal mentors to 1 to 2 participants, holding 2 to 3 on/offline meetings a week to help them successfully complete their projects. While it is possible for you to provide online-only mentoring, we suggest you visit Jeju Island to meet with your mentees in person. We will provide round-trip airfare (up to USD 300) to Jeju Island and up to five (5) days of room and board.

(Information regarding schedule, program and benefits are subject to change as we are in the process of finalizing the details. We will have more information later.)

Camp Overview

Date: July 3rd through 28th, 2017 (Check-in date: July 2nd)
Participants: 20
Location: Jeju National University / Kakao Space.1
Organizers: TensorFlow Korea User Group, Kakao, Google, Smart Grid CK Center in Jeju National Univ, Jeju Center for Creative Economy and Innovation, Jeju Local Government (Subject to change)
Home page: https://github.com/TensorFlowKR/ml-jeju-camp
Application: https://www.surveymonkey.com/r/LY29GM5 (By April 20 11:59PM AOE)
Contacts: Please leave your comments/questions on issues (https://github.com/TensorFlowKR/ml-jeju-camp/issues) in this page.
Benefits (TBD)

Full month of hands-on experience training deep learning models with TensorFlow and mentorship from top developers
Round-trip airfare to Jeju Island (up to $300 USD)
Accomodation in Jeju National University or Kakao Space, Jeju
Stipend: 1,000 USD
Google Cloud Credit ($500~1000 TBD)
Qualification

No nationality, gender, age, degree, education requirements
Must be able to stay in Jeju Island from July 3rd to 28th. (Weekday camp programs run from 10AM to 5PM)
Good understanding of TensorFlow and deep learning and ability to train models (should be able to understand all in https://github.com/hunkim/DeepLearningZeroToAll)
Basic communication skills in English (All programs will be in English)
Application (By April 20 11:59PM AOE)

Detailed proposal for Deep Learning Camp Jeju 2017 project (Please be as detailed as possible)
CV that showcases applicant’s experience with deep learning and TensorFlow
Previously implemented models (GitHub or other)
Other supporting materials to show your qualification
Application link: https://www.surveymonkey.com/r/LY29GM5"
Why Mean Squared Error and L2 regularization? A probabilistic justification.,1,1,False,False,False,learnmachinelearning,1490274736,False, 
"How to Learn Machine Learning, The Self-Starter Way",4,55,False,False,False,learnmachinelearning,1490278313,False, 
TensorFlow: Mutating variables and control flow,1,1,False,False,False,learnmachinelearning,1490286721,False, 
"To become a data scientist, focus on coding",0,14,False,False,False,learnmachinelearning,1490291372,False, 
Question Solving Regression Problem,1,3,False,False,False,learnmachinelearning,1490303015,True,"So, I've been trying to implement my first algorithm to predict the sales per month of a single product,  I've been using linear regression since that was what were recommended to me. I'm using data from the past 42 months, being the first 34 months as training set, and the remaining 8 as validation.


I've been trying to use 4 features to start:
Month number(1~12)
Average price that the product was sold during that month
Number of devolutions previous month
Number of units sold previous month



Here are images with graphs comparing the Real Data x Predicted Data and a Error x number of elements graph:
http://imgur.com/a/9tvIc


So far the results are not good at all (as shown in the images above), the algorithm can't even get the training set right. I tried to use higher degrees polynomials, and the regularization parameter, it seems to make it worse.

Then, I would like to know if there is a better approach for this problem, or what could I do to improve the performance.

Thanks a lot in advance!
"
Weekly Show-off!,1,5,False,False,False,learnmachinelearning,1490339346,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
Need help to tune an autoencoder for MNIST,2,1,False,False,False,learnmachinelearning,1490374188,True,"Hi,

I'm trying to build an autoencoder for the MNIST dataset. My first attempts don't work, and I feel like I could use some tips.

To start with, I've tried to replicate the results presented [here](https://www.r-bloggers.com/a-little-h2o-deeplearning-experiment-on-the-mnist-data-set/). I copy-pasted the code, and ran the experiment. The resulting scatterplot was far from good, and I decided to try and change the parameters.

After a bit of grid search, I've found that all attempts lead to very high reconstruction error. When I plot reconstructed digits, they pretty much all look the same apart from a tiny difference in brightness. I've tried more or less deep networks, with 2 to 32 neurons in the central hidden layer, and nothing works.

Here is the current training code :  
>ae = h2o.deeplearning(  
  x = xvars,  
  training_frame = h2o.mnist.train,      # Corresponds to rows 1:30000 in the original dataset  
  # validation_frame = h2o.mnist.test,  # Corresponds to rows 30001:42000 in the original dataset  
  hidden = c(400, 100, 32, 100, 400),   
  epochs = 600,  
  activation = ""TanhWithDropout"",  
  input_dropout_ratio   = 0.1,  
  hidden_dropout_ratios = c(0.5, 0.5, 0, 0.5, 0.5),  
  autoencoder = TRUE,  
  l2 = 10e-5,  
  mini_batch_size = 256,  
  seed = 42  
)

Anyone knows a set of parameters that worked in the past and that I can replicate to start with please ?

Thanks :)"
Is there any good tutorials on feature vectors with q-learning and q-learning with neural networks?,0,5,False,False,False,learnmachinelearning,1490387572,True,"Hi Reddit. I hope that I have come to the right forum. I am trying to get a deeper understanding of Q-Learning, DQL and machine learning in general. I am asking my fellow redditors for help. I do have experience with SE however not so much with ML. I want to implement a Q Learning algorithm with neural networks and compare it to a Q learning algorithm with feature vectors. Do any of you know of any papers covering this or if you have any links to articles explaining the concepts relating to this. So basically 
q learning,
q learning with neural networks,
neural networks,
q learning with feature vectors,
or feature vectors
I appreciate any help I can get. Thank you reddit and sorry if this is the wrong forum."
What is Machine Learning? Algorithm Types & Real Life Examples,0,5,False,False,False,learnmachinelearning,1490419881,False, 
"Weekly Scrum Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",5,6,False,False,False,learnmachinelearning,1490425641,True,"Let's have a scrum meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
GPU article check,3,5,False,False,False,learnmachinelearning,1490454554,True,I think about buying GPU and I'm low on budget. I found this article http://timdettmers.com/2017/03/19/which-gpu-for-deep-learning/. Is it accurate? Why there are no AMD cards?
can anyone please explain to me what the parameters of the nntraintool mean ? • r/matlab,0,1,False,False,False,learnmachinelearning,1490460071,False, 
"Using (0,1) or (-1, 1) for binary inputs? - neural net",9,10,False,False,False,learnmachinelearning,1490493652,True,"From here
https://visualstudiomagazine.com/articles/2013/07/01/neural-network-data-normalization-and-encoding.aspx
I read
""There's convincing research that indicates a -1.0, +1.0 scheme is superior to a simple 0.0, 1.0 scheme for independent binary variables.""

However it gives no links/sources for this and no explanation.
Can anyone shed any light on this choice?"
Question on online POMDP reinforcement learning,0,3,False,False,False,learnmachinelearning,1490504663,True,"Hi all, I'm new to reinforcement learning and have been reading about it in a POMDP, online setting. My understanding of online learning is the following:  
  
1. Data comes in --> Learn
2. Policy is generated
3. More data comes in --> Learn
4. Policy is updated
5. and on.  
  
My understanding of POMDP policies is that they are deterministic mappings of belief to action, pi: *b* --> *a*, and each belief state is a distribution over the underlying states.  
  
My question is, after each learn session, I get an updated policy, but with an updated policy, my set of belief states would be different as well (along with their distributions over states). So if an agent is applying the learned policies, how does it traverse each updated policy?"
How expert do i need to be in programming for ML?,4,7,False,False,False,learnmachinelearning,1490517071,True,"Hi guys, im kinda new with ML (less than 4 months). Im using scikit-learn mainly to do some basic ML project/task. Im not a very good programmer. Most of my python knowledge comes from tutorials online and documentation of sklearn, numpy and matplotlib. Just want some opinion from people that have been using ML for few years, is it worth it to spend and allocate my time to really grasp the programming side to become good in ML (planning to get this [python book](https://www.amazon.com/Fluent-Python-Concise-Effective-Programming/dp/1491946008/ref=sr_1_1?ie=UTF8&qid=1490516704&sr=8-1&keywords=fluent+python) )? Or is it just sufficient by reading online tutorials and doumentation?"
How do you input images to a CNN?,3,2,False,False,False,learnmachinelearning,1490524421,True,"Please could someone help? I know you need to input data to a neural net as a Vector, how do I convert images to vectors and input them to a convolutional NN in python? 

All examples Ive done are on MNIST which is all prepared nicely so I have no idea on how to go about doing this. Thanks!"
Unsupervised feature extraction,3,3,False,False,False,learnmachinelearning,1490527536,True,I have a decent amount of unlabelled data and a fairly small amount of labelled data. Does anyone have some insights on how to extract some information from the former and then train (fine-tune?) it on the latter?
Any good tutorial for learning Keras (TF) ?,4,13,False,False,False,learnmachinelearning,1490549343,True,"I'm trying to learn machine learning (I've already done sklearn class on udacity). But I can't seem to find any good tutorials on learning Keras for TF. I've found a bunch of blogs and stuff but most of them were for theano. Not to mention I'd prefer it to be a video tutorials.

Also I'm on windows. Don't know if that matter a lot or not since both keras and TF support windows now. But if its too much of a hassle to do it on windows I've also got a linux partition.

Thanks!"
[P]: Let's make an A3C: Implementation | A3C tutorial | Keras & TensorFlow with GPU | 300 lines | 30 seconds to train in CartPole environment,1,8,False,False,False,learnmachinelearning,1490552316,False, 
Vectorizing Quiz Results,0,2,False,False,False,learnmachinelearning,1490559982,True,"Hi /r/LearnMachineLearning,

I work for an apparel startup and I recently developed an interest in data science and it's application to the apparel industry (think Stitch Fix). I have been self-learning this subject and am trying to apply them at work as training/learning using real data. 

The idea is very similar to what Stitch fix is doing - taking quiz results as input and returning a style recommendation for each unique user. For my project, I'm to do something simpler first by clustering customers based on quiz results and what they have bought. 

In my approach, I'm thinking of combining 2 distance metrics - quiz results and items they bought - and then grouping them by using K means. Since we have our own catalog, I could just assign 1s or 0s for all items in an array for items each user bought. However, I'm too sure how to deal with the quiz results, which has 6 questions but different amount of options in each question. For example, one question has 3 answers to choose from but another one has 7 answers to choose from. Users can only pick 1 answer for every question. 

Intuitively, I would assign a standard 7x6 (6 questions) for each user. and for questions which have <7 options, I would just assign , say 0 for the ""non-existent"" option. Is this the right way of doing it? Or is there a better way to normalize the data?

I hope I'm being clear with my problem! I would be grateful for any advice anyone can provide.

Thanks!"
[P] Neural Image Captioning using TensorFlow,1,4,False,False,False,learnmachinelearning,1490561133,False, 
Backpropogation confusion,4,7,False,False,False,learnmachinelearning,1490574952,True,"So I have a semi working backpropogation algorithm, but what I can't seem to wrap my head around on every version of neural network implementations is the derivate of the sigmoid function being used to calculate the error of a neuron.

So I understand the formula is effectively this for an output neuron 'O', where w is the expected output, o is the actual output, and 𝛿 is error.

𝛿O = (w-o)(o-1)(o)

Except what I see right away is if the actual output of a neuron is 1, or very very close to 1, then the expected output doesn't matter...

𝛿O = (w-1)(1-1)(1) = (w-1)(0)

I feel like I am supposed to be applying the sigmoid function a second time somewhere. Right now if my output neuron is outputting a '1' (something like 0.9999....) and I feed back in a '0' as the expected output, it still thinks it has an error of like 6*10^-8 or something infinitesimally small like that.

Which is very very wrong, since its basically as far away from the fed in value as possible...

Here's a link to my code:

https://github.com/SteffenBlake/AIExample/blob/master/SimpleAI/DeepThink.cs"
1 Can anyone give a real life example of supervised learning and unsupervised learning?,3,4,False,False,False,learnmachinelearning,1490605646,True,"There is a stackoverflow question with same title, but the answers given there are not satisfactory and not pertaining to the title."
Word Vector Service / API,5,6,False,False,False,learnmachinelearning,1490615123,True,"I've been playing around with word2vec on my local machine, but realized that my computer doesn't enough memory to load the larger models, like [Google News dataset](https://code.google.com/archive/p/word2vec/) (3.5GB unzipped). I was going to try and build an AWS instance. But before that, I was curious if anyone knows of any MLaaS options that may have a free tier with a server API for playing around with word vectors or word similarity?"
Has someone tried to create networks with different types of activation function on the same hidden layer ?,3,7,False,False,False,learnmachinelearning,1490622538,True,Maybe there is a reason why people don't seem to do it :)
Tensorflow + ML,9,7,False,False,False,learnmachinelearning,1490642483,True,I want to start of with ML while learning tensorflow along the way. I have decent knowledge in python. Which tutorial would you recommend to learn both at the same time
[Request] Trained MLP Binary Neural Network Model,6,3,False,False,False,learnmachinelearning,1490655853,True,"Hi, I want to try some quick experiements with inference using binary neural networks. I've been trying to find a pre-trained model for something simple like MNIST. Unforunately every library ive found seems to need a lot of pre-reqs ( such as GPUS, which i dont have access to!). Since in the end, I just need a simple file of weights (just a bunch of -1s and 1s really!) would someone be able to help me out? just something like MNIST using 1-2 hidden layers ( maybe 768-1024-10 or 768-1024-1024-10)! if someone has all the infrastructure for this setup, it might only take a short while! Thanks a lot! "
Is there a good flow chart explaining style transfer?,1,3,False,False,False,learnmachinelearning,1490703802,True,I am looking for a good flow chart explaining the mechanism of style transfer. The only decent one I am able to find is this https://magenta.tensorflow.org/assets/vgg_classifier_output.png . Any one else have other images(with explanations optional)?
IoT And 5G All Set To Dominate The World,0,1,False,False,False,learnmachinelearning,1490707658,False, 
Implementing a random forest,3,8,False,False,False,learnmachinelearning,1490712818,True,[deleted]
Important ML papers for beginners,2,9,False,False,False,learnmachinelearning,1490715416,True,I want a list of papers for a newbie
How to set up Mac for machine learning?,1,1,False,False,False,learnmachinelearning,1490716547,True,[deleted]
On the cross-validation for Neural Networks / Deep learning,5,5,False,False,False,learnmachinelearning,1490738318,True,"Hello,

I am concerned about model (hyperparameter) selection when working with Neural Networks. The issue or my misunderstanding is how to assess the number of epochs.
I know that ideally you use Early Stopping over a validation set to get the final model; but, when working with not very big datasets, it would be better to use cross validation.
The thing is that if we want to extract the number of epochs (the mean) from the cross-validation, this number has a very high variance (depending on the fold, it might get semi-stuck in local minima and take more epochs; or just converge faster).

Summarizing:

- Classic ML algorithms: 
1) Cross Validation 
2) Select best parameters 
3) Train over the whole training set

- NN / DL: 
1) CV 
2) Select best params 
3) How to train over the whole training set without using Early Stopping (because there is no validation set)?

Thank you
"
[P] Yannl - A C++ neural network library focused on compactness and portability that I've been working on for educational value/fun,2,4,False,False,False,learnmachinelearning,1490748096,False, 
Beginner question: what is the difference between the derivative of the cost function and the error gradient?,2,12,False,False,False,learnmachinelearning,1490751668,True,"Hello, preface to this, I'm 17 and I've never finished a calculus class, I'm doing this out of a personal interest in machine learning but my skills and knowledge are still very sketchy, so please feel free to correct any mistakes or stupidity in my reasoning or terminology or whatever.

Moving on, I don't really understand the difference between the error gradient and the derivative of the cost function. To my understanding (I'm on mobile so forgive the format), if I were using a quadratic cost function, which is 1/2 (Observed-Expected)^2 where observed and expected are the real output vs the optimal output for each class for a given training example. This outputs a one dimensional array with the same number of elements as there are classes in the network, and the summation of this is the networks cost. This is my understanding of cost, please correct me if I am wrong. 

Now here is the part that I don't get, what is the difference between a networks error gradient and the derivative of the cost? If the derivative of that cost function is just (observed - expected), then would the error gradient simply be a class-label sized vector with each one plugging the output nodes observed value into the derivative of the cost function? Or is that completely​ wrong? And how does the error gradient actually relate the partial derivative of whatever regression type you are using? Let's say I run my networks output nodes through a softmax regression function, would the gradient calculation be different? I'm really confused about the terminology here, forgive my stupidity, I did actually manage to get a softmax neural network that plays tic-tac-toe to work but honestly I'm confused as to *how* it works and I can't optimize it for bigger and better tasks if it's cobbled together out of bits of math I'm not fully understanding."
An Introduction to Probabilistic Models,0,4,False,False,False,learnmachinelearning,1490763429,False, 
Differences between a shallow autoencoder and a Restricted Boltzmann Machine?,0,1,False,False,False,learnmachinelearning,1490768001,True,"I can define a shallow autoencoder very simply:

    h0 = activation(X * W + hb)
    v1 = activation(h0 * transpose(W) + vb)

I can then train the model using a standard optimization algorithm like gradient descent. This makes sense to me. It's a two layer neural network that shares weights between the first and second layer.

An RBM is very similar to the above, except it has a bunch of extra steps:

    /**
     * Converts elements to binary and randomly samples
     * positive activations.
     */
    def bin_rand_sample(z):
        relu(sign(z - random))

    h0 = bin_rand_sample(activation(X * W + hb))
    v1 = bin_rand_sample(activation(h0 * transpose(W) + vb))
    h1 = activation(v1 * W + hb)

And to train it, I do the following:

    PGrad = transpose(X) * h0
    NGrad = transpose(v1) * h1

    W += (PGrad - NGrad) / number_of_elements(X)
    vb += reduce_sum(X - v1)
    hb += reduce_sum(h0 - h1)

This does not make intuitive sense to me at all. Why are we converting `h0` and `v1` to binary and randomly sampling positive activations? Why aren't we doing the same for `h1`? What is that training step doing? How is this any better than the autoencoder above?

The code I'm looking at for implementing an RBM is [here](https://gist.github.com/Cospel/f364df97b4944cec2dc0), written in python and tensorflow."
Install NumPy on Python in 1min !!,1,0,False,False,False,learnmachinelearning,1490768624,False, 
Time series prediction,0,1,False,False,False,learnmachinelearning,1490770209,True,[deleted]
TWIL (This Week I Learned) - Share something new that you have learned this week!,1,7,False,False,False,learnmachinelearning,1490771389,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
Built a Classification model. Realized my results are strange using k-fold CV. Any idea what is causing it?,7,6,False,False,False,learnmachinelearning,1490774851,False, 
Looking for a resource to test my ML knowledge and learn.,2,2,False,False,False,learnmachinelearning,1490778689,True,"Hello Everyone,
I have worked with implementing basic algorithms before as part of a course on ML for multimedia signals, but I do feel my knowledge is isn't solid, and there are gaping loop holes here and there. I am looking to find these and fill them up with understanding. This will be very helpful for upcoming internship interviews as well and many of them will test me on my ML knowledge as well. Therefore, can you suggest any online resource which can help me here?
Taking a MOOC would be the best option, but I don't have the time to do that right now, will take up one from start to finish this summer.
Thanks a lot!"
How to download and install python,0,1,False,False,False,learnmachinelearning,1490782299,False, 
I got an internship at an advertising sales and marketing company. My boss told me to do data analysis on the company's internal data. What am I supposed to do?,11,1,False,False,False,learnmachinelearning,1490791792,True,"I know how to solve a problem when the question is clearly defined.
Done that on kaggle so many times.
But what am I supposed to do when asked to do data analytics on some 200 excel sheets?
I asked him what he expected? or does he need help with something specific? He said, ""just do data analytics on the data and give me a report.""

Edit : Okay so since there is no goal, I can basically create one. What are some basic things in advertising/sales/marketing that are targets of data analysis.
"
Deep Learning Chatbot using Keras - Part I (Pre-processing text for inputs into LSTM),0,9,False,False,False,learnmachinelearning,1490804935,False, 
Question: Using WEKA for author identification,0,1,False,False,False,learnmachinelearning,1490808577,True,"Hi Friends,

I am trying to use WEKA for identification and classification of documents based on author using Naive Bayes. I have a dataset of stories written by sci-fi authors such as Isaac Asimov, Philip K. Dick and Ray Bradbury .


 



I have converted these documents into arff file using the following scheme: 


*@relation Authors*


*@attribute textOfStory string*  
*@attribute authorOfStory {""Isaac"",""Philip"",""Ray""}*

(In training and test data - using two or more novels/short stories in each set for every author)


 


Afterwards, I converted the textOfStory to attributes using String to Word Vector (IDF transform + TF transform = true). This resulted in unigram word vectors with certain frequencies. For eg. the word attribute ""screen"" was given value of 0.44544, 0.44544, 0 for the three authors.


 



Can anyone help me understand how these frequencies are being calculated? As I have read word unigram frequencies should be helpful in identifying and attributing the author. Am I going on the right path, is this the right way to proceed through this problem? How can I compare both the data set using Naive Bayes in an interpretable manner? Any help is appreciated.  

 



*Tl;dr: Want to correctly attribute writings of authors using Weka. Help to find the correct procedure for the same?*"
Natural language processing - can machines think/talk? -,0,2,False,False,False,learnmachinelearning,1490812925,False, 
Best model for running simulations?,0,3,False,False,False,learnmachinelearning,1490829448,True,"Hi, I'm working on a project where I am trying to determine the best place to add supply to a marketplace product (e.g. we already have X supply in some area with Y1 revenue and we want to know what Y2-Y1 will be when we increase X by 1). N = ~6000 zip codes
It's easy enough to predict Y1 using X with a RF regressor or Lasso model. But, since my goal is to run a simulation where I predict Y2 after X+1, I run into extrapolation issues with both of these models.
With RF models you particularly run into extrapolation issues for variables where Y1 is highest, and X+1 often returns a smaller value.
Does anyone have thoughts on models that are better suited to extrapolation?
I'm working in Python and R.
Thanks amigos!!!"
Are there any neural networks that do text pattern recognition/commonality identification?,2,1,False,False,False,learnmachinelearning,1490830154,True,"I'm a complete beginner. My circle of knowledge on neural networks and machine learning contains only a few TED talks, a few explanatory videos on youtube, and that's it. 

I'm trying to solve this problem, but in all honesty I don't want to learn how to program a neural network in order to solve it. But I also don't have any money to pay anyone to do it. In other words, I'm hoping for a few easy steps (maybe pre-built) neural networks to just run a few things through. 

**This is my problem**: 

I am building a French language learning course that teaches the 5,000 most common French words using mnemonics, sound design, and how those words interrelate with the culture and their deep meaning rather than what they seem to mean. 

Okay, exposition out of the way... 

**French grammar contains a lot of rules and exceptions, and complicated stuff that doesn't *seem* to make any sense.**

For example: **the genders of words.**

A lot of people say that it's impossible to know the genders of words, and you just have to learn it. However... I found this list online: 

*Typically masculine word endings (+90%)*:

-an, -and, -ant, -ent, -in, -int, -om, -ond, -ont, -on (but not after s/c¸)    
-eau, -au, -aud, -aut, -o, -os, -ot  
-ai, -ais, -ait, -es, -et  
-ou, -out, -out, -oux 
-i, -il, -it, -is, -y   
-at, -as, -ois, -oit    
-u, -us, -ut, -eu  
-er, -e´after C (C=t)    
-age, -ege, – ` eme, -ome/- ` ome, -aume, -isme    
-as, -is, -os, -us, -ex   
-it, -est 
-al, -el, -il, -ol, -eul, -all  
-if, -ef  
 -ac, -ic, -oc, -uc  
-am, -um, -en  
-air, -er, -erf, -ert, -ar, -arc, -ars, -art, -our, -ours, -or, -ord, -ors, -ort, -ir, -oir, -eur   
(if animate)
-ail, -eil, -euil, -ueil  
-ing 


*Typically feminine word endings (+90%)*
 
 -aie, -oue, -eue, -ion, -te, – ´ ee, -ie, -ue  
-asse, -ace, -esse, -ece, -aisse, -isse/-ice, -ousse, -ance, -anse, -ence, -once  
 -enne, -onne, -une, -ine, -aine, -eine, -erne  
-ande, -ende, -onde, -ade, -ude, -arde, -orde   
-euse, -ouse, -ase, -aise, -ese, -oise, -ise, -yse, -ose, -use 
 -ache, -iche, -eche, -oche, -uche, -ouche, -anche    
-ave, -eve, -ive   
 -iere, -ure, -eure   
-ette, -ete, – ˆ ete, -atte, -otte, -oute, -orte, -ante, -ente, -inte, -onte   
-alle, -elle, -ille, -olle  
-aille, -eille, -ouille  
-appe, -ampe, -ombe   
-igue  

After counting them up myself, I found that 78/79 Feminine endings end with E, and 8/92 out of masculine end with E. 

Even though I'm satisfied with this ""rule""; I want to **create a rule with greater accuracy** and I'm hoping I can do this with neural networks. 

I'm hoping that neural networks can uncover **""hidden rules""** that I myself can't spot in those endings. Maybe it can come up with a new rule that has greater obvious that will make it more obvious when a word is masculine or feminine? 

That's my hope. 


This is just one of many other problems I want to solve with my language learning course. I want to take these rules in grammar and exceptions and sort of find the ""broader"" or ""larger"" or ""more encompassing"" rules which take into account the exceptions so that it's more simple. 

Sorry for the length, it's difficult to talk about something complicated like this without this many words. 
"
Newb question: Help with 'toy' regression problem? (w/ code),3,5,False,False,False,learnmachinelearning,1490835423,True,"In an effort to better understand neural network applications, I gave myself a little ""toy"" regression problem to try out... 

**The Problem:** Given a function f(x) which has parameters ('knobs') p0, p1,...,  can the neural network learn how these parameters affect the function? i.e., can it learn ""what the knobs do""? 


 Examples: 

                 f(x) = p0*sin(p_1*x)
                 f(x) = p0*(x-p1)**2
 
(so far I've just been keeping it to two parameters)
....where all variables are bounded on either -1 to 1 or 0 to 1. 


I've made a multi-layer neural network (first in Keras then in PyTorch), and tried various activations (ReLU, tanh, sigmoid, ELU), with 50 to 100 neurons per layer (this is a 'toy' problem after all), and anywhere from 1 to (heck) 20 layers, and I'm feeding it triplets [x, p0,p1]  (with random values, bounded by -1 and 1) and comparing it to single-value targets y...


. ...and the system pretty much **never** learns.   Sample picture below, and code follows as well.  


If I take out the parameters or set them to constants, then it's just an 'ordinary' nonlinear regression problem and no big deal, and the system can do that.  But I want it to be able to learn what the parameters do.


*Can anyone help?*    I thought this would be reasonably straightforward given the notion of NNs as ""universal approximators"", and the many, much-more-complicated problems that people have successfully tackled using such systems, so....mere regression of a function of a few variables?    


(It's not obvious to me how such a wide variety of multi-dimensional optimization problems, with presumably many local minima,  get solved via NNs & gradient descent, but my little ""homework problem"" is getting hung up, and I haven't managed to find any info this sort of problem on the machine learning sites I've been surveying.  Image recognition? sure.  Content analysis? sure.  Function approximation? not really.)


As far as implementation, I wrote the code in Keras, and then added PyTorch implementation to make it more likely that some reader could help.  But this is more a question about ""the problem"" itself and the network architecture and training strategy, rather than about any particular implementation.


Link to code:  https://gist.github.com/drscotthawley/7bb5673bfccc3277a337ba73fad533f7

Picture of sample (bad) output: http://imgur.com/a/VBEm3

Thanks.


PS- Asked on SE weeks ago, never got even a comment, so trying here. "
"Since I am beginner, which tools you would recommend me to learn first??",7,4,False,False,False,learnmachinelearning,1490849458,True,"I am just starting to study machine learning, I've been using Andrew Ng course at Coursera and I've been trying to put the math into code (python) from scratch, now I would like use some libraries to improve the code but I'm getting overwhelmed, I don't know which ones to use, or what the differences are, I am just getting confused. Since I am beginner, which tools you would recommend me to learn first?? "
Install Scikit-Learn on Python in 1min !!,3,0,False,False,False,learnmachinelearning,1490855784,False, 
Convex optimization or optimization for machine learning?,1,1,False,False,False,learnmachinelearning,1490860565,True,"I am a CS student, and next semester I have machine learning course. This semester I have to make a choice between 2 courses: Optimization and Convex optimization. Which one is more relevant? You can find short descriptions from the last year below.

Optimization:Introduction to fundamental concepts and algorithmic methods for solving linear and integer linear programs and current research trends in combinatorial optimization(Approximation Algorithms, Fixed Parameter Tractable (FPT) Algorithms, and Matroid Theory)

Convex optimization: The course will have as topics convex analysis and the theory of convex optimization such as duality theory, algorithms for solving convex optimization problems such as interior point methods but also the basic methods in general nonlinear unconstrained minimization, and last but not least several applications where the modeling part, that is the transition from the problem to the formulation of an optimization problem is discussed.

Unfortunately taking both of this courses is not possible.
Thanks!"
How to install Jupyter notebook,1,0,False,False,False,learnmachinelearning,1490862789,False, 
Classification problem: dealing with very unbalanced fractions (is it even a problem?),11,1,False,False,False,learnmachinelearning,1490866114,True,"Hi /r/learnmachinelearning !

I'm currently using deep neural networks on a classification problem (supervised learning). I have two classes of ""events"", let's call them ""noise"" and ""signal"". I first trained on 1 million events and tested on 200k with a fraction of 50% (1 noise for 1 signal), reaching an accuracy of 98.5% with a simplistic model (Keras library - 4 layers, 50 neurons total)

However the real life application has not a 50% fraction; instead the signal-to-noise ratio is of the order of 10^-3 . I am wondering how should I deal with that: first, I have a total available of 5M noise events and 600k signal events. To have a realistic ratio, I would then have only 5000 signal events (and 5M noise) to do both the training and testing (which includes evaluating the false positive and false negative rates).

Is this a problem? Should I try to increase the statistics for each? What would be your recommendations? Is there a kind of model that helps deal with such an uneven distribution?

I'm taking any kind of advice here :)"
How to install TensorFlow,4,6,False,False,False,learnmachinelearning,1490870311,False, 
Are there any variants of gradient descent for online learning?,5,6,False,False,False,learnmachinelearning,1490880122,True,"For online learning I mean only one sample at time is available for training. I'm aware of stochastic gradient descent, but it somehow seems different from an online setting and more related to small batch learning. 

I tried to implement SGD with momentum but I believe the gradients vary so much that the cost never get to its optima. Are there any variants that perform well in this scenario?"
Intuition Behind Machine Learning,0,4,False,False,False,learnmachinelearning,1490891188,False, 
GANs for Baseball Simulations,2,4,False,False,False,learnmachinelearning,1490895456,True,"Hello everyone! I had an idea recently, and I wanted to see what you guys thought about it. Baseball season is right around the corner, and I was wondering if ML could be used to simulate games in a very fast way.

My idea is basically that you give some stats of the opposing pitcher, some stats of each batter in the lineup against that pitcher, and run GANs on this with the output being the final game statistics (hits, homeruns, stolen bases ect.). Eventually this would give 'realistic' game simulations.

Does this sound like something that might work? A problem I could see is that baseball can be very random on the game level, and it might have a hard time trying to find what a realistic game is. Ideally, I suppose this system would also return a distribution of sorts, and not a single expected value for the matchup.

Let me know what you guys think!"
TensorFlow Range of size of another tensor's dimension,2,5,False,False,False,learnmachinelearning,1490899365,True,"I'm trying to define an operation for a NN I'm implementing, but to do so I need to iterate over the dimension of a tensor. I have a small working example below.

    X = tf.placeholder(tf.float32, shape=[None, 10])
    idx = [[i] for i in tf.range(X.get_shape()[0])]


This produces an error stating

    ValueError: Cannot convert an unknown Dimension to a Tensor: ?

When using the same code but using `tf.shape` instead, resulting in the code being

    X = tf.placeholder(tf.float32, shape=[None, 10])
    idx = [[i] for i in tf.range(tf.shape(X)[0])]

Gives the following error

    TypeError: 'Tensor' object is not iterable.

The way that I'm implementing this NN, the `batch_size` isn't defined until the training function, which is at the end of the code. This is just where I'm building the graph itself, so the `batch_size` isn't known by this point, and it can't be fixed as the training `batch_size` and the test set batch_sizes are different. 

What is the best way to fix this? This is the last thing keeping my code from running, as I got it to run with a fixed `batch_size`, though those results aren't useful. I've been pouring over the TensorFlow API Documentation and stack overflow for weeks to no avail.

Edit: I've also tried to feed in a placeholder into the range, so when I'm running the test/training set the code would be the following

    X = tf.placeholder(tf.float32, shape=[None, 10])
    bs = tf.placeholder(tf.int32)

    def My_Function(X):
        # Do some stuff to X
        idx = [[i] for i in tf.range(bs)]
        # return some tensor

    A = tf.nn.relu(My_Function(X))

However, this gives the same error as above

    TypeError: 'Tensor' object is not iterable."
Method for averging results when using committee training?,1,4,False,False,False,learnmachinelearning,1490902019,True,"I decided that the best way to run my network on more than one CPU core was to run committee training with a clone of my network on each CPU core, then dividing up the training data into chunks and shuffling who gets what data after each epoch. I'm implementing from scratch with no modules besides numpy and the likes, what sort of algorithm should I use for averaging the results from the committee after each epoch? Should each networks weights be set to a weighted average after each epoch so that when the next cycle begins, all the networks are identical again, or would it be better to have maybe a portion of the weight changes from committee members who lowered their cost added on to the weights of every other network, somewhat similar to momentum? Also, how should I average the weight changes in general? I imagine some sort of weighted average based on the decrease in cost but I'm not sure on the specifics."
Recommended Cloud Service for Pre-Trained Machine Learning Model?,4,1,False,False,False,learnmachinelearning,1490907362,True,"I have a machine learning model that is about 4GB in RAM when loaded and requires about two cores to compute in a realistic timeline (few seconds). If I wanted to create a server interface to call the classify() function, what services would you recommend? Is this something that can be loaded into AWS Lambda pay-by-call model? Or is it better to host on a dedicated instance due to the 4GB memory requirements? Looking for what would be cheapest for a student to experiment. Thanks!"
How good is the fast.ai course?,1,9,True,False,False,learnmachinelearning,1490934982,True,[deleted]
The course follows K.Murphy's A Probabilistic Perspective book and is aimed towards CS PhD Students,2,6,False,False,False,learnmachinelearning,1490937215,False, 
Weekly Show-off!,1,1,False,False,False,learnmachinelearning,1490944170,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
Is this idea dumb?,5,6,False,False,False,learnmachinelearning,1490954035,True,"My idea was to use graphics engines to generate labelled data for use in computer vision. Specifically I was thinking it would be possible to generate lots of training examples using a model of a hand and its x,y,z position relative to the camera (and possibly finger positions) and a screenshot and then trying to learn hand position in space from screenshots."
Some New Interesting Deep Learning Datasets for Data Scientists,3,17,False,False,False,learnmachinelearning,1490966023,False, 
Layman's guide to machine learning?,3,3,False,False,False,learnmachinelearning,1490973159,True,"I am a high school student, I have a base In statistics, a great base in general math and will soon learn calculus.  I understand basic python and R, but I'm not sure where to go from here.  How do I start into machine learning from essentially square one?"
"If you are in Dallas Chicago or NYC, this is an opportunity to expand your skills around machine learning for data science or data warehousing.",1,5,False,False,False,learnmachinelearning,1490978672,False, 
"Weekly Scrum Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",1,2,False,False,False,learnmachinelearning,1491030522,True,"Let's have a scrum meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
"A great list of pytorch related resources, tutorials and more.",0,5,False,False,False,learnmachinelearning,1491036463,False, 
"I made some Machine Learning, Deep Learning tutorials. It might be helpful.",8,25,False,False,False,learnmachinelearning,1491042198,False, 
"Hi, I need help converting structures of molecules to something that Keras can handle",5,2,False,False,False,learnmachinelearning,1491063910,True,"I'm a biotech engineering learning by myself how to work with Keras to create cool new  molecules  (or at least I'm trying)
The idea is to take multiple molecules like  [this one](https://pubchem.ncbi.nlm.nih.gov/compound/nicotine#section=3D-Conformer) and  train the neural network to generate the new molecules.

The question is, how do I convert the data(JSON, RDF, XML) in something that Keras can work with?

Thanks you in advance "
SnakeGame using Reinforcement learning,8,6,False,False,False,learnmachinelearning,1491096410,True,"Hi guys, long time lurker, first time poster. I have been trying to develop a snake game on a 300 by 300 grid. I've been using keras and a basic perceptron network. I have been toying with this for a while but I cant seem to get it to work properly. Any advice is very much appreciated. IF you so choose you can find the code 
[here](https://github.com/Bbowen100/SnakeGame/tree/develop)

"
Curriculum to learn evolutionary computation?,2,4,False,False,False,learnmachinelearning,1491154023,True,"Hey!

I am a Cognitive Science MSc student and I am researching perception. I am interested in working with evolutionary computation in my research (something akin to this: http://link.springer.com/article/10.3758/s13423-015-0890-8). However, my BSc is not in CS, so I believe I have a way to go to get into EvoComp. I have had Intro to Programming in Python and am currently advancing my knowledge of it, I took Math 101 and Intro to Computational Intelligence.

Can you recommend me a path to take to get into EvoComp? Online courses, textbooks ... I'll take anything. My current plan so far is advancing my Python skills and reading up on EvoComp in Russell&Norvig. Any other ideas?

Thanks!
"
Classifying French Genders using LSTM network,3,4,False,False,False,learnmachinelearning,1491178736,True,"I thought I would post it here. 
This project is not an in depth tutorial on LSTM, as there are plenty of them on the web and I didn't want to repeat the LSTM equations.  This was an learning/exploration project for me on the power and capabilities of LSTM. 

**Edit**

[Link](https://github.com/serega/pytorch-french-genders/blob/master/FrenchGenders-LSTM-Batch.ipynb)"
Order of Learning Machine Learning Subjects,8,0,False,False,False,learnmachinelearning,1491188928,True,"I have started learning ML.  My background is marketing product management in the information security space primarily security services:
1. preventative 
     A. scanning and remediation 
     B. penetration testing
2. monitoring and responding

Without going into details my intuition so far tells me machine learning could be used to things a lot better in both cases above.

Broadly I believe there will be a few roles in building a team seeking answers in this space:
1. programmer (Python)
2. data analyst (security analyst who understands the data sets)
3. visualization specialist (create outputs)
4. business interface (present and sell the results)

I am probably in my career best suited to #4.  Entering the space I need to understand to some extent the other 3.

1.  Teaching myself python now on Dataquest.  Wow... 25 years since I coded last with unix and sql.  I forgot how fun it is.
Rather than just teach myself is there a certification I can pick up along the way to kill two birds with one stone?

2. Preliminary investigating some of the statistical models under scikit learn.  There are a lot of models.  For my discipline of info security... What models are recommended I learn intuitively:
A. Regression
B. Classification

3.  Any reading to understand about translating the visualizations to business decision support? 

4. This is where my expertise will come in once I understand 2 and in particular 3.

If I am asking the wrong questions or this is the wrong approach in general please advise.

Regards.
"
"If we primarily use LSTMs over RNNs to solve the vanishing gradient problem, why can't we just use ReLUs/leaky ReLUs with RNNs instead?",5,6,False,False,False,learnmachinelearning,1491206410,True, 
List of Free Must-Read Books for Machine Learning,2,1,False,False,False,learnmachinelearning,1491213236,False,[deleted]
Machine Learning Captcha Prediction,6,1,False,False,False,learnmachinelearning,1491218982,True,"I want to write a code for prediction of captcha image of 5 characters (both numbers and image), e.g. 7C7PF. The dataset has around 10000 images, but I can't figure out how to model and provide labels to the dataset. Can anyone help me to get started? I am beginner in ML"
Unable to solve the Mountain Car problem from OpenAI Gym,2,2,False,False,False,learnmachinelearning,1491257694,True,"I've been playing around with reinforcement learning this past month or so and I've had some success solving a few of the basic games in OpenAI's Gym like CartPole and FrozenLake. However there's one basic problem that I simply cannot solve no matter what approach I use, and that's the Mountain Car problem. 

The only reward seems to be if the car reaches the top, otherwise it'll be -1. Unfortunately with this it seems as though the AI has to stumble upon the reward, but no matter what I do I can't seem to ""solve"" this environment. 

Does anyone have any recommendations for solving this? I've tried a variety of networks, from plain old DQN to Actor-Critic networks but none of them see to have any luck no matter what hyper-parameters I use.

Thank you!"
Desktop/Laptop for studying ML,10,3,False,False,False,learnmachinelearning,1491264032,True,"I'll star to learn ML, in the ""self-starter"" way. My problem is that I can't use the computer I have at home. Also, I don't have a notebook. I've graduated from a CS course last year, and have saved enough to buy a medium desktop.

For practice purpose, what should I aim? an i5-7600K, GTX 1050 and 16 Gb RAM is good enough, or even for practice that's low? I can't much better now, so, should I save more? or, just for studying, a notebook would be enough?"
Feature standardization in modern ANNs,2,2,False,False,False,learnmachinelearning,1491286868,True,"I noticed that a lot of modern architectures do per-channel mean subtraction, but doesn't rescale (to have the data on a [0, 1] interval) or do feature standardization (divide each channel by its standard deviation).
One example of a net that does this is VGG-net. Have I gotten this wrong and if not, what's the reasoning behind this?"
Scaling integer and boolean features for feature vectors (Naive Bayes/Neural Network),0,4,False,False,False,learnmachinelearning,1491290447,True,"I'm doing a classification task and I have text features (#occurences of a word) as well as other features (e.g. number of sections). Do I need to scale these or will the weighting occur automatically when using Naive Bayes and/or Neural Networks implemented by scikit (the ones I'm considering right now).

What if I add a boolean feature? E.g. does the word 'soccer' occur in my text at all, apart from counting only the number of occurences. Do I need a seperate way of rescaling everything?

Thanks!"
Need help with neural network,0,2,False,False,False,learnmachinelearning,1491300546,True,"Hello!

I am in the process of making a neural network for use in my experimental research work but can't seem to optimize it properly.
I am using Torch7's neural network (nn) package and the optimization package (optim) and this is the [code](https://github.com/ChaitanyaDhawan/ANN/blob/master/ann.lua). I am not getting very good accuracy. But, the used data has been known to give excellent accuracy (very close to 100%) as mentioned in this [paper](https://drive.google.com/file/d/0B5VRqh9iR39SUHBiTTJOWHNwMzA/view?usp=sharing). So, I will be very grateful if someone can help me with achieving the same or better accuracy. Please also suggest if this is the right place to post this or should I go somewhere else."
Proper cross-validation routine,4,2,False,False,False,learnmachinelearning,1491309965,True,"Hello,

I have a question about how to organize properly evaluation routine in my case. I have audio recordings of 10 speakers and I want to test how my neural network generalizes to new speakers. I am thinking of using recordings from 8 speakers for training, recordings of another for validation and the last one for testing. And then average results over all folds? Is it fair scheme? Is it fair to tune hyperparameters/architectures for CV score maximization?

An alternative would be to set aside 2 speakers and use them for validation/early stopping and then use the other 8 for leave-one-speaker-out CV loop, where 7 speakers are for training and the other for testing (early stopping is done on the 2 speakers set aside).

Thank you for your comments in advance!"
Extracting certain information from web page by machine learning,2,6,False,False,False,learnmachinelearning,1491315351,True,"I would like to extract certain types of information from web pages. Let's say postal address, phone, email.it would be probably very difficult to write regular expression or even something like a grammar and to use a parser generator for parsing it out, because of irregularity in websites.

So I think the way I should go is machine learning. If I understand it well, I should be able to make a sample of data where I will point out what should be the result and then I have something which can learn from this how to recognise the result by itself. This is all I know about machine learning.

Questions:

1) Can I solve this problem easily by machine learning? Is it a good way to go?

2) Are there any simple examples which would allow me to start? I am machine learning noob and I need something practical for start; closer to my problem is better; simpler is better.

Example Pics

https://i.stack.imgur.com/Q1drB.png

https://i.stack.imgur.com/upC6d.png"
Hierarchical classification reusing same CNN,2,2,False,False,False,learnmachinelearning,1491335743,True,"Say I want to train a classifier for classifying animal images, being as specific as possible. For example, if the classifier is unsure whether it is a beagle or a chihuahua, it should at least be sure its a dog rather than a cat, and light brown. My naive approach is to train a separate classifier for hierarchical level of classification -- a separate cat or dog classifier, a separate species classifier, a separate color classifier, and then use the more specific category if the confidence exceeds a threshold. But it seems like the net weights in the convolutional layers will be similar for each of these tasks and could be used, perhaps training only the last fully-connected layer on each semantic level. Has another done or seen something like this done before? Does it have a googleable name?"
Where to find paid help to extend LDA,1,3,False,False,False,learnmachinelearning,1491357800,True,"I'm trying to understand and extend LDA. However, it's about time I find someone who knows LDA inside out, is patient, and can help guide me in extending it.

I'm willing to pay good money for this help.

I'm wondering where to begin this adventure?"
Suggestions of where to start for similarity analysis using ML?,0,1,False,False,False,learnmachinelearning,1491362128,True,"Specifically, my problem is to analyze missions profiles (e.g. think airplane flight profile/mission for a close example) and compare one mission to many others... In the course of doing so pros and cons for the other missions should be taken into account and a suggestion should be made if a more optimal mission is noticed that is similar to the one I'm analyzing.

I thought about running through some classification algorithms (the basics of which I've been covering but not much beyond that) but am hesitant because no two missions will be equivalent so realistically I'm just looking for broad similarities and differences. 

This is my first big jump into ML so any help or pointers in the right direction is fine. I don't expect anyone to solve the problem, just looking for a push in the right direction for research.

Thanks!"
Layman tutorial on time series to predict growth and seasonal variations of Wikipedia page views - no math!,0,4,False,False,False,learnmachinelearning,1491373819,False, 
How to learn Machine Learning - Yoshua Bengio and Kevin Murphy,2,5,False,False,False,learnmachinelearning,1491375345,False, 
TWIL (This Week I Learned) - Share something new that you have learned this week!,0,1,False,False,False,learnmachinelearning,1491376163,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
List of Free Must-Read Books for Machine Learning,3,67,False,False,False,learnmachinelearning,1491388055,False, 
"Machine Learning ""Starter Kit""?",7,12,False,False,False,learnmachinelearning,1491495920,True,"Is there an ML ""starter kit""? I mean things like: what are the best programming languages/libraries for Machine Learning (if any specifically). Perhaps some books and some beginner projects (like MNIST). What are the thing that everyone starting in machine learning should have/read/watch? I'd think that Stanford's Machine Learning course from Coursera would be on the list, for example."
Alternatives to a Degree to Prove Yourself in Deep Learning,5,14,False,False,False,learnmachinelearning,1491501832,False, 
When does statistics become machine learning?,8,5,False,False,False,learnmachinelearning,1491512009,True,"I'm taking Andrew Ng's course and it seems like a lot of the first couple weeks is essentially just statistics.

At what point is it considered machine learning? E.g. when would linear regression start to pour over into machine learning?"
Weekly Show-off!,0,6,False,False,False,learnmachinelearning,1491548975,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
Hardware question (CUDA vs openCL),8,2,False,False,False,learnmachinelearning,1491588904,True,"Hey guys sorry if this isn't the right place, if there's somewhere more appropriate please let me know. I'm a college intern pursuing ML applications. I'm spoiled at work with a nice Titan-X setup but unfortunately my entire rig at home is worth less than a single card I use there. I'm trying to set up a configuration with what I have that would be useful for some personal projects as I move forward once I'm done with my internship. I'm lucky to be in a nerdy family and my brother who has a graphics card addiction has given me his old cards. These are the options I have:

* R9 390

* (2) GTX 760

* GTX 680

My card is the 680 and it's woefully outdated. I exclusively use CUDA at work so I have zero experience trying to train on openCL but from what I've heard the performance is considerably lower. If I could support 3 cards easily I'd throw the 390 and 760's in and call it a day but unfortunately that's not the case. I've been looking into PCIe expansions but options seem either limited, pricy or both. Are the 760s worth running for CUDA or should I stick to the 390? I'd ideally like the 390 in the system for gaming use occasionally, but most of the GPU uptime will hopefully be dedicated to training. Anyone have experience on the hardware side of things that could throw some light on the situation? I work in Theano primarily but I dabble in Caffe on occasion so I know both have CUDA backends readily available. "
[Question] Do you know features for EMG?,3,4,False,False,False,learnmachinelearning,1491598808,True,"Hello everyone, I'm doing a research about hand gesture recognition classifying sEMG signals that I got from 8 channels (electrodes). I've found some features: MAV, Variance, Zero Crossing, Slope signal change, WAMP, Waveform length, Mean frequency, 4 autoregressive coefficients and 9 bins of an amplitute histogram. I've used the following classifiers: binary tree, svm and neuronal network. However, my results are not very good. I'll be doing more research, but if you can give some information that could help me. Suggesting me some paper or readings. Or some idea about other features or different classifiers for that purpouse I'll really appreciate it.

Thanks in advance. :)"
How do we deal with Rare events continuous values predictions ?,1,8,False,False,False,learnmachinelearning,1491599107,True,[deleted]
fast.ai but for structured data?,5,2,False,False,False,learnmachinelearning,1491605702,True,"i know the  2nd semester is suposed to include some, but i want to do some analysis NOW on some data sets that are structured. is there a code first approach guide for this?  Think bayes and http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/ look pretty good"
"Weekly Scrum Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",1,6,False,False,False,learnmachinelearning,1491635230,True,"Let's have a scrum meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
Inquiry / Request for help regarding washed out color results of my attempt to implement CycleGAN,0,3,False,False,False,learnmachinelearning,1491673919,True,"Hi, I am student trying to study deep learning and GANs. I am new to both and I wanted to try recreating the CycleGAN paper in order to understand it more. (https://arxiv.org/pdf/1703.10593.pdf)

I am using tensorflow and I used their open sourced code as a guide. However, after training for 200 epochs, my results looked low quality and the colors are washed out unlike their results. I also tried training it a bit longer but I did not see any difference. I used their summer-winter yosemite dataset. There are some semblance of the transformations so I think I am not too far off. I am not sure what I am doing wrong, and I hope it is alright to consult the community and ask for advice as to how I can improve. Here is the link to my code: https://github.com/danieltan07/tensorflow-cycle-gan

Sample Results of the code:
http://tinyimg.io/i/pITQS9z.png

http://tinyimg.io/i/FdzZbbO.png

http://tinyimg.io/i/E0BQA8p.png"
great overview of feature engineering practices,0,1,False,False,False,learnmachinelearning,1491674165,False, 
What are good tutorials for transfering a local tensorflow model to a cloud instance for training?,4,2,False,False,False,learnmachinelearning,1491686985,True,"I have a directory ready to go, but I've found getting set up on AWS to be surprisingly difficult. I've searched for video tutorials, but they've been surprisingly unhelpful. Any pointers would be appreciated!"
Advanced Statistics MOOCs,6,14,False,False,False,learnmachinelearning,1491698743,True,"Hello Everyone,

I'm recently getting into both machine learning and computational modelling in general. While there are a plethora of machine learning courses that are advanced, it seems like they only brief touch upon some things that statistics takes a bit more of a bite out of.

For instance, conditional intensity functions (and their relation to point processes), generalized linear models, time-series analysis, spectral representations thereof, etc.

Does anyone know of a good MOOC that is basically ""advanced statistics""? All of the ones I've seen on Coursera and EDX have been more of a ""here's a Normal distribution"" and less of a ""here's a set of dependent point processes oscillating on an underlying spectral frequency; determine the conditional intensity function that describes the instantaneous rate for the point process"" type of thing.

Thanks!"
Possible to load a saved Keras model into Tensorflow to make predictions?,4,7,False,False,False,learnmachinelearning,1491710213,True,"I have a machine learning application which will ultimately run on a Raspberry Pi, but I have done training on different hardware. The machine learning model was built in Keras and I have saved the model after training. Is it possible to somehow load the Keras model with Tensorflow in order to make predictions on the Pi? As far as I know it is not possible to install Keras on the Raspberry Pi, but I have installed Tensorflow. "
Do you apply min max scaling separately on training and test data?,2,1,False,False,False,learnmachinelearning,1491710315,True,"While applying min max scaling to normalize your features, do you apply min max scaling on the entire dataset before splitting it into training, validation and test data?

Or do you split first and then apply min max on each set, using the min and max values from that specific set?

Lastly , when making a prediction on a new input, should that input be normalized using the min, max values from the training data before being fed into the network?"
Learning word vectors for NLP AI from Lawrence Berkeley National Laboratory,0,3,False,False,False,learnmachinelearning,1491718647,False, 
Performance Evaluation for ANN Regression Model,3,2,False,False,False,learnmachinelearning,1491730992,True,"My regression model (predicting SPT-N value from soil resistivity value) currently uses MSE in the objective function for learning. After getting the testing result, I would copy the prediction data over to excel to get the R-squared value.As of now, I've noticed that a better MSE value does not translate to a better R-squared value.

My question is which one should I use as the optimum performance evaluator (which one to give priority to), MSE or R-squared, for hyperparameter optimization in order to choose the best settings/model."
What's the best way for a data science newbie to make the most out of Kaggle?,4,12,False,False,False,learnmachinelearning,1491766854,True, 
"For this equation of a feedforward NN without activation function, why can it be transformed this way per author said?",2,2,False,False,False,learnmachinelearning,1491776187,True,"Image: http://imgur.com/a/wHZns

Replacing the symbols... Context: This is a feedforward neural network with 1 hidden layer without any activation function, flattened.

The author essentially says:

> if f(x) = (A)^T (B)^T x, then it can be rewritten as f(x) = (x)^T B A.

Shouldn't it be:

> f(x) = ( (x)^T B A ) ^ T 

Instead?

In such case, the author ignores the distinction between row and column vector. Right? Why and when can you do this? Due to it going to an activation function anyway?

I know this is a dumb question but I would still want to know why. Thanks!"
"Can't converge the error on my 7 20 5 1 network, what I'm doing wrong?",2,2,False,False,False,learnmachinelearning,1491776250,True,"I have a neurral network with 7 input, 2 hiddens layers with 20 and 5 neurons and 1 input, but I can't get the error to converge and can't find the reason, is there anything I'm missing?  
https://gist.github.com/anonymous/bcd99666f863c892de588c294be95dd5"
Using AWS for Machine Learning Training and Serving.,0,2,False,False,False,learnmachinelearning,1491780724,True,"Hi, I wanted to hear the pros/cons of using AWS to train (only transfer learning) the network and then do prediction on an uploaded image ? 

Basically what I am trying to build is a simple app, which will send an image to the AWS servers and the network will predict the object in the image and send the results back to the app. 
Are there any blogs that I can follow/ tutorials which do this ? 

I am thinking on building the back end using node, but I will have to send the image data to python to do the prediction. Is this a good way to go, anyone with experience setting something like this up? 

Thanks!

[ Shout out to fast.ai (http://www.fast.ai/) for tutorials on training networks on p2 instances ] "
Do you need a PHD to get a job in practical Machine Learning?,26,13,False,False,False,learnmachinelearning,1491804610,True,"I am planning on going for my Master's, but the little bit I've heard all say that it's very competitive to get a ML job even with a PhD. What is the job search like for ML? Is a PHD required?"
What's the best way to do Neural Style Transfer locally on an Android device?,2,1,False,False,False,learnmachinelearning,1491831993,True,"Hi,

I'm working on a project where I need to perform fast neural style transfer on an Android device, preferably without having to connect to any server.

I've seen the example in TensorFlow 1.0 samples, but building it on Windows seems to be a hassle. Any other way I get it working locally?"
How to connect hidden nodes to labels in LSTMs?,4,2,False,False,False,learnmachinelearning,1491832485,True,"I'm going to use the notation from

http://colah.github.io/posts/2015-08-Understanding-LSTMs/

Say I'm doing character prediction, and my labels are sentences. To make this as short as possible, I'll ignore one-hot encoding. Say I have a four-character training example like ""abcd"", and I want to train the LSTM to predict ""bcde"". When I pass ""abcd"" into the LSTM, I understand that the cells will output (h[1], h[2], h[3], h[4]). How do I connect (h[1], h[2], h[3], h[4]) to (b, c, d, e)?

My guess was to do something like compute the logits

    <h[t], w> + b,

and apply them to y[t], where y[t] is a training character, w is a weight vector, and b is a bias term. 

Alternatively, I've seen people build a fully connected layer between all the h's and all the y's, but that doesn't seem right."
Stateful LSTM's and Predictions in Keras,0,1,False,False,False,learnmachinelearning,1491867328,True,[deleted]
Machine Learning - Andrew Ng Coursera Cost,3,5,False,False,False,learnmachinelearning,1491883323,True,Does anyone know the actual cost for this? I went to sign up and it said $79 for the certificate. Is that really the whole cost for this class?
Staging time series data,2,2,False,False,False,learnmachinelearning,1491887877,True,"When analysing time series if you say have 10,000 examples which result in event 1 and you want to predict when they result in event 1 at different times in the series, how would you train on the multiple series, would each one be pivoted into a row of same dimensionality and each row is used as input?

I was thinking of using a recurrent rolling window, each of the 10,000 series contains a value for each day over a year period. "
Amazon Star Prediction,0,1,False,False,False,learnmachinelearning,1491892063,True,"Hey everyone.
I am fairly new to machine learning but have done already done some small models with different concepts (linear, cnn, rnn). This time I have [this](https://ufile.io/9887a1) dataset and want to predict the ""overall"" rating of the reviews. In this post I mainly want to discuss the way I should tackle this problem. For implementation I want to use TensorFlow. 
Here some things I thought of:

* convert the json data format to csv
* filter all NaNs (I had huge problems with those in my previous attempts)
* convert the data to tensors with TensorFlows built in csv decoder

So and here I don't really know what to do because I don't really know what to do with the review text and how I should lay out my model exactly. If anyone has an idea and wants to share it with me please let me know!
Also if this should not be the wrong subreddit for this subject don't mind to tell me ;)"
Why has Netflix moved from Star Rating to Like/Dislike?,24,11,False,False,False,learnmachinelearning,1491897523,True,Surely a 5 star rating gives more data than a simple Upvote/Downvote? 
What are some recommended topics to focus and prepare on for a Deep Learning ( + ML) entry-level job interview in a few days?,4,2,False,False,False,learnmachinelearning,1491904313,True,"I am trying to create a common place (this post) for topics and questions one should focus on for such an interview. 

I have had some exposure to DL, but none to ML yet. The interview might have ML related questions too. 

What can you recommend here?"
Ryskamp Learning Machine: A Machine Learning Engine that's easy to use,0,2,False,False,False,learnmachinelearning,1491904387,True,"Hey guys, I'm a newbie to the Machine Learning community and I want to share with you a machine learning engine that's easy to start with.

We can all agree, we are now living in the future and one thing remains synonymous with the it: artificial intelligence. As always, many have attempted to provide a solution to prominent problems yet very few stand out. What I understand it it's mostly because of how they approach the issue or because it's just too complicated.

So we've been working on the Ryskamp Learning Machine, and we hope to resolve these issues at the simplest way possible.

We have made a new algorithm that goes beyond traditional AI and we have recently open sourced our code, you can check it [here](http://useaible.com/code/) with its patent pending. You can check the full details of our license [here](https://github.com/useaible/RyskampLearningMachine/blob/master/License.md).

It works perfectly well with C# and I have attempted to work with it for a simple XOR app. It's fast and easy with only 4 major steps and the rest is optional.

You will just need to provide your data set as the answer key. In my case, it's the XOR table.

    static IEnumerable<dynamic> xorTable = new List<dynamic>
    {
    	new { Input1 = ""True"", Input2 = ""True"", Output = ""False"" },
    	new { Input1 = ""True"", Input2 = ""False"", Output = ""True"" },
    	new { Input1 = ""False"", Input2 = ""True"", Output = ""True"" },
    	new { Input1 = ""False"", Input2 = ""False"", Output = ""False"" },
    };

Then declare my inputs and outputs.

    var rlmNet = new RlmNetwork(""RLM_XOR_SAMPLE"");
    if (!rlmNet.LoadNetwork(""XOR_SAMPLE""))
    {
    
    	var ins = new List<RlmIO>();
    	ins.Add(new RlmIO(""XORInput1"", typeof(bool).ToString(), 0, 1, RlmInputType.Distinct));
    	ins.Add(new RlmIO(""XORInput2"", typeof(bool).ToString(), 0, 1, RlmInputType.Distinct));
    
    	var outs = new List<RlmIO>();
    	outs.Add(new RlmIO(""XOROutput"", typeof(bool).ToString(), 0, 1));
    
    	rlmNet.NewNetwork(""XOR_SAMPLE"", ins, outs);
    }

Next, you start the sessions and generate some random values for your AI. You will need to put it inside a loop. Part of this loop, would also be to make your new Cycle.

    long sessionId = rlmNet.SessionStart();
    	
    var rnd = new Random();
    for (int i = 0; i < 100; i++)
    {
    
    	var invs = new List<RlmIOWithValue>();
    
    	string input1Value = Convert.ToBoolean(rnd.Next(0, 2)).ToString();
    	invs.Add(new RlmIOWithValue(rlmNet.Inputs.Where(item => item.Name == ""XORInput1"").First(), input1Value));
    
    	string input2Value = Convert.ToBoolean(rnd.Next(0, 2)).ToString();
    	invs.Add(new RlmIOWithValue(rlmNet.Inputs.Where(item => item.Name == “XORInput2"").First(), input2Value));
    
		var Cycle = new RlmCycle();
		RlmCyclecompleteArgs result = Cycle.RunCycle(rlmNet, sessionId, invs, true);
		
		double score = ScoreCycle(result, input1Value, input2Value);
    }
	

And finally, provide how you score your the engine. Here I just give out a 100 score if it has the correct output. Here's the code for my ScoreCycle method.

    double score = 0;
    string output = null;
    
    output = cycleResult.CycleOutput.Outputs.First().Value;
    
    foreach (var item in xorTable)
    {
    	if (item.Input1 == input1 && item.Input2 == input2)
    	{
    		if (item.Output == output)
    		{
    			score = 100;
    		}
    	  
    		break;
    	}
    }


That's how easy it is to setup. I'm excited to try it with more games and see how far it goes. Lookup #RyskampLearningMachine and check out our [7 Machine Learning Breakthroughs](http://useaible.com/7-machine-learning-breakthroughs/) to know more or you can visit our website at www.useaible.com."
"ML behind Google Calendar, Todoist, etc. ?",2,9,False,False,False,learnmachinelearning,1491921434,True,"I recently realized that Google Calendar now has the goals feature that use ML to help you achieve your ...well, goals. 

[Google Calendar Goals Reference](https://www.google.com/amp/s/techcrunch.com/2016/04/12/google-calendar-goals/amp/)

Todoist have their new feature called Smart Schedule that helps you plan out due dates.

[Todoist Smart Schedule Reference](https://blog.todoist.com/2016/11/16/todoist-smart-schedule/)

I am learning ML and to this point every lesson I have learned is mainly data analysis, image recognition, etc. The ML biggest current uses. These two apps seem to be using it in a more practical manner. 

My question is, does anybody know of an open source project I could look at that is implementing ML in the ways the two apps have?

If not, could anyone point me in the right direction of how they are using ML in these applications?

Any help is appreciated!"
Music Information Retrieval - Useful Models,5,3,False,False,False,learnmachinelearning,1491932238,True,"There's a lot of literature on Speech Recognition.  The leading method appears to be using [Mel-Frequency Cepstral Coefficients](http://www.practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/) as emissions in a Hidden Markov Model to determine the phoneme being spoken at any given time, then stringing together those phonemes to predict words (and then passing this into a Natural Language Processing model to determine the most likely phrase, etc).  Long paper [here](http://www.cslu.ogi.edu/~zak/cs506-lvr/mjfg_NOW.pdf).

Papers on general audio information retrieval are more sparse.  I've read a few on feature extraction and source separation, but beyond that there doesn't seem to be much going on.  I'm working on a music information retrieval project to automatically notate rhythm, and I'm going down the same path as Speech Recognition, using MFCCs as my feature vector and putting them through an HMM.

Are there more fruitful models, or is the HMM king in this domain?"
Let’s code a Neural Network from scratch — Part 1,3,31,False,False,False,learnmachinelearning,1491952613,False, 
Monthly ELI5 (Explain Like I am Five) Thread,19,2,False,False,True,learnmachinelearning,1491952628,True,"Top comments need to be in the format of: `ELI5 $CONCEPT_NAME` and the replies should provide a clear explanation in a layman's term.
Here are the relevant rules from /r/explainlikeimfive breaking down the meaning of ""ELI5"":

- E is for Explain - merely answering a question is not enough.

- LI5 means friendly, simplified and layman-accessible explanations - not responses aimed at literal five-year-olds.
"
Which Udemy course is the best for beginners in ML?,3,9,False,False,False,learnmachinelearning,1491974923,True,"I'm a programmer (5 years experience), I want to learn ML with Python and change my career path. 

I came across 2 courses. I'm not sure which one should I buy. 

Machine Learning A-Z™: Hands-On Python & R In Data Science (
https://www.udemy.com/machinelearning/)

Deep Learning A-Z™: Hands-On Artificial Neural Networks(
https://www.udemy.com/deeplearning/)

Instructors of both the courses are same."
TWIL (This Week I Learned) - Share something new that you have learned this week!,3,7,False,False,False,learnmachinelearning,1491981258,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
Text classification with embeddings?,0,1,False,False,False,learnmachinelearning,1491984990,True,[deleted]
Transfer learning in autonomous driving,0,1,False,False,False,learnmachinelearning,1492003422,True,[deleted]
Transfer learning: autonomous driving,1,10,False,False,False,learnmachinelearning,1492004040,False, 
LSTM RNN for Time-Series Prediction,1,5,False,False,False,learnmachinelearning,1492007670,True,"Hi there,

I'm following a great guide by Jason Brownlee on using an LSTM RNN model for time-series prediction here: http://machinelearningmastery.com/time-series-forecasting-long-short-term-memory-network-python/

The dataset Jason is using is shampoo sales and he loads in the data and calls a parser function to change the datetime structure as follows:

# load and plot dataset
from pandas import read_csv
from pandas import datetime
from matplotlib import pyplot
# load dataset
def parser(x):
	return datetime.strptime('190'+x, '%Y-%m')
series = read_csv('shampoo-sales.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)
# summarize first few rows
print(series.head())

which gives the output: 

Month
1901-01-01 266.0
1901-02-01 145.9
1901-03-01 183.1
1901-04-01 119.3
1901-05-01 180.3
Name: Sales, dtype: float64

My problem is he uses two arguments in his parser function. The dataset I'm using is just financial data from Yahoo Finance, which is in the format 07/04/17 - ""%d/%m/%y"". I'm just wondering what I would need to do to load in my data like his so it will be able to fit into the model correctly? 

Many thanks,
"
Can somebody please help me understand this quick/simple LSTM derivative?,5,1,False,False,False,learnmachinelearning,1492015894,True,[deleted]
[D] Why is the derivative of the LSTM cell state w.r.t. to the previous cell state equal to the forget gate?,0,2,False,False,False,learnmachinelearning,1492021822,True,[deleted]
Need recommendations for a Convolution Neural Network architecture,1,6,False,False,False,learnmachinelearning,1492035844,True,"Hi all,

I'm currently working on implementing the A3C algorithm to play Atari games using only screen input. I've got the algorithm working for all the classic games such as Frozen Lake, Mountain Car, and CartPole so I'm pretty sure it work, my problem is currently the CNN architecture. 

I'm currently resizing the input from 210x160 pixels to 80x80 for the sake of speed and utilizing a very simple network, 32 filters, 2x2 maxpooling, 64 filters, 2x2 max pooling, 512 dense connected, and then output

I haven't really had much luck with this regardless of the games I've tested it on, I was wondering if any of y'all had suggestions for architecture. One of my concerns for games like Pong and Breakout is that the ball might be ""lost"" if I resize and use too many max pool layers, but I'm not sure if this is a legit concern or not

Anyways, any and all help appreciated, thank you!"
Need help with a practice problem for school.,1,0,False,False,False,learnmachinelearning,1492055328,True,"Hello, I was wondering if a user could help me with a problem real quick as I'm not really understanding the question. The problem is this :

Given the following state of memory (in hexadecimal)
 
     Memory
Address Content

   01     1A

   02     A1

   03     22

What are the contents of Register 3 after the execution of this instruction?

13 02"
[D] Why doesn't LSTM forget gate cause a vanishing/dying gradient?,0,1,False,False,False,learnmachinelearning,1492091033,True,[deleted]
The most comprehensive yet simple and fun RNN/LSTM tutorial on the Internet.,1,19,False,False,False,learnmachinelearning,1492102522,False, 
Weekly Show-off!,0,1,False,False,False,learnmachinelearning,1492153782,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
Would machine learning be good for my problem?,3,2,False,False,False,learnmachinelearning,1492157192,True,"Hi, I've been playing around a lot with python and machine learning recently.

I have a problem where I have some hardware we test and a LOT of parameters get pumped out. But the most important is something called areal density (bits per inch squared we can fit on a disk in a hard drive).

It's basically impossible right now to predict the areal density with any one or two of the other parameters. If you use like 5x parameters you start getting like a 20% R^2 using a statistical fit model.

Now I think machine learning could tell us some very important stuff about which of these parameters are having a big effect on areal density and give us a way to predict it in the future, but I'm not sure exactly.

What do you guys think? Is machine learning the answer to this very complicated 40+ variable fit? 

It seems like the issues with statistics is that you kind of need to have an idea of what correlates and which model to use ahead of time: but machine learning will kind of figure this out on its own and slog through tons of variables, correct?

Am I wasting my time or could ML be the answer?"
Building image search engine for interior design,0,7,False,False,False,learnmachinelearning,1492159778,False, 
Reinforcement Learning with Function Approximation,5,5,False,False,False,learnmachinelearning,1492167180,True,"I have two questions related to approximation action state values:

1. If I am doing Q-learning with a neural network, and I want to output all the Q-values for all possible actions in the last layer. Do I consider the entire action space, even if many of the actions may not even be available at a given state? I've seen many examples of gridworlds, where they allow up, down, left, right actions at any state and simply just have it not affect the state, but I feel like that isn't applicable generally.

2. I was considering how you could you Q-learning with a neural network for poker. In poker, you can obviously fold, call, raise, etc., but when you decide to raise, you have to specify some discrete amount. Because of this, not only can your action space become very large, but since the number of outputs of a neural network are fixed, how can you even represent this? The only solution I can come up with is considering a fixed number of percentages of your chips to be raised such at 0.5%, 1%, 2%, ... 100%, and just generate the Q-value for those for each state. But that kind of goes back to my first question as to whether or not that is an acceptable thing to do.

Thanks for the help!
"
Sci-kit learn: finding model weights by minimising loss function,0,3,False,False,False,learnmachinelearning,1492175481,True,"Here is the loss function I am attempting to minimise:

https://i.stack.imgur.com/VLdCG.png

Where p, delta and x are features from a dataset, and theta is the parameter I am trying to find. I have created a linear regression model with sklearn for the central portion of the equation, however, I am unsure of how to incorporate the other sections.

What would be the best way to find the model parameters (theta) by minimising this loss function with the sklearn package in python?

Can this be done in sklearn? If so, how?

Any insight whatsoever would really help; thanks so much for your time.

"
PANTOGRAPH - COPYING MECHANISM | WHERE IT IS USED?,0,1,False,False,False,learnmachinelearning,1492195997,False, 
Patrick Harrison | Modern NLP in Python,2,19,False,False,False,learnmachinelearning,1492202622,False, 
Machine Learning Discord Server,0,11,False,False,False,learnmachinelearning,1492203190,True,"There is a dearth of academic and professional Discord servers so I am reaching out to communities that may be interested in joining an active text and voice chat server about artificial intelligence, machine learning, and natural language processing.

invite links: https://discord.me/ai or https://discord.gg/CbVJYtz"
"Weekly Scrum Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",5,6,False,False,False,learnmachinelearning,1492240055,True,"Let's have a scrum meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
"Starting to get into ML, I think I'm running into two hard problems. I have no negative data, and I want to train an object detection model without bounding boxes.",2,7,False,False,False,learnmachinelearning,1492275010,True,"I basically have a bunch of images, which may or may not contain dogs.  Some subset of these images have a label that says ""Yes, there is a dog"".

I want to train a model to tell me whether or not an image has a dog based on this training data.  Is it possible?  I've found [this](https://www.cs.uic.edu/~liub/S-EM/unlabelled.pdf) method for training without negative datasets, but I'm not sure how I would go about object detection without bounding boxes like TensorBox requires."
Logistic Regression Outputs NaN,0,3,False,False,False,learnmachinelearning,1492306636,True,"I have a really simple data set. I cleaned the data (one hot encoding, normalizing the data and check for missing values or NaNs) and my learning rate is pretty small. But when tried to run a simple logistic regression using Keras and Theano as backend

    model = Sequential() 
    model.add(Dense(input_dim=84, activation='softmax',
                bias_initializer='normal', units=6)) 
    rms = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)
    model.compile(optimizer=rms, loss='categorical_crossentropy')
    

    batch_size = 100
    nb_epoch = 1
    n = X.shape[0] # number of training examples
    history = model.fit(X, Y_oh, batch_size=batch_size, epochs=nb_epoch)

Error:

    Epoch 1/1
    5459/5459 [==============================] - 0s - loss: nan

I checked [here](https://github.com/fchollet/keras/issues/5377) and tried to downgrade Theano to the version mentioned but it still gives the same error

Here is what X looks like

    [[ 0.35755179  0.13747887  0.3        ...,  0.          0.          0.        ]
     [ 0.36401758  0.14963742  0.55       ...,  0.          0.          0.        ]
     [ 0.37889517  0.13775149  0.275      ...,  0.          0.          0.        ]
     ..., 
     [ 0.34387947  0.18706723  0.05       ...,  0.          0.          0.        ]
     [ 0.35708726  0.12905512  0.75       ...,  0.          0.          0.        ]
     [ 0.37915882  0.08061174  0.05       ...,  0.          1.          0.        ]]

and Y_oh (generated using the following code):

    Y_oh = np_utils.to_categorical(Y.T[0],6)

    [[ 0.  0.  0.  0.  0.  1.]
     [ 0.  0.  0.  0.  0.  1.]
     [ 0.  0.  0.  0.  0.  1.]
     ..., 
     [ 1.  0.  0.  0.  0.  0.]
     [ 1.  0.  0.  0.  0.  0.]
     [ 1.  0.  0.  0.  0.  0.]]"
TensorFlow Classification Error for discrete label classes ?,2,4,False,False,False,learnmachinelearning,1492339416,True,"I was trying a very simple example of classification with Tensorflow.
Instead of using one-hot vector, tf.nn.softmax, and crossentropy loss with logits. I wanted to use the discrete case of 0/1 labels. Where the output of the NN model would be 0 or 1. Hence i did somehing like this 
y_ = tf.nn.sigmoid(tf.matmul(hidden, weight2) + bias2)
y_ = tf.cast(tf.greater_equal(y_, 0.5), tf.float32)
so this would give tensor of 0 or 1.
But when i try to train this gives me error saying that No Gradient Provided.
Here is the full code. 
https://gist.github.com/kris-singh/54aecbc1d61f1d7d79a43ae2bfac8516
My question what i am trying to do is it possible in tf or not? if yes how ? "
Implementing parallel processing in gradient descent neural networks?,4,9,False,False,False,learnmachinelearning,1492351231,True,"Hello! I've been making my own neural network library from scratch in python, it uses a stocahstic gradient descent method and on one CPU core I have managed, after several months of work to get it up to a fairly good speed. However, I have run face first into a brick wall when it comes to unlocking the power of additional CPU cores or parallel processing in general. I just can't seem to find a system that works, using additional cores to process more than one training example at once seems to break the stocahstic nature of the network and any attempts to divide the actual propagation process either are impossible due to the linear nature of the math or just make it slower due to implementation details. How is this sort of thing done in the real world? I'm very confused."
Derivating the log likelihood of data modeled by a GMM,3,3,False,False,False,learnmachinelearning,1492377107,True,"Given data **x** that we want to model using a GMM, the task is to take the log of P(x | mu, sigma) and derivative according the unknown mean mu_k.

[Here's an image of the problem described formally.](http://imgur.com/a/Zn0ut)

I've already done the first part. I'm not sure how to do the second (getting to d/dmu_k L).  
How does the fact that we don't know the means change things? Am I supposed to derive once for mu_1 and once for mu_2?  
I derived it for \mu_1 [here](http://mathb.in/137425). I have no idea how the posterior probability p_k|n gets into the solution.  


"
Creating a Deep Neural Network Regression model in TensorFlow,3,11,False,False,False,learnmachinelearning,1492389530,True,"Are there any examples and/or tutorials for creating deep neural networks for regression? Something similar to what tf.contrib.learn.DNNRegressor is currently doing. I want a bit more freedom than what is available through tf.contrib.learn estimators.

All DNN examples that I find seem to be relating to classification instead of regression."
Stepwise Multivariate Regression Library?,1,2,False,False,False,learnmachinelearning,1492395993,True,"Asked here a few weeks ago.
Was trying to use multivariate regression to predict the rating of Players in sport game (NHL/NBA/FIFA/MLB/WWE) etc as an introductory learning phase.

However... I realized there's always a constant 'b' when trying to predict. This is because the game round up the nearest overall.

So in other word; multivariate wouldnt exactly output the correct result. I believe this can be remedied with stepwise multivar regression. However SKLearn do not that a library for that.



thanks!"
Text multi-class RNN not performing,0,3,False,False,False,learnmachinelearning,1492422637,True,"I'm trying to do some text classification using TF. 

I'm using 2-3 layer LSTM and 2 FC layers on top to extract the classes of the text. Sigmoid activation is used in the output layer. The loss is decreasing but F1-Score is pretty bad and getting even worse with much training (f1-score: 0.25, precision: 0.18, recall: 0.45). Word embeddings are taken from GLoVE 42B.

It's my first attempt at text classification and I feel that I'm missing some crucial part in the algorithm.

The data is taken from here https://www.hackerrank.com/contests/indeed-ml-codesprint-2017/challenges/tagging-raw-job-descriptions.

My model and training script can be found here https://gist.github.com/warchildmd/7167725470f8309eb5e7c63b6cae6e19."
Face detection working on Windows but not on Mac OS,3,1,False,False,False,learnmachinelearning,1492437328,True,"I'm starting my adventure with ML. My and my friend prepared a project for school with face detection using logistic regression. Our program first selects the model and then performs face detection on one picture. All the functions were tested with test module provided by our uni, so we are sure they work properly. 

We tested our code on Macbook with Mac OS. It selected the best parameters correctly, but when it came to working with the photo the program couldn't detect faces properly. No error or anything, just wrong results.

After hours of looking for errors, unistalling Pycharm and whole python we decided to run the code on different computer. And it worked perfectly! Then we run the code on the same Macbook but on Windows and it also worked. So we came to conclusion that this must have sth to do with the operating system, but just can't think of the reasons.

We are beginners and would really appreciate all the help

Modules used: functools, warnings, matplotlib, pickle, numpy, math, time, sys
"
How to best estimate number of needed hidden layers and neurons?,3,5,False,False,False,learnmachinelearning,1492476400,True,"Hey all,

I working on a problem currently that has about 128 inputs that needs to be mapped to 6 outputs. Is there any shorthand way of determining how many hidden layers and neurons per layer I should approx have for this sort of problem?

Are there any general way to approximate necessary number of hidden variables and neurons for any *n* sized input with *m* sized output?

Any and all help appreciated, thank you!

EDIT: Just some additional information, this is for a reinforcement learning algorithm on atari games so the amount of training data can be as much as I need it to be"
My first explanatory ML article on the expectation-maximization algorithm!,2,11,False,False,False,learnmachinelearning,1492498581,False, 
"Deep learning - How many observations is ""enough"" ?",4,4,False,False,False,learnmachinelearning,1492506804,True,"Hi r/learnmachinelearning !

The title may sound stupid, because the answer is obviously: ""as many observations as possible"". Let me expose my problem:

I'm working in a classification problem, with two classes. For the ""signal"" class I have up to 1M available observations. For the ""noise"" class, 5M. I need to split that into learning and testing, with of course as many observations as possible for the training. The chosen method is a deep neural network.

The problem is that in the end application, the signal-to-noise ratio is of the order of 10^-3 : there are 1000 ""noise"" events for 1 ""signal"". This means that my test set will actually have very few ""signals"", and it makes benchmarking, evaluating the accuracy, a difficult task. 

Therefore I need to increase the number of observations in my testing set. I then need to make a trade-off between ""enough observations to have accurate training"" and ""enough observations to reliably evaluate the model"". 

As I have absolutely *no* feeling on the order of magnitudes usual to machine learning, I would need to iterate over different training/testing splits. Which would be extremely time consuming. So, do you have any idea or advice about that?

I think I *may* be able to get more observations but that would mean producing them, and the guy who does that will of course ask me how many I need."
Help - What do I do with the output of a LSTM cell?,4,4,False,False,False,learnmachinelearning,1492508488,True,"I'm trying to convert my RNN model to a LSTM but I'm struggling to understand what I do with the output of the cell state? 

Typically with an RNN the hidden layer goes through weights connecting the hidden layer to the output layer meaning you only get 1 set of outputs, however with LSTM you get outputs for EACH memory unit, so if I have 4 hidden memory units then I get 4 different sets of outputs - So how do I consolidate them into a single output? 

Should this go through another set of weights to an output layer like with RNN? Or do I sum the outputs?

Thanks,"
Using multiple RNN Cells in tensorflow,2,2,False,False,False,learnmachinelearning,1492524148,True,"So basically i want to compare the perfomance of diffrent cells that are present in the TF. So i am intilaing array that contains the cell type
CellType = [BasicRNNCell, BasicLSTMCell, GRUCell]
def RNN(x, weights, biases, index):
.....
Cell = CellType[index](nHidden)
the problem is that how to i pass index value to the function.
I tried defining index as a variable but the array excepts a int.
I tried index defination as tf.placeholder also but that dosen't work etither.
I tried several other things but nothing seems to work.
Here is the full code please have a look.
https://gist.github.com/kris-singh/66ef0a05bbde5461c67c98bccd312a4c"
Project Idea - Is It Possible?,7,5,False,False,False,learnmachinelearning,1492542561,True,"Hello all! I am confident in my Python abilities and somewhat familiar with TensorFlow. I decided a fun project to improve my abilities would be to create a program that tracks video game characters in videos. An example would be placing a Yellow Square over Pac-Man as he moves around the map. In terms of machine learning and Tensorflow, would a project like this be possible?"
Help Teaching Game Driver to Drive • r/MachineLearning,0,1,False,False,False,learnmachinelearning,1492545309,False,[deleted]
Underflow Encountered in exp,3,1,False,False,False,learnmachinelearning,1492559770,True,"I've been training an LSTM on a simple sequence of characters but I've found that I always seem to get some kind of error related to overflow or underflow.

I've noticed that my weights and biases connecting to output layer always seem to be the culprit, usually with exceptionally small numbers on the character output which i'm training it not to output. I think my backprop code is just constantly reducing the weights and bias to a point which it's becoming too small and causes underflow.

I'm a bit lost on where to find the error though, any advice?"
I have tried to write summary of a paper based on RNNs in layman terms,0,18,False,False,False,learnmachinelearning,1492575478,False, 
Beginner at ML; Please check out my blog and give me some feedback!,0,1,False,False,False,learnmachinelearning,1492582036,True,[removed]
TWIL (This Week I Learned) - Share something new that you have learned this week!,1,2,False,False,False,learnmachinelearning,1492585688,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
[Help?] Theano: Convolve every channel of tensor A with every channel of tensor B and collect each result,0,1,False,False,False,learnmachinelearning,1492588113,True,[deleted]
MLJAR Academy: Start with Machine Learning,0,2,False,False,False,learnmachinelearning,1492593497,False, 
Confusion arises when deriving the gradients of Normalizing Flows Variational Autoencoders.,0,1,False,False,False,learnmachinelearning,1492604187,True,"Hi,
I am currently studying improved latent variable posterior inference via [Normalizing Flows](https://arxiv.org/abs/1505.05770).

What is not clear to me is the derivation of the gradient: at a certain point I am stuck with ∇_{f(z_0)} z_0

This is a gradient of a vector w.r.t. a *transformation* of a vector. I wonder: is it possible to transform this very simple expression into a gradient of some function of the vector w.r.t. the simple vector?

I have posted all details of my derivation on [math.stackexchange](https://math.stackexchange.com/questions/2238934/how-to-express-the-gradient-of-a-vector-w-r-t-to-an-invertible-function-of-that) [(and imgur)](http://imgur.com/HDyHv13)

Any idea on how to solve it elegantly?"
[Help] Creating a NDArray for CNN training in DeepLearning4J,0,1,False,False,False,learnmachinelearning,1492604912,False, 
Can AI tell you about what's on the internet about AI?,0,1,False,False,False,learnmachinelearning,1492606177,False, 
ML boot camps?,1,2,False,False,False,learnmachinelearning,1492612113,True,[deleted]
I wrote an deep learning article without using MNIST,0,1,False,False,False,learnmachinelearning,1492625149,False,[deleted]
How to Autoencode your Pokemon,2,2,False,False,False,learnmachinelearning,1492626116,True,[deleted]
Looking for feedback/collaborators on project: Conversation Models in TensorFlow,0,8,False,False,False,learnmachinelearning,1492632735,True,"Hello, a couple months ago I made a project ([github link](https://github.com/mckinziebrandon/DeepChatModels)) to explore sequence-to-sequence conversation models in TensorFlow and create a clean API for doing so. It started mainly as a way for me to learn-by-doing, but I think it has evolved into a resource that many might find useful. 

(IMO) The code is very readable and well-documented. The type of person that would get the most out of reading through it would have an undergraduate-level (re: has taken courses on ML) understanding of machine learning, and some TensorFlow background couldn't hurt.

Anyway, I wasn't sure where to post this, but I want this to become a good resource for anyone looking to build conversation models in tensorfllow, and I'm also looking for more folks to collab with. Bonus: the project also has a small website made with Flask, should anyone be interested in learning how to deploy a simple tensorflow model to a website.

Thanks for any feedback/suggestions!"
Microsoft OneNote Audio Index/Search Algorithm?,0,1,False,False,False,learnmachinelearning,1492635363,True,"I just finished listening to TWiML's [latest podcast](https://twimlai.com/from-particle-physics-to-audio-ai-with-scott-stephenson/#) which interviewed the founder of Deepgram, an audio indexing company. It was refreshing to hear them describe their approach and challenges.

It made me wonder how a similar technology performs audio indexing. The first I thought of was Microsoft OneNote's built-in audio indexing and search capability. I use it pretty often and find it to be relatively accurate even given some really low quality recordings.

Anyone have ideas how OneNote performs this algorithmically?"
Everything you need to know about Adam Optimizer,1,13,False,False,False,learnmachinelearning,1492662843,False, 
Stock data for anyone interested in modeling it,0,0,False,False,False,learnmachinelearning,1492673343,False,[deleted]
Backpropagation through concatenate/split layers,0,2,False,False,False,learnmachinelearning,1492692970,True,"Hi,
Can anyone explain how the gradient is passed through these layers?


In case of concatenation, if one of the two input layers which are merged, is placed somewhere earlier in the network, will it receive two gradients? The one which follows the longer route is passed last?


In case of split, you have two gradients which are merged. Do you then take an average of them or pass each of them independently (you could in theory have two output layers each generating its own error gradient)?

Thanks,
MK"
How to implement multiple LSTM layers,1,2,False,False,False,learnmachinelearning,1492693966,True,"I've finally got my LSTM working to reasonable performance using no libraries (only numpy). I've read that using multiple layers of LSTM can improve performance and hierarchical understanding but how do I implement it?

Obviously the output from the first LSTM goes into the second LSTM but do I pass it through a sigmoid function first? 

Also does it change the back propagation process? Do I just treat them independently?"
Reclassifying Messy Data,1,3,False,False,False,learnmachinelearning,1492699232,True,"Hello all! First time posting here; I have a a medium dataset of about ~2k rows that follow this specific outline:


There are ~100 hierarchy level 1s, that split into the 2000 subhierarchy level 2. I need to create sub-sub-hierarchies. The trick is hierarchy 1 is very orderly and maintained, something simple like 'Section 1,2,3,4,etc', whereas Hierarchy Level 2 was a dumping ground for all remaining information. I want to split out hierarchy level 2 based on common keywords. For example, Hierarchy level 2 might be 'steel - 10 inch' or 'steel - 20 inch', and I want to group them as steel for Hierarchy level 3, and 10in and 20in for level 4. (They get more complicated/convoluted, this is the simplest of scenarios)


The ask: What would be a good ML approach to this problem? I've taken the intro coursera course and consider myself pretty solid in python and regular data transfomration techniques (macros, formulas, etc)
https://github.com/thepank25/ML-sample"
How to autoencode your Pokemon [Article Linked],0,3,False,False,False,learnmachinelearning,1492705012,False, 
Beginner Project Ideas,2,4,False,False,False,learnmachinelearning,1492709201,True,[deleted]
Course in applied deep learning,0,1,False,False,False,learnmachinelearning,1492710090,True,[deleted]
Course in applied deep learning,0,3,False,False,False,learnmachinelearning,1492710699,False, 
Mathematical Machine Learning Textbooks,8,14,False,False,False,learnmachinelearning,1492711471,True,"When I try to search for good introductory machine learning textbooks, all I can find are people asking for ones that DON'T require a strong math background. I have the math background, so I'd like to find a book that can teach me these concepts with suitable mathematical rigour. I've just finished the third year of a BSc in statistics, so I'm familiar with multivariable probability and statistics as well as the associated calculus and linear algebra one has at this point, plus I'm quite familiar programming in R and Python. Unfortunately I don't have Measure Theory yet, so I'll have to avoid books using that extensively for now. Any suggestions would be greatly appreciated!"
Looking for TenorFlow/Layer help with my OpenAI card game playing agent (repo inside),0,1,False,False,False,learnmachinelearning,1492743767,True,[deleted]
Bias term in Kernel Ridge Regression,0,1,False,False,False,learnmachinelearning,1492753893,True,"Hi all -

in Kernel ridge regression, the regularization term in the cost function is given by a^T K a, where a are the parameters to be minimized, K is the kernel matrix so that K[i, j] = <xi, xj>, and so, is a n x n matrix if n is the number of training examples. The a that minimizes the cost function is given by (K+lambda I)^-1 y, and so is a n dimensional vector. However, in order to include a bias term, a must be a n+1 dimensional vector. How do we analytically find what the bias term must be to in order to minimize the cost function?"
Weekly Show-off!,2,3,False,False,False,learnmachinelearning,1492758546,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
Why does the SSD network need an specific input size?,4,3,False,False,False,learnmachinelearning,1492769323,True,Hello fellow redditors! Usually before using an image as an input for the Single Shot Multibox Detector (SSD) the image gets cropped/warped into the desired input size. Wide images like the one of the KITTI dataset will get squeezed a lot and therefor lose some information. I am wondering why the Single Shot Multibox Detector needs a specific input size of 300x300/512x512. Wouldn't it be more efficient if the network was able process wide images without squeezing them as well?
How it Works: Machine Learning,1,12,False,False,False,learnmachinelearning,1492772068,False, 
How can one additional convolutional layer decrease accuracy dramatically?,1,4,False,False,False,learnmachinelearning,1492788313,True,"I'm experimenting with ConvNets on MNIST and encounter the following problem:
When I use two convolutional layers I get a precision of ~99.3%, but when I add a third the precision drops to ~11%.


I think this might be the vanishing gradient problem, but I find it surprising that it happens that abruptly and with such strong effect.
The reason why I believe this is because the accuracy of the net and the weights of the first layer don't really change each epoch.

This is how my network architechture looks like:

(conv 5x5 layer -> relu -> maxpool)-> (conv 3x3 layer -> relu -> maxpool)* **n** -> fully-connected -> relu -> fully-connected -> softmax

The 5x5 layer uses 20 filters, and the 3x3 layers use 50 filters and a zero padding of 1.

This works well for n=1 but not for n=2.



So my question is, what's the reason for the sudden decrease in accuracy? I thought much deeper ConvNets were common, so the idea that this is the vanishing gradient problem surprises me.
Are there any examples of ConvNets with more layers that work well on MNIST?"
A question on input normalization.,1,2,False,False,False,learnmachinelearning,1492802875,True,"I'm interested in trying to have my neural network solve a rubixs cube, but I am not sure how to handle the inputs. I tried having each tile being given a number ranging from .1 to 5.4 based on what position it will be in when solved, but this does not seem to work correctly and it seems like an oversimplification of the data. To ask the question in the simplest terms, how do I turn data like this into numbers?"
Machine Learning Blogs,3,2,False,False,False,learnmachinelearning,1492812773,True,"Are there any blogs about machine learning that I should follow? Soon I will start my own journey into machine learning and thought about documenting the process in a blog.

Thanks for any help! "
"GLMs, CPUs, and GPUs: An introduction to machine learning through logistic regression, Python and…",3,18,False,False,False,learnmachinelearning,1492812791,False, 
Point me in the right direction. X-post from MLquestions,1,1,False,False,False,learnmachinelearning,1492818603,True,[deleted]
How long did it take you to complete the Andrew NG course?,13,10,False,False,False,learnmachinelearning,1492840011,True,"I did it one hour a day, six days a week, and it took me six months. I did take good notes and sometimes I would go through the material twice to make sure I understood it.

Side question - what is the book people usually read after they finish the NG course?"
"Weekly Scrum Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",0,2,False,False,False,learnmachinelearning,1492844852,True,"Let's have a scrum meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
Doing truncated SVD of 'sub features' matrix rather than on combined features matrix?,0,2,False,False,False,learnmachinelearning,1492861838,True,"I have the following source of data which can be obtained as such:

A1 = M users x N features of category 1

A2 = M users x N features of category 2

A3 = M users x N features of category 3

Category 1 is say items owned while category 3 are pages visited.

Normally, I would combine all the N features grouped by the users to create a A_joined matrix, but the number of columns on N is too many to store and work with on category 3.

Since A1, A2, and A3 contain 'categorized' features, can I do truncated SVD on each As and join them into A_joined2?

Mathematically I know they don't represent the same thing, but for practicality, am I not getting the principle components of each sub categories?

Thanks a lot."
Implementing Neural Networks from Scratch.,2,1,False,False,False,learnmachinelearning,1492872219,True,"
I was implementing NN from scratch to model for regression problem. But my code is giving me overflow error after some iterations. Should i normalise the values after every batch.

My batch_size = 10. Here is the link to my code 
https://gist.github.com/kris-singh/ced9e0ee4f2678a471905690dcd83756
Here is a link to my what my derivation of the backpropogation to the system.
https://ibb.co/eYLxt5"
Learn Artificial Intelligence with these best selling courses,0,0,False,False,False,learnmachinelearning,1492884461,False, 
Tensor Flow vs. h2o?,0,3,False,False,False,learnmachinelearning,1492886184,True,"is one of these libraries superior to the other? how do they compare in terms of features, speed, etc? "
Representing real life processes as MDPs,0,4,False,False,False,learnmachinelearning,1492890922,True,"Does anyone have a basic idea of I can encode a simplified real life process like Amazon package logistics as a MDP gridworld, for example?"
This was kind of painful at the end,12,23,False,False,False,learnmachinelearning,1492893269,False, 
"Looking for visual tools, like Grasshopper?",7,1,False,False,False,learnmachinelearning,1492901510,True,"One my friends showed me this http://www.grasshopper3d.com/ but you need to own Rhino3D and it only works on Windows.

Is there any free/less expensive tools that works on Mac?"
C# GPGPU API to help parallelize algorithms(possibly error propagations and transcandental functions) on multiple GPUs,0,3,False,False,False,learnmachinelearning,1492904537,True,"Being an open-source project for C#, it can use multiple GPUs even if they are completely different, it can pipeline the operations and overlap stages to elliminate read latencies write latencies compute latencies. Not only just primitive arrays, but structs can also be computed on.

This project lets developers write their genuine OpenCL kernels to run on all devices with help of its iterative auto load-balancer. So at each ""step"" or ""epoch"" (or whatever iteration it is), all GPUs get more fair workloads accordingly with their capabilities and performances.

Download source: https://github.com/tugrul512bit/Cekirdekler

Wiki: https://github.com/tugrul512bit/Cekirdekler/wiki

Tutorial: https://www.codeproject.com/Articles/1181213/Easy-OpenCL-Multiple-Device-Load-Balancing-and-Pip

Any feedback with some speed-up ratio is appreciated.

(machinelearning subreddit was not taking new messages, so this was opened here)"
Is a Pricey Masters Degree Worth It?,9,5,False,False,False,learnmachinelearning,1492906856,True,"I would like to take my career in a new direction with machine learning, and am exploring the different pathways available.

One way is to go to school and get a masters degree. The program I've been exploring is the masters of Data Science at Berkeley. The curriculum has what I want and with the distance learning, I can be anywhere in the world and still get an education. However, the tuition for the program is $63,000. (There's also the masters program in Machine Learning at CMU, and the machine learning masters program at University College London, but these would require relocating since they're not available online.)

The other path is to take classes online. There are several available that I can take from places like Dataquest, LinuxAcademy, ScienceAlert, Udemy, etc. I can pick and choose which ones I want and complete them at my own pace. Plus, the total cost would be less than 1% of the tuition at Berkeley.

And, since I'm making a huge leap from being simply a troubleshooter to an AI architect, I'll need to show potential employers what I can do. The plan is to post projects on github showing what I've worked on, both in class and on my own. (I intend to do this regardless of which path I take.) I am hoping this can show the progression of my knowledge and be the bridge between what is listed on my CV and what I can do.

So now I'm wondering....if the cost isn't an issue, which of these paths would work best in terms of impressing an employer? Will it be the degree, or the drive that would pique someone's interest to hire me? Please let me know what you think.

"
Building user features from logs - how to do it?,0,3,False,False,False,learnmachinelearning,1492931372,True,"Hello everyone! Suppose I have logs of interactions of user with the system (for example, search/buy logs like in Amazon or music/playlist log from Google Plus Music).

Clearly, users have different tastes, so (for example) in Amazon setting same keywords should yield different results fir different users - for example, Go can be both the programming language and the ancient board game. To this end, it looks like a good idea to create some kind of ""numerical"" description of the user based on his previous interactions - it could be used later with other features such as keywords, date/time, etc. I have no idea how to do this, but this seems to be a fairly standard problem. Can you tell me how to do this and where such methods are described?

(Yes, I tried googling, but I can't get an idea of what keywords should I have used)"
Where does this transpose in the Vector Form of SVMs come from?,1,3,False,False,False,learnmachinelearning,1492947364,True,"Hey, so I'm learning about Neural Nets using an online course and in the notes it states the following: http://imgur.com/a/OyMcC

But as far as I know, if we multiply the weight Matrix W by the input Vector x, to get the i-th entry in the output vector, we take w_i - the i-th row of W - and build the dot product with the column vector x. No transpose needed, right?

Thanks!
"
Can Word2vec be used for making recommendation systems?,10,10,False,False,False,learnmachinelearning,1492971261,True,"So as far as I know, word2vec works on the principle that similar words will lie closer in the n dimensional space.

Instead of word2vec if I make something like say, laptop2vec where  I capture the co-occurrence of laptop models, will I be able to build a recommendation system? What are the pitfalls (pros and cons) of this? "
[D] Study group for Stanford MMDS online course?,7,8,False,False,False,learnmachinelearning,1493017507,True,"Anyone interested in a study group for Stanford's MMDS course? I'm planning to cover the entire online course as well as the book for the next 2-3 months. 

I was thinking maybe a weekly virtual sync-up to check each other on progress/work on problem sets/clarify doubts if any. 

course link -> https://lagunita.stanford.edu/courses/course-v1:ComputerScience+MMDS+SelfPaced/about

book -> http://infolab.stanford.edu/~ullman/mmds/book.pdf

I'm from Bengaluru/Bangalore. We can also use our office space for discussions. 

original post -> "
Dimensionality reduction: when should I stop?,2,6,False,False,False,learnmachinelearning,1493034880,True,"Hello,

I'm trying to implement [this](http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf) paper about dimensonality reduction on images. I have a different dataset though, based on software-generated fingerprints with a resolution about ~150x60 pixels.

My question is, at what dimension of the feature maps one should stop before the flattening layer? In the paper they go straight from 9x9 feature maps to a scalar value via a (I assume) 9x9 kernel-sized convolution or/and pooling. Is this a good practice?

For instance I built a model following the third pattern [here](http://cs231n.github.io/convolutional-networks/#layerpat), which is: ```INPUT -> [CONV -> RELU -> CONV -> RELU -> POOL]*3 -> [FC -> RELU]*2 -> FC```

After my last pooling layer, my feature maps have the following dimensions: 64@1x4, which I then flatten for the first FC layer. Is 1x4 too small before the flattening? Should I try and apply a full convolution/pooling to avoid flattening and directly getting scalar values at my last conv layer?

"
Best way to learn scikit-learn or the most fundamental libraries for ml??,7,18,False,False,False,learnmachinelearning,1493041139,True, 
Can you recommend a statistics book for me?,2,5,False,False,False,learnmachinelearning,1493041451,True,"I know Calculus and a little linear algebra. I recently completed the Andrew NG course (it took me six months instead of the prescribed 11 weeks... maybe i am special).

I guess [this](https://www.amazon.com/Pattern-Recognition-Learning-Information-Statistics/dp/0387310738) book is my target. Can you recommend a statistics book that will prepare me to read that book?"
Jonathan Whitmore | Mental Models to Use and Avoid as a Data Scientist,0,5,False,False,False,learnmachinelearning,1493060891,False, 
Data Format for RNN (And a few other related questions),0,4,False,False,False,learnmachinelearning,1493071424,True,"So I'm trying to learn how to build RNNs. I'm using the Machine Learning Mastery tutorial and the example only uses one feature (it is the airline passenger data set, with each timestep representing the amount of passengers during that period).

I understand how it's done with one feature (which also happens to be the output), but how is done with multiple features?

[What if I had a dataset with five different features, one expected output (regression)](http://imgur.com/a/h2sgv), and I wanted to have the time steps / window set to 30 (so a month if each step represents a day) - what would the shape of the data be? I'm having a hard time intuitively understanding the best shape / format the data needs to be for RNNs. Is there a rule-of-thumb / best practice here? What would be the *best* RNN approach (there are several different approaches in the MLM tutorial) for this type of data set?

In addition, how well do RNNs handle data sets with, say, 500 features and a few thousand records?

Thanks for your help! I understand that might not make total sense but hopefully that screenshot / data example helps. I'm using keras."
Unable to reach high accuracy on training data,0,2,False,False,False,learnmachinelearning,1493076915,True,"A few months ago I did the Andrew Ng's Coursera class, so this is my first attempt at making predictions with neural nets by my own.

I am trying to predict credit score (good/bad) on a [german dataset](https://gist.github.com/brunoklein99/e07e5d7ae74b788b8cb696d36fb01401)

I am using Keras with the default TensorFlow backend. 

After encoding my data and normalizing it, I tried to evaluate my model on the training set (first 600 of my 1000 samples), just so I could confirm a high accuracy and have at least over-fitting. But to my surprise I could only reach 70% accuracy, I tried changing the number of units (for more and less), tried making the NN deeper and also tried training more, but I always end up getting about 70% accuracy.

For encoding I made all my category attributes into a one-hot array (one of K). The quantitative features were left as is.

For normalization I made all input values be on the [-1, 1] range.

My labels are 1 or 0 (good or bad).

I decided to use gradient descent as my optimization function, since that was what was used in Andrew's class and I understand how it works. For the same reason, I decided to use sigmoid as my activation function.

I noticed after training, most of my predictions (on the test set) have a similar output in the [0.5, 0.7] range.

I don't understand what I am missing.

This is my code: https://gist.github.com/brunoklein99/147bcd4e4e8c83afb80cce8231773587

This is my code output: https://gist.github.com/brunoklein99/064bc62acc485e47eb951304a5156dbd

Does anyone have any tips for me?"
How to break the deep learning tutorial to MY deep learning application barrier?,2,2,False,False,False,learnmachinelearning,1493078325,True,"One barrier I've found is that a lot of deep learning tutorials (e.g., TensorFlow) seem to bury the data munging/data import step before running the deep learning model, which makes it hard to understand how to use the model on my own data. 

Other barriers have to do with, say, a fancy loss chart that works for MNIST but not for my custom cat identifier (or whatever).

What have you done to move from running tutorials to running models on your own data?"
Lots of free data science and machine learning textbooks,0,1,False,False,False,learnmachinelearning,1493083574,False,[deleted]
Bellman Equation - how can it possibly work? Do you have an intuitive explanation?,5,3,False,False,False,learnmachinelearning,1493088232,True,"I've been digging into Reinforcement Learning and though I get the theory behind the Bellman Equation - add the current reward and the optimal reward from that point forward, I am not sure how is it possible to predict the optimal reward in the future without knowing the entire state of the environment at that point of time. How are we able to look into the future with this equation? Or is it only possible when we can map every possible state-action group?"
Random numbers,9,3,False,False,False,learnmachinelearning,1493095678,True,"I wrote a backpropagating neural network today to try and see how ""random"" pythons random number generator is. I was able to get my predictions up to around 60% after training. This got me curious about random number generators in other languages. I'm assuming they are similar but does anybody have specifics on random number comparisons between languages?"
Word association in literature with machine learning,1,2,False,False,False,learnmachinelearning,1493101478,True,"Hi!

I want to search through books spanning a few centuries and see if there is a difference in the usage of a specific word in certain time periods. The way I want to do it is to see what words are most likely to precede or follow the certain word. Maybe the word black in certain times and genres are more often followed by the word “magic” and other times “clothes”.

So I am asking here to see if you have any suggestions on where to start?

I have the data in text-format and I know the year the book was written. I prefer using Matlab and would like to write the code myself as much as possible since I love writing algorithms. If it is much easier in say R I don’t mind learning it as well."
Method to find a bounding box on a picutre?,3,3,False,False,False,learnmachinelearning,1493106214,True,"Hi,
I want to make a text recognition neural net, but unfortunately have no idea how to train a network to find the bounding box of the sign I will be holding. If I had the bounding box I could extract the area and apply some common model for the characters. Any idea?
A picture would look something like this: http://i.imgur.com/cKO8iqe.jpg"
Detecting patterns in a time series dataset,0,4,False,False,False,learnmachinelearning,1493111466,True,"Currently I'm developing a project on the automotive area and I have a dataset formatted (I can change it easily to another format if needed) like so:


Timestamp | DidTrip | Distance
---------|-------|--------
2017-04-20T00:00:00+00:00 | 0 | 0
2017-04-20T01:00:00+00:00 | 1 | 10
2017-04-20T02:00:00+00:00 | 0 | 0
... | ... | ...


DidTrip indicates whether or not the driver started a trip, and if so, the distanced traveled.

What I want to achieve, is to detect patterns that indicate the most likely hours in a day that the driver will initiate a trip.

What algorithms can I use for this? Are there any good libraries that implement those tools? Thank you."
Best beginner project to do in the vacation ??,4,7,False,False,False,learnmachinelearning,1493113330,True, 
What is the problem with back propagation in Neural Networks when the Activation function only outputs Positive values?,2,2,False,False,False,learnmachinelearning,1493113820,True,"I'm watching CS231n and on lecture 5 minute 17:00 karpathy discusses the issue when the activation is always positive and how it can affect back propagation  

I don't get what the issue is, can you guys explain it to me? 

And what is the issue with zig-zagging or if its always positive? And Why all grad positive and negative?

https://youtu.be/GUtlrDbHhJM?t=17m31s

Can someone give me a concrete example ?"
Structuring data for predicting student grades,0,1,False,False,False,learnmachinelearning,1493130171,True,"I have a question regarding best ways to structure a data set for training and prediction. My task is to predict grades in courses for students and to work on this I have a data set on ""transcripts"" for students at a college. These transcripts are simply anonymized records of classes taken by students, and the grades received.

Each instance in the data set represents a student taking a course and contains information on the student (gender, major, a number that uniquely identifies a student across multiple of these records) and information on the course (semester, department, course number, instructor, some schedule information and the received grade. It also contains a year.
Personally, I want to treat this as both a regression and classification problem for now. I look at the grades (A, B, C, D, F) as both categorical (for classification) and their respective numeric values (4.0, 3.0, 2.0, 1.0, 0.0) for regression.

With grade as a target, I have computed a bunch of additional predictive features for each data instance: 
* gpa at beginning of course (computed from previous grades received in earlier classes for same student) 

* average grade for course 

* average grade for professor 

* course load (how many other courses does student take in that semester) 

* minutes of class per week 

* student standing (freshman, sophomore, etc)

Many of these are trying to build an idea of a ""history"" for each student at the point the course is taken, without actually including information on all courses the same student has taken in the past, since that is far more complicated.
Do you notice any major flaws in this?

Ideally, one would try to discover similar students who have taken the same classes and received similar grades in the past, and use that information to predict a grade for a student taking a course. I just don't know exactly how to tackle that."
A good resource to understand the use case of each machine learning algorithm ?,2,16,False,False,False,learnmachinelearning,1493131084,True,"Hello there,

I have been writing a few state-of-the-art papers about machine learning for companies for a few months. But I have a problem : the more I read, the less I understand.

There is a huge amount of algorithm to solve all kind of closely-related problems, and I am starting to have trouble to differentiate use cases for SVM from Factorization Machines from logistic regression from bayesian inference from gradient descent...

Sometimes many can be used to solve a specific problem, and picking the right one seems very difficult. I can understand advanced mathematics, I am mostly seeking for an overview or a summary of the state-of-the-art algorithms.

Could anyone point me onto good resources that sums up all the machine learning and associated algorithms and their preferred use case ? Either a book, a research paper or a tutorial ? 
Thanks a lot !"
Stanford's machine learning course on Coursera,0,1,False,False,False,learnmachinelearning,1493137588,True,[deleted]
Advice for organizing and planing useful side projects?,2,1,False,False,False,learnmachinelearning,1493141468,True,"I have this problem of not following through with a lot of side projects I start because of over thinking it, deciding it's too hard or simple, or not relevant to the skill sets I'd like to peruse. Any one have a similar problem? Any advice on how to plan right the first time? Pretty much how do you set out planning a project given that you want to demonstrait certain skills. (Lets falsely assume that I have a clear idea of what those skills are)"
Image sharing patterns/predictions in social media accounts?,0,1,False,False,False,learnmachinelearning,1493146770,True,"There is a fashion instagram account (antisocialsocialclub) that shares pictures of people wearing its brand. I am interested in finding out the likelihood of an picture being selected (by tagging them). Some of the attributes I have identified by observing are gender, race and visibility of the logo.

I was thinking Amazon ML's prediction system could be a good fit, however since its primarily for analyzing text data, processing the images and categorizing their attributes might be quite complicated. Are there any libraries or tools specific for image pattern analyzing?"
Tools for Manually Labelling Datasets?,2,8,False,False,False,learnmachinelearning,1493149883,True,"Hey folks,

I'm embedded in a few small projects right now that involve categorical classification of text or HTML data with pre-defined labels. One is ~binary, the other is multiclass.

Right now, I'm labelling with custom Jupyter notebooks, which is painstaking and takes too long. What I really want is a tool that lets me look at the text and then click one of the labels or skip it. There's something kinda like this [for images already, here](https://github.com/USCDataScience/supervising-ui).

I could build this with Jupyter/IPython Widgets, but that sounds nearly as painful as what I'm doing now. Is there a tool for this use-case already? Or are we all slogging it painfully through notebooks, shell, and dodgy webapps? :)"
Build with AI - easily build machine learning into your applcation,0,5,False,False,False,learnmachinelearning,1493149915,False, 
Every example of LSTM I find still confuses me,0,1,False,False,False,learnmachinelearning,1493171770,True,[deleted]
What are the important parameters which determines the rate of learning and loss of a deep learning model?,0,1,False,False,False,learnmachinelearning,1493188078,True,[deleted]
What's a good algorithm to match candidates?,2,0,False,False,False,learnmachinelearning,1493188534,True,"I'm trying to create a system where it matches company A requirement with a list of potential employee database.

*I'm doing it just for a test, nothing serious."
TWIL (This Week I Learned) - Share something new that you have learned this week!,0,2,False,False,False,learnmachinelearning,1493190482,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
I have datasets in Excel that are analyzed by humans every quarter. How could I try to automate this process?,5,3,False,False,False,learnmachinelearning,1493196845,True,"Hi Reddit, hopefully this is the right place to ask this question (if not, please send me my way).
I have a considerable amount of data in Excel that is manually analyzed by humans periodically. Basically, there are some 10-15 columns with data that they look at, maybe do some research about it and then fill another 20 columns manually (some are percentages, some are categories, etc).
I have a few years of data in spreadsheets that could be used as guides for a machine learning algorithm. If I were to try to automate this process, what tools do you recommend? Any interesting plugins in Excel available? Should I strip data off of Excel and work some place else?
Any help will be greatly appreciated"
I want to learn Machine Learning in C++,9,6,False,False,False,learnmachinelearning,1493200967,True,"Where should I start from if I want to dive into c++ for machine learning.

Thanks.

I was unable to find any tutorial or book regarding this matter."
PlanesNet - labeled training data for detecting airplanes in Planet imagery,2,2,False,False,False,learnmachinelearning,1493205893,True,"For the past couple months I've been working on building out a labeled dataset called PlanesNet: https://github.com/rhammell/planesnet

The goal was to build a dataset that can be used to train machine learning algorithms to automatically detect the location of any airplanes within [Planet](https://www.planet.com) imagery. 

Right now PlanesNet contains 10500 example RGB image chips, each 20x20 pixels, that are labeled as ""plane"" or ""no-plane"" depending on if there is an aircraft present in the chip.

The plan is to continuosly update this dataset as new Planet imagery becomes available. It'll be possible to grow dataset by hundreds of samples a month as more Planet satellites start collecting. The imagery is made available through Planet's Open California dataset and is openly licensed for use.  

Now that I've got this dataset started, the next step is to begin trying out some ML algorithms to see how accurately the chips can be classified into the correct classes. 

I have some limited experience using the tensorflow MNIST tutorials, which work on similar sized image chips, so my first go around will be to recreate those with the PlanesNet data and see how it performs. 

Any other suggestions on where to start? If anyone is interested in collaborating, or is able to run this data through their own algorithms with good success I'd like to hear about it. 

"
Generative Handwriting Network,1,1,False,False,False,learnmachinelearning,1493212200,True,"Hi all, I have been thinking about beginning a project to generate handwriting based on character input. Obviously it would be trained using a writing data, so my question is what would be the best structure for this network?

My first thought was LSTM, but is there a better option? Also what would be the best format for the data: raw images, spatial progression points of the writing, or something else?

I'm fairly new to working with NNs so all help is appreciated (also not all of my terminology or NN knowledge may be correct, sorry)."
How independance are hyperparameters in classic ML models ?,0,1,False,False,False,learnmachinelearning,1493214412,True,"Hi everyone,

I have a non-answered questions for a while now about the independance of hyperparameters.
Let's take a random forest classifier.
Basically, is it reasonnable to assume that if I optimize the number of estimators, can I assume that this one wont dramatically change if I modify the splitting 'criterion' ?

Do you have any ressource regarding this subject ?

Thanks"
Use of early stopping when comparing different algorithms?,0,1,False,False,False,learnmachinelearning,1493223505,True,"I am intending to compare different approaches to a classification task using various neural nets.

In most papers I've read usually the authors use a pretty fixed schedule of ""learn for some number of epochs"" and ""reduce learning rate at epochs a, b and maybe c to fixed values"".

This makes me wonder how to determine for how long I should train and at which point I should reduce the learning rate.

I am wondering if I could ""just"" use early stopping instead, which would still require me to determine the patience parameter, but it seems ""more adaptive"" compared to a fixed schedule, allowing for faster competition of tests.
Would that skew the comparison results somehow and is not done for that reason?
"
Help me plan self study ML program,5,22,False,False,False,learnmachinelearning,1493225748,True,"I would like to plan a practical self study ML program. Which is essentially a curated list of resources that I'd like to study/implement in chronological order. By practical, I mean that I would like to focus more on implementation rather than research. However, I understand reading few research papers will be helpful. I'm thinking about doing this in Python. 

What I've done:
- Gone over Andrew NG ML course
- Took CS 7641 - ML (mostly theory) - https://www.omscs.gatech.edu/cs-7641-machine-learning 
- Took CSE 8803 - Big Data for Health (Predictive analytics based on Spark) - https://www.omscs.gatech.edu/cse-8803-special-topics-big-data-for-health-informatics

Plan I would like to follow:

- Numpy
    - https://github.com/donnemartin/data-science-ipython-notebooks#numpy
    - https://getpocket.com/a/read/1692024308

- Pandas
    - https://github.com/donnemartin/data-science-ipython-notebooks#pandas

- Sci-kit learn
    - https://github.com/donnemartin/data-science-ipython-notebooks#scikit-learn

- Tensorflow
    - https://cloud.google.com/blog/big-data/2017/01/learn-tensorflow-and-deep-learning-without-a-phd
    - Implement Neural Net to learn handwritten characters. Similar to MNIST examples. 

- Keras
    - Start learning keras from documentation and other resources

I'm hoping people more familiar with the field can help me with the following:

1. Is this a good list to follow in chronological order?
2. I feel like I am missing exercises/problems that would allow me to use/test the knowledge I gain from learning about the above. Are there more resources for this?
3. I'm simultaneously reading Deep Learning book (http://www.deeplearningbook.org/). It is good but missing implementations thus far (I'm on chapter 2). Are there other books that are more focused on implementation (python/tensorflow)? I just found this https://www.manning.com/books/machine-learning-with-tensorflow but I'm not sure whether it is a good resource..
"
Neural Networks Without a PhD: Topologies,0,2,False,False,False,learnmachinelearning,1493230117,False, 
Perceptions of Probability and Numbers,0,3,False,False,False,learnmachinelearning,1493253043,False, 
Demo - Lyrebird,0,0,False,False,False,learnmachinelearning,1493253793,False, 
How do multiple CNN layers connect together?,1,1,False,False,False,learnmachinelearning,1493259896,True,"I writing a neural framework for detecting static gestures with a low resolution 2 dimensional grayscale input. So far it works pretty good with a single CNN layer that has a dimension of 10x6 and a depth of 30 (30 different kernels). There is no max pooling and no fully connected layer yet except for the output softmax layer. I would like to add another CNN layer between the first CNN and the softmax layer, however, I haven't found any documentation on how to connect between the two CNNs. Would each kernel in the second CNN be three dimensional and connect to each kernel layer in the first CNN? How else would I connect the two CNNs? Any advice would be appreciated. "
My first assignment!,1,11,False,False,False,learnmachinelearning,1493264340,True,"Ok,I am newbie here.I have to tried to learn ML on my own.But everytime something  comes up.I am determined to get proficient this time.

This is the problem:
https://www.hackerrank.com/challenges/predicting-house-prices

I wrote something in Python.I want to know why if I vary the learning rate(alpha),the results vary widely.Does alpha need to be <1/2h( h is the number of data in the dataset.).Also,I tried to add a regularizer,but then it became even worse.May be the parameters are not right. I want to know how do you decide what the parameters will be.Do you just test them and then decide?Or is there some kind of a ""formula""?And if you could just point out what are some stuffs that I could do better.

Here is my code:



    w,h = map(int,raw_input().strip().split())
    arr = []
    res = []
    for i in xrange(h):
        arr.append(map(float,raw_input().strip().split()))
        res.append(arr[-1].pop())

    #print arr
    #print res

    test = []
    for i in xrange(input()):
        test.append(map(float,raw_input().strip().split()))

    def regression(x,y):
        theta = [1]*(w+1)
        alpha = 0.5/h
        c = 1000
        while c:
            for i in xrange(h):
                old = list(theta)
                delta = sum([(old[0]+sum([x[i][j]*old[j+1] for j in xrange(w)]))-y[i] for i in xrange(h)]) #comment summation part
                theta[0] = old[0] - alpha*delta
                for j in xrange(w):
                    theta[j+1]=old[j+1]-alpha*delta*x[i][j]#commented out the regularizer+alpha*abs(old[j+1])
            #k = sum(abs(theta[j]-old[j])/old[j] for j in xrange(w+1))/len(theta)
            #print old
            c-=1
        for i in test:
            print (theta[0]+ sum([theta[j+1]*i[j] for j in xrange(w)]))


    regression(arr,res)

I know the code is kinda messy,but I was determined start it last night itself.I am learning from CS229.

Thanks for reading."
Training a LSTM to forecast time series data (i.e. river flow),2,5,False,False,False,learnmachinelearning,1493278536,True,"I have a set of data in the following format (see below) and want to train an LSTM to forecast river height based on a number of variables like rainfall and temp. I had some success using a NARX previously, but now I want to use a LSTM. Probably with a look back window of 5 or 6 as that is worked best with the NARX. I'm probably going to use Keras, but I'm confused about the input format and the overall network structure. I've been trying to follow the following Stack Overflow answer [located here](http://stackoverflow.com/questions/39674713/neural-network-lstm-keras), but I'm still confused particularly about the output dimension. I'm also looking for suggestions about the overall network structure and what would work best in terms of layers. 

number|height|temp|rainfall
:---|:--:|---:|---:
0|4.63|45.0|0.0
1|4.66|44.5|0.0
2|4.70|44.2|0.2
3|4.78|44.0|0.1"
Unsure if my implementation of a Convolutional layer doesn't learn or it's the correct behaviour,4,2,False,False,False,learnmachinelearning,1493291402,False, 
[Matlab] Problem with Neural nets on MNIST handwritten digits,2,1,False,False,False,learnmachinelearning,1493293081,True,"Hi!

I am trying to use the Matlabs neural nets to identify the handwritten digits from MNIST. http://yann.lecun.com/exdb/mnist/

So I started with code to read the data:

	%Read the trainingset
	trainImg = fopen('train-images-idx3-ubyte','r','b');
	trainLabel = fopen('train-labels-idx1-ubyte','r','b');

	%Skip the ""magic"" number, 16 for images and 8 for labels.
	fseek(trainImg,16,'bof');
	fseek(trainLabel,8,'bof');

	%Amount of images to read from training set (60000 is max)
	N = 100;

	%Predefine matrices
	img = zeros(28,28,3);
	IM = zeros(28*28,N);
	LM = zeros(10,N);

	for i = 1:N

		%Read the next image
		temp = fread(trainImg,28*28,'uchar');
		%Store the data for neural network learning input
		IM(:,i) = temp;
		%Store the image for viewing purpose
		img(:,:,i) = reshape(temp,28,28)' / 256;

		%Store labeldata
		LM(:,i) = fread(trainLabel,1,'uchar')*ones(1,10);

	end

Then I train the neural nets with the data:

    net = patternnet(10);
    net = train(net,IM,LM);

The problem here is that the confusion matrix seems to be wrong. If I understand the matrix it only shows the classification errors of the digit 1. Like this: http://imgur.com/hrVNl9P. (I get the same errors if I use N = 60000, I only smaller N since it is faster.)

Any ideas on where I went wrong?

I also have a question on what the output is if I put in image data into net, like this:

    net(IM(:,1))

The result I get is:

    0.8999
    0.9000
    0.9000
    0.8999
    0.9000
    0.9000
    0.9001
    0.9001
    0.9000
    0.8999

Are they probabilites of which digit the model thinks it is or what?"
Overfitting questions regarding DL,2,6,False,False,False,learnmachinelearning,1493296412,True,"I read from time to time on some papers, that you should always start with a ""simple"" model, and check if it can completely overfit data. Then, you could add some more layers, or bigger kernels to try and find more complex features and get better validation accuracy.

Unfortunately I can't recall the exact papers/guides where I found this tip and what they said, but I'm pretty sure what I described is close to that. 

Do you guys apply this method when you're starting a project with new data? At what point do you say ""ok, stop, I have xx accuracy and yy loss, I can't overfit more than that""?

In general, what is your workflow when building a new model?"
Datasets used in studies,1,2,False,False,False,learnmachinelearning,1493299111,True,"Is there a unified location where I can find  datasets used in various studies?  Of note I am interested in playing around the  dataset used in this skin disease study

https://www.ncbi.nlm.nih.gov/m/pubmed/28117445/

Thanks!"
Implementing K Nearest Neighbours from Scratch - in Python,0,14,False,False,False,learnmachinelearning,1493315041,False, 
Predicting Acute Medical Events,0,1,False,False,False,learnmachinelearning,1493332207,True,"I'm completely new to ML, but I'm working at a company that's developing large medical data sets and I'm interested in how we can apply ML techniques to predict and hopefully prevent acute medical events.  In short, we have data on medication adherence, biometric test results related to their disease state, and daily environmental data about exacerbating conditions for their disease, and records of acute medical events such as emergency room visit or emergency medication use.  I'm looking for recommendations on books or other resources to learn about how to analyse this time series data to predict/prevent such event and any software tools to actually do it.  I've been playing with WEKA a bit, but I haven't been about to figure out how to do this time of analysis.  Most of the information I've seen is related to classification. The only time series analysis examples I've found on the web deal with making numerical value predictions like future stock price based on a single data set.  I want to combine multiple data sets (from multiple patients) to predict whether an event is likely to occur in the near future.  Any insight would be appreciated."
Finding accurate precision and recall for Keras 2.0?,1,1,False,False,False,learnmachinelearning,1493336624,True,"It looks like they removed the precision, recall, and f1score metrics from the API since it wasn't really accurate. So then how should I get these metrics? 

Some have pointed to make ones yourself following their [metrics](https://keras.io/metrics/) page but if it's that easy, why wouldn't they just write it and add it to their standard library instead of forcing us to write our own? Would it still be inaccurate if I do it this way?"
red-data-tools/jekyll-jupyter-notebook: Jekyll Jupyter Notebook plugin,0,4,False,False,False,learnmachinelearning,1493344586,False, 
"How to know if neural net is broken, needs more layers, needs larger layers, needs a different learning rate, etc...",0,1,False,False,False,learnmachinelearning,1493347816,True,[deleted]
Variational Autoencoder Cost Function Question,7,4,False,False,False,learnmachinelearning,1493374985,True,"I understand the part about the KL-divergence to have the latent code match our spherical gaussian prior.

What I don't understand is why the reconstruction loss should work.  As I understand it, the prior should eventually force the means and variances output by the encoder to approximately equal 0s and 1s, respectively.  Thus, shouldn't drawing a sample from this be equivalent to just picking any point in the latent space randomly.  Why should the reconstruction of this point look anything like our original input?

Quick example - say we're looking at MNIST.  I feed in a digit 4, the encoder outputs approximately 0's for means and 1's for variances.  A sample I draw from this could now represent any digit in latent space such as a 9 and or 7, leading to the reconstruction loss being meaningless.

I'm positive my understanding is flawed somewhere.  But where?"
Emotion Detection Using Machine Learning - ParallelDots,0,1,False,False,False,learnmachinelearning,1493380836,False, 
For out-of-core learning systems such as VW that use the hash trick - What happens if the test set has values that don't appear in the train set?,0,2,False,False,False,learnmachinelearning,1493385967,True,"This might be a simple question but I'm trying to understand what happens. I (think I) understand how the hash trick works - long story short it converts the particular entry value into its hash (I know this is imprecise). However, what happens if a value doesn't appear in the test set? In this case, is it correct that its hash value would not have been trained on? If so, what does it do when it encounters it?"
"TensorFlow: A proposal of good practices for files, folders and models architecture",2,5,False,False,False,learnmachinelearning,1493387991,False, 
Understanding LSTM Networks -- colah's blog,0,5,False,False,False,learnmachinelearning,1493388343,False, 
How to structure a dataset for a CNN!?,3,2,False,False,False,learnmachinelearning,1493399244,True,"Hi. Just wondering how to structure a dataset for a Convolutional Neural Network. The kind where I have an image and a label. Would it look something like, x2 Lists; 1 for images, which is a collection of numpy arrays and the other list for the label. 

Would I have to somehow line up the lists so list_1[0] would correspond to the correct label list_2[0]

I think have the jist of it. Is there an easy way (some tool or something) to do this? Thanks!"
Using VGG16 with Keras,1,3,False,False,False,learnmachinelearning,1493405452,True,"Hi,

I am using Keras to predict 14 classes by following this tutorial: https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html

The first model where you predict from scratch works fine by using 14 instead of the usual 2 classes. 
But when I start using the VGG16 model I get this error: 'valueerror error when checking model target: expected dense_2 to have shape (none, 14) but got an array with shape (44926, 1))'

This is the code I am currently using for working with the VGG16 model: https://gist.github.com/anonymous/d7ebed447879572a4a566e8273ff3ff4

I changed the last dense layer to Model.add(Dense('14', activation='softmax')) but that apparantly does not work. 

I think the problem lies with how the np.array is made when generating training labels. I also dont have the exact same amount of training/validation images per class but that did not matter with the first model I made from scratch. 

Any help appreciated."
How to use the GPU efficiently?,2,7,False,False,False,learnmachinelearning,1493411282,True,"So, I'm a begginer on machine learning and I've been struggling to get the max of my gpu using Keras with tensorflow backend.

I know that that my gpu is weak for machine learning (GTX 750m - 4GB - 384 cuda cores) but I've tried to train a simple RNN with 12 features (12 previous outputs) and a small data sets of 200, 1000 and 4000 points.

From what I researched, GPUs should take advantage of mini-batches, right? I tried using CPU and GPU with different sizes of batches, and every single time the CPU (i7-4702MQ) outperformed the GPU by more than 50%. 

I don't know if I'm doing something wrong, or if I'm getting the theory wrong and it was supposed to be this way. 
Any help would be appreciated. Thanks in advance!


EDIT: Here is the link to the program and data: https://github.com/makalaia/CPUxGPU"
"Detecting uninformative, redundant labels in multilabel learning",3,1,False,False,False,learnmachinelearning,1493412442,True,"I'm working on a fairly large dataset, which is comprised of 144k documents scraped from the web along with the number of times a user on delicious (social bookmarking service) assigned a tag to that url. My goal is to, given a new document and the features extracted from it and an incomplete or empty label vector, predict the rest of the labels- in essence, suggesting tags to a user who adds a new bookmark.

I have an initial approach that seems well suited to the problem at hand. [This is the paper](http://dl.acm.org/citation.cfm?id=2969599), it can be found freely available on several university sites but I'm on mobile and can't get the url, only the google referral link. Regardless, this isn't a problem.

The issue I have is that the label vectors are enormous. There are 65000 unique tags. Although this is still sparse, and the learning can be done with a sparse solver, the nature of my data makes it much less sparse than that which the authors are working with. My dataset aggregates the tag counts over all the users who have tagged that document, and so the number of nonzero entries for each document is much greater- the average number of labels per document in the datasets the authors used for learning with incomplete labelling was 4 or less, whereas I'm dealing with around 28. I'm going to go ahead and give it a shot but I'm expecting to have issues with memory consumption and performance. In that case, I see a couple options to sparsify the labels further-

- I have a much larger dataset, the complete tagging data for the entire history of delicious, and that is broken down by user- each label vector will be binary and only the tags a single user applied. I can join the two datasets on the url id and pull out all the entries for urls in the smaller dataset. I can't make use of the other data from the large set because it does not have the documents scraped for each url. This is a pretty simple task, but it means that I will have multiple data points per document that contradict each other, and I don't know if that will be an issue. This doesn't change the number of nonzero entries in the full label matrix but it does reduce the number per document, and the learning algorithm can be batched.

- Feature selection in the traditional way, dropping uninformative or extremely rare tags. I'm fine with this approach, but I'm not sure how i ought to evaluate whether a label is useful before training the model and could use suggestions.

- finding labels that act as synonyms- different users might use different tags to mean the exact same thing. If I can identify those labels, I could merge them- going back to the larger dataset broken down by user, dropping the more infrequent of the pair, and treating the other as the logical OR of the two tags. I would like to do this regardless of the other approaches, as it increases sparsity in such a way that reduces noise at the same time. If I can join ""color theory"" and ""colour theory"", for example, the relationship between them can be inferred before any of the more sophisticated inference happens. I wouldn't be throwing away information as long as I'm only merging tags that are equivalent with a high confidence. However, I have no idea on how to do this without manually annotating tags, which is not feasible or desirable.

Any thoughts? Anything I'm missing as to how I might handle this? Thanks for taking the time. A bit later I will add links to the datasets I mentioned in case other people find them useful, they took a lot of work to put together and are extremely well done. 

- "
YouTube series on machine learning,4,12,False,False,False,learnmachinelearning,1493432795,False, 
Great Python Libraries To Learn Machine Learning,3,16,False,False,False,learnmachinelearning,1493433873,False, 
programming language to get started.,5,2,False,False,False,learnmachinelearning,1493440920,True,"Im new with machine learning. I would like to know what programming language has the simplest and easy learning curve for me to get started implementing machine learning and deep learning (I dont care about the performance or other factors, I just want the easiest to learn to start doing hands-on examples) . Im reading some fundamentals books on machine learning and deep learning but I still have not decide on which language to choose"
what is Machine Learning? A simplified understanding - Source Dexter,1,8,False,False,False,learnmachinelearning,1493448503,False, 
"Weekly Scrum Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",5,3,False,False,False,learnmachinelearning,1493449672,True,"Let's have a scrum meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
Handling Missing Data in RNN / LSTM (Time-Series),0,6,False,False,False,learnmachinelearning,1493486138,True,"As the title suggests, I have a time-series data set and there is a lot of missing data. What is the best way to handle this for a LSTM model?

To give further detail, I have about five data sources to create the dataset and some of them do not allow me to get historical data so I'm missing quite a bit for the features in that source. I can fill some in using the most recently observed sample, but for the most part that isn't possible.

Some suggestions I have seen are:

 -- Hidden Markov Modeling

 -- Expectation Maximization

 -- Using a neural net to predict the missing values

But for all I feel like I will be losing a lot of data integrity. How is this usually handled / what is the best way to adjust for this in LSTM models?

I'm using Python / Keras / TensorFlow.

Thanks for the help!"
Binary image classification what is the effect of imbalanced classes?,1,3,False,False,False,learnmachinelearning,1493501945,True,"I am building a binary image classifier. It will be 1 if the object is a banana and zero if anything else. I have more pictures of ""anything else"". What should be the ratio between them, what is the effect of imbalance? Is 1:5 too bad?
"
Great Books To Help Learn Machine Learning!,6,22,False,False,False,learnmachinelearning,1493502413,False, 
A Step by Step Backpropagation Example,0,21,False,False,False,learnmachinelearning,1493526786,False, 
Genetic algorithms in kaggle ?,2,0,False,False,False,learnmachinelearning,1493545946,True,"I was going through the kaggle's titanic leader board , and there are many submissions with genetic algorithms at the top 
such as --> https://www.kaggle.com/hanania/titanic/based-on-genetic-programming-lb
Where can i learn more about this ? 
I found tpot when googling, but was not about to get such a genetic function out of it.

How do these functions work and where can i find the library to implement them and also learn more about genetic algorithms.

"
Learning Bayesian nonparametrics,2,4,False,False,False,learnmachinelearning,1493579286,True,"I've been really piqued by Bayesian ML of late, and unfortunately, while there's a whole bunch of tutorials on neural networks, there's very little introductory material on Bayesian nonparametrics. Can someone help me with a reading list of sorts to better get a grasp of the big ideas in the field?"
Which commercially available games uses artificial neural networks and where they use it?,8,7,False,False,False,learnmachinelearning,1493600841,True, 
PCA + Deep Learning ?,7,3,False,False,False,learnmachinelearning,1493638211,True,"Hi all!

I'm wondering if it's common and/or if it's a good idea to use Principal Component Analysis (PCA) on a dataset before feeding it into a deep neural network.

To my understanding, the more ""raw"" the variables in the dataset are, the better the DNN will perform. I however do not how well DNN deal with correlation. 

I have a dataset with a ton of possible variables, too many to fit in memory. I also know that many of these variables are correlated, sometimes very strongly. Hence the idea of applying PCA on my dataset to extract as many information as possible from it in a lower dimensional space, which would make the training faster while also potentially providing more information than if I supply hand-picked variables that I think make sense. 

What do you think?"
Cross-Lingual Word Embeddings from scratch,0,1,False,False,False,learnmachinelearning,1493638917,False, 
Cheat Sheet on Keras 2.0: Neural Networks in Python,2,35,False,False,False,learnmachinelearning,1493649819,False, 
Help with improvement of Sliding Window Detection with 3D point cloud data,0,1,False,False,False,learnmachinelearning,1493657912,True,"Hey guys,

I'm doing my Master's thesis on 3D object detection and have an already working classifier for 3D objects from point clouds. The problem is that the classifier requires segmented objects for classification.

As I get a whole scene as a 3D point cloud, I tried mimicking a Sliding Window approach in 3D: I have a Sliding Cube with different scales that outputs potential objects from the point cloud. The current problem I'm facing is that the classification levels are very bad. Since I have a number of classes (say: 5) and a background class, every 3D cube gets classified. Unfortunatelly, my recognition accuracy is very bad, most of the time the boxes get an overlap-score of 0%, meaning that the classification is completly wrong.

My questions now are: Is there already some properly working implementation of Sliding Window in 3D? How can I improve my algorithm? Or is there an easier way of segmenting proposal for objects to be classified from a point cloud.

I'm currently using Matlab as my tool if that is of any importance.

Thanks a lot for your help!"
"Python implementation of ""Keep it simple! How to understand Gradient Descent algorithm""",0,2,False,False,False,learnmachinelearning,1493662089,True,"This is my python implementation of [""Keep it simple! How to understand Gradient Descent algorithm""](http://www.kdnuggets.com/2017/04/simple-understand-gradient-descent-algorithm.html) . For beginners; this is the simplest form of gradient descent algorithm which may help you to understand backpropagation.

https://gist.github.com/anonymous/017ecfb0496027da93486d45b9d405c1"
Multivariate RNN / LSTM Keras Tutorial (In Search of),0,2,False,False,False,learnmachinelearning,1493665214,True,Has anyone ever found / used a good **multivariate** LSTM tutorial using keras? I'm having a lot of trouble finding resources in this domain.
What is the intuition behind the Storkey Learning rule for Hopfield Networks?,0,1,False,False,False,learnmachinelearning,1493666798,True,Is it that the additional terms of [the Storkey Learning Rule](https://en.wikipedia.org/wiki/Hopfield_network#The_Storkey_learning_rule) basically reduce the weight changes (due to hebbian learning) when the old weights *already* produce the correct behavior for the new pattern?
Assessing the quality of ML learning resources,0,3,False,False,False,learnmachinelearning,1493669640,True,"I have taken some ML classes online and in university and i think finding great explanations online is possible, but not easy. So in an effort to make this process easy I am compiling resources in basic undergraduate concepts like Decision trees and SVM for now. I would like to get user ratings so that the community will know which resources are best.

For the list of some decision tree resources I have found: https://kenrose.net/channel/2/search?query=decision+tree&category=27

But i am trying to get more user ratings so if you have used these resources to learn about decision trees, then please rate them here https://kenrose.net/comparator/51/52

Also i'm trying to get some user ratings on SVM explanations so i created this page as a basic starting point for getting user ratings on two SVM resources i have used: https://kenrose.net/comparator/137/132

Also if you have any feedback in general, let me know"
How to use Magenta and Tensorflow to generate music in a free Google Cloud instance,0,2,False,False,False,learnmachinelearning,1493671810,False, 
Layman tutorials in data science with intuitive visuals and no math (new book),3,5,False,False,False,learnmachinelearning,1493697856,False, 
Need help with the gradient for a neural net (autoencoder)?,1,3,False,False,False,learnmachinelearning,1493704948,True,"I seem to have encountered an issue with calculating the gradient for each example in the mnist dataset. I'm trying to produce a simple autoencoder but my gradients are the same for every column of the first weight and row of the second weight. The output is just a blob of all the gradient of the training examples. Not sure where I went wrong with the gradient...

Some code:

    def sigmoid(x):
        return 1/(1+np.exp(-x))

    class input_layer():
        def __init__(self):
            self.output = 0 

    class hidden_layer():
        def __init__(self, input_layer, weights, activation, lambda_value=0):
            self.prev = input_layer
            self.next = None
            self.weights = weights
            self.bias = np.ones([1, self.weights.shape[1]])
            self.z = 0
            self.output = 0
            self.dEdz = 0
            self.dEdw = 0
            self.dEdb = 0
            self.Lambda = lambda_value

        def forward(self, w, x): #x: 100x784, w:784x128
            self.z = np.dot(x, w) + self.bias
            self.output = activation(self.z)

        def backward(self):
            self.dEdb = sigmoid_prime(self.z)
            self.dEdz = np.dot(self.next.dEdz, self.next.weights.T)*sigmoid_prime(self.z)
            self.dEdw = np.outer(self.prev.output.T, self.dEdz) + self.Lambda*(self.weights)

        def predict(self, x):
            return activation(np.dot(x, self.weights) + self.bias)

    class output_layer():
        def __init__(self, hidden_layer, weights, activation, lambda_value=0):
            self.prev = hidden_layer
            self.prev.next = self
            self.weights = weights
            self.bias = np.ones([1, self.weights.shape[1]])
            self.z = 0
            self.output = 0
            self.error = 0
            self.dEdz = 0
            self.dEdw = 0
            self.dEdb = 0
            self.Lambda = lambda_value

        def forward(self, w, x): #x: 100x128, w: 128x784
            self.z = np.dot(x, w) + self.bias
            self.output = self.z #activation(self.z)

        def backward(self):
            self.error = self.prev.prev.output - self.output
            self.dEdz = -self.error #np.multiply(-self.error, sigmoid_prime(self.output))
            self.dEdw = np.outer(self.prev.output.T, self.dEdz) + self.Lambda*(self.weights)
            self.dEdb = -self.error

        def predict(self, x):
            return np.dot(x, self.weights) + self.bias #activation(np.dot(x, self.weights))

        def stats(self):
            return (1/2)*(np.dot(self.error, self.error.T)) + (self.Lambda/2)*(np.sum(np.sum(self.weights))**2 + np.sum(np.sum(self.prev.weights))**2)

    def sigmoid_prime(z):
        return np.exp(-z)/((1 + np.exp(-z))**2)

    def forward_prop(layers, W):
        i = 0
        for l in layers:
            l.forward(W[i], l.prev.output) #
            i += 1

    def backward_prop(layers, W):
        n = len(layers) - 1
        while n >= 0:
            layers[n].backward()
            n -= 1


    def gd(iterations, layers, input_layer, W, dataset, alpha=0.05):
        for i in range(iterations):

            # Record total error
            error = 0

            # Forward and backward pass for each example
            for k in range(dataset.shape[0]):
                input_layer.output = dataset[k].reshape([1, 784])
                forward_prop(layers, W)
                backward_prop(layers, W)

                # Record error
                error += layers[-1].stats()

                # Update weights for this iteration 
                j = len(W) - 1
                while j >= 0:

                    #Update weights
                    W[j] = W[j] - alpha*layers[j].dEdw
                    layers[j].weights = W[j]

                    #Update biases
                    layers[j].bias = layers[j].bias - alpha*layers[j].dEdb
                    j -= 1
            if i % 10 == 0:
                print(""iteration {}: Error {}"".format(i, error))

    activation = lambda x: 1/(1+np.exp(-x))

    W_1 = 0.01*np.random.randn(784, 64)
    W_2 = 0.01*np.random.randn(64, 784)

    l1 = input_layer()
    l2 = hidden_layer(l1, W_1, activation, lambda_value=100)
    l3 = output_layer(l2, W_2, activation, lambda_value=100)
    layers = [l2, l3]
    W = [W_1, W_2]

images of output, weights and gradient:

http://imgur.com/a/v7o1m"
Keras KL Divergence as loss function gets negative.,3,3,False,False,False,learnmachinelearning,1493726194,True,"Hi r/learnmachinelearning! Do you know why this happens? My prediction labels are bit vectors (one bit per class, usually with all classes to 0 except one of them but there also could be the case where more than one class is set to 1), and the last layer in my model is a Sigmoid of N_CLASSES units. My loss function gets to 0 and the accuracy doesn't improve. Neither the validation loss does. Is that normal? How could I solve this?
I hope this information is enough. Thank you in advanced!"
"If You Were Attempting to Solve This Problem, What Would You Do?",1,0,False,False,False,learnmachinelearning,1493730087,True,"General Problem: Estimate the traffic of a website for the past x, time period (year, month, week, etc.), with a high degree of accuracy compared to actual data for that site.

My understanding of ML is superficial so bear with me. I have a bird's eye view of the general field, but nothing complete enough to point myself in a direction appropriate to solving this problem. 

What I'm looking for is some pointers from those of you with more experience that'll guide me into some optimal solution spaces.

Questions and Thoughts (please point out anything illogical or ignorant):

1. My understanding of supervised learning is that is a subset of ML where the output and inputs (features?) are given and the task is to determine an appropriate algorithm to explain the relationship. From this, I'm thinking that this might be the most optimal way to go as I'll have 'training' data in the form of factual statistics.

Inputs are a bit trickier for this as I'll know some and be totally unaware of others. Is it possible to give give a general solution space as the input where the program can determine the most critical features? 

Or do all features have to be defined up front?

2. How big of a data-set are we looking at for achieving meaningful results? Data-set as defined by websites with factual traffic statistics

Looking forward to hearing from some of you guys


"
Predicting a single value from multivariate time series?,2,3,False,False,False,learnmachinelearning,1493735515,True,"I'm looking for advice on which kind of analysis to apply to this data, since I've not been able to find similar cases in the literature. 

My data fits the standard supervised learning setup; given a bunch of (X,Y) pairs, learn f(X) ~= Y. Except each X is a multivariate timeseries that spans several hundred timesteps (days of the year), and in a deployed scenario the model should give daily predictions given the state of multivariate timeseries and its history. 
 
Is a Kalman filter suitable for this type of thing? "
Adding new user input into LightFM dataset,0,1,False,False,False,learnmachinelearning,1493743538,True,"Hello,

I'm using the lyst lightFM library for my model. 

They use a method to fetch the dataset. I'm wondering how I can use this dataset, but add user input, and retrain the model around the user input (User rates a few movies)

So then I can output some movie recommendations for them.

Sourcecode is basically this: 

http://lyst.github.io/lightfm/docs/quickstart.html"
"[Project] Are there any sources for using DCGANs for creating video i.e movies, gifs? What is needed to support a project like this?",0,1,False,False,False,learnmachinelearning,1493746651,True,"So from what I gather, this requires a massive training set, and likely GPU processing power.  
Are there any training sets that I might be able to use on a laptop?   Also what are some good notebooks/papers that go over this, or hell, even tutorials would be nice."
Understanding Tensorflow structure,2,5,False,False,False,learnmachinelearning,1493752284,True,"In Tensorflow's github at https://github.com/tensorflow/tensorflow/ there are different folders for Python and other languages, such as C. I was wondering, does Tensorflow solely use python files for its computation or does it use C code to execute lower lever commands? 

I was planning to start contributing to the code, but I was curious to whether I have to deal with the C code also included in the github repository. "
trying to HelloWorld with simple math,14,1,False,False,False,learnmachinelearning,1493760019,True,"well, I know, abother one noob lay hands on NN (py + Keras to be clear).

I am knda trying to learn ML with a pet projects. I am person who not very good in learning by theory and better in practice. 

So I got a lot of questiuon and this are easiest of them:

I made a model

    model = k.models.Sequential()
    model.add(k.layers.Dense(1, input_dim=1, activation=""relu""))
    model.add(k.layers.Dropout(15))
    model.add(k.layers.Dense(1))
    model.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics = ['accuracy']) 

And I made a train set

    trainX = np.array([*set(np.random.randint(0, x) for x in range(1, 10000))], dtype=np.int)
    trainY = trainX * 42
    model.fit(trainX, trainY, epochs=500, batch_size=64)

* Its OK for numbers between 0 and 10000, but not good for nums out of range. 
* Same model completely not working for  **trainY = trainX * trainX**

Well, I guess ""why"" is a question. Actually I think I kinda have to give NN more factors and Im not using it in appropriate way. But Im not interested in cool stuff like image recognition or voice control, but  wanna understend how to detect and group sequences of numbers and so on. "
Very good overview of applied machine learning in trading.,1,8,False,False,False,learnmachinelearning,1493762678,False, 
A programmer's sightseeing tour: Machine Learning and Deep Neural Networks,0,1,False,False,False,learnmachinelearning,1493767298,False,[deleted]
Question: Clustering with Binary Data,0,1,False,False,False,learnmachinelearning,1493775733,True,"I have a data set with about 5000 entries of 19 binary variables that I would like to cluster in to 3-5 groups.  Some of the material I have read has said that algorithms like k-Means and Hierarchical Clustering should be avoided when working with binary data and I think I understand their explanations for why.  

However, I haven't been able to find many recommendations for what clustering methods would work best with this kind of data.  If anyone has ideas I would love to hear them."
Machine Learning – Hands On Python and R In Data Science,8,23,False,False,False,learnmachinelearning,1493795840,False, 
TWIL (This Week I Learned) - Share something new that you have learned this week!,1,1,False,False,False,learnmachinelearning,1493795923,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
Document Clustering Best Approaches,5,3,False,False,False,learnmachinelearning,1493800775,True,"Hello, I am currently working on document clustering project for my uni and I was wondering what are the best approaches to  clustering documents? 

As for *approaches* I am referring to algorithms, document representation ways, programming languages and frameworks/libraries. As for *best* I am talking about time and memory complexity, and efficiency.

My current approach is running K-means with tfidf representation, using python and scikit-learn.

My aim is to eventually cluster efficiently a document set of ~5mil English documents on an i5, 8 GB RAM machine running Linux. Which is probably doable with my current approach (haven't tried yet) but I am also looking for other options. 

Follow up question:  Is there a way to create a dendogram (hierarchical clustering) of my document set on my machine.... ever? And also save that dendogram on file?

I would really appreciate any tips and advice. Thank you"
"Every single Machine Learning course on the internet, ranked by your reviews",6,92,False,False,False,learnmachinelearning,1493857337,False, 
Is it possible to train your model on an external hard drive?,3,1,False,False,False,learnmachinelearning,1493863288,True,"I apologize in advance if this is trivial.

My Mac has 8G and a new project i'm working on is exceeding it's limitations. I was wondering if I could use my external to train my model?

"
CNN shorthand notation explanation,0,1,False,False,False,learnmachinelearning,1493869939,True,[removed]
Pre-trained NN for monochromatic images?,0,1,False,False,False,learnmachinelearning,1493882958,True,"Hi all,

Does anyone know of a pre-trained neural network (such as VGG16 trained on ImageNet) that was trained on monochromatic images? I want to try transfer learning and I don't think upsampling my greyscaled-data to RGB is a good idea..."
Breaking through with a new type of Machine Learning engine,6,1,False,False,False,learnmachinelearning,1493953472,True,"Hi Guys, we just open-sourced our project, the Ryskamp Learning Machine, and we wanted to share it with you in hopes of getting feedback and help those who might be interested in something new. This is not the traditional machine learning engine, we use logical algorithms as opposed to the traditional mathematical approach. Also, the engine doesn't need a gpu, yet it is still able to match the popular engines out there and still be accurate. These are all just words until proven, so I highly suggest you check out our code through [our Github Repository](https://github.com/useaible/ryskamplearningmachine).

You might be interested in seeing some actual benchmarks. You can do so by visiting our [Head to head site](http://dev.useaible.com/headtohead), which you can test the performance of our engine against Tensorflow and ENCOG. The code for the games are also available to view online through [Github](https://github.com/useaible/Useaible-machine-learning-challenge).

You can read about our other capabilities and what the [RLM 7 breakthroughs](http://useaible.com/7-machine-learning-breakthroughs/) can do for those who are in the machine learning field. Our goal is to be able to break the barriers and separation of the machine learning community with ease of use and performance.

I appreciate you guys taking the time to read this. Your feedback, negative or positive, is very much welcome. We're all just trying to make the world a better place. Cheers!

TLDR: We open-sourced our new Machine Learning Engine, the Ryskamp Learning Machine!"
Help what algorithm fits this scenario?,5,2,False,False,False,learnmachinelearning,1493956928,True,"Hi I am trying to fit a prediction model into a data that always follow a trend (y decreases as x increase) but not direct y = ax + b relationship. For example 
9,8,7,6.5,5,4,4.3, 4, 3.5 (should predict 3.0 to 3.2 for next one)
another example
5, 4.5,4,3.8,3.6,3.5 ( should predict 3.0 to 3.4ish for next one)

... It is pretty obvious and a kid should be able to predict the next number with pretty good accuracy if the graph is plotted. These data are more like second degree polynomial like some what converge or diverge as x increases so polynomial fit with 1 degree does not work. However when I try polynomial fit with 2 degree it is good in some cases while other times it tend to overfit and create a graph like a U shape. Like I said before, the data tend to be one direction trend and U shape is not a one direction trend. Any idea what algorithm I should use to predict? The number of data points given is relatively small like 10 - 20 data points and that is all you have to train, just one sample.
Edit: yes univariate function. just x.
ANY HELP IS GREATLY APPRECIATED"
"Multilayer perceptron with a tuned tanh activation function does not converge with backprop. Standard logistic function working successfully, only the gradient update term is changed (derivation seems ok). Any issues/ideas why this happens? (xpost neuralnetworks)",3,1,False,False,False,learnmachinelearning,1493971630,False, 
Beginner Friendly Applications for a Deep Neural Net?,7,5,False,False,False,learnmachinelearning,1493971963,True,"I built a neural network with back propagation. So far the only thing I have tested it with is the stereotypical binary calculator tutorial, but I am looking for any interesting applications that I could feasibly use this for. Any suggestions, papers, videos, etc welcome!"
"From 0 to 1: Machine Learning, NLP & Python-Cut to the Chase",0,1,False,False,False,learnmachinelearning,1493978325,False, 
Newbie question: Do startups develop their own ML algorithms or they use existing one's?,11,11,False,False,False,learnmachinelearning,1493981728,True,"Hello everyone, 
I'm new to Reddit and UX is not so compelling. So kindly forgive for violation of rules, if I did any. 

I'm learning ML since a day. I came across a question which is so practical for anyone like me who entered ML. 

My question is : Do startups or any other tech companies create their own learning algorithms or do they use existing algorithms for the needs they have? If they use existing, how can we identify what algorithm to use and how to identify algorithm based on our problem? 

Please guide me on this. 

Thanks. "
Quick question about Andrew Ng's course on Coursera,5,6,False,False,False,learnmachinelearning,1493984585,True,"I am planning to take Andrew Ng's course soon, but I don't quite get the way Coursera works, and some things don't seem to be explained on the website. The [course website](https://www.coursera.org/learn/machine-learning) says that the course has just started on May 1. Can I take it later, e.g. in the summer? Do I have to follow some fixed schedule in order to receive the certificate?

Thanks for any explanations."
What are your top 5 ML algorithms and why?,8,10,False,False,False,learnmachinelearning,1493984656,True,"I want to focus my time on learning how to use a few ML algorithms that are highly accurate. But, I don't know where to start. "
Research advice,0,1,False,False,False,learnmachinelearning,1494000511,True,"Hi
I am a second year computer engineering student who got an opportunity to do a machine learning research internship at a prestigious university. I am still very new to machine learning and don't know how I should go about it. I'm doing the Andrew Ng course currently. Can someone please tell me how I should go about it. I have two months to prepare. Thanks!"
Datmo CLI to help track work in machine learning,0,1,False,False,False,learnmachinelearning,1494016771,False,[deleted]
Please suggest a brief math mooc or vid series to help with the Ng Stanford Cousera course?,13,5,False,False,False,learnmachinelearning,1494024316,True,"I sort of understand theta, alpha, J, h.....but my understanding is very theoretical, not intuitive.  He jumps into it without warning, and only continues to reference it/depend on it more and more.

I'd like to stop, and spend some time focusing on the specific language (theta, alpha, derivitive, J, h, etc) of standard ML math.

Is anyone able to recommend a primer mooc or vid series that covers this?"
"Weekly Scrum Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",1,3,False,False,False,learnmachinelearning,1494054438,True,"Let's have a scrum meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
Understanding Gradient Descent,8,6,False,False,False,learnmachinelearning,1494064426,True,"I guess I'll start by saying that I'm a former Biochemistry now Computer Science student and I am quickly converging down the path of data science. Never has a subject involved so many concepts that I find interesting, I'm really excited in learning ML. 

To lean into Neural Networks I started watching [Siraj Raval's videos](https://https://www.youtube.com/channel/UCWN3xxRkmTPmbKwht9FuE5A) on youtube, and examining his code, and then coding up my own similar solutions. I've been particularly following his Intro to Machine Learning Udacity series. I'll admit I haven't gotten very far in it, but I have a question about the code he uses that I hope users here wouldn't mind answering for me here. It's more of a mathematical question than a language question, and is why I ask here instead of stackoverflow. 

Here is the code: 

    def step_gradient(b_current, m_current, points, learningRate):
    b_gradient = 0
    m_gradient = 0
    N = float(len(points))
    for i in range(0, len(points)):
        x = points[i, 0]
        y = points[i, 1]
        b_gradient += -(2/N) * (y - ((m_current * x) + b_current))
        m_gradient += -(2/N) * x * (y - ((m_current * x) + b_current))
    **new_b = b_current - (learningRate * b_gradient)**
    **new_m = m_current - (learningRate * m_gradient)**
    return [new_b, new_m]

I've just recently learned least squares linear regression, and how it is basically the operation of producing a linear function that has the lowest possible error wrt to a given dataset.  You achieve this lowest error line by taking the partial derivative of your total error function wrt to the intercept and the slope of this function. Setting the partials equal to zero will yield the intercept and slope values that optimally minimize your total error. 

With Gradient Descent however, you don't set the partial to zero, you just evaluate it, and in the case of the above code in order to converge to a minimum error you iteratively subtract the evaluated partial from the slope/intercept value you are evaluating at... i.e. 

        new_b = b_current - (learningRate * b_gradient)
        new_m = m_current - (learningRate * m_gradient)

Finally now, here is my question. Why would taking the partial from the current value guarantee/suggest convergence to minimum? I get how in the case of least squares regression we're able to get the error minimized values for the intercept and slope by setting the partials to zero (that makes total sense to me). I don't get how subtracting the partial from a current value brings us closer to an error minimized value. So there is my question: 

*How does subtracting a partial from a current value bring us closer to an error minimized value?*

-----
Forgive me for being long winded. I perhaps could have, and will revise what I've said for clarity and concision. It's late where I am, but this has kinda been bugging me."
Anyone know what kind of hardware setup they used for the DeepMind A3C paper?,4,7,False,False,False,learnmachinelearning,1494106943,True,"I'm currently working on an implementation of A3C and noticed the paper claimed that they could ""solve"" pong with 16 threads in 40 million frames, taking a total of about 4 hours (page 8 of their paper)

My current implementation is getting about 1.2 million frames per hour on a K80, so I'm wondering if anyone knows whether they ever stated what their hardware setup is? I'm curious if my implementation is inefficient or they're just throwing it at more GPU's

Thanks all"
Question about 1D Generative Adversarial Networks - Can't Achieve Convergence,0,1,False,False,False,learnmachinelearning,1494109611,True,[deleted]
RI Seminar: Yann LeCun : The Next Frontier in AI: Unsupervised Learning,0,2,False,False,False,learnmachinelearning,1494116267,False, 
Andrew Ng's Machine Learning videos,1,4,False,False,False,learnmachinelearning,1494121705,True,I'm working through Andrew Ng's Coursera course on Machine Learning. I saw another thread that mentioned he also had videos of lectures on Youtube. Does anyone know if the youtube videos are mostly just updated versions of the Coursera videos? Or would there be a benefit to watching the videos despite having nearly completed the Coursera course?
An article I wrote on the vanishing gradient problem!,0,5,False,False,False,learnmachinelearning,1494124580,False, 
Does anyone know any projects on Open Health Care that I can contribute to or fork on GitHub??,0,3,False,False,False,learnmachinelearning,1494140405,True,I am beginner but would like to learn by contributing.
"Question: Study Plan, Prioritisation. How much Data Structures and Algos needed/ are useful ?",3,2,False,False,False,learnmachinelearning,1494150936,True,"I am really interested in Machine Learning and Artificial Intelligence and am motivated to learn it.
I researched on how to start and then decided to take the Stanford, Andrew Ng Machine Learning Course and learn/ revisit  the maths needed in the course simultaneously

Should I learn some more about Data Structures and Algorithms first? I could take the 4 course Stanford Algorithms specialization on Coursera. (I already know about things from the first course and some basic knowledge of graphs and trees )
pros: useful for traditional SE interviews, interesting
cons: Limited time available

I want to know how much of Data Structures and Algorithms knowledge is needed and useful for Machine Learning? Should I take the algo specialization or directly start with ML?

Background: Engineering grad(Non-CS), Intro CS courses at college, self-taught CS fundamentals( Databases, Basic Algorithms, Web Technologies), some training at a big Tech company - first job 9 months, now working in a demanding job as a Software Engineer at a startup - 2 years

TL;DR: Self-taught Software Engineer. Interested in ML and AI. Confused about learning data structures and algorithms first or directly jumping into learning ML"
How to prepare a custom dataset?,1,2,False,False,False,learnmachinelearning,1494153517,True,"I have a set of images (~6k) and I intend to train some deep learning models over that data.
I observed that the common datasets (like MNIST, CIFAR) are in octet-stream format. So how do I format my datatset into octet-stream? What preprocessing should I do before training? 
I have already cropped the images to a fixed resolution.
Thanks!"
007. Machine learning best practices we've learned from hundreds of competitions - Ben Hamner,0,18,False,False,False,learnmachinelearning,1494158963,False, 
ML competitions 4fun open teams: is there such a thing?,3,5,False,False,False,learnmachinelearning,1494174145,True,"Hello guys,

I was wondering if there are communities or subreddits where it's possible to find or form teams to compete on Kaggle or join other competitions.

I often try to do some competition for fun, to improve my skills, but having no real-world experience with data science problems (I'm a ML Engineer/Data Engineer), I quit after facing issues with the steps where I'm weaker (preprocessing and model improvents through iteration, most of the time) and the parts where I'm stronger (code quality, robustness, automation, productization) are never put to use.

Then I thought that joining a team would be a great idea to bring my skills to the group and at the same time, share the burden of bootstrapping a solution and iterate over it. But I have no idea on where to find such a team. I know many people with a skillset comparable to my own, but almost nobody that has experience on practical data science. 

I'm also thinking about starting a meetup for this purpose but I would like to know if there are alternatives."
U-Net with CONV GRU/LSTM?,4,2,False,False,False,learnmachinelearning,1494196221,True,"I need to process 3D Medical Image, which is basically sequences of 2d images. U-Net achieve good result using 2D data only without any further context. But I would like to achieve better results using RNN's. So do you think is possible to switch the conv layers with somekind of convulotional recurrent NN's?"
Two questions: Where to start for the knowledgeable beginner? Is there any controls based machine learning?,2,4,False,False,False,learnmachinelearning,1494229947,True,"Hello all. Just some background, I have an EE BS and MS in Fields  and a BS in Math. I currently oversee Optical Fiber technicians. While I love my job, its not forcing me to learn anything. I rarely use my degree. After being rejected for a handful of places, I got feedback saying they want a fields engineer who can program. One of the things that piqued my interest and my old thesis adviser worked on was Machine Learning, specifically in regards to optical sensors. 

Is there a simple guide to learning the basics of ML? I found a great course but its too costly, goes over a ton of stuff I already know and takes up too much time. 

Are their intermediate courses or books on integrating ML, filter design, and Controls theory? From a beginner understanding, there might be some crossover with stuff like filters (both standard RLC and microstrip) and different feedback loops. I might be completely off. But Controls theory is a huge part of EE and it would be nice to incorporate some of ML into it. 

Sorry if this is already answered. I didn't see anything like it in the search. Thanks for your answers. "
Learn machine learning from scratch,13,17,False,False,False,learnmachinelearning,1494246853,True,I want to learn machine learning from scratch.. can anybody tell me from where should i start ..and any proir knowledge needed for the same .
Problems installing caffe,0,1,False,False,False,learnmachinelearning,1494258551,True,"I have a linking problem when i try to compile caffe, when it tries to build the .so library. The .o files are generated well.
The error is the following:

LD -o .build_release/lib/libcaffe.so.1.0.0
/usr/bin/ld: .build_release/cuda/src/caffe/layers/cudnn_softmax_layer.o: relocation r_x86_64_32 against .bss' cannot be used when making a shared object; recompile with -fPIC
.build_release/cuda/src/caffe/layers/cudnn_softmax_layer.o: error adding symbols: bad value

the error indicates someting in the cudnn_softmax_layer.o file.
I already tried with the -fPIC option and the error is the same.

anyone know how can i resolve this? thank you"
How do I build my own dataset for machine learning?,6,2,False,False,False,learnmachinelearning,1494261717,True,"I am completely new to machine learning. I've read a few online resources on the subject, but I don't quite understand how the data is prepared for the ML algorithms. 

[Take CIFAR10 image set](https://www.cs.toronto.edu/~kriz/cifar.html) that's used in many ML tutorials, for example:

- Already nicely cut into 32x32 pixels, with subject in the center of the image
- Already classified into 10 generic classes, ie: 'dog', 'bird'

But if I wanted to do something different and more specific, like classify different bird breeds, how would I generate the training data? With CIFAR10, I can build a model which tells me if the image is a bird, but not the kind of bird. 

---

**Let us assume we don't have any nicely labeled images of bird breeds**, would the process of building training data be like this:

- Somehow access a huge image resource, manually center subject and cut out into 32x32 pixels. 
- Label each subject with the bird breed

And do this until I have at least 10k images under each bird breed class? Then I can feed this to an ML algorithm, have it crunch data, and then fix up any misclassifications? Ie, do *supervised machine learning*.

But that is extremely tedious, and not possible to do at an individual level unless I have massive amounts of free time. There are currently 9,956 species of birds. That means to build training data, I have to manually label 9,956*10,000 images... impossible!

Would *Unsupervised Machine Learning* be a workaround? Basically:

- Somehow access a huge image resource
- Run ML algorithms to determine if an image contains a bird (since we already have bird classification models from CIFAR10)
- If bird, build a bounding box of 32x32 on the subject
- Run unsupervised machine learning algorithms
- ???
- Somehow the unsupervised machine learning algorithms find patterns and classifies each bird into its own category, from which I can then manually label the category to be the breed? ie, the algorithm finds all birds with color patterns resembling Scarlet Macaws, and puts it into a category. Then I go in and manually label that category as Scarlet Macaws, and now I have a classification for Scarlet Macaws specifically.

Is that right? I would still have to manually label things ultimately, but the latter seems like less work than the former. Please explain ELI5, I'm a complete noob."
In Search Of The Holy Posterior,0,1,False,False,False,learnmachinelearning,1494265115,False, 
"Watch What Happens When an Algorithm Tries to Predict the Next Frame 100,000 Times in a Row",0,7,False,False,False,learnmachinelearning,1494271247,False, 
"What has Kaggle learned from 2 million machine learning models? Feb 04, 2016",1,2,False,False,False,learnmachinelearning,1494277960,False, 
What’s New — pandas 0.21.0.dev+10.g80abd97.dirty documentation,0,0,False,False,False,learnmachinelearning,1494281382,False, 
"PyTorch vs Tensorflow, which one do you use and why?",3,7,False,False,False,learnmachinelearning,1494283034,True,Just curious what others thoughts and opinions on these two different frameworks are
The World’s Most Accurate Parser Goes Open Source,0,21,False,False,False,learnmachinelearning,1494294683,False,[deleted]
Discrete Mathematics for Beginners,0,1,False,False,False,learnmachinelearning,1494301319,False, 
Free eBook: Machine Learning with R - Second Edition (PDF/ePub/Mobi),2,7,False,False,False,learnmachinelearning,1494315628,False, 
Suggested Setup?,4,1,False,False,False,learnmachinelearning,1494325876,True,"Does anybody of you have a ""Machine learning setup"" you can suggest?
Stuff like what OS should I use. 

(I'm programming in python .... That might be important to know)
I hope you guys understand what I meant. 

Thanks for every answer. 
Have a nice one :)"
How To Create A Neural Network in JavaScript - Scrimba screencast,0,4,False,False,False,learnmachinelearning,1494331411,False, 
Learn Automated Text Classification using machine learning,0,1,False,False,False,learnmachinelearning,1494333842,False, 
Stuck on tutorial.. cannot load dataset?,1,1,False,False,False,learnmachinelearning,1494361045,True,"I am following [this tutorial](https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721) on using ML for identifying birds.

I want to use CIFAR-100 instead of CIFAR-10 dataset. When I unpack the tar file, I see these files:

    file.txt~   meta    test    train

He has this line which loads his dataset:

    # Load the data set
    X, Y, X_test, Y_test = pickle.load(open(""full_dataset.pkl"", ""rb""))

But I **don't see** *full_dataset.pkl*. Instead, I tried:

    X, Y, X_test, Y_test = pickle.load(open(""cifar-100-python/train"", ""rb""))

But this errors with:

    ValueError: too many values to unpack

Can someone help me get set up correctly?"
Introduction to reinforcement learning,0,7,False,False,False,learnmachinelearning,1494366529,False, 
"""Neural Networks for Noobs"" critique/feeback",1,6,False,False,False,learnmachinelearning,1494366688,False, 
Fast gradient method,0,1,False,False,False,learnmachinelearning,1494377410,True,"Hi, 

Can someone explain the fast gradient descent method to me? I am confused over it. Thanks "
matlab tutorial collection in english part 2.,0,0,False,False,False,learnmachinelearning,1494379570,False, 
TWIL (This Week I Learned) - Share something new that you have learned this week!,4,3,False,False,False,learnmachinelearning,1494400151,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
Cluster validation in unsupervised machine learning using R,0,1,False,False,False,learnmachinelearning,1494403066,False, 
Sound Recognition with Neural Network,1,3,False,False,False,learnmachinelearning,1494416410,True,"My goal is to create a tool that can differentiate and assign a sound to an object. For example I want to input a sound file of a dog barking and it should detect that it does indeed sound like a dog.

My question is: What is the best approach to do that? How should I convert it audio data to make it suitable for a Neual Network to learn? Would appreciate any help."
Top 15 Python Libraries for Data Science in 2017,1,48,False,False,False,learnmachinelearning,1494427086,False, 
L2 Heatmap Regression,3,5,False,False,False,learnmachinelearning,1494430779,True,"I've seen this approach in a number of papers - mostly related to localizing keypoints in images like human body parts, object vertices etc... If I'm understanding it correctly, one makes a network output K feature maps (with e.g. a 1x1xK convolution operation) and then supervises the L2 distance between the outputted maps and ground truth maps. In other words, it's much like the good old fashioned [FCNs for Semantic Segmentation](https://arxiv.org/abs/1411.4038) but with L2 loss instead of crossentropy. Also, if I'm not much mistaken, the ground truth targets are greyscale images with Gaussian blobs pasted on.

I'm having a hard time seeing what the advantages of this approach are, versus the old-fashioned crossentropy loss. And please correct me if I'm wrong about any of the above.

[Flowing ConvNets for Human Pose Estimation in Videos](https://arxiv.org/abs/1506.02897)

[Joint Training of a Convolutional Network and a Graphical Model for Human Pose Estimation](https://arxiv.org/abs/1406.2984)

[Single Image 3D Interpreter Network](https://arxiv.org/abs/1604.08685)

[RoomNet: End-to-End Room Layout Estimation](https://arxiv.org/abs/1703.06241)

[Human pose estimation via Convolutional Part Heatmap Regression](https://arxiv.org/abs/1609.01743)"
Comparing dense compute platforms for AI,0,2,False,False,False,learnmachinelearning,1494430794,False, 
Easy way to get started with a simple image classification problem?,2,2,False,False,False,learnmachinelearning,1494441145,True,"Does anyone have suggestions for a beginner-friendly way to do a simple (custom) image classification? Basically the problem I have is, I have a large number of microscope images, and I want to sort them into 2-3 categories (round and splotchy, round and not splotchy, other.)

I do not have any machine learning background, and have ~1 year experience with Python.

Please let me know if there's any other information that would help clarify."
Multi-class classification with growing number of classes - question,2,4,False,False,False,learnmachinelearning,1494483988,True,"Hey,
I have a multi-class classification problem where the algorithm should detect (and later on classify) new classes.

An example for such a task could be classifying if an image shows a dog or a cat. Furthermore, the model should be able to recognize that a goose doesn't fit into one of these two categories, thus create a new class.

**Specific Questions:**

* How can the model detect new classes?
    - Some unsupervised clustering algorithm
    - When all classes are predicted by a value beyond a certain threshold?

* Is there a (proven) model, which can handle a growing number of classes to classify - without expensive retraining of all the other classes?
    - one vs all?
    - one-class?
    - something completely different?

I greatly appreciate every form of help and experiences you had with such a problem. Thank you in advance.

Here are two links where similar questions were asked, but (at least for me) not fully answered.

[Stackexchange](https://stats.stackexchange.com/questions/244073/streaming-multi-class-classification-with-growing-number-of-classes)

[Stackoverflow](http://stackoverflow.com/questions/34204700/multiclass-classification-growing-number-of-classes)
"
[D] Metrics representation in papers,0,1,False,False,False,learnmachinelearning,1494508497,True,"I wondered what exactly meant a ""training step"" in most of the plots representing a net's metrics (accuracy, loss...). For example see Fig.2 in [this paper](https://openreview.net/forum?id=Sy8gdB9xx&noteId=Sy8gdB9xx). [Click just for the figure](http://i.imgur.com/HwXIVd1.png)

Does ""iteration"" here simply mean training on a batch? If so, why don't these kind of plots also show epochs, or at least indicate the number of iterations per epoch?

I'm having trouble connecting between my plots and this one first instance, I always thought it was best to go through your set multiple times (hence the term ""epoch"") to train well, but this representation doesn't put in perspective (maybe it's obvious and I'm missing something?)"
What's the first online course you completed after finishing Andrew Ng's Machine Learning course?,4,6,False,False,False,learnmachinelearning,1494511107,True, 
Example Sentiment Analysis Project With Deep Learning models!,0,11,False,False,False,learnmachinelearning,1494520740,False, 
/r/learnmachinelearning featured in self-learning program on the topic!,0,1,False,False,False,learnmachinelearning,1494529352,True,"Hey everyone—this sub has a ton of useful information for people interested in machine learning. Help us strengthen the content on this topic at [Alcamy](https://alcamy.org/library/ml). Through Alcamy, users can create their own topics on any topic and aggregate existing resources online (think anything from informative YouTube videos, blog posts, news articles, and scientific journals, etc.) to help other learners gain some insight on and contribute to the topic at hand. We only launched our beta earlier this month and made it to the #1 spot on ProductHunt. Since then, members have started curating their own topics! While I have an elementary level understanding on the topic of machine learning, I was hoping you guys could take a look at the site and maybe even contribute to the topic library! If you have any questions about how the topic works or really, anything else pertaining to the platform, please don't hesitate to ask!"
Machine Learning School Project,3,0,False,False,False,learnmachinelearning,1494531010,True,"Hello /r/LearnMachineLearning,

At my school, every student has to do a project of their choice as a part of finishing school. Me and my project-partner have decided to do something with Machine Learning, but we are both not experienced with the subject. We both have a little bit of experience with Python but that's it. We have to put in a minimum amount of 80 hours into the project (including documentation). We are looking to have a project that would be easy enough to get into from a beginner level, but hard enough to actually reach those 80 hours (or more).
At first, we wanted to remake MarI/O (https://youtu.be/qv6UVOQ0F44), but we figured it would be too hard to accomplish without spending too much time on it.

Do you have any ideas what kind of program we could make?

Thanks in Advance!"
Best resources to ramp up quickly,8,1,False,False,False,learnmachinelearning,1494539385,True,"So I just accepted an internship for the summer that will have me doing (among other things) some machine learning. I have casually explored the topic a bit (I know classification vs. regression, but not much beyond that) but am far from knowledgeable on the topic. 

I want to get up to speed as quickly as I can on machine learning. What are the best resources out there, and is there an order I should be going in? I am most versed in Python, so Python resources would be ideal (I have some familiarity with Pandas and Matplotlib as well).

EDIT: to clarify, I've looked at the top posts. I'm looking for a recommendation for a Python-based course to get me up and running as quickly as possible."
Is it possible to save Tensorboard's t-SNE data after visualization?,0,2,False,False,False,learnmachinelearning,1494543125,True,"I would like to use the 3D points that Tensorboard generated with t-SNE for some processing, but don't know how to, is it even possible?  
"
Monthly ELI5 (Explain Like I am Five) Thread,0,0,False,False,False,learnmachinelearning,1494544633,True,"Top comments need to be in the format of: `ELI5 $CONCEPT_NAME` and the replies should provide a clear explanation in a layman's term.
Here are the relevant rules from /r/explainlikeimfive breaking down the meaning of ""ELI5"":

- E is for Explain - merely answering a question is not enough.

- LI5 means friendly, simplified and layman-accessible explanations - not responses aimed at literal five-year-olds.
"
Advanced Moocs?,3,9,False,False,False,learnmachinelearning,1494564308,True,"I recently finished coursera's course on data science, the one by Roger Peng. I tried competing at kaggle but was only able to get  around a little over the 50th percentile. In order to get a higher score I think I would need a learn more machine learning algorithms and ensambling. Which mooc teaches this?"
Weekly Show-off!,9,1,False,False,False,learnmachinelearning,1494572942,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
Need some advice on Udemy courses,1,3,False,False,False,learnmachinelearning,1494588976,True,"My goal is to apply machine learning to algorithmic trading and to eventually become a data scientist. Which classes would you guys recommend? If you had all three, in what order would you take them?

https://www.udemy.com/machinelearning

https://www.udemy.com/python-for-data-science-and-machine-learning-bootcamp

https://www.udemy.com/learning-python-for-data-analysis-and-visualization"
I need help... My life future will be decided within 10 days... Story in the post,19,7,False,False,False,learnmachinelearning,1494589273,True,"Hey guys,

I'll give a context about my situation, you can ignore it if you want.

I'm 20 and I am currently studying Music. I came from a scientific-focused high school so I don't have trouble with maths or physics. I chose Music because that's a passion of mine that I always loved, but recently, I realized that it wasn't worth it anymore. The risk of unemployement was too high. Even my professor told me I'm wasting my potential here, so he told me of another school that focuses both on Music and Science! He even wrote a letter of recommendation to increase my chances of being admitted, I don't know if he has a good reputation but first link on Google shows me a reputable lab in the field of study.

In February, I started following courses online on programming, I also followed a few Machine Learning course ( the one with Andrew NG ) but I haven't finished yet. However in May and April I had no time to follow these courses anymore, I had to focus on my exams, in case I can't make it to that other school.

Today, my exam are finished, I have 10 days left until the deadline. I have to send my ""dossier"", which is grades, certifications etc... Not sure how we say it in English sorry... 

The pro of my ""dossier"" : majored in first semester, maybe not in second semester as I was less focused because I had to follow other classes. 2 letter of recommendation from 2 of my professor.

The cons of my ""dossier"" : below average grade in math and physic in highschool ( I was lazy... ) no certification that tells I'm a musician

**This is where I need you guys** : 

I got 10 days to make something, anything, that would make my ""dossier"" better than the other candidates. I'm thinking of a software in .exe preferably, but a python code file will do. I know the basics of Python and I have Octave and TensorFlow installed on my computer. What do you guys think? I could maybe create a AI application that could make background noises ( busy city, birds singing ) into a song with rhythm and such by comparing it with another song that already exist and match the frequencies at the same time? 

What I need to create is something simple enough that I can make ( and understand ) in 10 days, but complicated enough to impress the admission people.

And as title says I need help guys. I don't just want to copy/paste some guy's work, I need study material so I can understand what I did, so I can explain it further if I can get an interview with the admission people. Do you guys have any shortcut ( I mean like very specific course material ) to what I'm trying to make? As I said I only have 10 days so I can't go through a whole course... 

I really need your help guys... My life depends on it. I'll be forever grateful to you. 

"
Does anyone have tutorials on the meaning on weight and biases?,5,2,False,False,False,learnmachinelearning,1494603179,True,"I understand the use of weights and biases. I use tensorflow to capture the histograms of the weights and biases and I'm not sure what I'm supposed to be looking for. 

Also, how do I know if I am seeing a dead relu error? 

How do I know if neurons in my network are dead? "
How to solve this problem?,5,9,False,False,False,learnmachinelearning,1494622416,True,"The task is to automatically correct user-entered SKUs. Dataset is 2 columns and 2.5 million rows: user entered incorrect SKU(string sequence) and corrected SKU. Also a table of 0.5 million ground truth SKU's.

I am thinking about using GAN for this. Is it a good idea?

https://github.com/LantaoYu/SeqGAN

What's the best algorithm to use in this senario?

"
Please help! Deep Q-learning equation.,1,3,False,False,False,learnmachinelearning,1494634576,True,"Hello everyone. I have been researching the deep Q-Learning area when I came across this formula: γmaxa′Q(s′,a';θ). Can someone please explain what this is or provide an alternative algorithm for my newbie head to wrap around? Thanks in advance!"
"Weekly Scrum Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",4,4,False,False,False,learnmachinelearning,1494659232,True,"Let's have a scrum meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
Visualizing features in neural networks,2,4,False,False,False,learnmachinelearning,1494700292,True,"I'm learning about neural networks and I really like how you can track progress of a neural network applied to image recognition by visualizing the images representing the features that the neural network has generated at each layer.

If my data is not an image, but - say - a matrix with some data that doesn't really make sense to ""visualize"", is there a convenient way to see what's happening at each stage of the network, and how it's trying to solve the given task? Does anyone have more examples (beyond image recognition) where people have provided some form of information about the features in each layer of the network?

Thanks."
How to Predict If a Borrower Will Pay You Back,0,16,False,False,False,learnmachinelearning,1494708634,False, 
difference between skip connection and residual connection,3,7,False,False,False,learnmachinelearning,1494717554,True,"What is the difference between skip connection and residual connection? Do people use these two terms interchangeably?

Thanks."
Videos of Practical Deep Learning Part 2 ( Jeremy Howard ) are online now,5,23,False,False,False,learnmachinelearning,1494786409,True,"Part one was awesome , and I'm so exited about part 2 , I hope I can use my GTX 1050 TI to train models . 

https://youtu.be/NOkp3rEGeyE"
Images of varied sizes as input (Keras),0,2,False,False,False,learnmachinelearning,1494806543,True,"Hi everyone,

I been struggling to get my model to learn the orientation of cars, on the EPFL dataset. I've cropped the images according to the provided bounding boxes, and therefor they of course all have varied sizes.

Im basically just using the Resnet model from Keras with my own softmax layer at the end. 

My problem is to get the model to accept the training data. If i pass it as a list, i get an error that it has to be an array. But if i convert the list to an array, i just get an array of shape (2137,) where 2137 is my number of images. So when i pass that to the model.fit method, i get this error: 
ValueError: Error when checking input: expected input_1 to have 4 dimensions, but got array with shape (2137, 1)

Is there anyway i can make this 4 dimensional, but still have varied image sizes?

Any help is very appreciated!

Kindly,
Benjamin"
I have the ISL book but I want to use Python,0,1,False,False,False,learnmachinelearning,1494807552,True,"I know a bit of java and python and I'd like to do some statistical learning. I bought the ISL book but I want to use python, not R. Is the book still gonna be okay for me to use? If not, are there any workarounds or other free online books I can use for python?
Thanks in advance.



"
"New to ML, need advice on text classification",2,4,False,False,False,learnmachinelearning,1494812848,True,"I'm making a smart assistant for a website. I have implemented a basic naive bayesian text classification to get intent for user query. Now i'm interested in tensorflow and cbow after some readings. Can anyone point me to right direction, or direct implementation which i can play with?"
Need some advise regarding training a RNNLM,0,3,False,False,False,learnmachinelearning,1494819594,True,"Hello. I'm trying to create a model using the Ubuntu Dialogue Corpus as my starting point (https://arxiv.org/abs/1506.08909). I have another corpus that is much smaller, 20,000 training examples instead of 1,000,000. Will this be enough to train, or will I need to leverage other models/corpuses? I tried initializing the training with GloVe embeddings (https://nlp.stanford.edu/projects/glove/) but that only seemed to hurt the model. Also, does anyone know if the labels in that corpus (EOT= end of turn, EOU, end of utterance) are being used/processed at all by the network? I am not in this field and am still learning. Does anyone know of any similar papers/projects (rnn, LSTM, dual encoder, retrieval based ) ? Thanks﻿"
A simple example using Keras + TensorFlow.,0,16,False,False,False,learnmachinelearning,1494834821,False, 
Machine learning for videogame economies (question),0,1,False,False,False,learnmachinelearning,1494855551,True,"Hey guys,

A bit of background for anyone interested:
I'm a final year student at Imperial College, in London, and me and my supervisor are trying to apply some machine learning principles to in-game economies so as to be able to predict the prices of items based on their features and gain a monetary edge as one would in real world community marketplaces.

Recently when trying to apply all the standard machine learning algorithms using the Java Weka library (which seems a bit archaic but was recommended, feel free to suggest any other libraries down in the comments), I came across a problem analysing my data. My records always contain an array similar to this one:

    ""mods"": [
          {
            ""value2"": 0,
            ""value1"": 0,
            ""value3"": 0,
            ""name"": ""{0}% increased Evasion and Energy Shield"",
            ""value0"": 21,
            ""type"": ""EXPLICIT""
          },
          {
            ""value2"": 0,
            ""value1"": 0,
            ""value3"": 0,
            ""name"": ""+{0} to maximum Life"",
            ""value0"": 105,
            ""type"": ""EXPLICIT""
          },
          {
            ""value2"": 0,
            ""value1"": 0,
            ""value3"": 0,
            ""name"": ""+{0}% to all Elemental Resistances"",
            ""value0"": 13,
            ""type"": ""EXPLICIT""
          },
          {
            ""value2"": 0,
            ""value1"": 0,
            ""value3"": 0,
            ""name"": ""+{0}% to Fire Resistance"",
            ""value0"": 43,
            ""type"": ""EXPLICIT""
          },
          {
            ""value2"": 0,
            ""value1"": 0,
            ""value3"": 0,
            ""name"": ""+{0}% to Cold Resistance"",
            ""value0"": 42,
            ""type"": ""EXPLICIT""
          },
          {
            ""value2"": 0,
            ""value1"": 0,
            ""value3"": 0,
            ""name"": ""{0}% increased Stun and Block Recovery"",
            ""value0"": 8,
            ""type"": ""EXPLICIT""
          },
          {
            ""value2"": 0,
            ""value1"": 0,
            ""value3"": 0,
            ""name"": ""Reflects {0} Physical Damage to Melee Attackers"",
            ""value0"": 95,
            ""type"": ""IMPLICIT""
          }
      ],        

The array is of **variable length**, it has **no particular order**, all elements have the **same fields** and there is a maximum of **10** elements in the array.

This is the only part of my data points which I have no idea how to handle. If I create ten blank spaces for all of them using attributes such as mod0name, mod0type, then mod1name, mod1type, etc, the algorithms would deduce that their positions are not interchangeable - but they are.

I never concentrated on ML in my degree so I'm clueless as to conventions when it comes to this type of thing - I apologize if it's been answered many times already. Any help would be appreciated.

Paul
"
Unsupervised Learning Explained with GIFs,4,25,False,False,False,learnmachinelearning,1494859070,False, 
Learning Machine Learning: Too Early?,4,1,False,False,False,learnmachinelearning,1494873310,True,"Hello, I am an undergrad in CS & Math and I just want to know if you need a strong mathematical foundation before touching ML.
Now that the semester is over, I was planning to take Andrew Ng's class on ML on Coursera. So far, the highest Math classes that I've gotten to is Calculus 2 (Integral & Series) and Discrete Math 1(Probability & Proofs). Do you think I need to wait until I get into Linear Algebra, Multivariate Calculus, and Probability Theory before adventuring on to ML?"
Anuj Gupta | Building Continuous Learning Systems,0,3,False,False,False,learnmachinelearning,1494883195,False, 
New to ML - Encoding categorical features with a changing number of values?,0,1,False,False,False,learnmachinelearning,1494883733,True,"Hi all, I'm just starting to get my hands dirty with scikit learn and have come across a problem that makes me think I might be approaching this incorrectly. 

I'm trying to set up some anomaly detection (using OneClassSVM) based on a few categorical features - things like the names of senders and receivers of messages. I have a training set that I've used a LabelEncoder for to convert the strings into integers, and then a OneHotEncoder to convert the integers into binary arrays. 

The issue comes when I try to take testing data and encode it using the same LabelEncoder as before. Since my testing data has values in let's say the ""Recipient"" column that aren't present in the training data, the encoder doesn't know what to do with them. 

At first I considered trying to get a more complete training set, but in reality, if there's an unseen Recipient that shows up, I want to handle it gracefully and possibly flag it as an anomaly. 

Is there a way to leave ""headroom"" in my encoder to allow for future mappings? Am I approaching this the wrong way? 

Thanks for any advice."
100 hours of GPU instances for free without signing up using credit cards! It supports tensorflow and pytorch,2,22,False,False,False,learnmachinelearning,1494907968,False, 
"beginner here, do we care about the fact that correlation might not mean causation?",4,6,False,False,False,learnmachinelearning,1494931756,True,"lets say that i'm making a survey to determine a few factor that makes someone more eligible than other to become good player in overwatch ( or any other game ) in europe

and let's assume that we can detect a correlation between proficiency in english and rank: the better your english the better you are in overwatch

and let's say we pick one random guy who's pretty good in english, do we just say that he has high chance of being a pro ow player? or is it just correlation?

"
"Crawled the web for a dataset of shoes (16,000 images)",3,3,False,False,False,learnmachinelearning,1494954656,True,"Hey guys! 

I have a dataset of 16,000 shoe images. I want to use Deep Learning for this dataset (or a part of it) so that it clusters similarly looking images together. 

Can you please guide me. I'm so excited about Deep Learning, but am still newbie. 

Thanks :) "
does keras use gpu processing power?,22,1,False,False,False,learnmachinelearning,1494960037,True,"hello,

so my processor is i5 4460 and my gpu is gtx970

im not sure but i think my gpu is pretty solid so i'd like to use it for my machine learning problems

my computer just spent 400 seconds to train an ANN with 11 inputs, 2 hidden layer, and 1 output ( beginner here, not sure if this info is relevant? ) and i'd like it to be faster, because i'm planning to do that with sound and such...

how do i know if keras ( i thought it was built upon tensorflow? ) is using my gpu, because i did install gpu support for tensorflow

thx!!"
Machine Learning 101: ML Algorithms with K-Fold Cross Validation,0,14,False,False,False,learnmachinelearning,1494966649,False, 
What is the best approach to apply machine learning to classify whether you will like X based on previous X likes/dislikes from a small sample set?,2,1,False,False,False,learnmachinelearning,1494972289,True,"I was looking at one-shot learning using BPL. Found out about this through Siraj's video on one shot learning and he linked this research paper. Is this feasible?
I need some help since I am truly a beginner in this and for what I'm trying to do this has to work with small sample sets (say max 10-20). I am open to hearing about different approaches.
Thanks!"
Keras 2 model retraining using functional API,0,1,False,False,False,learnmachinelearning,1494973143,False, 
TWIL (This Week I Learned) - Share something new that you have learned this week!,5,1,False,False,False,learnmachinelearning,1495004899,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
Audio comparison,0,1,False,False,False,learnmachinelearning,1495010643,True,"Hey,

There is a work project that I am supposed to do and right now I feel like I am in way over my head. I appreciate any help or direction.

The project is supposed to work like this:
1. Show random word out of pre-defined list.
2. Person says the word.
3. Machine prints out a rough percentage of how close you are to native-like pronunciation (pre-recorded spoken words).

There are 10-15 words in the pre-defined list. I was thinking of classification (providing examples in the range of nonsense to excellent pronunciation) and printing out how likely it thought the speech input to be the displayed word. That is only because of my lack of knowledge in this area.

I would have just used Google Speech API and used a hacky way to do it, but one version of it has to work offline in a stand somewhere so that's where I thought of training a model."
Measuring the difference of prediction of two models and find where they disagree?,2,1,False,False,False,learnmachinelearning,1495014211,True,"Hello everyone,

I have two models for classification (decision trees). They take the same input variables (just real numbers, no images or such). However, they don't always agree where to classify an object. Is there a way to measure where they disagree? So for example lets say they agree if the numbers are small for x, but disagree at high numbers for variable x. Is there an algorithm/method that would tell me that the disagreement is big for x<1500 or so?
If you know such a thing, could you also tell a citable source for it?

Thank you very much!"
convolutional network for song classifier?,2,2,False,False,False,learnmachinelearning,1495020167,True,"hello

so i'm working on a project that will tell you whether a song is jazz or not, i know it's been done before, and in a much better way, but i'm just trying to get into a school and this project might get me there!

if i convert the song into this : http://imgur.com/a/iZeHb ( btw can someone tell me what this is? ) and run a dataset of 1000 song, 500 of which are jazz and 500 of which are not jazz, train the convolutional network to recognize jazz pattern in the spectrum, would it work? or should i go with another method? 

thx"
xkcd: Machine Learning,7,161,False,False,False,learnmachinelearning,1495020814,False, 
Guidance for Beginner?,2,2,False,False,False,learnmachinelearning,1495028130,True,I have completed Andrew Ng's machine learning course on Coursera and the 'Top 5 Machine Learning Libraries in Python' course on Udemy. I am now starting to read Christopher M Bishop's 'Pattern Recognition and Machine Learning'. I want to get some hands on experience with programming some algorithms and solving some problems and see some 'machine learning action' to get a feel for it and further my motivation. Can anyone point me to a good direction? (I am an Undergrad student in Mathematics and have taken an Introductory course in Python in college and read a bit later on my own.)
multivariable calculus for ML?,2,1,False,False,False,learnmachinelearning,1495035137,True,"Hello all!

CS student here, and for unimportant reasons I will not be taking a class on multivariable calculus at my university.

I was wondering if anyone could set me on track with the right topics in multivariable calculus to self-study so that I will be competent mathematically when it comes to learning ML.

My hope is to not have to go through an entire course's worth of work on my own if only part of it would be relevant to ML.

Thank you!"
How do I represent a neural network in code?,2,1,False,False,False,learnmachinelearning,1495036667,True,"Hi there. I've been for a while now looking for a way to represent a neural network in code. I'm not sure what is the best way as I haven't been able to find many sources which should show the code representing a neural network. There are a plethora of sources of explaining how they work but not many that the underlying code and structure of the system. 

Structure is what I'm mostly concerned with here. I've seen an example of a neural network being represented with matrices but I'm  not sure what I think of that. If I were to think of the top of my head I'd probably model a neuron as a class as well as have a data-structure to hold the connections between the neurons. But I'm not really sure if theres a simpler and easier way to go about this? 

If anyone could explain this to me or point me to a source that does so, I would be very grateful :)  

EDIT: If it makes any difference at all, I specifically want to code an evolutionary neural network so I'm wondering which is a good way to represent this in code :)
"
Where is CPU vs GPU mode set in Caffe?,1,1,False,False,False,learnmachinelearning,1495037470,True,"I'd like to run it as GPU if possible, otherwise CPU mode, but I'm getting the error:

       Cannot use GPU in CPU-only Caffe: check mode.

The solver.prototxt has the line:  solver_mode: GPU

According to CPU-Z, I have a 650Mhz Intel HD Graphics 4000 Ivy Bridge GT2 with OpenCL and DirectCompute 5 support.

Why does it only run if I set the solver mode to CPU?
"
AI coders - How do you decide on the type and shape of your neural network?,9,6,False,False,False,learnmachinelearning,1495071893,True,"There seems to be an eye watering array of NN models, along with any number of ways to construct each: number of layers, number of nodes, optimizer, loss algorithm, epochs versus batches etc. How do you decide? For example, I am analyzing grayscale images. I'm passing 3x3 pixel intensity values to an RNN-LSTM in Keras with Tensorflow backend. Given the outer 8 pixel intensities I want the NN to return the value of the central pixel in the block. Everything is working. Or not. The terminal ticks over, says it's doing stuff. I occasionally test the model. The results are slightly better than chance (0.1015 accuracy on a picture composed of random pixel values). Almost all references online are related to the mnist data set or some other vanilla example that doesn't quite fit with what I want to do. Even so, the examples don't ever explain the reason for choosing the model and shape of the NN being demonstrated or where to go for advice on alternatives. How did you decide on the makeup of your NN.

ps. I'm an intermediate level hobby programmer. I am no math expert but can feel my way around in the dark for a short distance. I'd be really grateful for any guidance.
"
Online Learning Options,1,3,False,False,False,learnmachinelearning,1495077944,True,"Hi all! I was browsing reddit while feeling overwhelmed about my machine learning progress and I thought to myself ""I wonder if there is a machine learning sub?"" Then I found this! 
In doing so, I've read some posts about online learning options. I have already taken the machine learning specialization from Coursera (bummed it was cut short). And when I finished, while I did well, I didn't feel I had any real experience. I found Udacity, which seemed very hands on, but a steep price tag. I was originally attracted to the guaranteed job part, but found out that was only open to US residents (I'm Canadian). I learned from this sub about Udemy and I was wondering if others could share their thoughts? At $10/course, it seems like a steal. Especially compared to the $278 (exchange is killer) I'm paying per month for Udacity. I'm about 25% of the way through Udacity after about 1.5 months and I enjoy the option to speak to a mentor. I love that there are communities like this out there, but I am usually too shy to partake. I see so many complex questions, I don't find I even understand most of them, that alone have anything useful to contribute, so I'm scared to ask my super simplistic questions. Also, with a mentor, I can ask my quick question without having to write a long post (like this, haha). Are there other places to find mentors? I would appreciate any advice you could give!

tl;dr: should I continue to pay $278/month for Udacity (and mentor) or cut my losses (25% done after 1.5 months) and go with Udemy?"
Math for deep learning?,6,5,False,False,False,learnmachinelearning,1495106463,True,what online math course or book do you recommend to take prior to diving deeper in deep learning? My sc course at college included almost no maths so I am not sure what to do
To apply series capacitive compensation in a transmission line in a simp...,0,1,False,False,False,learnmachinelearning,1495115562,False, 
Turning an unbalanced training model into predictive model,0,3,False,False,False,learnmachinelearning,1495123124,True,"Hi Everyone, 

Quick question on taking a training model and then using it for prediction. 

Assume I have 2 data sets, the first is small and has the truly observed outcome. This data set is also unbalanced (N = 100, Targets = 25, Non-targets = 75). To identify best features, model parameters etc, I am using leave one out cross validation and a balanced cross validation data set approach. This can be summarized as follows: 

     1) Remove 1st observation and down-sample Non-targets to be equal with targets
     2) Train model 
     3) Make prediction on removed observation
     4) repeat steps 1 - 3 100 times to account for sampling variability 
     5) Aggregate prediction votes and classify observation as majority vote

After developing this model and identifying the proper feature, parameter settings etc. I want to apply this to a new data set and classify each observation as Target/Non-target. To do so should I 

A) 

    1) Train model using optimal features/settings on all training data 
    2) Make predictions on second data set using newly trained model

B) 

    1) Train model using optimal features/setting on balanced training set down-sampling Non-targets (same method as above)
    2) Make predictions on second data set
    3) repeat steps 1 and 2 100 times to account for the sampling variability 
    4) Final prediction is based upon the aggregate voting 

Thanks in advance!"
How do you get better/ bounce ideas when alone?,4,6,False,False,False,learnmachinelearning,1495130805,True,"Hi all,

I'm trying to learn to be better at ML. I took an intro course a while back and have some time to do some competitions on Kaggle. Problem is, I am limited to just Googling best methods for dealing with problems. Any advice on how to bounce ideas off of people when I don't work in ML? "
What is a good machine learning topic for undergraduate final year project?,2,4,False,False,False,learnmachinelearning,1495131218,True,"I have little knowledge to machine learning, have only taken basic AI courses. I am very interested in machine learning after watching some videos.

Would like to do a machine learning topic for my final project that is not too difficult yet interesting. Will also be taking neural network courses.

Please introduce me such a topic, and if possible the direction for this project. Many thanks."
Trying to get emergent behavior out of ants using dollar-store neural networks,2,6,False,False,False,learnmachinelearning,1495136099,True,"After about five minutes of research, it turns out I have no clue what a neural network actually is.

What I thought a neural network is: a directed graph - each vertex is a neuron that can fire with a specified strength. When it fires, it sends a signal through all of its outbound connections to other neurons (making this a flow-forward network). A neuron will fire if all the signal strengths its inbound connections add up to a specific ""activation requirement"".

Then, I took this discount ""neural network"" and dropped it in a virtual ant - a thing with a position in a 2D grid, amongst food, walls, and other ants. Ants have some input neurons that fire when they receive some stimuli (""there's food in front of me"" - ""there's a wall/edge of the grid beside me"" - ""there's a pheromone here"" - ""I'm hungry"").

This discount neural network becomes the ant's only hidden layer. The number of neurons, their connections, and their firing strength/activation requirement are all selected randomly from ranges I specified. Some hidden layer neurons connect, eventually, to output neurons that, when fired, perform an action (""eat food"", ""move"", or ""place pheromone"").

All ants perform one ""cycle"" of this neuron activation in a timestep. Each ant has a given lifespan in timesteps that goes up by eating food. The top N pairs of a generation breed with each other for the next generation - the rest of the generation is filled out with more randomly spawned ants.

The breeding method is simple, and, as it turns out, really stupid: take half of each parent's neurons, keep connections between them but sever connections to neurons that were not taken, plop them in the child's hidden layer, randomly spawn new connections. Connections to input and output neurons are preserved. I thought this would (slowly) cause the ants to get smarter. Turns out it just causes the number of neurons they have to grow to stupid levels.

I originally wanted to know how to make a better genetic evolution algorithm for my ants, but I guess now I want to know how to apply actual neural network ideas to this problem (which doesn't feel like a traditional problem for ANNs to solve).

[Here's](http://imgur.com/a/0hNsG) a couple of screenshots from the program."
Potentially going for my PhD,0,1,False,False,False,learnmachinelearning,1495141122,True,"I'm thinking about going for my PhD focused on ML.  My background is in Computer Science and I have an MS where my thesis was on statistical animal detection.

I've been working with data and analytics for the past decade or so and am conversationally familiar with the basic ML patterns.  

Those of you who have your doctorates, would you imagine this would qualify for a program?  What should I be focusing on?  How have your job prospects fared?

I don't really have any academic people in my life, so I'm hoping I can impose upon your experiences."
How to decide the range of parameters for random forest?,0,0,False,False,False,learnmachinelearning,1495152778,True,So I know caret has a default range for mtry and number of trees. But how would you know in what range you should use and how big should the steps be in-between each parameter if you do it manually?
Self Learning Information Theory (Basics of ML),5,18,False,False,False,learnmachinelearning,1495153835,True,"I am trying to learn more and more about the basics of Machine Learning. One of them is Information Theory.
This blog post: https://medium.com/@nishantnikhil/introduction-to-information-theory-hamming-7-4-code-b341bd01d955 summarizes some of my learnings about Information Theory.
I plan to make a series over it."
Help with Keras?,8,2,False,False,False,learnmachinelearning,1495155659,True,"Short version: Is there anybody who would be willing to answer a bunch of random questions to help me understand Keras? 

Long version: I'm trying to write a custom RNN layer in Keras by extending the LSTM class. However, I'm running into all sorts of issues, in large part because I'm having trouble figuring out how Keras *works* on a basic level. For example, I see how the steps function works in the base RNN and the LSTM classes, but I'm not entirely sure how it interfaces with call, or what types the variables are supposed to be, and that's making it difficult for me to manipulate variables. "
How do you calculate log probabilities for the output of neural nets?,3,1,False,False,False,learnmachinelearning,1495157975,True,"I was reading Karpathy post on Deep RL (http://karpathy.github.io/2016/05/31/rl/) and he mentions taking the log probability of (-1.2, -0.36) instead of raw probabilities (30%, 70%) for the outputs of the network. How are you these values calculated? I tried finding the log of 0.3 and 0.7 but that doesn't give the same values."
What is Lasagne? How does it relate to Theano?,1,4,False,False,False,learnmachinelearning,1495167061,True,"Basically the title. I'm just starting out and I stumbled across both Theano and Lasagne. I know that Theano is a machine learning library, and that Lasagne somehow works with Theano. But what's the difference between the two, and why is this extra library, Lasagne, needed? Thanks."
To implement a 3 phase network and to observe voltage regulation in tran...,0,1,False,False,False,learnmachinelearning,1495174724,False, 
Weekly Show-off!,0,2,False,False,False,learnmachinelearning,1495177969,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
Visualizing tensorflow models without tensorboard,1,2,False,False,False,learnmachinelearning,1495179354,True,"I found this [figure](https://3.bp.blogspot.com/-8Lsg0rnxl7k/WRtttN18MKI/AAAAAAAAB0o/KpHbFnYBmTYQ3dBjVLimPUkKphU_qLBfgCLcB/s1600/image2.png) in a [blog](https://research.googleblog.com/2017/05/using-machine-learning-to-explore.html) by google and was wondering if there is any way to generate such networks from tensorflow. I know of tensorboard, but I want aesthetics that match this figure. I found [this](http://ethereon.github.io/netscope) but it presently supports Caffe only."
Machine Learning 101 - Basic introduction to machine learning and the use of gradient descent,0,9,False,False,False,learnmachinelearning,1495184956,False, 
Deep Learning library for TensorFlow for building end to end models and experiments.,0,7,False,False,False,learnmachinelearning,1495185049,False, 
ML solutions for Windows 10 64bit?,3,2,False,False,False,learnmachinelearning,1495185328,True,"I attempted fiddling around with TF previously but couldn't get it to work as it wasn't supporting my system at the time.

Now my computer's a mess of Python libs and who knows what else that I dare not even begin to clean up (yet).

In the mean time, can anyone let me know if there's something I can toy around with ML that basically requires no extra effort to set up? I'm fine using any language but I just want something ""Plug and Play"" that I can get results fast and expand on from there.

Does such a thing exist?"
Pandas Cookbook - Concise with real life examples,0,34,False,False,False,learnmachinelearning,1495190536,False, 
Learning And Development Professionals – CX University,1,1,False,False,False,learnmachinelearning,1495191487,False, 
Zero Shot Learning on a matching problem?,16,1,False,False,False,learnmachinelearning,1495208500,True,"I can't seem to label my issue, so let me describe it:

Basically, I need to be able to predict whether two samples from any category actually belong to the same category. The main problem is: during test time, none of the categories I use have been seen during training.

Now of course, tested categories and training categories should share many features: for instance let's say during training, I only match between letters from an alphabet I wrote. And, during testing, we will try to match letters from an alphabet another person wrote.

I originally thought this fall into the ""Zero shot learning"" category, but I'm not sure now since I'm not trying to predict any class, I'm just trying to say whether or not unseen samples are matching.

If you know of any paper that treat this problem, please share here! Thanks"
"I would like to start some ML coding using Python sooner rather than later suggestion book, tutorial etc.",9,16,False,False,False,learnmachinelearning,1495221143,True,"* I have beginner to intermediate skills in python.
* I have not used pandas, numpy, etc in any coding I have done.
* Graduated with a BS in Math 30 years ago and I am brushing up on linear algebra, probability, and statistics now.
* Purchased the following books and I am about a week into each;
** ""Superintelligence: Paths, Dangers, Strategies""
** ""The Master Algorithm:How the Quest for the Ultimate...""
    
Would like to thank everyone for their input.  I spent the weekend surveying all of the things I thought I would need to get into this field of study.  The only thing I could come up with after seeing all of the subject I needed to learn or brush up on was: ""How does one eat an elephant?""  Besides what else do I have to do with the rest of my life.
** ""Artificial Intelligence: A Modern Approach""
What I'm looking for are some simple/easy examples just to feel like I am moving forward."
How to design neural networks architectures?,3,2,False,False,False,learnmachinelearning,1495229626,True,"Hello, I'm fairly new to machine learning, so correct me if I'm wrong in any of these points please.

With all these frameworks and tools to build neural networks, like tensorflow, theano, keras, etc. It seems that implementing neural networks have become a lot easier, since it's not needed to implement the backpropagation algorithms, optimizers, regularizers and so on. 

Then the difficulty in **applying** machine learning nowadays lies more in defining hyperparameters that define the training and the structure of the network (aside from collecting data).

So I was thinking, what would be the techniques (if there are any) to design the optimal architecture of an neural network?

Thanks In advance!"
To implement a 3 phase network and to observe voltage regulation in tran...,0,0,False,False,False,learnmachinelearning,1495258040,False, 
"Weekly Scrum Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",3,3,False,False,False,learnmachinelearning,1495264235,True,"Let's have a scrum meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
To implement a 3 phase network and to observe voltage regulation in tran...,0,0,False,False,False,learnmachinelearning,1495269975,False, 
where can i get some processing power for free?,3,3,False,False,False,learnmachinelearning,1495272225,True,"hey guys

so i just need some processing power for a couple hours for a personal project

i dont rly want to pay ( yes... i'm an asshole lol ) but it's mostly because this is a one time thing, i just want to show a project to an admission comitee and after that i won't be doing deep learning for a couple of years until my master or PhD

i know there was a website linked here but I can't find it ! Help please!

thx!"
matlab tutorial collection in english part 2.,0,0,False,False,False,learnmachinelearning,1495276025,False, 
Dig Out Relevant Text Elements with Entity Extraction API,0,1,False,False,False,learnmachinelearning,1495276377,False, 
To observe the variation of voltage regulation with transmission line pa...,0,0,False,False,False,learnmachinelearning,1495289117,False, 
Choosing architecture for RNN,2,6,False,False,False,learnmachinelearning,1495294713,True,I want to build a RNN to model time series data. I have heard that LSTM is a good architecture to use and I have some experience with it. Are there any other RNN architectures I should take a look at for this project?
"Woleebaph Ronder Wily, or, An AI invents colors",0,3,False,False,False,learnmachinelearning,1495298509,False, 
Learning Deep Learning as a MSc Comp. Sci Student?,2,4,False,False,False,learnmachinelearning,1495317579,True,"Hi,

During my studies I have gained a decent understanding of the basics of ML and the field of AI but my courses never touched upon deep learning much. So I am looking for some online course and would like to hear your opinion on the course ""Deep Learning A-Z""?

The preview is a bit repulsive in the sense that they try to sell the idea of ""no mathematical knowledge required"". I am afraid that they will skip fundamental concepts. Is that true by your experience?

Feel free to recommend other courses on the topic, I'd say that my mathematical foundation is sound, but probably a bit rusty.

Bonus: during the majority of the my ML studies I mostly examined the theoretical side of things, and rarely had the chance to apply the algorithms and concepts in practice. Feel free to recommend a course, or any other material really, that could show me the practical possibilities of ML."
Attacking Machine Learning with Adversarial Examples,1,6,False,False,False,learnmachinelearning,1495317789,False, 
Let's start a Coursera ML group!,8,23,False,False,False,learnmachinelearning,1495324484,True,"[Stanford Machine Learning Course](https://www.coursera.org/learn/machine-learning?utm_source=gg&utm_medium=sem&campaignid=693373197&adgroupid=36745103715&device=c&keyword=stanford%20machine%20learning&matchtype=e&network=g&devicemodel=&adpostion=1t1&creativeid=156061453612&hide_mobile_promo&gclid=Cj0KEQjw0v_IBRCEzKHK0KiCrKMBEiQA3--1Njl2aBYh0Xk0UEI5RL-BDtSFwNrEBAH1Au4daWqwHHoaAu8k8P8HAQ) is starting this week and I think it would be cool to start a little community of people to help each other out on the course so that way we can ask questions and get quick responses if we're stuck, or to come up with cool ways to apply the stuff we learn.

I've just completed the first week, and this stuff seems super interesting, and I'd love to find a bunch of likeminded people to take it with!"
matlab tutorial collection in english part 2.,2,0,False,False,False,learnmachinelearning,1495341045,False, 
how we findout the size of matrix by using matlab?,2,0,False,False,False,learnmachinelearning,1495361533,False, 
Elements of statistical learning reading group,35,28,False,False,False,learnmachinelearning,1495379454,True,"Hi everyone, anyone interested in covering specific chapters of this book. We can have weekly discussions for each chapter. 

The plan is to start from basics- linear algebra, probability etc. and then cover topics in the book. 

Edit: Download- https://statweb.stanford.edu/~tibs/ElemStatLearn/

Edit: One of our fellow member has set up a slack group. Please join- stats-elements.slack.com

For first time slack users (like me), an email invitation is required for joining so pm /u/techedlaksh your email address or post it here. 
"
How to start,5,1,False,False,False,learnmachinelearning,1495384201,True,"Hey I'm a web developer and I want to start to study machine learning, so what are the main topics to start? Methods? Materials? Books? Programming languages? Thanks "
Graphlab,1,1,False,False,False,learnmachinelearning,1495386101,True,Are there any good resources or tutorials on graphlab?
Building a bot for a game,8,8,False,False,False,learnmachinelearning,1495426454,True,[deleted]
Would anyone be interested in posts exploring what it's like at a big ML conference?,4,1,False,False,False,learnmachinelearning,1495441512,True,"I've signed up to go with my current team to [ICML](https://2017.icml.cc/) this year. I'm certainly a beginner in ML, and this conference will be the first proper Machine Learning conference I've attended. For me, it will be 3 days in the conference proper, and 2 days in the workshops ([many of these sound pretty interesting](https://2017.icml.cc/Conferences/2017/Schedule)).

If people would be interested in getting details on what a high-profile ML conference is like (from the perspective of a fellow beginner) I'd be happy to keep track of my experiences there. 

I myself am particularly curious as to how accessible the conference is to a hobbyist undergrad, and how much participation in this conference for a week improves my knowledge of the field's technical aspects. There may be aspects you are more curious about and please feel free to comment them below and I'll do my best to investigate. "
trouble installing cuda and cudnn,19,1,False,False,False,learnmachinelearning,1495444540,True,"this is a problem on my end... if it's not written like this : 

step 1 : do this

step 2 : do that

i'll have a lot of trouble doing anything

can someone please help me? for the cudnn thing i got to the part where there was an explosion of some sort on screen then my computer heated like crazy meanwhile. had to close it because it was running for a few minutes already

and also the path thing... what is it?

edit: i'm on windows"
Practical Machine Learning With Python - Part 1,8,40,False,False,False,learnmachinelearning,1495458421,False, 
Trying to model a neuron and n. network in OOP,15,0,False,False,False,learnmachinelearning,1495460603,True,[deleted]
Learning Advanced Neural Networks,1,3,False,False,False,learnmachinelearning,1495476415,True,"I have a computer science background and have done some work with neural Networks in the past but I am looking at getting back into it. Are there any resource material on how neural networks are used with detecting objects in videos or images? Also I am trying to understand how you can retrieve a dynamic result from a given input, like a number of faces in a photo."
Does anyone have the Book Crossing dataset?,3,1,False,False,False,learnmachinelearning,1495505110,True, 
Auxiliary Classifier in TFlearn or tensorflow?,0,1,False,False,False,learnmachinelearning,1495522199,True,"I've been looking at googles inception v3, and its tflearn implementation [here](https://github.com/tflearn/tflearn/blob/master/examples/images/googlenet.py) but it seems to be missing a the auxillary classifiers of the original. I've been looking around and I can't seem to find how to even implement them in tflearn or tensorflow. The closest I've found was a google groups post about how to do it in lasagna linked [here](https://groups.google.com/forum/#!topic/lasagne-users/N_yLm_46Dy8). Has anyone done this before in tflearn or tensorflow? "
Any implementation ideas for speech imitation.,1,3,False,False,False,learnmachinelearning,1495542253,True,"Hi 

I think that it would be very cool to have an algorithm that could take in your text input and say your text in some famous person's voice (ex. Morgan Freeman)

It is basically creating a text to speech engine with that person's voice.

Please comment any implementation ideas that you may have."
Novelty Detection in Images / Likelihood that class is present,0,3,False,False,False,learnmachinelearning,1495544074,True,"Assuming I have a dataset containing only positive examples of a certain class (say, images of cats) - what would be the best way to train an estimator that can predict whether a new sample is similar to the training data (yet another picture of a cat) or if it is likely not belonging to this class (image of a truck)?


Now I guess the obvious way to solve this would be gathering a large and varied dataset of negative examples (images that do not depict cats)

Is there a decent way of going about this with only the positive examples?

Keywords, links to relevant papers or any other resources would be highly appreciated!"
Post Processing in Semantic Segmentation (DL),4,1,False,False,False,learnmachinelearning,1495550545,True,"Is there any know method to include post processing during training in a semantic segmentation task ( like blob size, or connected-component analysis)? If there is, how one can include it in GPU pipeline?
"
Is AlphaGo a GAN?,4,5,False,False,False,learnmachinelearning,1495552640,True,"Still now I thought that DeepMind's AlphaGo has two different neural networks which finds policy and value using two different networks but  today I read this article 

https://medium.com/intuitionmachine/deep-adversarial-learning-is-finally-ready-and-will-radically-change-the-game-f0cfda7b91d3

>Deep Mind recently demonstrated the amazing potential of deep (adversarial) learning with AlphaGo, 

Is AlphaGo a GAN? How is the GAN AlphaGo works?"
Predicting Features for different body types.,0,3,False,False,False,learnmachinelearning,1495558275,True,"Suppose you want to predict the location of some facial feature (e.g. right eye) on a set of outlines of human figures with different body types. Would it be possible to train a network on a set of images (or outlines), by showing the eye's correct location, so that it eventually learns to predict it accurately on its own? If so, how would one approach this problem from the machine learning point of view? Thanks."
"March Machine Learning Mania, 5th Place Winner’s Interview: David Scott",0,4,False,False,False,learnmachinelearning,1495560451,False, 
How do I compare several classifiers over multiple datasets?,2,1,False,False,False,learnmachinelearning,1495566223,True,"Hi there,

I have been running some experiments with several algorithms. I'm trying to ascertain whether one algorithm is statistically superior to all others, given the context I'm working on. 

I'm running stratified 5-fold cross-validation 10 times. I'm collecting the average accuracy over the 5 folds, and then the average and standard deviation of this average over the 10 runs. Also, I'm repeating the experiment for 15 datasets.

Let me show an example of what my results look like:

Dataset | Method 1 | Method 2  | Method 3
-------|--------|---------|--------
Dataset 1 | 99.99+- 0.01 | 65.00+-2.10 | 64.00+-1.50
Dataset 2 | 99.99+- 0.01 | 70.00+-1.30 | 52.10+-3.40

What kind of statistical test am I looking at? I have a really weak background when it comes to Statistics, since my college Statistics course was mostly focused on probability theory.

I greatly appreciate any kind of help.


"
Trying to use machine learning on a smart watch application. Which smart watch has the best access to mobile sensors?,2,6,False,False,False,learnmachinelearning,1495583917,True,"I own an apple watch and attempted to use that device to pull mobile sensor information from but it was a horrible experience. Everything is stuck behind a barrier and some things aren't even accessible. I want to work with something more easily managed. Something with an accelerometer, gyroscope, and HeartRate monitor. I wanted it to record audio as well but I can sacrifice that for the sake of everything else.

Not sure if the community has programmed with anything that can do all of that, or with a device which they enjoyed. Any guidance is appreciated!"
How To Use Anaconda With Sublime,1,13,False,False,False,learnmachinelearning,1495589937,False, 
Need answer about some Machine Learning related questions?,4,1,False,False,False,learnmachinelearning,1495594541,True,"Recently, we planned to build a system for image processing to extract info from images. At present we are using AWS Recognition to do the that. But, in some cases, we are not getting accurate information from AWS. So, we've planned to build our own custom one.

We've 4/5 months to do that. At least a POC version. Also, we've planned to use Tensorflow for that. We all have no prior experience about Machine Learning & Deep Learning but already have 5/6yrs of experience on Computer Programming by using different languages. 

Currently, I'm studying ML from a course of Udemy & my approach to solve this problem is...

* Learn Machine Learning(ML)
* Learn Deep Learning(DL)
* Above ML & DL maybe I'll be ready to understand the whole thing & can able to build a system for Image Processing.

In abstract what I've understood is, I've to write one Deep Learning Program in Python by using Tensorflow. By using that Program I've to build a Model. Then I've to train that Model by using some training data. Then, when my Model achieves a certain level of accuracy I'll use some test data. 

Now, there some places at where I've bit confused & here are my questions regarding that confusion...

* I know tensorflow is a library but at some places, it's also mentioned as a system. So, is it really a library(piece of code) only & something more than that? 
* I got some Image Processing Python code in Tensorflow tutorial section (https://www.tensorflow.org/tutorials/image_recognition#usage_with_python_api). We've tested that code & it's working exactly the way AWS Recognition service work. So, here my doubt is... can I use this Python code as it is in our production work?
* After train a model with some training data does those training data get part of the whole system or Machine Learning Model extract some META info from those training data & keep with itself rather whole raw training data(in my case it'll be raw images).
* Can I do all these ML+DL programmings over my Linux System? It has Pentium 4 with 8GB RAM.
* Also, want to know... the approach which I've mentioned to build a solution for my problem is sufficient or I need to do something else also.
"
TWIL (This Week I Learned) - Share something new that you have learned this week!,1,9,False,False,False,learnmachinelearning,1495609897,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
What is the difference between layer normalization and instance normalization?,2,5,False,False,False,learnmachinelearning,1495621437,True,"Thanks in advance :)

Links: 
Instance Norm: https://arxiv.org/abs/1607.08022
Layer Norm: https://arxiv.org/abs/1607.06450v1"
What are best practices for implementing a LSTM?,9,1,False,False,False,learnmachinelearning,1495659983,True,"I've been working very closely with LSTMs recently and for some reason had it in my head that dimension reduction was a good way to prevent over-fitting. But someone just told me it's best practice to start with as much data as possible and then just use dropout (please let me know if this is also incorrect).

This made me realize that maybe I don't know the best practices for LSTMs. I understand them fundamentally, but practically speaking, I'm just throwing things at the wall and learning from what sticks.

That said, are there any best practices for implementing LSTMs?"
Want to predict values based on categorical values --where do I start?,3,7,False,False,False,learnmachinelearning,1495662603,True,"As the title suggests, I have some historical data that I want to use to predict future values. Things like model number, series number, color, finish type,  and high bid value. 


All of our values are in a SQL table, as well as exported to a rather large CSV file.

The idea is to take the older information and use that to predict what people may bid for each item.


Is this something I could use machine learning for or am I looking for something else, like a neural network? 

If I'm in the right place, where should I start?"
"Deep Learning Is Not Good Enough, We Need Bayesian Deep Learning for Safe AI",2,16,False,False,False,learnmachinelearning,1495663241,False, 
Suitable algorithms for different types of data-set,0,5,False,False,False,learnmachinelearning,1495664359,True,"Hello all. Is there some resource available that suggests what types of machine learning algorithm are suitable for specific types of data-set?


e.g. X algorithms are suitable for EEG data. x, y, and z are state-of-the-art X algorithms.


Pre-processing and desirable data-set characteristics would be very helpful to.


Doesn't matter if it's an academic publication, technical report, or blog post.... I think this would be useful to many people"
xcessiv/README.md at master · reiinakano/xcessiv,0,1,False,False,False,learnmachinelearning,1495664534,False, 
why do we fit feature scaling only on training set? Shouldn't we apply it directly to full dataset?,4,9,False,False,False,learnmachinelearning,1495707934,True,I find it weird to apply MinMaxScaler() only to the training set like in the documentation and few other python ML books. Does it really matter? Isnt it better to apply it on full dataset
Need suggestions on which optimizers to use for our self-driving car DeepLearning Model.,0,1,False,False,False,learnmachinelearning,1495712220,True,"Hi, our team is building a DeepLearning model for a self-driving car
We are currently using basic Adam optimizer, but the training time increases dramatically after third epoch.
We were not able to go beyond 4th epoch due to continual increase of training time.
Our Model uses Keras 2.0. TF backends. Has about 1.4million parameters. layers consist of - batch norm - 2dConv - max pooling Our training data is around 30gb. Training takes about an hour per epoch ( up to third epoch) on Nvidia Tesla K80. The model contains both classification and regression, concatenated at the end.
Would appreciate any direction or suggestions on which optimizers to use, in order to stop training time to reach infinite.
I think the problem lies within the Keras adam optimizer."
Automated Machine Learning - A Paradigm Shift That Accelerates Data Scientist Productivity @ Airbnb,0,6,False,False,False,learnmachinelearning,1495717058,False, 
Need to hire someone for help with project build,3,1,False,False,False,learnmachinelearning,1495725583,True,"I know R well enough, but I suck at machine learning and building models. I have a big project at work due, and would really like to hire someone for a complete walk through of what I've done so far. The only issue is that I cannot share an data so I think the whole thing would have to be done via Skype with a camera on my computer screen. Looking online, hourly rates for go for $20+ hour which seems insanely reasonable. How do I find a legit source for several 4 to 8 hour sessions?"
Multiple GPUs across many ec2 spot instances - How do I save work incrementally?,0,1,False,False,False,learnmachinelearning,1495731033,True,"If I have a large training that would take days and are using ec2 spot instances, how do I make sure that the work I've done don't get lost in case Amazon decides to shut my instances down? Is there a TF module that incrementally saves / sync's work that's been pickled  or something like that?"
Need an advice on what path to take,4,8,False,False,False,learnmachinelearning,1495732235,True,"Hello everyone,
I want to become a self-taught programmer. I have a big passion about technology, but no money to pursue a degree. Taking a student loan is also not an option in my case atm. 

I am also super excited about ML and would love to work in this field at some time in the future. Because of that I decided that the first language I was going to learn would be Python. Right now I am at the very beginning, finishing Python basics and getting ready to get familiar with Numpy and Math aspect of ML. Once I am ready, I was thinking about taking Siraj Deep Learning course on Udacity to cover basics and then moving on to more specific courses like self-driving cars, computer vision etc. 

But even though I realy like ML, my main goal right now is to start making money as a programmer after one year. 

My question is - do you think I would be able to find an entry level job after succesful completion of all those Udacity courses and accumulating a portfolio of what I can do? 

Or is it better to first become a programmer in some specific field where ML is hot, and then steadily learn how to implement this stuff? If yes, what language would you recomment to learn and what field to aim? 
For example, Swift - IOS Development. 

I am just in the beginning right now, so I understand that I might be even asking the wrong question because of my current understanding of everything. Would be happy to hear your suggestions and corrections.Thank you!"
Real world uses for Markov chains?,7,5,False,False,False,learnmachinelearning,1495741349,True,"I've seen that Markov chains make for great Twitter bots, but what real world uses are there?"
First time Deployment of a model?,3,6,False,False,False,learnmachinelearning,1495770992,True,"Hello!

I've never deployed a model and don't know where to start. Background is in Econometrics and basic machine learning. Only experience is running experiments and data mining. All the information I can find seems focused on paying for a service and I'm not looking to do that. Thanks!"
Everything that Works Works Because it's Bayesian: Why Deep Nets Generalize?,2,14,False,False,False,learnmachinelearning,1495776729,False, 
Weekly Show-off!,3,3,False,False,False,learnmachinelearning,1495782758,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
How I Built a Reverse Image Search with Machine Learning and TensorFlow: Part 1,3,24,False,False,False,learnmachinelearning,1495816473,False, 
Python for Data Science and Machine Learning Bootcamp,0,1,False,False,False,learnmachinelearning,1495830270,False, 
Some questions about batch normalization in CNN,1,2,False,False,False,learnmachinelearning,1495838080,True,"Hi,

What is the number of means (or variances) of the batch normalization in CNN training? Suppose that the width, height, and depth (channel #) of an output feature map for layer k are Wk, Hk, and Dk. Then, is the number ""Wk x Hk x Dk"" or ""Dk""? How about in CNN inference? Thank you for your time and consideration!"
"Weekly Scrum Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",6,5,False,False,False,learnmachinelearning,1495869027,True,"Let's have a scrum meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
How can I improve my KNN classifier?,5,5,False,False,False,learnmachinelearning,1495892694,True,"I'm trying to teach myself a bit about machine learning, so one of the first things I did was implement a KNN classifier in ruby. My goal was to classify text product reviews into 8 classes:

* books-positive
* books-negative
* kitchen-positive
* kitchen-negative
* dvd-positive
* dvd-positive
* electronics-positive
* electronics-negative

I created features from my reviews by converting them into a set of bi_grams, removing stop words and then using a bag of words model. I calculate the closeness of feature by euclidean distance.

However the result wasn't very good, the max percentage of correct classifications I've gotten is about 28% which is little better than just guessing. Are there any one know of anymore improvements I can make to my classifier to make it better? Or any resources I can use to research from. I've included my source code and training/testing data below if anyone wants to take a look.

https://pastebin.com/x6DbQtts

https://pastebin.com/jDBsndPx

https://pastebin.com/SKikxz5G"
how we findout the inverse of matrix in matlab?,2,0,False,False,False,learnmachinelearning,1495892969,False, 
What recommender system should I use?,10,4,False,False,False,learnmachinelearning,1495931490,True,"Hi! So, I'm trying to build a recommender model for users and items, and was wondering about the approach I should take for it. Here are some pointers on the data:
1. I have a LOT of users (~5 million), but only 50 items I want to recommend.
2. I have a ratings matrix (5 million users x 50 items) that's either 0 or some positive number with the sparsity (percentage of zeroes) being 96.11%. The rest of the 3.89% is positive numbers.
3. On average, each user has given 2 item reviews out of 50.

My thoughts thus far: matrix factorization might be the way to go. The sparsity is not an issue (Netflix data was more sparse and yet matrix factorization did well). However, on an absolute scale, will 2 reviews per user be too little to generate useful predictions using matrix factorization? Is this too much of a ""cold start?"" Should I consider other approaches like item-to-item collaborative filtering?

Thank you for reading, I look forward to hearing what you guys have to say :)"
how we findout the determinent of matrix in matlab?,1,0,False,False,False,learnmachinelearning,1495951328,False, 
Which Algorithm for modeling a sequence and predict the next value,7,7,False,False,False,learnmachinelearning,1495958896,True,"Hi,

I have a repeating sequence like the following, with occasionally random values (maybe noise): ABCDABCEDABCDABCD

What could be an algorithm to model the sequence and predict a following value at a certain time. For example I had ABC and no it should say D (of course it can only give a percentage since it is not always D following ABC).

First I wanted to try HMMs, but I think there is no hidden state, since i ABC are my states and can be observed. My second thought would be markov chains, but I am not quite sure if there is an good way to learn the probabilities and give me a prediction given one or two (for a second degree markov model) of the following value.

I also wanted to look into RNNs, but it would be great if someone with experience could tell me in advance if they are a good way for this task or if I should focus on more promising ways.

Thanks in advance."
dataanalysisclassroom – making data analysis easy,0,8,False,False,False,learnmachinelearning,1495975900,False, 
AI Learning Path,1,28,False,False,False,learnmachinelearning,1496008548,False, 
Modern Machine Learning Algorithms: Strengths and Weaknesses,0,10,False,False,False,learnmachinelearning,1496020510,False, 
how to adds comments to your matlab code?,0,0,False,False,False,learnmachinelearning,1496029572,False, 
How to balance a pole on a cart.,0,1,False,False,False,learnmachinelearning,1496036685,False, 
How to Solve the New $1 Million Kaggle Problem - Home Value Estimates,2,13,False,False,False,learnmachinelearning,1496038328,False, 
Open Curated List of Machine Learning Surveys,0,16,False,False,False,learnmachinelearning,1496064090,False, 
"A great Deep Learning box for $1700: Assembly, setup and benchmarks",4,28,False,False,False,learnmachinelearning,1496070610,False, 
Introduction To Probabilistic Modeling and Machine Learning,0,5,False,False,False,learnmachinelearning,1496072594,False, 
How to identify a model or algorithm that can provide us the optimal value of variable features while values of other features are fixed?,0,1,False,False,False,learnmachinelearning,1496072608,True,"For example, there's a dataset containing some features (has some variable and some fixed features) and one class target. And there's a classifier that is able to predict the ranking score. The ranking is based on the target class (so for a particular sample of data it could be out of 10)
I want to find out what input features can maximize the ranking score.
How should I go about something like this? Without coding it out.
I want to be able to break down the problem and understand how to solve it, so looking for some guidance on that.
"
Understanding Tensorflow using Go,0,4,False,False,False,learnmachinelearning,1496089930,False, 
SVD: what to do when training data has less attributes than production data?,2,5,False,False,False,learnmachinelearning,1496106310,True,"I use SVD for dimension reduction because I can easily have more columns than most SQL DBs prefer to handle. So my training matrix is a pivot of a table that looks like:


 


Table 1:

| Users | Attributes |
|---|---|
|User1| Item 1|
|User1| Item 2|
|User1|Item 3|
|User2|Item 1|
|User2|Item 4|

...x10M+

 


This gets pivoted into:


 


Table 2:

|Users|Item 1|Item 2| Item 3|Item 4|
|---|---|---|---|----
|User1|1|1|1|0|
|User2|1|0|0|1|


 



Now, usually, to train my algorithms I work with samples of ~300K rows of Table 1 that get pivoted into Table 2 that I then do K truncated SVD to reduce dimensions. The problem is, the full data set can have many more columns/attributes than the sample data because as I add more rows, new items might creep for for a user on row 301K.


 


Question: how do I handle the full data set with additional columns/attributes?

I thought of querying all possible items and pre-set the columns in the dataframe so I can build my sample data matrix with max items and do them same for full data? 

(P.S. I build the SVD incrementally in chunks, which might be another issue altogether)"
3d Tic Tac Toe,3,2,False,False,False,learnmachinelearning,1496107314,True,"Hello, I am trying to code a 3-dimensional tic tac toe AI. The board is 4x4x4, with first to make four in a row.

What do you think is the best method to create a perfect/strong AI? (Monte Carlo, Minimax, Heuristics, Neural Nets, etc.)"
getting into neural networks?,3,1,False,False,False,learnmachinelearning,1496109790,True,"hello, i am incrementtimestwo, i am a programmer, i am out of ideas, so i decided to try and get into machine learning, but what i have found is that there are no good explanations to neural networks, i mean yeah i can program one according to instruction, but whats the point if i dont understand it, if i dont understand why we need an activation function, or why, i want to know exactly why we are doing certain things, and exactly how the mathematical inner workings of a neural network work, but all i can find is guides on how to replicate a set of instructions, no in-depth explanations.

i have googled, believe me, and  i found nothing."
[1705.09558] Bayesian GAN,0,1,False,False,False,learnmachinelearning,1496113598,False, 
Why is C++ not used for machine learning?,10,11,False,False,False,learnmachinelearning,1496118257,True,"From my admittedly limited experience so far with machine learning, very few programmers are using C++ to write machine learning programs. Why is this? What makes the language less suited for the task?"
Trouble Identifying distribution for problem,0,2,False,False,False,learnmachinelearning,1496131422,True,"I'm looking for a distribution of the following type:

    f(t | p1, p2) = 0 if t < p1, 0 if t > p2,  1 else

I receive pairs of data (t, {0,1}). I was thinking of just fitting a Gaussian and using the points where f(t) > 0.5 as p1 and p2. However it is not clear that this is the best solution. 

I was wondering if there is some sort of Guassian where f(t) is maximized over a set of continuos values (instead of a single point). I was also thinking of a double sigmoid (one sigmoid centered at p1 that goes low to high and one centered at p2 that goes high to low)

Anyone know a model to use here? Thanks
"
How would I receive the image data of an openAI gym environment into a numpy array?,1,3,False,False,False,learnmachinelearning,1496146089,True, 
How did you become a data scientist?,14,35,False,False,False,learnmachinelearning,1496151184,True,"As an aspiring data scientist, it is interesting for me to know how someone became one. "
Classification/Clustering Ensemble Method,0,1,False,False,False,learnmachinelearning,1496164774,True,"Recently I have had a few datasets where it isn't really feasible to classify all of the responses (open text), but a pure clustering methodology only works on about half of the responses. Is there a method that combines classification with clustering? What would be ideal is for me to use the wss error to identify the # of clusters and then go into the data and code 10-15 responses into one of each of the categories. Finally use those targets to help improve the ability for the model to cluster into the appropriate groups. Are there any papers on something along this method that I could read, or does anyone have experience doing this? "
Good list of courses to learn Machine Learning,1,1,False,False,False,learnmachinelearning,1496165697,False, 
Unsupervised Machine Learning for Fun & Profit with Basket Clusters,0,10,False,False,False,learnmachinelearning,1496177287,False, 
The best place to start learning R for data analysis.,0,1,False,False,False,learnmachinelearning,1496195008,False,[deleted]
Can some one share tutorials for ensemble in sklearn?,0,2,False,False,False,learnmachinelearning,1496212171,True,I am looking for some simple tutorials for model ensembling using sklearn.  Preferred ensemble would be for a multi classification ensemble model with SVM.
TWIL (This Week I Learned) - Share something new that you have learned this week!,3,2,False,False,False,learnmachinelearning,1496214701,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
Interior design search engine based on text query search,1,6,False,False,False,learnmachinelearning,1496226512,False, 
Practical Machine Learning With Python - Part 2,0,21,False,False,False,learnmachinelearning,1496238610,False, 
Is anyone taking the applied machine learning in python course on Coursera?,4,6,False,False,False,learnmachinelearning,1496245088,True,"I just decided it would be fun for a little extra practice and because you can audit it and submit the programming assignments, etc. at no charge. Was wondering if anyone else had plans to go through it as well. I don't know if they will open up a discussion board when it officially starts or not, but I already had questions on the programming assignment, so thought it might be a good idea to chat with others. "
Why is MATLAB considered an inferior language in deep learning?,5,3,False,False,False,learnmachinelearning,1496252578,True,"I'm trying to learn how to program CNN's, most of my research is done in MATLAB so I've started using MATLAB's deep learning toolbox. While browing stackoverflow I saw a post from Andrej Karpathy where he said he started his research using MATLAB but transitioned to tensorflow because nobody would take him seriously. Google searches are not giving specific reasons for why MATLAB is inferior to other deep learning frameworks, if there are serious drawbacks to using MATLAB then I may transition to using tensorflow etc. "
Network anomalie detection on WiFi router?,0,4,False,False,False,learnmachinelearning,1496253648,True,"Hey.


I am trying to develop a system that will **detect unusual network traffic on a home WiFi router** to stop various types of attacks (Namely **Distributed Denial of Service Attacks**). I want this router to **learn** what normal and abnormal traffic looks like and possibly take action if there is unusual traffic. 



**Any general ideas on how to go about this?**


**My data:**

I have built a packet sniffer that logs all ICP,TCP, and UDP packets that are streaming through the router. I have all of the data that lives in a IP packet's (MAC addr, ports, ACKS, TTL, Flags..etc) header as well as the actual data payload. 

**Ideas:**

I will certainly need to use some sort of unsupervised technique b/c there are no labels attached to the traffic. I was thinking about using some sort of clustering algorithm, or possibly even some type of reinforcement learning due to the streamed nature of my data.

**Any advice is welcome! Thanks!**

"
Struggling to find the right method of interpreting results - Multiple Logistic Regression w/ Binomial Dependent,0,2,False,False,False,learnmachinelearning,1496253825,True,[deleted]
What kind of features are extracted with the AlexNet layers?,0,2,False,False,False,learnmachinelearning,1496259460,True,"Question is regarding the method where the fully connected layer 'fc7' from the pre-trained AlexNet is used to classify images, method can be seen here https://se.mathworks.com/help/nnet/ref/alexnet.html.
What kind of features is it actually extracting?
I used this method on images of paintings on two different painters. First using about 150 training images from each artist and then determining the correct artist on 40 test images. This works really well, about 85-90% correct classification and I would like to know why it works so well. The features are stored in a 300x4096 matrix."
What are the advantages and disadvantages of each programming language when it comes to Machine Learning?,8,7,False,False,False,learnmachinelearning,1496260054,True,"For example, I heard Matlab is designed for the types of computations that ML algorithms use, but C++ is the fastest programming language, but python is the easiest to program in. 

Is there a comprehensive guide to the advantages and disadvantages to each programming language? "
Conditional Probability explained,2,11,False,False,False,learnmachinelearning,1496269278,False, 
Good beginner tutorials that have NOTHING to do with image recognition,9,12,False,False,False,learnmachinelearning,1496305137,True,"It's so hard to google when EVERYTHING tensorflow is about image recognition.

All I simply want to learn is how to take 2 variable arbitrary numerical inputs and get 1 numerical output and train for the max of that output.... (find the inputs that give the highest output, eventually I'll have 7 or so)

I will be feeding to/from an external program, which is trivial in python."
Learn Colors with Cars for Children - Learn Colours for Kids With Loplli...,0,0,False,False,False,learnmachinelearning,1496318269,False, 
Cheat Sheet of Machine Learning and Python (and Math) Cheat Sheets,0,1,False,False,False,learnmachinelearning,1496318320,False, 
The machine learning paradox - O'Reilly Media,0,4,False,False,False,learnmachinelearning,1496322684,False, 
Code for Tensorflow Machine Learning Cookbook,2,26,False,False,False,learnmachinelearning,1496323069,False, 
Get started with machine learning using Python,0,3,False,False,False,learnmachinelearning,1496331028,False, 
A Big Data Cheat Sheet: From Narrow AI to General AI,1,3,False,False,False,learnmachinelearning,1496332262,False, 
"What chance does a good developer, but with bad math skills, have at making it in ML?",3,1,False,False,False,learnmachinelearning,1496339328,True,"Kind of as the title suggests, I'm a full-stack developer of 10+ years, pretty deep into my career already. I did not go the CS route, and am self taught. I also have a legit ""learning disability"" when it comes to advanced math, i.e. anything above basic algebra. 

But on the other hand, I've learned a lot on my own, enough to hack together a damn respectable resume'. And I've decided that machine learning is ""my shit"". I've already been dabbling here and there by applying other peoples utils to do things like classify text by language, match up titles of drugs by similarity using Jaccard similarity , and sentiment analysis.

 But I don't know a thing about the underlying science of how that's calculated. 

But regardless, I want ""in"". Is there space in the ML world for somebody to become good at ""applied machine learning""? Can I get jobs by just wiring up other libraries, knowing how to do ETL operations, and such? Or do I really need to know the science and math behind it?  I just want to make cool applications that present data and information that's been massaged by ML routines, I can do everything else around that. I specialize in presentation of data analytics, but it's mostly all SQL based stuff.

Thoughts on where I may fit in, in this realm?"
How to set up and install Python libraries on Windows?,11,2,False,False,False,learnmachinelearning,1496348048,True,"I'm testing the waters a little bit, so I'm not planning to install Ubuntu or use a VM to run Linux. I originally tried using bash on Windows, but the kernel kept crashing when I tried opening a jupyter notebook. Installing using pip has also been difficult especially for scipy and matplotlib. 

Some other forums online suggest downloading anaconda, which even now I'm not too sure what it does. For other windows users, how did you set up a workspace for using Python?"
Weekly Show-off!,0,4,False,False,False,learnmachinelearning,1496387573,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
"Which python ML library should I use? (Theano/lasagne, Tensorflow, Keras, etc)",11,22,False,False,False,learnmachinelearning,1496407140,True,"I had already gotten started with theano/lasagne but I noticed Tensorflow has a much larger support network (check out #tensorflow at freenode, compared to #theano or #keras). 

What ML library do you use?"
Noob here... how to train a network on linear data (frequency related to position in time),1,6,False,False,False,learnmachinelearning,1496420018,True,"I want to start by saying I am very new to neural networks and coding. I have been thinking about a project, but I am unsure of how to start. I am working with MATLAB. I want to train a network to detect whether an audio file contains a male voice or a female voice in a noisy environment. I have been looking at the neural networking toolbox, but it looks like the sample data provided is not necessarily dependent on each other. The frequency value in my data is strictly dependent on its position in time. I have no idea how to show this relationship in code. Any help is appreciated. S"
While building a TF-IDF: Determining a good balance between Max and Min Document Frequency.,6,7,False,False,False,learnmachinelearning,1496421165,True,"I am using sklearns' TfidfVectorizer and I want to make a Tfidf in order to *capture the essence* of some wikipedia articles. This means I want to obtain only the **meaningfull** words while dropping the rest. The corpus size is 110k+ documents.

While I am aware of the principles around document frequency, I was curious what would be some good max_df's and min_df's amounts?

My idea so far is that min_df should be around 0,2 of the documents and max_df around 0,4 - 0,5. I am leaning towards this scheme because I want the essence of the document, not extraordinary terms nor garbage terms. But with those amount I am getting pretty terrible terms... But I am not using a stopword list either, because I would like those terms to be removed by the df filters. But I am considering using one in any case.

Any thoughts?"
What is the technical basis of claims by AI experts that say has many years before it is able to compete with humans?,0,1,False,False,False,learnmachinelearning,1496443259,False,[deleted]
What are the technical challanges that keep AI from being as good as human as some tasks?,9,8,False,False,False,learnmachinelearning,1496443936,True,"I keep reading articles that say things like ""Experts predict AI at human level intelligence by 2045""... But the articles never give a technical reason for it to take so long. They just present the conculsions of the experts. What is actually keeping AI from being better at different human fields? Isn't it basically a bunch of math and hardware problems? Why would that take 30 years to solve?"
What do I gain by using kNN on this problem?,2,1,False,False,False,learnmachinelearning,1496448509,True,"I have 4 classes. I have population means for 8 metrics for each class. 

I've classified ~600 samples by taking the euclidean distance to each of the metrics and summing over the whole class. Repeat for all four classes. Whichever class has the minimum is the winner. 

Now, I'm going to continue to gather samples over time. I want to classify each sample as it comes in. Do I gain anything by using k nearest neighbors rather than just comparing against the population means?"
How do you do segmentation based on energy variance?,0,2,False,False,False,learnmachinelearning,1496452257,True,"I'm doing a gesture recognition project and want to segment data by energy levels. I'm using Python, but I have no idea where to learn how to do this. The function I got from a paper was the integral from -infinity to +infinity of the signal at time t squared. I'm not sure what threshold I should use to decide if a current gesture is being performed. As in, what value of the signal would I start segmenting it? I've normalized the data from the accelerometer to be from -1 to 1. "
I am a Computer Science student looking to start learning ML. Does anyone know any good resources to get started and/or does anyone have any advice for a beginner?,8,12,False,False,False,learnmachinelearning,1496452533,True,"I realize the question is vague, but anything helps! "
Best ConvNet for my problem?,0,1,False,False,False,learnmachinelearning,1496453098,True,"Hi guys,

Apologies for the simple question.

I have a bunch of labelled data (~10K images) and would like to do image recognition of a class of objects. Moreover, I would like to train a model to be able to draw bounding boxes on the target objects. 

I have already used this tool to draw bounding boxes for all of my training/test images: https://github.com/davisking/dlib/tree/master/tools/imglab and spit this data into an XML file.

Now I'm trying to figure out the best neural net library to use to train a model, where I can feed it my XML file, or easily convert my XML file to a format it accepts. Preferably a straightforward python library where I don't have to do a lot of manual tuning. 

I'm overwhelmed by all the options. Any suggestions? Thanks."
Several questions about a wildlife modeling problem,0,2,False,False,False,learnmachinelearning,1496460690,True,"Hi guys,

My background is in ML but I have very limited experience with neural nets. I'm doing a side project to increase my knowledge.

I'm working on an image classification project where I'd like to identify the species of wildlife in photos. For context, I have about 200 classes and 1K positively labelled examples per class. I'd like to train a neural net to solve this problem. 

1. I'd like to try building an app around the model, and be able to use that app to classify new wildlife I see when I'm in nature (no internet). That means the model would need to be downloaded with the app, and need to locally run classification of new images. Is this feasible from a computational/space perspective? Does this restrict what model or library I should use?

2. How do I know whether I should stack models? Specifically, I know that the background environment of the photo will be predictive in classifying the wildlife. For instance, is the animal on grass, in a tree, in an urban area, etc. I'm considering training another NN just to classify the ecology of the background of wildlife photos (into about 25 classes), and feed that ecology output into the NN that classifies the wildlife. Alternatively, I could just hope that the wildlife NN can learn the importance of the background ecology by itself. Since training the ecology NN would be expensive (I don't have those labels yet) I'd like some intuition about how useful it would be. Any ideas?

Thanks in advance! "
"Weekly Scrum Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",5,4,False,False,False,learnmachinelearning,1496473828,True,"Let's have a scrum meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
[Q] Kreyszig or something more rigorous?,1,2,False,False,False,learnmachinelearning,1496491883,True,[deleted]
Implementation of sklearn RandomForestRegressor - stuck after encoding,1,1,False,False,False,learnmachinelearning,1496500081,True,Nevermind. See below. I figured it out!
Will machine learning ever be in the domain of web development?,6,3,False,False,False,learnmachinelearning,1496517155,True,"I'm a web developer and I hate my job and the industry and my coworkers. It's pretty much a fashion industry with arbitrary rules and trends and idiot lemmings running from one thing to the next. They have their head stuck in the sand and they want the world to stay the same. They want to feel like how they did when just knowing how to code was enough to make you special. Well coding is getting easier, if not more paint by numbers, and I'm just sick of the whole scene. It's pseudo-intellectualism makes me sick. 

I'm sure many of you are developers and of course I am not talking about you. I'm just talking about the developers that I know and my impression of the industry.

I've been studying math for the last few years with the sole purpose of being able to do machine learning (and also 3d graphing). My worst? ...Yes, my absolute worst fear is that machine learning will get so easy that those developers will follow me. After I've put in all this work I don't want Joe Awesome Web Developer to be able to do **more** than I can by just using AWS or Azure or some other ML API. 

Will I have any advantage because I understand the math and can implement the algorithms on my own? "
Creating a dataset to train for CNN image classification,1,3,False,False,False,learnmachinelearning,1496521966,True,"Hey guys,

currently, I am diving into the topic of machine learning with neural networks. Now I thought about using neural networks to solve one of my own problems. It looks like I need to craft my own dataset to train a neural network, or at least retrain one of the popular nets like inception from Google. 

Is there any guide out there how many data you need to train a neural network from scratch? How many training data per class, how many test data? Is there any scientific approach to this problem? If not, can you guys share ur experience? Does the dataset run into limitations with and extremely high number of classes (let's say more than 5000?). How do I label such a huge amount of data efficiently? Is there any step I need to pay attention to while taking photos of the objects?

Does the dataset for a ""simple"" classification net differ from a detection net? Do I have to train the detection net with different images, for example, images that do not contain one class but several classes? And how does labeling work with this dataset?

I appreciate all input to my question and I'm thankful in advance."
"What does ""scaled by"" mean in ""something scaled by something""?",3,1,False,False,False,learnmachinelearning,1496525475,True,"I'm doing the [machine learning course of Coursera](https://www.coursera.org/learn/machine-learning/home/welcome). I don't understand what ""scaled by"" means, I'm not a native speaker. I don't know if it means multiply, divide or something else.

Here are two sentences:

* ""**scaled by** sigmoid gradient of z2""
* ""Theta1_grad and Theta2_grad are the same size as their respective Deltas, just **scaled by** 1/m""

Thank you!"
Bayes Theorem explained using a simple story,0,43,False,False,False,learnmachinelearning,1496525771,False, 
Classification of handwritten characters - really stuck!,0,1,False,False,False,learnmachinelearning,1496526329,True,"Hello!
I started implementing classification of handwritten characters in python for a project. I'm new to machine learning and I was trying to implement logical regression for multiclass classification, but I'm pretty sure I got lost along the way. I watched the videos from Andrew Ng course, read half a book on The Perceptron Algorithm and multiple turtorials and after a week I really don't know where to go from here. Do you know any materials that would help me? I'm not familiar with libraries in python specifically designed for ML and I was trying to implement the code from scratch like I did with previous assignments.

My main concern right now is optimisation problem and finding the values of w. And I'm not sure if I should add some tresholds for the classes. And if so, should this also be optimised as parameters?

I'm attaching a link to what I created so far, but I'm thinking about dumping it all and starting again.

https://pastebin.com/MBw082Wr

I'm really desperate and I would appreciate all the help and motivation. Thank you!
"
What is the rule of thumb regarding training data ratio of variance vs. volume?,1,1,False,False,False,learnmachinelearning,1496530708,True,[deleted]
Ideas for ML project at internship,2,3,False,False,False,learnmachinelearning,1496532773,True,[deleted]
Overview of ML approaches,1,4,False,False,False,learnmachinelearning,1496546108,True,"Can someone point me to some readings/videos which summarizes the different areas of ML and how they are related: neural networks, probabilistic graphical models, GANs, etc.?"
Anyone know of similar tutorial sites like kaggle's 'getting started' page?,1,11,False,False,False,learnmachinelearning,1496548632,True,"the page I'm referring to:

https://www.kaggle.com/wiki/GettingStarted

I want to learn mostly data science, and I want to get a ton more practical statistics experience. I'm not really looking for a course sized website like udacity, just some tutorials that walk through building and analyzing data sets out there. I feel like I'd be able to get stats exp if I do a few of these."
"Learning with a project, need suggestions",1,2,False,False,False,learnmachinelearning,1496551780,True,"OK so I thought it'd be better if I start learning by making a project. 


This is the project: https://github.com/craftbase/chicago-murders


I have scraped the data from https://www.dnainfo.com/chicago/2017-chicago-murders


The data contains below in CSV format

> Date, Name, Age, Race, Time, Cause, Neighborhood, Address


How can I make use of the above data to predict the murders? Which algorithm or approach should I follow? "
Deep Learning | Udacity - YouTube,1,4,False,False,False,learnmachinelearning,1496553569,False,[deleted]
Question on using EM to infer missing data on a latent factor method (collaborative filtering) model.,0,2,False,False,False,learnmachinelearning,1496553666,True,"The full question was posted on [Stack Exchange] (https://stats.stackexchange.com/questions/283414/using-the-em-algorithm-on-a-latent-factor-model-collaborative-filtering) but I wanted to post here as well.

So the general question that I have is -- I have a latent factor model that incorporates some item-specific information (specifically: genres of movies) into the model.

The problem is that in my dataset, some movies lack genre information. Now I can (and have) simply removed those entries to train, but I wanted to see if I could use EM to optimize the model.

My questions boil down to 2 main ones:

1) On the M-step, it seems computationally intensive to have to update my parameters (e.g., α, βi) each iteration of EM. When I used EM on Bayesian nets, we had closed form solutions for the update rule, instead of using a numerical optimization method such as gradient descent. Am I missing a closed form formulation?

2) On the E-step, I understand conceptually I want to estimate the value of the ""hidden"" parameters. In my particular case, the hidden parameters are whether each movie (without genre information) falls into a particular genre. So I want to infer that.

But I'm not sure how to mathematically state this, and therefore how to code it. 

Can anyone help me out?"
Image classification with images in cloud?,1,3,False,False,False,learnmachinelearning,1496557560,True,"Hi guys,

I'm using TensorFlow for an image classification problem.

The issue is that I have about 1000 images for each of 200 classes. At an average of 200kb per image (they are 1280p), this amounts to  40gB of space. I don't have that much space on my personal laptop, so the images are all on the internet and I have not downloaded them locally.

Is there any way to get tensorflow to accept images located on the internet?

Also, any advice on what quality of image is needed for good image classification? Is 1280p overkill?

Thanks!"
Sklearn predictors that require One-Hot vectors?,1,7,False,False,False,learnmachinelearning,1496613905,True,"I'm working through some Sklearn and I recently found out that some of the predictors expect One-Hot vectors rather than just encoded vectors. Does anyone know of a full listing fully describing this?

Also, should the one-hot only just be on the output of my predictor (as well as the training label) or should I also encode the variables of my input data (where it makes sense to, obviously) "
how do i interpret the SVD matrix for a LSA result?,3,6,False,False,False,learnmachinelearning,1496616303,True,"First, I'm not even sure if I am writing this correctly so please advise me. I want to learn! 
Second, I am not understanding how to interpret the result. How does each number correspond to the word?

Please explain in layman's terms as I have been looking everywhere and I do not understand it. And I feel like interpretation just kind of stops at this matrix.

Example:

    strings = [doc1, doc2, doc3]
    words = [""cupcake"",""bacon"",""ipsum"", ""lucas"",""dolor""]

    # =====
    #count words, sorts col by most freq word and TFIDF function....suppose it is correct
    # =====

    df_TFIDF = TFIDF(df)
    new_df = df_TFIDF.dot(df_TFIDF.transpose())
    U,sigma,V = linalg.svd(new_df, full_matrices= True) 
    new_a = np.dot(U, np.dot(np.diag(sigma), V))
    print(new_a)

MY new_a is:

    [[  9.61216394e-02   3.85809556e-02  -2.70328123e-18  -1.69149356e-17  7.78234101e-03]
     [  3.85809556e-02   2.21407602e-02   5.36306029e-18   7.43162102e-18  7.78234101e-03]
     [  2.17420317e-20  -7.60971111e-20   1.62166066e-19  -4.01216850e-20    1.08710159e-19]
     [ -2.72148563e-17  -1.57703055e-17  -1.53574811e-18   1.34105440e-01    4.94943278e-02]
     [  7.78234101e-03   7.78234101e-03   3.91188381e-18   4.94943278e-02   2.21580543e-02]]"
Should I be concerned using sigmoid activation function for NNs?,6,4,False,False,False,learnmachinelearning,1496627111,True,"The NN section of Andrew Ng's coursera course always used the sigmoid activation function. I understand why this was used for the output layer (the NNs were used for classification, and so like logistic regression we needed values between 0 and 1). However, I'm not sure I understand why it was used on the hidden layer (do you even need an activation function? If so, why, and what properties are desirable/necessary?).

Furthermore, in the activation functions section of the TensorFlow Machine Learning Cookbook, it says ""The sigmoid is not often used because of the tendency to zero-out the backpropagation terms during training."" Can someone help explain why this is and why/when it might be a problem?"
Need help with how to diagnose training and validation metrics,2,2,False,False,False,learnmachinelearning,1496662042,True,"I'm currently learning to build a DNN binary classification model on some dataset. But when I analysed the results, I found it counter-intuitive that the training accuracy changed almost at the same rate as the validation accuracy. So did the losses. And they all reached a plateau at some point. How could I possibly improve the model performance at this stage? Here's a snippet of the results:
    
    fold: 0 epoch: 0 batch: 0
    training loss: 0.674389 validation loss: 0.67371
    training accuracy: 0.656331 validation accuracy: 0.656968
    Fold: 0 epoch: 0 batch: 500
    training loss: 0.527997 validation loss: 0.527813
    training accuracy: 0.734021 validation accuracy: 0.733639
    Fold: 0 epoch: 0 batch: 1000
    training loss: 0.526019 validation loss: 0.526277
    training accuracy: 0.736067 validation accuracy: 0.735111
    Fold: 0 epoch: 0 batch: 1500
    training loss: 0.525466 validation loss: 0.525721
    training accuracy: 0.736672 validation accuracy: 0.73532
    Fold: 1 epoch: 0 batch: 0
    training loss: 0.525416 validation loss: 0.525261
    training accuracy: 0.735794 validation accuracy: 0.736488
    Fold: 1 epoch: 0 batch: 500
    training loss: 0.525751 validation loss: 0.525623
    training accuracy: 0.735472 validation accuracy: 0.735887
    Fold: 1 epoch: 0 batch: 1000
    training loss: 0.525579 validation loss: 0.525459
    training accuracy: 0.735538 validation accuracy: 0.736077 "
Is it worth getting into machine learning for me?,16,22,False,False,False,learnmachinelearning,1496665627,True,"I'm 17 years old high school student (finishing next year). I have about 5 years of experience in software development and last 3 years of it doing commercial projects for the clients. This year I came upon the topic of machine learning and I decided to check it out. I was pretty fascinated by it and did few applications on small data sets.

Now, I can't decide whether I should just keep doing current job or dive in machine learning resources. I never had good grades in math throughout high school (and I was told I'm not born for maths) but this summer I decided to brush up my skills and I realized I love to do math. I spent spare time repeating things from primary and high school on Khan Academy and I became much more confident in my math knowledge and started to understand some things which were confusing for me before. Now I do exercises from textbooks and use Expii.

I heard that 90% of machine learning engineers have master degrees but I'm certainly sure I'm still not ready for university level of maths. That's not the only obstacle; even if I had the chance to get in university, there are no machine learning curriculums in my country. I really like ML and I'm very ambitious and disciplined, but I'm concerned it's not enough to get into this sector."
Foundations for Deep Learning,0,2,False,False,False,learnmachinelearning,1496673568,False, 
Implementing K Means Clustering from Scratch - in Python,0,1,False,False,False,learnmachinelearning,1496674860,False, 
How to extract features from variable duration time-series data?,3,1,False,False,False,learnmachinelearning,1496686221,True,"up vote
0
down vote
favorite
I have 4 different data sets with samples of time-series measurements of different actions. The duration (# data points) of each measurement in the different sets is:

    Set # 1 = 40000 data points  
    Set # 2 = 8000 data points
    Set # 3 = 5000 data points 
    Set # 4 = 40000 data points 

My plan was to have a window size of 100 data points over which to calculate features such (mean, kurtosis, variance..etc); however, since the time-series measurements are of different lengths, would it be appropriate to adjust the window size for each set so that I will have the same number of features across all samples? Or is there a better approach?

The purpose of these features is for multi-class classification using an svm or random forests model."
Criticisms on my data analysis work?,2,3,False,False,False,learnmachinelearning,1496686899,True,"Hey all,

I was wondering if there's a specific subreddit/discord channel or something where I can go to get feedback on my data analysis work. I've chosen to do some work on the New York crime data - basically predicting the type of crime. The link to my notebooks is [exploration notebook and prediction notebook](https://github.com/IanQS/Machine-Learning-mini-projects/tree/master/data_exploration)

I do have some self-criticisms but I'm not sure how to address them so I'm hoping the collective wisdom here can help? 

**Explore:**

1) Map data. I've plotted it but ""so what""? I don't know how to draw any conclusions from it. Anyone have any resources? 

2) I've dropped some variables, for example datetime (dd/mm/YY) and kept day month year, since I reason that the model should be able to ""reconstruct"" the datetime if all of it turns out to be important. I'm not sure if this is a valid assumption, or if what I'm doing is wise. 

**Predict:**

1) I'm defining ""correct"" if the class is the same, but I feel like my error function is wrong. I feel like I should be using cross entropy during the training process but I have no idea how to do that...

2) I feel like using real numbers to represent my classes is wrong and that I should be using One-Hot Vectors since there's no real ""distance"" between a class 1 and a class 2. I'm not sure if this opinion of mine is correct.

Also, I figure I should probably share the dataset. I'm not sure what the common method is so if people could suggest that it would be much appreciated"
What's the best method to solve this problem?,0,1,False,False,False,learnmachinelearning,1496693991,True,[deleted]
Why does Keras' `predict` function run fast on a GPU?,1,1,False,False,False,learnmachinelearning,1496706651,True,"I understand why keras' fit_generator runs more quickly on a GPU, but why does predict also more quickly?

It's too bad, it'd be nice if it were able to run quickly on a CPU for practical use in IoT."
Which Framework to use for Multivariate regression,4,9,False,False,False,learnmachinelearning,1496716126,True,"I want to use ANN to help with linear regression in an engineering problem. A quick google search and wikipedia shows that there a myriad of ANN libraries available. 

The most popular seems to be python based with Tensorflow leading the pack. However, [this] (https://stackoverflow.com/questions/33720645/why-is-this-tensorflow-implementation-vastly-less-successful-than-matlabs-nn) question seems to suggest that TensorFlaw is not as good as Matlab for linear regression.

Can somebody suggest me a good ANN library to use for linear regression? Atm, i am not interested in logistic regression or classification."
Help with multi-label classification from 2 features,0,3,False,False,False,learnmachinelearning,1496720808,True,"<Python>Hello, I need to classify data consisting of 2 features: a part number and a sentence and then assign a label to them.  So it is very similar to this StackOverflow [question](https://stackoverflow.com/questions/10526579/use-scikit-learn-to-classify-into-multiple-categories)  except that instead of one column (sentence), I have another feature like a part #.  Is there a scikit-learn classifier I can use where I have a numeric feature and a sentence feature that I can label?  In the 2nd cell of this [notebook](http://nbviewer.jupyter.org/gist/anonymous/5c6b6ea061b7519e20170031a46ec412), I was hoping if I add the part number to each of my row data, that would work, but got an error.  I'm assuming I am missing the correct classifier or processor to handle a 2nd column.  Thanks for any help on this."
"Noob attempt, Unable to fit a straight line using Keras",6,4,False,False,False,learnmachinelearning,1496778179,True,"Hello,
I am trying to use keras to fit a straight line y=5x+10. Unfortunately, I am getting a very high Mean Square Error.

Any idea what could be wrong?

    from keras.models import Sequential
	from keras.layers.core import Dense
	import numpy as np
	import random
	import matplotlib.pyplot as plt

	a=5
	b=10
	all_data_list=[]
	for x in range(1,1000):
		y=a*x+b
		all_data_list=all_data_list+[x,y]



	all_data=np.array(all_data_list)
	all_data=all_data.reshape(999,2)


	X_train = all_data[:, 0]
	Y_train = all_data[:, 1]



	model = Sequential()
	model.add(Dense(10, input_dim=1, kernel_initializer='uniform', activation='sigmoid'))
	model.add(Dense(1, kernel_initializer='uniform', activation='linear'))

	# Compile model
	model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])

	# Fit the model
	model.fit(X_train, Y_train, epochs=300, batch_size=100, verbose=2)

--------------------------
Epoch 299/300
0s - loss: 8215848.8108 - acc: 0.0000e+00

Epoch 300/300
0s - loss: 8215306.5480 - acc: 0.0000e+00"
Using Tensorflow on EC2?,1,2,False,False,False,learnmachinelearning,1496807136,True,[deleted]
Resources for understanding of tensorflow internals?,1,7,False,False,False,learnmachinelearning,1496810430,True,"Hello, I find myself needing to modify this https://github.com/ibab/tensorflow-wavenet so that I can call the generate portion repeatedly in a persistent framework and get a few predictions each time. My current issue is that when I attempt to call it the second time, it says it is unable to load the saved model, even after adding a sess.close() at the end.

Rewriting this properly for my use case would enable me to skip repeating the preprocessing steps ideally, and replace in-session state values with new ones of what actually happened. So therefore I need to understand much more about tensorflow sessions, graphs, running a session, etc. I'm poking through the docs now but would very much appreciate an in-depth tutorial or blog post."
https://www.reddit.com/r/MachineLearning/comments/6fro6v/image_recognition_for_beginners/?st=J3MLUP98&sh=03b0bb76,1,1,False,False,False,learnmachinelearning,1496816449,True,[removed]
TWIL (This Week I Learned) - Share something new that you have learned this week!,6,7,False,False,False,learnmachinelearning,1496819479,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
The simple things to know about independent events,0,1,False,False,False,learnmachinelearning,1496832449,False,[deleted]
"First ML project, would love some hints",4,6,False,False,False,learnmachinelearning,1496835439,True,"Hi,
I am looking into machine learning and to get started I have decided on a hopefully fairly contained project. 

However I am having an issue finding guides or examples that deal with using machine learning for other things than image or word classification. I would therefore be very grateful for any tips on where I can find them.

As for the project I am trying to train a model on 50ish factors for each country in the world and would like to run predictions on the effect of changes to one of the factors in a specific country.

This also where I really lack guides on how to use the trained model for that type of scenario.

*Edit:*
To extend my idea which as it turns out might not be a perfect fit for machine learning:

The target is to create a model that predicts the effects of changes of one factor in a system of socioeconomic factors. 
The model would be based on historical data from ""all"" the countries of the world. An example question to the model would be for it to predict the changes in median salary based if the employment rate rises with 1%.

I hope that clarifies the goal a bit, if this isn't a good fit for a machine learning project I might have to continue my search for a good project to get to grips with ML."
The simple things to know about Independent Events.,0,3,False,False,False,learnmachinelearning,1496838131,False, 
"27 Machine Learning, Python and Math Cheat Sheets",0,1,False,False,False,learnmachinelearning,1496857027,False, 
"DecisionTreeClassifiers doing fairly well at prediction KNN, RF and XGB doing very poorly. Am I overfitting?",1,5,False,False,False,learnmachinelearning,1496857320,True,"First my data set is about 2 months worth of 1min time series data. I have scaled the features and I see some strong correlations in the TS data to the events I'm trying to predict. However, the only algorithm that seems to be doing well is the DecisionTrees. I know these tend to overfit a dataset so I'm wondering if that's what i'm seeing. I would think the other algorithms would have some level of success as well but they are not currently. I have also run GaussianNB classifier which makes way too many wrong guess but seems to show a predictive trend in the guesses(i.e. predicting the event multiple times before the event early but ultimately predicting it correctly). Any thoughts on what might be wrong and how I can start improving my results?"
What are the logos on this subreddit thumbnail?,8,6,False,False,False,learnmachinelearning,1496860202,True,"This is quite a noob question but I don't recognise all the logos on this subreddit thumbnail and I can't seem to be able to reverse search the image in google image. So I'm asking here because I'm probably missing out on some great tools or communities, thanks for your time and sorry for the the dumb question."
How I Built a Reverse Image Search with Machine Learning and TensorFlow: Part 2,0,21,False,False,False,learnmachinelearning,1496873429,False, 
A developer trying to find the matrix form of gradient descent via backprop,1,6,False,False,False,learnmachinelearning,1496877678,False, 
A machine learning model to predict twitter bots,1,14,False,False,False,learnmachinelearning,1496879054,True,"Hi guys!

I've been trying to build a model to identify whether a particular user's profile is suspected of being a bot account. These accounts exhibit several characteristic tell-tale signs like impossibly large numbers of tweets and followers, accounts that are only a few months old, or twitter feeds comprised nearly entirely of retweets. Here are a couple of examples:

https://twitter.com/LuvMyLife____ (7000+ tweets since May) https://twitter.com/matt_urban1a (nearly all retweets)

I developed a really simple web app where you can submit a twitter profile, and the app will try and predict whether or not the individual is a bot. You can then give feedback as to whether or not the guess was correct. Can someone give it a try and see how it works? The tweet must be in the full URL format like the examples given above. Your feedback (clicking ""correct"" or ""incorrect"" after submission) will make the algorithm better. The site is here:

http://valkommen.pythonanywhere.com/

Let me know how it works!"
[Help] Time-Series Data Anomaly Detection,0,3,False,False,False,learnmachinelearning,1496879294,True,"Hey all!

I'm fairly new to data science stuff(this is my first project), so any pointers are very much appreciated. 


I am trying to create a model to predict/classify anomalies in time-series data. You can think of it as fitbit-esque data, and I'm looking to detect abnormal decreases in steps taken throughout multiple days and also intraday. 


I'm currently starting off with some traditional ML techniques, specifically One-Class SVMs, Isolation Forest, and maybe PCA. before attempting some more advanced methods like LSTM.

However, I am not sure how to represent the data properly. I am able to run just the steps through the algorithm ([see IsolationForest code example](http://imgur.com/a/h2LlW)) and it gives me a prediction of which values seem to be outliers, but I don't think it is taking into factor the time-period at all.

Can someone take a look?

Thanks in advance!


"
"""Advanced Machine Learning with Python"" free today",0,2,False,False,False,learnmachinelearning,1496881634,True,"PacketPublishing gives away a book every day for free. You do need to create an account to get it, but that means you can add it to your account and can download it whenever you want.

Today's book is ""Advanced Machine Learning with Python"" and it's available (as all the future free books) at this page: https://www.packtpub.com/packt/offers/free-learning

This is the book on amazon if you want to read the reviews: https://www.amazon.com/product-reviews/1784398632/"
Understanding Machine Learning with Python (Pluralsight course free for 1 week),2,12,False,False,False,learnmachinelearning,1496890465,False, 
Сurrent state of anomaly detection algorithms for time series,0,16,False,False,False,learnmachinelearning,1496928330,False, 
Best pre-trained image recognition model compatible with iOS/Android?,0,7,False,False,False,learnmachinelearning,1496930062,True,"Hey guys,

I'm trying to figure out what best pre-trained image recognition model can be run on iOS/Android. 

From some quick research, it looks like Caffe2 is a good tool to use. I've seen tutorials suggesting Squeezenet can be used on Caffe2, with ~57% top-1 accuracy on Imagenet (which seems low to me). Based on some quick googling, I couldn't find evidence that Inception or other superior models work on Caffe2?

Is there any better alternative?"
How much faster are 3x3 kernels than larger kernels in TensorFlow?,1,7,False,False,False,learnmachinelearning,1496930281,True,"I believe there are some numerical tricks employed to speed up the 3x3 convolution, but not the other kernel sizes. Is that true? Precisely how much faster in terms of compute time is a ConvNet with 3x3 kernels, rather than using larger kernels, given that the same number of total parameters are used (but just distributed differently in depth and width)."
"Free, on-line video lectures for statistical learning",4,3,False,False,False,learnmachinelearning,1496948911,True,"Hi all. I am preparing an exam (Stochastic Methods) and I am looking for a free, on-line course with video lectures to deepen some of the topics related to statistical learning. I found a huge number of courses and I am not able to pick one (time, unfortunately, is limited). One of my favorite is the course ""An Introduction to Statistics Learning"" (YouTube lectures), but it lacks some topics. Are you aware of any on-line course (with video lectures) that follows, more or less, ""The Elements of Statistical Learning"" or ""Pattern Recognition and Machine learning"" by Bishop? I am NOT looking for a Coursera & Co. course, though. Any help is appreciated!"
tensorflow queues,0,5,False,False,False,learnmachinelearning,1496956708,True,"Hi all, I've got a set of about 40k images in 27 categories that I'm trying to classify, and I'm having a lot of trouble even getting them into the graph.  What I think I want is to have labels and images in a queue that I can read batches from.

Here's what I've got:
    # Start with a file containing a list of images, 
    # the category is extracted from the filename and
    # converted to an integer
    def readImageList(infile):
        categories = ""0ABCDEFGHIJKLMNOPQRSTUVWXYZ""
        f = open(infile, 'r')
        filenames = []
        labels = []
        for line in f:
            label = line.split(""/"")[-2]
            tag = categories.index(label)
            labels.append(tag)
            filenames.append(line.strip())
    return (filenames, labels)

    imageList, labelList = readImageList(sourceFile)
    batchSize = 80
    # lists to tensors
    images = tf.convert_to_tensor(imageList, dtype=tf.string)
    labels = tf.convert_to_tensor(labelList, dtype=tf.int32)
    lx = tf.one_hot(labels, 27)
    # create a queue to load and process images, and make the
    # compute nodes to do the work
    filename_queue = tf.train.string_input_producer(images, num_epochs=epochSize, shuffle=True)
    image_reader = tf.WholeFileReader()
    fn, image_file = image_reader.read(filename_queue)
    image = tf.image.decode_png(image_file, channels=3)
    image.set_shape([200, 320, 3])
    image = tf.to_float(image)

    numPreprocessThreads = 1
    minQueue = 256

    imageBatch = tf.train.batch([image], batch_size=batchSize,
        num_threads=numPreprocessThreads,
        capacity = minQueue + 3*batchSize)
    labelBatch = tf.train.batch([lx], batch_size=batchSize, 
        num_threads=numPreprocessThreads,
        capacity = minQueue + 3*batchSize)

The next part is stuff I don't got.

    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        sess.run(tf.local_variables_initializer())
        coord = tf.train.Coordinator()
        threads = tf.train.start_queue_runners(coord=coord)
        ibx,lbx = sess.run([imageBatch, labelBatch])

The ibx tensor looks correct, of size (80, 200, 320, 3), but the lbx tensor has everything in it, and is of size (80, 42636, 27)

If I stick with image filenames for now, and use tf.train.shuffle_batch:

    imageBatch, labelBatch = tf.train.shuffle_batch([images, lx], batch_size=batchSize, 
        num_threads=1,
        capacity=50000,min_after_dequeue=10000,enqueue_many=True)

then 
    ibx,lbx = sess.run([imageBatch, labelBatch])
gives a correct lbx tensor of size (80,27) and a filename tensor of size (80,).  I can then write a function:
     def LI(filename):
         file = tf.read_file(filename)
         data = tf.image.decode_png(file, channels=3)
         data.set_shape([200, 320, 3])
         data = tf.to_float(data)
        return data

and do this:
     sbx = tf.stack(list(map(LI, list(ibx))))
to get sbx of size (80, 200, 320, 3) which is what I want.

My questions include:
* Is what I want (i.e. batches of size (80,27) and (80,200,320,3), with the expectation that I'll eventually have layers to turn (200,320,3) into (27)) the correct thing to want?
* I feel like I must be over-complicating things somehow, is there an obvious place that I'm going wrong?

(I've read a whole bunch of tutorials and SO guides and it seems like everybody just wants to tell me how to read MNIST/CIFAR/imagenet instead of my own data....)

thanks!"
"Normalization & Classification -- Different Scales, Different Underlying distributions",2,1,False,False,False,learnmachinelearning,1496961083,True,[deleted]
Real-world NN architecture for multiple object in image?,5,8,False,False,False,learnmachinelearning,1496965230,True,"To give an example with a cat classifier: if I have many images of cats against a blank background, how do I train a NN classifier to identify a cat, and overcome three obstacles:

1. Classify as cat even when the background is different than blank.
2. Classify as cat even if it is closer or further from the camera
3. Classify all the cats in the image

Questions:

1. What is the easiest/best established NN architecture for that type of problem?
2. How can you solve obstacle #2 without images of cats that are near and cats that are far? (because that many images would take a lot more computing power to train)

---

I learned a lot of the theory lately, but am having trouble putting it all together. I keep coming across Machine Learning techniques that sound vaguely like what I need, but the only way to find out if they are is to dig into them and study them. This is not a good goal oriented approach :)

So I would really appriciate if you can go into detail about how to implement this, what the different components are, how they iteract. I'm pretty sure that this is a common enough problem that NNs solve, that it is understood by the community in way that can be explained in some detail. Thanks!

Edit: I'm looking for a pictural sort of explaination. e.g. ""The CNN feeds into the RNN that feeds into fully connected layer"" and then why each of those matters."
"For logistic cost function, why do we need to consider cases (y=1 and y=0) ? Why we do not need to do so for mean square error cost function ?",9,6,False,False,False,learnmachinelearning,1496978059,False, 
How to train a neural network in a game context,2,5,False,False,False,learnmachinelearning,1496988133,True,"I'm currently trying to use a neural network to play the nim game (with k heaps and a maximum of 3 object removed per turn). Basic Q-learning did great, now I want to try a NN for the task.

I could train a NN with backpropagation and gradient descent on some examples, that's what I'm coding right now but I don't expect it to generalize, and it's not interesting to give all the possible combination and the perfect moves to learn. I'm more interested in something that learns against itself with random moves, just like Q-learning.

Now if the NN only knows when he lost or won, there's no cost function, no way of knowing in which direction to push the weights? I'm still reading but I'll definitely try an evolutionary approach, but I'm curious if there's a way closer to q-learning but for NN (or with a NN).

edit: ended up trying the evolutionnary way, it kinda worked but it requires a lot of processing power even for a simple game of Nim"
Gene Kogan - Picasso's terminal; data science and AI in the visual arts,0,3,False,False,False,learnmachinelearning,1496988139,False, 
Weekly Show-off!,5,7,False,False,False,learnmachinelearning,1496992353,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
Machine Learning Algorithms - A Detailed Tutorial,0,25,False,False,False,learnmachinelearning,1496996702,False, 
Crowdsourcing for Machine Learning,0,1,False,False,False,learnmachinelearning,1497026450,False, 
[Help] LSTM for next character prediction,3,2,False,False,False,learnmachinelearning,1497027336,True,"Hi everyone.

I'm trying to train a Recurrent Neural Network to, using a 100-character string as input, predict the next character. However, the output text ends repeating itself over and over, instead of actually predicting text according to the input.

I've used Python + Keras (over Theano) and followed this tutorial: http://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/. I'm using the architecture specified for the second example (two LSTM layers with 256 units each, with a dropout probability of 0.2, and a dense output layer with an output unit for each of the possible characters to output) and a dataset of about 200 KB. I've run 50 epochs with a batch size of 64. 

This is the input sentence I used (it's in Spanish):

	 hincó de rodillas ante él, diciéndole:

	-no me levantaré jamás de donde estoy, valeroso caball

And this is the result I got (seed + predictions):

 	 hincó de rodillas ante él, diciéndole:
         
	-no me levantaré jamás de donde estoy, valeroso caballero, que estaba diciendo:
         
	-ste que se dice -dijo el cura-, y el cual se dejare a su amo de la mancha, estaba diciendo:
        
	-ste que se dice -dijo el cura-, y el cual se dejare a su amo de la mancha, estaba diciendo:
        
	-ste que se dice -dijo el cura-, y el cual se dejare a su amo de la mancha, estaba diciendo:

I've tried the following approaches to improve the results, but none of them have solved the problem.

- Using an English dataset (as there are fewer possible output characters)
- Increasing the size of the dataset to about 4 MB
- Using more epochs (75).

Right now I'm trying to increase the Dropout probability to 0.5, but the problem is that I don't have a lot of computational power available and the training will last at least a week or two. Therefore, I'd like to know if there's any obvious mistake I didn't see before trying more changes. Maybe the dataset is too small? Maybe the dropout probability was too low? Maybe I need more layers? 

Of course, if there's any part of my problem or my approach that I haven't made clear enough, don't hesitate to ask me for more details about it. In case it's necessary, the complete code I've used can be found [on my Github] [1] (I haven't uploaded the results of the changes I've mentioned because they were very similar to the one that is already on the repository)

Thank you so much in advance for all your help!

[1]: https://github.com/AlexGascon/playing-with-keras/blob/master/%232%20-%20Text%20generation%20with%20(larger)%20LSTM%20Recurrent%20Neural%20Network/Text%20generation%20with%20(larger)%20LSTM%20Recurrent%20Neural%20Network.ipynb"
What is a good distribution to provide to sklearn RandomSearchCV?,0,1,False,False,False,learnmachinelearning,1497029269,True,"RandomSearchCV wants either a list of values, or a distribution object. I typically see people pass in value lists for parameters like C or epsilon like: [0.001, 0.01, 0.1, 1, 10]. So typically increasing by an order of magnitude each step. What distribution should I use to approximate this behavior? A uniform distribution from 1 to 10 would almost never fall below .1. "
Are there private tutors for Machine Learning?,15,7,False,False,False,learnmachinelearning,1497031580,True,"I'd like to pay someone to teach me how to solve a project I'm working on that requires Machine Learning.

Any subject in Math or ML that comes up during the project, that I need to learn in order to reach the goal of completion of the project, he/she will teach it to me while we work the problem. 

Basically I need help navigating all the lectures and courses out there. And I need help with how each ML subject I learn helps in relation to my goal.

Are there teachers like that out there online? Where do I look up good ML teachers? Maybe an ML consultant?"
A general purpose Seq2Seq package using TensorFlow. (tf ver. 1.2.rc1),1,2,False,False,False,learnmachinelearning,1497032478,False, 
Interactive tutorial: beginner's introduction to generative adversarial networks (GANs) with TensorFlow,0,19,False,False,False,learnmachinelearning,1497032666,False, 
ArrayFire vs. OpenCV? [x-post from /r/machinelearningquestions],0,2,False,False,False,learnmachinelearning,1497033993,True,"Greetings,

I'm currently working at an internship where my boss and I want to build an application that can process images obtained from various cameras placed at different locations in a facility. I've been researching different frameworks and libraries that work with the CUDA environment, and this brought me to ArrayFire and OpenCV. Does anyone here have any particular recommendations for or against using either of these two libraries for computer vision development? Is there a different framework we should try instead?

Thank you."
Learn the law of total probability with simple visuals.,4,8,False,False,False,learnmachinelearning,1497061681,False, 
"Tutorials and implementations for ""Self-normalizing networks""",1,11,False,False,False,learnmachinelearning,1497065301,False, 
"Weekly Scrum Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",0,3,False,False,False,learnmachinelearning,1497078619,True,"Let's have a scrum meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
What are the best lightweight python IDE's for machine learning?,14,5,False,False,False,learnmachinelearning,1497113185,True,I have a very low memory system and I am looking for a lightweight IDE for machine learning  in python. I had already tried pycharm and spyder but both are heavy for my low memory system. Do you have any recommendations for lightweight IDEs.
Where can I learn how to read these diagrams?,6,23,False,False,False,learnmachinelearning,1497118688,False, 
Are there methods for finding out how informative each input node is to specific output of DNN?,1,3,False,False,False,learnmachinelearning,1497123674,True,"Is there a method that allows computing the importance of each position in an input vector to producing specific values in the output layer?

In my specific case, I am training a DNN to predict behavioural variables from fMRI data. I turn the fMRI voxel data into a single vector and train the DNN to predict a behavioural variable. I would like to find out which parts of that vector are most useful for the DNN in predicting the behavioural variable, so that I could find the area in the brain that provides this information.

Somewhat related information that I've found so far is about finding the visual features the lead to a certain output. For example here: http://yosinski.com/deepvis
This is based on starting with a random input and then iteratively approximating an input that provides the output in question. However, it is not apparent to me if it is possible to find the importance of specific input nodes to the output.

Is this perhaps impossible to really quantify information content of each individual input node, because the network can combine information from all the input nodes in a too many different ways?

Perhaps a solution would be to set a single input node to zero during testing and do this for each of the input nodes? This would show how lack of information from each node affects the output accuracy.

Edit: Wording."
"Hey guys, newbie here who needs your direction with my first project..",1,3,False,False,False,learnmachinelearning,1497134247,True,"I have web scrapped a decent data set of coloured images. Now, I would like to use TensorFlow to cluster the similar images together into something like a t-SNE visualisation. 

What's the right way to do that? 

Thank you!"
Understanding fully connected layers,3,3,False,False,False,learnmachinelearning,1497140726,True,"I just need a confirmation of what it means to be a fully connected layer as opposed to a sparsely connected layer. Am I correct in assuming, a fully connected layer receives a non-zero set of weights from the previous layer? 

Also, since each hidden neuron might receive one weight from each neuron of the previous layer, do all of those weights need to be non zero or is it enough if the dot product of weights with current neuron results in a non-zero value?"
Multiclass object recognition,1,1,False,False,False,learnmachinelearning,1497191405,True,"Hi a newbie here,

I was reading across object recognition papers and did some reading on how the architectures have evolved​ over time from Alexnet to Residualnet for object recognition. Then I even read up on a few papers that combine object detection + recognition such as faster-rcnn, Yolos. 
Here are my generic doubts related to these topics
How many classes can you train at max with the classification algorithms? 
Let us assume I trained a cnn for 1000 classes today but tomorrow I want it to learn a 1000 more would retraining it 2k classes be the best solution or is there an online learning algorithm which can keep on learning new classes but not forget the old ones? 

Can this online learning algorithm be combined with YOLO or faster-rcnn 

Appreciate any guidance!"
Resources for Evolutionary Algorithms,6,9,False,False,False,learnmachinelearning,1497198064,True,"What are the best resources for an introduction to evolutionary algorithms? A Google search only came up with textbooks, which is fine if that's the best that's available but thought I'd check here as well. Are there any MOOCs or blog post primers out there? Thanks in advance for your help.

Edit: I found some more resources searching for ""Genetic Algorithms"" instead. Here's an excellent blog post primer with example code in JavaScript: https://www.burakkanber.com/blog/machine-learning-genetic-algorithms-part-1-javascript/"
Implementing a Gaussian Mixture Model with code for plotting (<150 lines). Examples included.,0,3,False,False,False,learnmachinelearning,1497198681,False, 
Factorizing 5x5 into 3x3 convolutions,2,1,False,False,False,learnmachinelearning,1497200270,True,"On page 3 of the [Inception v2 paper] (https://arxiv.org/pdf/1512.00567.pdf), they talk about converting 5x5 convolutions into two 3x3 convolutions. I understand why the 5x5 has 25 parameters, and why the factorized version has 18 parameters. 

However, it seems like the 5x5 requires 25 mult-adds, and the factorized version requires 90. My reasoning is that the first 3x3 conv layer has 9 neurons that each do 9 mult-adds (for a total of 81), and the second 3x3 layer has to do an additional 9. 

But the paper says the amount of computation for the factorized version compared to the 5x5 version, is 18/25. What part of my calculation is incorrect?"
Are there examples for using machine learning with GPUs (CUDA) without the use of a ML library like Tensorflow,2,6,False,False,False,learnmachinelearning,1497203368,True,"I want to play around with GPU programming using CUDA for machine learning (specifically deep learning). I know libraries like Tensorflow have GPU support, but I want to be able to do the calculations myself to play around with CUDA.

I haven't been able to find any tutorials or examples that use CUDA outside of ML libraries that do all the calculations for you. I tried going through the Tensorflow code to understand how it uses CUDA, but it is pretty complex. I was hoping for a smaller example. Any examples would be very helpful."
"[Code] Visualizing RNNs using the ""Attention"" mechanism",0,1,False,False,False,learnmachinelearning,1497211373,False,[deleted]
Appropriate model for data sizes for NLP,1,1,False,False,False,learnmachinelearning,1497213351,True,"I'm trying to write an application for document classification

I've been reading this page from stanford: 

https://nlp.stanford.edu/IR-book/html/htmledition/choosing-what-kind-of-classifier-to-use-1.html

in the last paragraph it reads 

""If there is a reasonable amount of labeled data, then you are in the perfect position to use everything that we have presented about text classification. For instance, you may wish to use an SVM.""

What does reasonable mean in this context? I know it depends on a large number of factors so I don't expect a hard number but some considerations or a ballpark would be great"
Exploring LSTMs,0,5,False,False,False,learnmachinelearning,1497220565,False, 
Monthly ELI5 (Explain Like I am Five) Thread,6,3,False,False,False,learnmachinelearning,1497223262,True,"Top comments need to be in the format of: `ELI5 $CONCEPT_NAME` and the replies should provide a clear explanation in a layman's term.
Here are the relevant rules from /r/explainlikeimfive breaking down the meaning of ""ELI5"":

- E is for Explain - merely answering a question is not enough.

- LI5 means friendly, simplified and layman-accessible explanations - not responses aimed at literal five-year-olds.
"
Deep learning and machine learning cheat sheets,1,30,False,False,False,learnmachinelearning,1497231399,False, 
SVM analytical gradient calculus question (cs231n question),1,1,False,False,False,learnmachinelearning,1497234551,True,"For the third equation under [this section in the notes](http://cs231n.github.io/optimization-1/#analytic)

I'm hoping my tex works below:

`[; \nabla_{w_j} L_i = \mathbb{1}(w_j^Tx_i - w_{y_i}^Tx_i + \Delta > 0) x_i ;]`

The summation is removed in the derivative wrt the incorrect class, why is that? Are we not still adding up the losses?

thank you
"
"How do you know when you're ""done"" with a dataset?",1,5,False,False,False,learnmachinelearning,1497255167,True,"I've racked my brains working on a dataset to try and improve the classification scores. I understand that it's an iterative process but right now I'm out of ideas but I still feel very unsatisfied. At the same time I don't know if I'm missing something obvious or anything so I guess my questions are the following:

1) do you have a personal checklist of what to do / try in different situations? If so would you share it with me? 

2) At what point should I just throw in the towel and move on? I know that it's not always possible to see good scores depending on dataset + quality of work but I also don't know when I'm giving up and when there is nothing within my capabilities to do."
"Model learns up to a point, then the training loss plateaus.",1,3,False,False,False,learnmachinelearning,1497255490,True,[deleted]
ML Thesis help with libraries and tools,0,2,False,False,False,learnmachinelearning,1497262549,True,"Hi Guys, first of all i am new to this reddit and ML, i am also more than beginner with Java. 

For my thesis, Ive got a Attribute-Value mapping java class. I have to edit this class so it can always learn from every mapping it registers. I was wondering, could anybody please suggest me which way would be better for me? Neural Network or Rule-based-systems, and which libraries are better for me? 

Thank you very much in advane "
Multiobjective learning. Need some guidance.,0,2,False,False,False,learnmachinelearning,1497279869,True,"I need to improve a classifier with some other network (say an autoencoder, by using feature-extraction). I know nothing about multiobjective optimization, and I find papers with stuff like ""Pareto optimal vectors"". Literally have no idea what that means. All I know so far is that, if you train two models together, on the same dataset, towards different objectives (say image reconstruction and classification), sometimes the classifier does better. 

I am in desperate need of articles related to this, any kind of introduction, anything that would help me. Thanks ! "
Understanding and implementing CNNs from scratch,15,36,False,False,False,learnmachinelearning,1497289371,True,"Hey Guys,

I have written a **series of articles aimed at helping people understand how CNNs (convolutional neural networks) really work by working through the maths and implementing all the layers used in CNNs from scratch with just Numpy**. Writing these articles has helped me gain a lot of insight into how the deep learning libraries are structured, how gradients are calculated and flowed through the network and how such complex ideas are actually implemented.

[deepnotes.io/implementing-cnn](http://deepnotes.io/implementing-cnn)

I hope these articles will be of some help to people who want to dig in and nail the conceptual and implementation details of CNNs.

**Update**: Complete code can be found here: 

https://github.com/parasdahal/deepnet"
Understanding ANN Objective Functions,5,1,False,False,False,learnmachinelearning,1497306622,True,"Correct me if I'm wrong but I understand that objective functions in an ANN (or any other optimization) has to be convex in order for it to converge.

----

Let's say I want to combine multiple objective functions into one (loss = loss_A + loss_B).

My questions are:

1) Can you combine any functions (e.g. MSE + cosine) depending on your task? Are there any rule of thumbs?

2) Does training on the combined objective result in overall lower values for each term assuming it converges (e.g. values have lower MSE and cosine distance)

3) Do all the terms in your objective have to be convex or just one term in order to have a viable objective function?

4) Any sites I can read up on this that's easy to digest (e.g. understandable for a biologist/fine arts major)?"
Nuno Castro - Ranking hotel images using deep learning,0,6,False,False,False,learnmachinelearning,1497329827,False, 
How would you feed data into an RNN?,6,6,False,False,False,learnmachinelearning,1497348293,True,"I would appreciate some help in explaining how data must be fed into an RNN:
- Do RNNs need labels since the next timestep is often the 'y' value in an RNN.
- How would you feed input into an RNN to produce predictions? Would you have to feed a sentence in literally?
- There are many ways to use an RNN, one-many, many-one, many-many. Are there any examples available on how I should format the data?"
syntactic reordering,0,2,False,False,False,learnmachinelearning,1497356443,True,"Hi to all,

i just started learning LSTM in order to use this kind of RNN networks for my thesis, syntactic reordering for machin translation. actually i know the bases of LSTM and got familiar with them. but my problem is how to identify weights as well as activation function for each LSTM block. i also want to know when can i use each block for changing the order of words?"
"Clustering binary values (0,0,0,1,0,0) against single values (10.50)",2,3,False,False,False,learnmachinelearning,1497359551,True,"I have a dataset that looks like this:

|   Group  |  X  |     
| --- | --- | 
| [0, 0, 0, 0, 0, 0, 0, 1, 0] |  10  |    
| [0, 0, 0, 0, 0, 1, 0, 0, 0] |  15  |    
| [0, 0, 0, 0, 0, 0, 0, 0, 1] |  7  |    
| [0, 0, 0, 0, 0, 0, 0, 1, 0] |  11  |    
| [0, 0, 0, 0, 0, 1, 0, 0, 0] |  15  |    
| [0, 0, 1, 0, 0, 0, 0, 0, 0] |  20  |    
.....

Representing a graph database with values corresponding to nodes. I was wondering if there was any way to cluster this type of data (i.e. somehow develop a distance metric for the binary values)?

Any help or advice is much appreciated.

EDIT: I will describe the problem I am facing in more detail.

I have a dataset that is encoded with a medical hierarchical terminoly system that represents an acyclic directed graph. In my dataset I have 9 ""diseases"": F0,F1,F2,F3,F4,F5,F6,F7,F8 that are represented by the following graph http://imgur.com/a/oK3ur. The more u go down in the tree, the more specific the disease gets (i.e.: F0 = lung cancer, F8 = Malignant Tumor in Left Lung). 

The nodes are related, in that a patient that has F8 also falls under the term F4, F1 and F0. In other words, if I say to my database: Give me all patients who have F0, it will return my all patients in my dataset. As an example: If I have 1000 patients with F7 & 1000 Patients with F8, then F4 will consist of 2000 patients (F7+F8) plus the patients that are solely marked with F4 (another 1000) for a total of F4 (F7+F8+F4) = 3000 patients. 

Every patient in a node has been given a value representing something like 'Life Expectancy' that is normally distributed. My goal is to find nodes that are outliers or cause a deviation (i.e.: F0 has a mean of 15, Patients with F4 have a mean of 4 and are an outlier). I was trying to represent the nodes in a binary way (i.e. F0 = 1,0,0,0,0,0,0,0,0 and F8 = (1,1,0,0,1,0,0,0,1 --> because a patient that has F8 also falls under F4, F1 and F0) and in this way relate the nodes to eachother. Then cluster these two values together.

I am not sure if I am going at this the right way, it is probably pretty confusing (to explain aswell)."
ML notes: Why the log-likelihood?,1,4,False,False,False,learnmachinelearning,1497367893,False, 
Looking for 'intuition' on techniques for recognizing knock patterns.,4,6,False,False,False,learnmachinelearning,1497373600,True,"I've been teaching myself the Keras API through various projects. (to start, I taught a LSTM how to play a simple game I wrote)

Now I'd like to recognize someone knocking a board in a specific pattern (shave-and-a-hair-cut--two-bits). I'm not having much luck. 

I recorded several knock sounds and several stretches of ambient audio. I then wrote a little app that outputs random knock sequences, quiet sequences and sequences that match the correct pattern. I used this to make 500 training files. 

I SFTF each file with a frame size of 2^10 and then create time slices that look ahead 9 samples. My ""y"" values are all zero except for the final bit of the final slice of the sequence (if it's a ""positive"" sequence).

I then feed these into a LSTM layer like so. 

model = Sequential()
model.add(LSTM(32, batch_input_shape=(batchSize, trainX.shape[1],look_forward,)))
model.add(Dense(1))
model.compile(loss='mean_squared_error', optimizer='adam')

My thinking here was that the LSTM would learn what a ""knock"" looked liked and would learn the sequence of them that yields ""positive"" results. 

That doesn't seem to be happening :/  I've tried playing with the various parameters. I've tried making the network stateful (I think). I've tried feeding in batches vs entire samples. 

Is this too much subtly for a single LSTM to recognize? Perhaps an LSTM isn't the right tool to use here? What would you all suggest?"
Problems while trying to build an RNN in TensorFlow. How to properly shape/build a numpy array for use with the TF graph nodes?,0,1,False,False,False,learnmachinelearning,1497379879,True,[deleted]
Visual analysis and diagnostic tools to facilitate machine learning model selection.,0,6,False,False,False,learnmachinelearning,1497424173,False, 
TWIL (This Week I Learned) - Share something new that you have learned this week!,4,6,False,False,False,learnmachinelearning,1497424267,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
how to know if my tensorflow is really running on gpu?,6,12,False,False,False,learnmachinelearning,1497433581,True,"Hi guys, I have a gtx 1050ti. I installed the cuda, cudnn v5.1, python v3.5. Previously I installed anaconda (but it's only for python 3.6 and I've encountered few troubles to install TF). 

when i run the code below it shows gpu:0 (which is my gtx1050ti)
`sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))`

but Ive seen alot of article online that when 
`import tensorflow as tf`
this will show up
`I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally`
`I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally`
`I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally`
`I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally`
`I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally`

^ it doesnt run on mine when i execute the `import tensorflow as tf`

Im a bit confused whether the TF program runs successfully on GPU or not"
[Beginner's Guide] Machine Learning applied in stock trading.,1,10,False,False,False,learnmachinelearning,1497438173,False, 
Understanding The Difference Between ERP And WMS,0,1,False,False,False,learnmachinelearning,1497445779,False, 
Columbia AI Micromasters,0,4,False,False,False,learnmachinelearning,1497453643,True,"What are people's opinions on this Micromasters (edx)?

I'm doing the Machine Learning and AI segments following the Stanford/Coursera course and am fairly impressed."
I wrote a blog post summarising a new research paper - Facebook Research just published an awesome paper on learning hierarchical representations,0,23,False,False,False,learnmachinelearning,1497457609,False, 
Do larger neural networks take longer to train?,4,4,False,False,False,learnmachinelearning,1497462015,True,[deleted]
I'd like to be a data scientist later on. Should I study Computer Science or Math?,28,4,False,False,False,learnmachinelearning,1497476377,True,Everything is in the title
LSTM and multi-variable regression,3,4,False,False,False,learnmachinelearning,1497489332,True,"This [blog] (http://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/) has an example of using LSTM which has a single 'Y' value. 

My data is of the form:

     X1, X2, X3, Y1, Y2

Is there any Keras example which considers multi-variable regression using LSTM?"
"""Unbounded"" Multi Label Classification?",0,2,False,False,False,learnmachinelearning,1497494634,True,"Not sure how to describe what I am looking for to search for articles on it, and I'm hoping you guys can help.

I have a bunch of passages of text. Each passage should be tagged with zero or more tags (label) -- This is considered multi-label classification, correct? 

Now, if I want to apply the same thing, but with an unbounded set of tags (e.g.: I would like the ability to add additional tags at a later date by providing more training and validation data), is there an existing algorithm that would enable this kind of machine learning?

Ideally, what I would like to do is tag concepts to passage of text, and enable my algorithm to learn high-level concepts such that I can ask what articles it knows about contain these high-level concepts. "
Language detection from video (no sound),1,6,False,False,False,learnmachinelearning,1497505784,True,"Hi, I have found nothing about it on google so I am asking here.

Do you know if there are any research (and if possible dataset) about detecting language from a video but without using the sound ? Like, you provide a video of a person talking (but without the audio) and the algorithm gives it guess on which language the person is using."
Machine Learning -Hands On Python and R In Data Science,1,9,False,False,False,learnmachinelearning,1497527879,False, 
Data Version Control - using Github with cloud storages for iterative ML and collaboration on DS projects,0,2,False,False,False,learnmachinelearning,1497529159,False, 
How to learn prerequisite maths for machine learning?,8,7,False,False,False,learnmachinelearning,1497532893,True,"Hi,

I understand that one needs to be competent in linear algebra, multivariable calculus, and probability in order to properly use machine learning. I have no real background in maths other than in high school and i'm currently taking a non maths course in university (medicine). Does anyone have any advice in which books or courses to do in order to brush up on the necessary mathematics?"
Easy q - is my model overfitting?,0,1,False,False,False,learnmachinelearning,1497537006,True,[deleted]
Implementing Gaussian Log Likelihood in Tensorflow,2,3,False,False,False,learnmachinelearning,1497538248,False, 
Zero to One — A Ton of Awe-Inspiring Deep Learning Demos with Code for Beginners,0,29,False,False,False,learnmachinelearning,1497540193,False, 
10 buzzwords to know about neural networks,2,0,False,False,False,learnmachinelearning,1497563865,False,[deleted]
Applying Q-Learning to a Shifting Action Space?,1,3,False,False,False,learnmachinelearning,1497566789,True,[deleted]
Andrew Rowan - Bayesian Deep Learning with Edward (and a trick using Dropout),0,16,False,False,False,learnmachinelearning,1497585276,False, 
How to get confidence interval from RNN?,0,3,False,False,False,learnmachinelearning,1497586613,False, 
Complete guide to artificial intelligence and machine learning,0,0,False,False,False,learnmachinelearning,1497588543,False,[deleted]
Weekly Show-off!,0,8,False,False,False,learnmachinelearning,1497597153,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
Unstable MLP's accuracy on train dataset,3,2,False,False,False,learnmachinelearning,1497607116,False, 
Bricklaying,0,0,False,False,False,learnmachinelearning,1497607854,False, 
"What is ""Probability""?",0,1,False,False,False,learnmachinelearning,1497611588,False, 
Resources for understanding of pytorch internals?,3,6,False,False,False,learnmachinelearning,1497615416,True,is there some resource or tutorials for understand pytorch internals?
Think Before You Buy an AC Supply,0,0,False,False,False,learnmachinelearning,1497620031,False, 
will wolf,0,1,False,False,False,learnmachinelearning,1497621788,False,[deleted]
Random Effects Neural Networks in Edward and Keras,0,3,False,False,False,learnmachinelearning,1497622440,False, 
How do I debug my q-learning solution for OpenAI's cartpole?,5,3,False,False,False,learnmachinelearning,1497623256,True,"I tried to solve the cartpole game from OpenAI's gym using q-learning, but my implementation scores lower than the baseline (choosing random actions): https://pastebin.com/8wGn0LkA

Could anyone provide any suggestions or tips on how to go about debugging the algorithm? It's hard to inspect my q-learning state space because it's so large, and I can't think of any other good techniques for finding the bugs in my code.

I'm more interested in learning debugging techniques because I'd like to be more self sufficient, but feel free to mention any problems you see in the code as well. Thank you!"
Resources for NLP,1,2,False,False,False,learnmachinelearning,1497623451,True,"I am new in field of machine learning. I have learnt very basic things like regression , classification, and  neural networks. Now I want to do a project that involves natural language processing. Could someone share beginner friendly resources for NLP preferably in ‌python."
Learn Machine Learning with Python - Hands on,0,0,False,False,False,learnmachinelearning,1497624745,False,[deleted]
A quick question regarding implementing A3C and actor critic networks in general,0,1,False,False,False,learnmachinelearning,1497635479,True,"I was working on implementing the A3C algorithm and I came across this problem. When I tried to create my actor and critic models in separate networks, the models would fail to converge to a reasonable policy 9/10 times. However I noticed when looking at other A3C implementations, they would have just one network that would take in a state and output an action and a value. When I switched to that it worked perfectly.

My question is why is that? I was under the impression actor and critic models were meant to be separate networks, and even so, is there a particular reason why keeping them in separate networks would mean it wouldn't be able to converge?

For context the loss function was the same, all that was changed was going from two networks, one would output action the other the value, to one network that would output both.

Any and all help hugely appreciated, thank you!"
Machine learning for detecting stock market pump.,5,11,False,False,False,learnmachinelearning,1497635704,True,"Hello,

I have recently enrolled in Georgia Techs OMSCS specializing in machine learning. I want to get my feet wet and learn as much as I can about machine learning before  the fall. I have to decided to do a small project that has probably been done before many times. I am interested in training an algorithm to search for patterns that indicate a possible pump in a stock. Can anyone point me to papers or resources?  Thanks. 

EDIT: I do know that predicting stock prices is nearly impossible. I am just doing a project to learn machine learning. "
Implementing project using recommender system,2,5,False,False,False,learnmachinelearning,1497635968,True,I have a basic knowledge of machine learning. Specifically I know regression and neural networks. What would be the best way to implement a recommender system? Can it be done using neural networks?
The Terrible Deep Learning List - 15 working examples to get you started with Deep Learning,0,17,False,False,False,learnmachinelearning,1497656517,False, 
[P] Automatic Reddit Categorizer update (first version working!),2,3,False,False,False,learnmachinelearning,1497658205,True,"Yesterday I asked a few people about creating a program that can [automatically categorize reddit submission into appropriate sub-reddit using Title text](https://www.reddit.com/r/MachineLearning/comments/6hc8tg/r_automatically_categorizing_reddit_submission/).

The first version is ready and it works!

https://www.youtube.com/watch?v=gudnFNBXc58



A lot of people helped me yesterday and thanks to comments by /u/deltasheep1 and /u/olBaa I was able to create it. It is very bad code right now since I just learned python programming and my knowledge of ML is very limited (mainly sentdex videos), but I feel super happy that I was able to create this program.

Here is how I did it (please bear with me because I know I'm a total noob)

1. First Run this Google Big Query
 
    SELECT
  subreddit,
  title
FROM
  [fh-bigquery:reddit_posts.2017_03],
  [fh-bigquery:reddit_posts.2017_02],
  [fh-bigquery:reddit_posts.2017_01],
  [fh-bigquery:reddit_posts.2016_12],
  [fh-bigquery:reddit_posts.2016_11],
  [fh-bigquery:reddit_posts.2016_10],
  [fh-bigquery:reddit_posts.2016_09],
WHERE
  subreddit IN ('programming',
    'business',
    'design',
    'entertainment',
    'science',
    'security',
    'worldnews',
    'politics',
    'mobile',
    'startups',
    'google',
    'microsoft',
    'bitcoin',
    'facebook',
    'amazon',
    'movies',
    'gadgets',
    'technology',
    'linux',
    'gaming',
    'apple',
    'design',
    'music'
    )

2. Then export the results into a Table and export it again to a CSV file to your Google storage bucket

    http://imgur.com/a/0REvN

3. Then install Google Data Labs and Create a notebook

    https://cloud.google.com/datalab/

4. Then use the following program to run it!

    https://storage.googleapis.com/superasn/script.html


I've still got a lot to learn and my next challenge is to create a small webpage so that people can enter the title in a web form and it shows the correct sub-reddit using it."
Help deciding which Statistics courses to take,0,1,False,False,False,learnmachinelearning,1497662486,True,"X-post from /r/AskStatistics

I'm going to be a junior in college soon, and I need help choosing between different statistics courses! I'm very much interested in Machine Learning and Data science, but I'm not sure which Statistics courses will help for that, if I decide to attend graduate school. I'm hoping to complete a minor in either Math or Stats, but I'm not too focused on the official title, rather the material I'll learn. Any help is appreciated!! Here's some course sequences I'm deciding between: 

1. Probability and Stochastic Processes (In the Math Department, 3 courses): Basic concepts of random variables, distributions, independence, correlations, moments, limit theorems, conditional probability, Markov chains, gambler's ruin, branching process, birth and death processes, numerical simulations in Matlab. / Exponential distributions, Poisson processes, continuous time Markov chains, renewal theory, insurance ruin and claim problems, numerical simulations in Matlab. / Martingales, Invariance Principle, Brownian motions and applications in option pricing, stationary processes and applications in Wiener filter, numerical simulations in Matlab. 

2. Statistical Methods for Data Analysis (3 courses): Introduction to statistical methods for analyzing data from experiments and surveys. Methods covered include two-sample procedures, analysis of variance, simple and multiple linear regression. / Emphasizes application and understanding of methods for categorical data including contingency tables, logistic and Poisson regression, loglinear models. / Topics covered include survival methods for censored time-to-event data, linear mixed models, non-linear mixed effects models, and generalized estimating equations. 

3. Introduction to Probability and Statistics (3 courses): Introduction to basic principles of probability and statistical inference. Axiomatic definition of probability, random variables, probability distributions, expectation. / Point estimation, interval estimating, and testing hypotheses, Bayesian approaches to inference. / Linear regression, analysis or variance, model checking. 

4. Introduction to Bayesian Data Analysis (1 course): Basic Bayesian concepts and methods with emphasis on data analysis. Special emphasis on specification of prior distributions. Development for one-two samples and on to binary, Poisson, and linear regression. Analyses performed using free OpenBugs software. 

5. Multivariate Statistical Methods (1 course): Theory and application of multivariate statistical methods. Topics include statistical inference for the multivariate normal model and its extensions to multiple samples and regression, use of statistical packages for data visualization and reduction, discriminant analysis, cluster analysis, and factor analysis. 

6. Linear Algebra (2 courses) 

7. Numerical Analysis (2 courses) 

8. Real Analysis (1-3 courses) "
Twitter bot of Anderson Cooper trained using LSTM,2,11,False,False,False,learnmachinelearning,1497668572,False, 
PyData Tel Aviv Meetup: Amir Balaish | Attention Models,0,3,False,False,False,learnmachinelearning,1497671240,False, 
My experiment to locate myself indoors using Logistic Regression on wireless AP signal data,2,13,False,False,False,learnmachinelearning,1497671803,False, 
"Weekly Scrum Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",11,5,False,False,False,learnmachinelearning,1497683418,True,"Let's have a scrum meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
Machine Word - Flashcard for Kids - Starfall Learning English for childr...,0,1,False,False,False,learnmachinelearning,1497698257,False, 
Internships with only Python and R,7,8,False,False,False,learnmachinelearning,1497717815,True,Can anybody who has found an internship in Machine Learning with only prior knowledge of R and Python share the company or process they used to find such an internship?
"If, as a hobby, I want to work on a computer program that can play a drum solo based upon many past solos the program learnt, where should I start?",6,6,False,False,False,learnmachinelearning,1497718737,True,"Good programmer, completely new to machine learning."
[Python] Going from using calculus for gradient descent (in linear regression) to linear alegra -- vectorization,6,7,False,False,False,learnmachinelearning,1497731364,True,"I've been taking Andrew Ng's machine learning course on Coursera and reworking the problems in python. I found [this site](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-1/) and have been comparing my answers with his.

I have not yet grasped linear algebra fully and I'd like to know about something specific. In order to do (single variable) linear regression, my gradient descent func looked something like this:
    
    #hy is the hypothesis function
    #J is the cost function
    def gd(alpha,theta,h):
        #d = derivative of the cost function
        d = limit((J(theta+h)-J(theta))/h,h,0)
        if d != 0:
            print d,theta
            theta = theta -(alpha * d)
            
            gd(alpha,theta,h) 
            
        else:
            print 'convergence', d,theta
            cpoints = [hy(s,theta) for s in range(50)]
            plt.scatter(sizes,prices)
            plt.plot(cpoints)
            plt.axis([0,30,-20,40])
            plt.show()
        
        return theta

Where John's version looks like this:

    def gradientDescent(X, y, theta, alpha, iters):  
        temp = np.matrix(np.zeros(theta.shape))
        parameters = int(theta.ravel().shape[1])
        cost = np.zeros(iters)

        for i in range(iters):
            error = (X * theta.T) - y

            for j in range(parameters):
                term = np.multiply(error, X[:,j])
                temp[0,j] = theta[0,j] - ((alpha / len(X)) * np.sum(term))

            theta = temp
            cost[i] = computeCost(X, y, theta)

        return theta, cost

They both produce generally the same answer, but I'd like to learn how to do this with linear algebra. I want to know what is going on here:

    for j in range(parameters):
            term = np.multiply(error, X[:,j])
            temp[0,j] = theta[0,j] - ((alpha / len(X)) * np.sum(term))

Thanks in advance!"
Coefficient of Variation - a measure to compare datasets.,0,5,False,False,False,learnmachinelearning,1497735351,False, 
Just how import is the math behind machine learning,6,2,False,False,False,learnmachinelearning,1497739675,True,"So  I've been going through Andrew Ng's machine learning course and have gone through up to Support Vector Machines. While I feel I understand most of the intuition behind the algorithms, I'm definitely not following 100% with the math. 

For example, I get how gradient descent works towards finding a local minimum to optimize regression, but I don't totally understand the math behind why it works. However, at least from the playing around that I have done with scikit-learn so far, it doesn't seem to be necessary for me to understand every single step and exactly how/why it works. 

Is it of critical importance for me to fully understand every last bit of math, or will knowing generally how the algorithms work and which ones to use in which situations be enough? "
Tensorflow equivalent implementation for map,0,3,False,False,False,learnmachinelearning,1497793202,False,[deleted]
Machine Learning - Image Content Analysis,0,1,False,False,False,learnmachinelearning,1497798407,False,[deleted]
Machine Learning for Image Content Analysis,1,1,False,False,False,learnmachinelearning,1497801095,False, 
"Generative Models, VAE and true meaning of GANs",1,11,False,False,False,learnmachinelearning,1497801241,False, 
Machine Learning: A gentle introduction,6,35,False,False,False,learnmachinelearning,1497808030,False, 
Practical PyTorch: GridWorld with Reinforcement Learning (Policy Gradients with REINFORCE / Actor-Critic),3,3,False,False,False,learnmachinelearning,1497812194,False, 
Looking to create a chat bot that will emulate the writing style of a specific author.,0,1,False,False,False,learnmachinelearning,1497815923,True,"So, I've played around with simple chat bots using readily available chat logs that I could train my model on. Now, I'd like to play with the writing style of said chat bot. 

I'm a bit stuck on how to approach this. I could train a model to learn the authors text but I'm not sure how to get that learned text to properly respond to questions or statements. 

Any tips or recommendations would be much appreciated

[EDIT] I'll be using tensorflow
"
How to detect if two objects are the same without training?,4,4,False,False,False,learnmachinelearning,1497828423,True,"I'm very new to ML and have experimented with various ML frameworks.  Ive watched CalTechs course and started through the Stanford course, but I have a problem I'd love to understand better. 

Given two photos of cars is there an approach that would be able to tell if the two cars are the same (within a margin of error)? In this case, I would not want to train the specific vehicles in advance. Also the cars photos could be from slightly different perspectives. I.e. A front left, the left side, or the rear left. 

For example given a network of security cameras I would like to identify a car when it arrived, and identify (within a margin of error) when that car appears on a different camera. 

Any advice on approaches or feasibility would be appreciated. Thanks. "
A Guide to Blockwork,0,1,False,False,False,learnmachinelearning,1497829025,False, 
Implementing BPTT with LSTMs,4,2,False,False,False,learnmachinelearning,1497830660,True,"I've successfully implemented BP for the ordinary neural network, from scratch, and have experimented with small variations to BP/NNs. My implementation is generally equivalent to the how the algorithm is explained in *Artificial Intelligence a Modern Approach*.

I'm now wanting to implement BPTT with LSTMs. After reading [this](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) and [this](http://blog.echen.me/2017/05/30/exploring-lstms/), I feel I understand the feedforward portion well enough and the theory of gradient descent is very straight forward. However, I'm just not sure how to formulate BPTT with the LSTM structure. I believe I could easily extend BP to general RNNs but the internal mechanics of LSTMs are what I'm not sure about. I'm finding very few pages which even talk about training and even fewer talk about actually implementing it.

So what I'm wanting to know is, is there a relatively easy to implement algorithm for LSTMs like with BP and could you link me to it please?"
Getting Fireplace Builders Perfect Warm Space,0,1,False,False,False,learnmachinelearning,1497837824,False, 
How do 'forget gates' know not to remove essential information from the Cell State in an LSTM?,4,3,False,False,False,learnmachinelearning,1497838900,True, 
How to build a neural network whose outputs are generated only from its input classes,0,1,False,False,False,learnmachinelearning,1497845664,True,"To illustrate my point, for example, I want to train a NN that takes batches of sentences, and outputs the prepositions only from respective sentences. Like,

>Input 1: ""Alice is watching TV in the house."" >>
Output 1: ""in""

>Input 2: : ""Bob is standing outside the garage."" >> Output 2: ""outside""

What's the architecture of the kind of NN model?"
Variational Inference and Deep Learning: An Intuitive Introduction,0,8,False,False,False,learnmachinelearning,1497848753,False, 
Commercial Builders,0,1,False,False,False,learnmachinelearning,1497849715,False, 
How to make simple image classifier with 2 categories with my own set of images?,4,9,False,False,False,learnmachinelearning,1497855074,True,"I just want to create a simple python script that can try to classify an image as either rectangle or circle. All the images involved are simple black and white circles and triangles created in MSPaint.

I've googled and can only find how to do it with other photo sets, like the sets in ImageNet. Thanks."
How can I use a neural network to maximize the predicted output by optimizing the inputs?,2,3,False,False,False,learnmachinelearning,1497858241,True,"Say for example I had a data set about how plants grow, where the inputs are the plant growing conditions (e.g. temperature, weather, etc.) and the output is the height of the plant after 5 weeks. 

If I trained a neural network to best predict the height of the plant given the growing conditions, how could I use that neural network to find the optimal growing conditions?

The title of a paper or technique or any help really would be much appreciated, thanks"
AC Repair and Maintenance,0,1,False,False,False,learnmachinelearning,1497863183,False, 
Help With Simple Neural Network,3,2,False,False,False,learnmachinelearning,1497872872,True,"Hey guys, I tried making a basic neural network today for the very first time and I ran into a problem. For some reason, the cost value keeps jumping around and never seems to be reduced. Anyone know why?

I was following along with this video:
https://www.youtube.com/watch?v=gQLKufQ35VE


The cost looks like this the entire time it's training:
http://imgur.com/a/5ckb7


CODE (programming language: lua):

	-- training set
	local dataB1 = {2, 1, 0}		-- NOTE: [1] is number 2, [2] is number 1, [3] is number 0
	local dataB2 = {3, 1, 0}		-- NOTE: [1] are widths of flowers, [2] are heights of flowers and [3] is whether the flower is a sunflower or not
	local dataB3 = {2, .5, 0}
	local dataB4 = {1, 1, 0}

	local dataR1 = {3, 1.5, 1}
	local dataR2 = {3.5, .5, 1}
	local dataR3 = {4, 1.5, 1}
	local dataR4 = {5.5, 1, 1}

	local dataU = {4.5, 1, ""should be 1""}
	local all_points = {dataB1, dataB2, dataB3, dataB4, dataR1, dataR2, dataR3, dataR4}


	local function sigmoid(x)
		return 1/(1+math.exp(-x))
	end

	-- training
	local function train() 
		local w1 = math.random(1,10)	-- generates a random value between 1 and 10 (inclusive)
		local w2 = math.random(1,10)
		local b = math.random(1,10)
		local learning_rate = 0.2

		for i=1, 10000 do
			-- pick a random point
			local random_idx = math.floor(math.random(1,#all_points))	-- #all_points is the length of all_points
			local point = all_points[random_idx]
			local target = point[3]		--targets 3rd value of points

			-- feed forwards
			local z = w1 * point[1] + w2 * point[2] + b
			local pred = sigmoid(z)

			-- now we compare the model prediction with the target
			local cost = math.pow(pred - target, 2)		-- (pred - target)^2
			print(""cost: "" .. cost)		-- the '..' concatenates the text and the variable 


			-- derivatives below!
			local dcost_dpred = 2 * (pred - target)

			local dpred_dz = sigmoid(z) * (1-sigmoid(z))

			local dz_dw1 = point[1]
			local dz_dw2 = point[2]
			local dz_db = 1

			local dcost_dw1 = dcost_dpred * dpred_dz * dz_dw1
			local dcost_dw2 = dcost_dpred * dpred_dz * dz_dw2
			local dcost_db  = dcost_dpred * dpred_dz * dz_db

			-- now we update our parameters!
			-- as I want to update the already existing weights and bias, I have taken away local
			w1 = w1 - learning_rate * dcost_dw1
			w2 = w2 - learning_rate * dcost_dw2
			b = b - learning_rate * dcost_db
		end
	end

	train()
"
Practical Machine Learning With Python,5,23,False,False,False,learnmachinelearning,1497875810,False, 
Which neural network library should I use?,3,1,False,False,False,learnmachinelearning,1497881151,True,"My goal is to: a) understand neural networks and ""deep learning"" on a level deeper than applications, and b) use a library that is common enough that I'm not wasting my time learning it, and people will care that I've learned to use this library.

I am tempted to go with tensorflow since it looks relatively low level and pretty popular. Is this a good choice?

I know virtually nothing about neural networks, besides for the basic idea of how they work (watched the MIT open courseware lecture on them). "
A simple GAN in Keras,1,1,False,False,False,learnmachinelearning,1497881541,False, 
Neural Network Simulator - running in your browser.,0,3,False,False,False,learnmachinelearning,1497885599,False, 
Using ANNs on small data – Deep Learning vs. Xgboost,0,0,False,False,False,learnmachinelearning,1497891676,False, 
using kaggle to get started with machine learning,3,7,False,False,False,learnmachinelearning,1497901047,True,"Hi, Im pretty new to the field of machine learning. Is it a good idea to teach oneself machine learning by solving kaggle datasets? what are your thoughts?"
Guide to Buying Your New Home,0,1,False,False,False,learnmachinelearning,1497901860,False, 
[Advice] Would this pre-built be suitable for an ML beginner?,5,4,False,False,False,learnmachinelearning,1497902140,True,"A local store near me is offering this prebuilt computer from Microcenter for $649. 

[Here's a link](http://www.microcenter.com/product/474127/g221_desktop_computer)

Specs are as follows:

Core i5-7500 (3.4/3.8)

ASRock B250 Pro 4 Motherboard

16GB DDR4-2133 RAM (2x8GB)

256GB SATA SSD + 1TB SATA HDD

GTX1060 6GB (make of this card is unclear, as it looks anonymous in the pictures)

I'm just starting out in ML and currently have an old Core2Duo with a 750ti in it to run NLP models on, so I was curious if this would be a good price to get a more modern beginner rig that I can grow with as I learn more.

Thanks in advance for any feedback!
"
[1706.05137] One Model To Learn Them All,0,3,False,False,False,learnmachinelearning,1497911598,False, 
Bricklaying,0,1,False,False,False,learnmachinelearning,1497924944,False, 
General Building Contractor,0,1,False,False,False,learnmachinelearning,1497943993,False, 
Create Your Own Neural Network In few minutes In Python,0,1,False,False,False,learnmachinelearning,1497950642,False, 
Construction Project Management,0,1,False,False,False,learnmachinelearning,1497953129,False, 
Logistic Regression Explained - Machine Learning Algorithm Tutorial,0,8,False,False,False,learnmachinelearning,1497962483,False, 
Actuarial Science for Machine Learning?,19,7,False,False,False,learnmachinelearning,1497963156,True,"My job would pay for me to take actuarial exams as well as the review associated with them.

Would this be a decent use of time? Machine Learning and actuarial science seem like theyre really similar but I don't see much online about them being paired. It's all statistics right?

I see this as a way to steer my job towards something more ML oriented while obtaining more formal/accepted education in the area to apply to Masters programs with."
How to Build an Email Sentiment Analysis Bot: An NLP Tutorial,0,33,False,False,False,learnmachinelearning,1497964327,False, 
Is Machine Learning suitable for the problem I am trying to solve ?,4,2,False,False,False,learnmachinelearning,1497966583,True,"Hi All,

I have a specific problem I am trying to solve. I am trying to compare computer performance data (perfmon data) e.g. CPU over time, between Computer A and Computer B, to see if the CPU usage pattern is similar/following the same trend or pattern.

I am investigating ML as a route to finding a solution.  I have started to go though various beginners tutorials on ML and statistics. However, the more I learn, the larger the field becomes, to the point where I'm uncertain if I'm looking in the right areas.  So the first part of my question is using ML to find a solution sensible?  
Secondly, are there any particular areas to focus my learning on,  tools and libraries to use?

Thanks in advance :-)"
Hey I need help to rebuild a Sentiment Analysis project,0,1,False,False,False,learnmachinelearning,1497968695,True,"Hello !

I did a Twitter Sentiment Analysis project, that was completely made from Sentdex tutorials on YouTube. I might as well say I plagiarized the whole thing. I intend to build a new one from scratch so I get to know everything about it, and I know I need to study something for this. My questions are : 

1. How much and what do I need to know before I can start rebuilding the sentiment analysis project ? 

2. I can take the UoW Classification course if needed and the Stanford NLP course. Will they be helpful ?

3. I am planning to go through tutorials provided in Kaggle's [Bag of Words meets Bag of Popcorn](https://www.kaggle.com/c/word2vec-nlp-tutorial). Will it help ?

I have basic programming knowledge in Python, also am going through MIT's 6.00.1x course and know a few things about Machine Learning."
Advice on classifying data types from semi-structured and unstructured text data,0,2,False,False,False,learnmachinelearning,1497976540,True,"I'm somewhat stuck, I'd like to apply natural language processing techniques (or something similar) to identify primitive data types (I.e string, number, date, etc...) as well as be able to identify text as an entity of some sort (i.e cardinal may be referring to a bird). I'm receiving data from web applications and IoT devices and it can be in a free form text (string) or structured as json (keys and values are not known ahead of time).

I've tried to do some initial research and have come across a good bit for extracting entities from English text but I'm not sure my problem quite fits underneath that since I won't likely have sentences to derive any sort of context from. Any direction or material to reference that would help me get started would be a great help. Thanks"
Tensorflow in-depth tutorial?,2,12,False,False,False,learnmachinelearning,1497980941,True,"I am fairly acquainted with tensorflow now, after spending better part of one year learning machine learning and last few months learning tensorflow.

Still, I feel that I don't know much about the capabilities and features that tensorflow has to offer. There is so much about configurations for graphs, optimising the graphs, running code efficiently through loops in graphs (particularly the use of while-loop) etc. Is there a streamlined tutorial or notebook repository where I can find such examples?
I tried reading the documentation and reading from examples given. Honestly, I feel that I grasp better when going through a question answer or notebook format.

Any link or insight is appreciated."
Cross-Validation and Feature Selection,1,2,False,False,False,learnmachinelearning,1497997298,True,"I have about 150 samples 1000 features (ranked by their importance by Relieff score). My question is, what would be the best approach to:

* choose the hyper parameters
* choose the optimal number of features to use 
* report the accuracy of my model using SVM and kNN (I don’t intend to choose which one of them is best to use, but rather report their accuracy)

**First approach: Cross Validation**

* Split data 80% training and 20% for final testing

* Using training data, perform feature ranking with Relieff score

* Using training data, loop over the K number of features (starting from the most to the least important) and hyper parameters, using 10-Fold cross validation (to computer the 10-Fold misclassification rate for each combination)

* Choose the best K (number of features) and Hyper parameters values, giving the least misclassification rate

* Train my algorithm using the training data and optimal parameters and test on the testing data (the 20% of my initial data, which were not used at all for selecting the parameters)

* Report accuracy

**Second approach: Nested Cross Validation**

* Split data into 10 folds (External Cross Validation)

* Do the same as above (Internal Cross Validation) to choose optimal K number of features, and hyper parameters using 10-fold cross validation.

* for each external fold, train using 9/10 of data with best chosen parameters and test using 1/10 of data

* report the average accuracy of the 10 external folds 
	
Which one should I choose? Any suggestions?
"
[cs231n Question] Softmax Classifier Derivative Please help!,1,3,False,False,False,learnmachinelearning,1498002130,True,"I posted this over in /r/cs231n but didn't really get much direction, so I'm hopeful for anyone's additional help! This is in reference to the first assignment part 3, which has us derive the subgradients for the softmax classifier function, So:

I was wondering if someone could check out my partial derivatives and make sure my calculations are correct. My fundamental math skills are pretty garbage, so please bear with my struggles, im working to improve them:


the correct class partial derivative, and the loss function we're given from here:

http://cs231n.github.io/linear-classify/#softmax

is here:

http://i.imgur.com/p4PN3qm.png?1


then the incorrect class partial derivative is here:


http://i.imgur.com/ufoOD8B.png?1


It seems I must have messed something up with my calculus or algebra due to my code not outputting the correct values. I've been looking at this for a couple hours, and I'm pretty sure my code reflects my derivation, so it must be the derivation.

Please help!"
TWIL (This Week I Learned) - Share something new that you have learned this week!,5,3,False,False,False,learnmachinelearning,1498029071,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
Advice for using ML for duplicate detection,0,2,False,False,False,learnmachinelearning,1498030010,True,"I’m starting to learn about machine learning in order to attempt to solve a problem at work. I work for a software company. We get an extremely high quantity of bug reports, and I would like to apply machine learning to identify possible duplicate reports. When something breaks, we get hundreds of duplicate bugs worded in their own unique (but similar) way. 

For example:
A bug where the title of a button is the wrong shade of blue


Might produce:

""The title is the wrong color""

""The page’s font looks dark""

""Incorrect text color of the button""

""The title is dark blue instead of light blue""

etc.

Traditionally, these are manually identified, and we relate the duplicate reports to the first, master bug. 

Ideally, as we start to manually relate the duplicate reports, it will assist in ongoing supervised learning by providing a master bug, and a list of related bugs with their various wording. As more dupes accrue, the more vocabulary variations are learned.

I *think* I should use probability estimation for this, and recommend master bug(s) that exceed a certain level of probability.

I’m hoping to get a 1000ft view of how a ML engineer would approach this sort of problem so I can focus my learning to the applied methodology required to solve the problem. 

In case you haven’t gathered, I’m not a data scientist or mathematician. I’m proficient in python, c++, and Swift. I would like to use this problem as a primer for machine learning. Thank you!



"
What is the state of the art in text classification?,1,2,False,False,False,learnmachinelearning,1498030056,True,"I've seen implementations using both LSTMs, CNNs and NB-SVM (Naive Bayes SVM). What is currently considered best in terms of efficiency and accuracy – particularly for multi-class labelling?"
PyTorch vs TensorFlow - spotting the difference,1,28,False,False,False,learnmachinelearning,1498031583,False, 
[TensorFlow] How to detect multiple objects on images?,14,5,False,False,False,learnmachinelearning,1498034966,True,Just like this http://cdn.mos.cms.futurecdn.net/68410d4fa6f0ffb90001ce07f670ea44.jpg
Rainwater Tank Installation,0,1,False,False,False,learnmachinelearning,1498039608,False, 
Info on time series prediction with neural networks?,2,1,False,False,False,learnmachinelearning,1498050398,True,"I am a total beginner in the topic of machine learning and neural networks, but have some decent background in software development. Recently I've been given a task to research NN-based approaches to time series prediction (because other approaches did not work well in the past).

Our data consists of time series average values for weeks, days, hours, etc. The goal is to get a good prediction for the smallest time unit (hours).

I am more interested in general approaches and libraries rather than implementation from scratch (it's certainly interesting, but the time constraints are tight).

I would appreciate any suggestions of papers or books, as well as general search terms (e.g. should I use RNNs or something else?)."
Microsoft Launches A Machine Learning And AI Powered Selfie App,0,1,False,False,False,learnmachinelearning,1498051959,False, 
Are there any text-to-speech pretrained models?,1,2,False,False,False,learnmachinelearning,1498052730,True,"Hi, I am looking for any kind of text-to-speech pretrained model. I would like to play around with an application, but do not seem to find one. I know that there is tacotron and lyrebird, but haven't found any pretrained model for them."
10 Data Science Podcasts You Need To be Listening To Right Now,3,3,False,False,False,learnmachinelearning,1498055473,False, 
Getting Started With Deep learning Using Tensorflow/pyTorch,2,3,False,False,False,learnmachinelearning,1498066071,True,"I am a final year undergrad interested in ML and Computer Vision. I am perplexed where to start .. i have completed the CS231n and Andrew Ng's Course .. i have some experience coding in python .. The problem that i face is the problems that i like to solve are computationally intensive.. Hence please suggest me toy projects that can be useful and can add value to my portfolio.. Sorry for being a Noob..  
Seeking your help .. "
Tensorflow (Python): Adding hidden sigmoid layer to the tensorflow beginners tutorial completely destroys the results of the classifier. Where am I going wrong?,1,0,False,False,False,learnmachinelearning,1498066950,True,"    from __future__ import absolute_import
    from __future__ import division
    from __future__ import print_function

    import argparse
    import sys
    
    from tensorflow.examples.tutorials.mnist import input_data
    
    import tensorflow as tf
    
    
    
    for hidden_n in (10,50,100,150,200,250,300,500,700,1000):
      for rate in (0.01,0.1,0.3,0.5,1.0,2.0,3.0,5.0):
        mnist = input_data.read_data_sets(""MNIST_data/"", one_hot=True)
        print(""Using:\n\tRate : {} \n\tHidden : {}"".format(rate,hidden_n))
        x = tf.placeholder(tf.float32, [None, 784])

    # sigmoid layer-----------------------------------------------------
    
        W_1 = tf.Variable(tf.zeros([784, hidden_n]))
        b_1 = tf.Variable(tf.zeros([hidden_n]))

        sig = tf.nn.sigmoid(tf.add(tf.matmul(x, W_1),b_1))

    # output layer------------------------------------------------------
        
        W_2 = tf.Variable(tf.zeros([hidden_n,10]))
        b_2 = tf.Variable(tf.zeros([10]))
    
        y = tf.add(tf.matmul(sig, W_2),b_2)
    
    #-------------------------------------------------------------------
    
        y_ = tf.placeholder(tf.float32, [None, 10])
        
        cross_entropy = tf.reduce_mean(
            tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))
        sess = tf.InteractiveSession()
        tf.global_variables_initializer().run()
        vars = [
          (1000,10,3),
          (5000,200,1),
          (2000,100,0.5),
          (2000,100,0.1)
        ]
        for e,b,r in vars:
          train_step = tf.train.GradientDescentOptimizer(rate*r).minimize(cross_entropy)
          for _ in range(e):
            batch_xs, batch_ys = mnist.train.next_batch(b)
            sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})
        # Test trained model
        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))
        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
        print(""Accuracy:"",sess.run(accuracy, feed_dict={x: mnist.test.images,
                                            y_: mnist.test.labels}))


I took the code linked at the [tensorflow site](https://www.tensorflow.org/get_started/mnist/beginners) and I made only a few changes to it. But most changes won't affect the result significantly.


But when I add the hidden sigmoid layer the accuracy drops from ~.9 to ~.4 -~.6.

What am I doing wrong? Have I missed any important thing? 

Edit: The drop happens with all learning rates and hidden_n.


EDIT: I got it to work. I replaced 'tf.zeros' with 'tf.uniform'. When declaring weights and bias."
Team up for an ML blog/ project?,15,4,False,False,False,learnmachinelearning,1498074525,True,"I've recently started learning ML. I was wondering if any other beginners would want to team up for a small project or an ML blog? This was my approach when I started learning how to code a few years ago and it worked out great. 
"
Free Machine Learning Lessons with MLJAR,5,7,False,False,False,learnmachinelearning,1498079323,False, 
Is RNN language modeling not unsupervised learning?,2,3,False,False,False,learnmachinelearning,1498119235,True,"I'd always thought of it as unsupervised because input/output was in the same domain. But even though having targets will never be an issue, we still *need* targets for the 'machine to learn', so we don't have an algorithm that is finding structure by itself (we are telling it the structure it's supposed to learn). So it's not unsupervised?"
Finding the Tanimoto score in Programming Collective Intelligence's exercise.,3,3,False,False,False,learnmachinelearning,1498123891,True,"**Backstory**-I am trying to get a grip on the concepts of Machine Learning. I'm referring to Toby Segaran's book ""Programming Collective Intelligence"". In the second chapter of the book, 'Making Recommendations', he uses a ratings table (implemented as a dictionary), to derive recommendations and make comparisons. An exercise at the chapter's end encourages reader to find the similarity between two critics using the Tanimoto score.

I've researched a bit about the Tanimoto score on the internet. From what I've understood about it, Tanimoto is only concerned by if an object falls within a set or not. This is confusing for me, because I can not see a way, by which I can include critics ratings in the similarity calculation procedure. So, am I supposed to be concerned with just wether a critic has seen a movie or not, or is there a way through which ratings that two critics give a movie also weighs in on the what their similarity will be?"
Features-based/NLP : How would do predict on a item which can have between 1 to 7 sentences to describe it?,0,0,False,False,False,learnmachinelearning,1498125009,True,"Hi everyone,

I'm currently working on two classification problems. One is features based, the other is close to sentiment analysis in NLP.

In both cases, my target can be describe by either 1 to 7 rows of data (features or sentences) coming from differents sources.
I currently have good results by simply predicting of each row and averaging the probabilities to get a prediction of the item.

I wonder if there is another way to actually predict on items directly ?
I have used ensemble techniques for the features based model and Conv-LSTM for sentiment analysis.

Thanks"
"If I'm doing research for a pattern recognition problem or classification problem, what can I do in progress?",4,2,False,False,False,learnmachinelearning,1498126681,True,"I'm a master degree student deciding to use an machine learning method apply on pattern recognition or classification problems. While I'm studying literatures, I've found that performances of these tasks are accomplished by high performance(correct rate) by former researchers, such as UCI dataset yeas ago.

Now that if I want to devote myself in similar problem, what kind of direction can I do for contribution?

For training time, it seems that the current training time is already extremely short, and I don't see reduce millisecond of training time may do any good.

For accuracy, datasets such as UCI has already reach correct rate as high as 95%. What does everyone doing classification problems aims for?

PS. I don't use deep learning due to my computer don't owe an GPU."
Determining help desk solutions based on previous tickets.,0,2,False,False,False,learnmachinelearning,1498138637,True,New to this sub and fairly new to ML in general. I am thinking of starting a project that would attempt to provide solutions to common IT help desk problems based on previous tickets and solutions. I am wondering where to start and what tools I should learn in order to make this work. Thanks! 
Data Scientist Resume Projects,0,45,False,False,False,learnmachinelearning,1498139424,False, 
"Wanting to get hands on with Machine Learning, where do I start?",1,2,False,False,False,learnmachinelearning,1498141378,True,I have a pretty decent knowledge of Machine Learning from a decent amount of reading/studying but I'd like to turn my knowledge into application. What are some good locations to apply my ML/AI? Are there places for beginners in the field to get my feet wet/hands dirty?
Import pre-trained Tensorflow into Keras?,0,2,False,False,False,learnmachinelearning,1498153202,True,"I am looking for a tutorial on how to run these [pre-trained MobileNet](https://research.googleblog.com/2017/06/mobilenets-open-source-models-for.html) from Google using keras, just to test how well the perform on my dataset. Can someone guide me in the right direction?

edit: Just to be clear, my input will be a single image, and I expect the output to be image with boxes around the detected objects with labels and accuracy."
In supervised learning can data labels be a pair of numbers?,1,1,False,False,False,learnmachinelearning,1498155768,True,"I've seen binary classification, and real-valued regression, but can the labels be a pair such as (24, 18)? How would that change the model?"
What is a good first machine learning project related to cancer?,2,8,False,False,False,learnmachinelearning,1498159817,True,My end goal is to use machine learning to predict mutations that might lead to the development of cancer or which mutations would respond best to a drug. 
I want to pay someone to create a really high quality intro to machine learning course for all of Reddit,25,43,False,False,False,learnmachinelearning,1498187224,True,"Hey all,

I work for a company that is doing very well, and we're looking to give back. We're currently looking for someone to create (and give away) a live introduction to machine learning course.

We pay competitively, and it will be 100% free for everyone. If you know anyone please let them/me know."
The Kaggle data science community is competing to improve airport security with AI,4,5,False,False,False,learnmachinelearning,1498198142,False, 
Weekly Show-off!,4,1,False,False,False,learnmachinelearning,1498201956,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
How to find the optimal skill rotation in MMORPGs using an ML Algorithm?,1,1,False,False,False,learnmachinelearning,1498202184,True,[deleted]
Welder and Welding Services,0,1,False,False,False,learnmachinelearning,1498205683,False, 
Whoever Controls Machine Learning Controls the Future,0,1,False,False,False,learnmachinelearning,1498215848,False, 
A huge clean library for ML ebooks,0,1,False,False,False,learnmachinelearning,1498231704,False, 
cheat sheet cleaning/preparing and show data for ML,4,3,False,False,False,learnmachinelearning,1498254965,True,"i struggle with cleaning or preparing testing and training datasets with few lines of simple code. Although pandas and matplotlib do a good job of plotting graphs and show and edit csv files, i think I get a little bit lost, since I dont really know what methods exist (especially pandas). Is there a 'cheatsheet' for this "
LSTM input shapes in Keras,10,3,False,False,False,learnmachinelearning,1498257348,True,"I'm having a hard time grasping LSTM input shapes in Keras. I've tried looking at keras/examples already for a model to go off of. 

I'm trying to teach the machine to translate my human clicking and snapping sounds to characters of the alphabet . My training data x is 500 rows of 1 millisecond arrays with corresponding labels.
x.shape: (500, 1, 4410)
labels.shape: (500,)

    model = Sequential()
    model.add(LSTM(64, input_shape=x.shape, return_sequences=True, activation='sigmoid'))

After this line, I get an error that says, 
>""ValueError: Input 0 is incompatible with layer lstm_1: expected ndim=3, found ndim=4"".

I've tried changing the shape of my training data to (500, 1, 4410), and got the same error. 
I also tried changing the shape to (500,4410) and got:
> ""ValueError: Error when checking input: expected lstm_1_input to have 3 dimensions, but got array with shape (500, 4410)""

Any help is appreciated! Thank you."
Trying to implement a softmax classifier..,27,2,False,False,False,learnmachinelearning,1498284334,True,"Hey all, so I've put a decent bit of time into this already and am getting frustrated. Basically I've got just a softmax classifier with no hidden layer (a.k.a I have a weight matrix). The forward propagation matches other results on the internet, but my gradient seems to simply memorize one class on the Indian diabetes database and can't descend to anything for the iris database, and I've seen people online solving iris with just a softmax (although I don't know if they had a hidden layer). Also, when I try numerical approximation to check my gradient the numbers are off, but I can't figure out what my gradient calculation is supposed to be, and I've looked everywhere at this point.

Can anyone help me out? How can I test my classifier to see if it's behaving appropriately? Do I need a hidden layer?"
"Weekly Status Check Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",0,4,False,False,False,learnmachinelearning,1498288220,True,"Let's have a  meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
The GAN World,0,3,False,False,False,learnmachinelearning,1498300258,False, 
How to get the best results out of Torch-rnn,0,2,False,False,False,learnmachinelearning,1498312380,True,"Hi all,

I'm starting to play with [char-rnn](https://github.com/karpathy/char-rnn)/[torch-rnn](https://github.com/jcjohnson/torch-rnn) with a dataset of about 18mo of text from Project Gutenberg. I'd like to be able to generate some short passages out of it that make a little bit of sense.

I've ran the default setup (2 days!) on my laptop and the results got progressively better and started to plateau around epoch 25 (out of epoch 50). In the end, the Validation Loss was around 1.462 and the training loss around 1.3 but the output was far from making sense nor was it even a little bit correct grammatically. The default setup is 2 layers, a batch size of 50 and 128 hidden units in the RNN (not sure about the sequence length).

I'm re-running a training with different settings, hoping to hone in on the best combination to get semi-credible to credible output. This time I'm using 3 layers, 512 hidden units, a batch size of 64 and a sequence length of 128, using the LSTM model. 

After 3 epochs I'm getting a validation loss of 1.43 and a training loss of 1.23. The output seems a little better already but not by a wide margin (it still makes 0 sense grammatically).

So a couple of questions:  
- Am I being too hopeful that I can achieve grammatical sense with this dataset?  
- When's a good time to stop and adjust? I haven't started to play with dropout yet but I'm wondering if my new settings are closer to a good model or not. What's a good tell?

Hope this is not too naive. Thanks!"
Why is SVM memory efficient?,5,4,False,False,False,learnmachinelearning,1498317191,True,"Reason given on scikit learn documentation: Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient..... I dont understand this"
The real easy caffe example : Age and Gender Classification,2,9,False,False,False,learnmachinelearning,1498319515,False, 
Is there an NLP API that ranks in order of positive text?,2,2,False,False,False,learnmachinelearning,1498319644,True, 
Best deep learning course after ML course?,12,27,False,False,False,learnmachinelearning,1498327618,True,"Hi, I recently completed a machine learning course in university that covered all the basics including regression, SVMs, kernels, boosting, clustering, and touched on neural networks and deep learning. I found it really interesting but I want to get some more applicable knowledge and experience (with deep learning specifically) as I'll be starting at Google in a few months. I've found lots of resources online but I was wondering if you guys had any input on which would be the best path to take. I want to get some experience with TensorFlow, but I don't have a lot of experience with python, my course used Matlab.

Here's what I'm considering:

- [CS231n: Convolutional Neural Networks for Visual Recognition](http://vision.stanford.edu/teaching/cs231n/)

- [CS224n: Natural Language Processing with Deep Learning](http://web.stanford.edu/class/cs224n/)

- [Udacity - Deep Learning by Google](https://www.udacity.com/course/deep-learning--ud730)

Would anyone be able to vouch for any of these courses, or make any recommendations given my situation and background? Or if you have any other course suggestions I'd be happy to hear them. I'm eager to get started but just want to make sure I'm going down the best path. Thanks!"
I need help with a TicTacToe Neural Network I wrote,3,4,False,False,False,learnmachinelearning,1498328965,True,"I wrote this net to learn to play Ticktacktoe by playing against an opponent who chooses moves randomly and recording each win from the perspective of the player that won. After each game, it uses these recordings to train itself using the standard logistic regression cost function. Yet for some reason, it always maintains a roughly %50 win rate. I'm not sure what's going wrong, so could anyone take a look at my code? It's written in Octave and the relevant function is SelfSuperviseTicTacToe. https://www.mediafire.com/?b5bvdj1w3cioqvc"
Beginners guide to summarize data in R,0,11,False,False,False,learnmachinelearning,1498348345,False, 
Multilayer perceptron giving different prediction for same input,0,4,False,False,False,learnmachinelearning,1498416820,True,"I'm trying to train a multilayer perceptron to give me a binary classification. The training seems to go well.

Training output:
   
    ('Epoch:', '0001', 'cost=', '112.558782221')
    ('Epoch:', '0002', 'cost=', '64.157170181')
    ('Epoch:', '0003', 'cost=', '43.059423962')
    ('Epoch:', '0004', 'cost=', '30.658051707')
    ('Epoch:', '0005', 'cost=', '22.522848253') 
    ('Epoch:', '0006', 'cost=', '16.229121455')
    ('Epoch:', '0007', 'cost=', '12.027928557')
    ('Epoch:', '0008', 'cost=', '8.904733737')  
    ('Epoch:', '0009', 'cost=', '6.372925325')
    ('Epoch:', '0010', 'cost=', '5.282866159')
    ('Epoch:', '0011', 'cost=', '4.022785049')
    ('Epoch:', '0012', 'cost=', '3.284904347')
    ('Epoch:', '0013', 'cost=', '2.561985810')
    ('Epoch:', '0014', 'cost=', '2.091165893')
    ('Epoch:', '0015', 'cost=', '1.800062044')
    ('Epoch:', '0016', 'cost=', '1.341862108')
    ('Epoch:', '0017', 'cost=', '1.194651621')
    ('Epoch:', '0018', 'cost=', '1.054406572')
    ('Epoch:', '0019', 'cost=', '0.956931485')
    ('Epoch:', '0020', 'cost=', '0.803146835')
    ('Epoch:', '0021', 'cost=', '0.801673206')
    ('Epoch:', '0022', 'cost=', '0.718695209')
    ('Epoch:', '0023', 'cost=', '0.662291717')
    ('Epoch:', '0024', 'cost=', '0.624042775')
    ('Epoch:', '0025', 'cost=', '0.563019502')
    Optimization Finished!
    ('Testing Accuracy:', 0.83459997)

But I noticed that if I dig into my testing results they are all over the place. If I input the same data multiple times I will get different predictions each time. The data set I have is quite sparse (i.e. lots of zeros). Some features are almost completely 0, while other features are complete with data. 

I'm mostly surprised that the model gives different outputs for the same input. I'm guessing this means the model is not well trained, but if somebody could explain why/how this happens that would be great. 

I tried keeping this short. Let me know if there is any other info that would be helpful to have to help answer this question"
Checking if two vectors of values belong to the same human,3,4,False,False,False,learnmachinelearning,1498429402,True,"Hi

I'm doing an exercise task for machine learning and I have some questions that would make me very grateful if you could help me with it.

The task requires you to built a binary classifier, which takes two vectors of bio-metric parameters and returns 1 if these two vectors correspond to the same person and 0 if those are parameters of two different people.
The parameters are represented by the vector with 400 floating point elements. There are 52284 vectors and corresponding person's ids for training samples.

To solve this task I've computed the modulus of difference between each vector, and assigned a label 1 if id's of those vectors are the same and 0 if not. After that I've trained sklearn RandomForestClassifier using this data.
The result was tested on another dataset of vectors, and the accuracy score was 0.98800559048383252. The task asked to compute equal error rate, which I've calculated to be 21.3%
The EER that would be considered good is 4%. So here are my questions:

1)all pairs of 54k vectors take a lot of memory(even though we can use only half of them, it's still a lot). Because I'm restricted with memory(8gb), I've decided to take every n-th pair of data. Is it correct way to approach this problem?

2)When I've checked the label distribution I've found it to be very unbalanced(out of 453628 samples I've collected, only 2987 had class 1). Should I resample/rebalance my training set for better result and if so, what is the best way to do so?

3)Is it possible to reach 4% EER by tweaking the parameters of the estimator, or should I switch to some other method? If so which method would be preferable?

Any other helpful hints would be highly regarded."
Data understanding,5,3,False,False,False,learnmachinelearning,1498430567,True,"I was going through the handson-ml book and there is second chapter which talks about end-to-end ml. In that chapter the author talks about data correlation but he does not give any background about it or provide more resources for it? He just gives on type of correlation factor and that's it. Why did he pick one particular correlation calculation factor was never mentioned? 
 Why is it important to understand correlation between numercial features? How is this different from feature selection?
 Are there good resources that highlight more of such methods?"
Training data for neural net with conflicting data points due to equivalent outcomes,1,2,False,False,False,learnmachinelearning,1498460277,True,[deleted]
Problem with solving Lasso least-squares by Gradient Descent,0,1,False,False,False,learnmachinelearning,1498474918,True,"Hello all,

I am trying to find solution to Lasso Regression by Gradient Descent. 
I was able to solve least squares with gradient descent for regression without penalty, and with L2 penalty (ridge regression).
I lack strong math background, but as far as i understand [THIS](www.cs.cmu.edu/~ggordon/10725-F12/slides/08-general-gd.pdf) to solve lasso, we have to set somekind of thershold in gradient, so when coefficient is in [-lambda, +lambda] we set coefficient to 0.



Here is my code (which is unable to find solution same as solution in sklearn).
If anyone could help me, where am I missing something, I would be grateful

[LINK TO CODE](https://paste.ofcode.org/kAv8j45uCVmXR9hKuMkRmJ)"
"Some tips for reducing the size of your architecture, for a smaller dataset?",4,1,False,False,False,learnmachinelearning,1498476504,True,"Ok, so you have an architecture which performs well on a large dataset. Now you want to train that architecture on a subset of the large dataset. How do you go about optimizing it? I've tried:

- reducing dropout
- reducing the number of layers
- reducing the number of units per layer

I still get relatively bad results (compared to the benchmarks). Do you have any suggestions / tips for how you would go about ""shrinking"" an architecture to fit a smaller dataset, without overfitting badly? "
Square Function using CNNs,3,2,False,False,False,learnmachinelearning,1498478485,True,"Hello , 

I am trying to make a square function neural network using only CNNs , yet i'm not getting the results to back that up..

here's the link to the github code (since it's big for here) 
https://gist.github.com/anonymous/33bb5afaefd099f26c4ba7efa192426a
I'm pretty new to the scene but i'm trying to become better and better .

So.. i was looking at the layer_flat results (which should be the y_prediction values) some come as negative ... which is **absolutely** refused .

i scaled my dataset down to 0-1 range , if you guys need any help in understanding the code i'm 24hrs per day here . 

"
Best paid online courses for machine learning?,5,5,False,False,False,learnmachinelearning,1498484907,True,"Hi everyone, I've taken Andrew Ng's course and of course read through many of the free resources online, and I wanted to know if anyone has recommendations for online PAID classes? I've been eyeing [this course on Experfy](https://www.experfy.com/training/courses/machine-learning-foundations-supervised-learning) for a while now. I feel pretty comfortable with my theoretical knowledge, and am looking for paid courses that teach using practical examples and applications of machine learning. 

Can anyone vouch for this course? Or do you have any other recommendations?"
Brendan Herger | Machine Learning Techniques for Class Imbalances & Adversaries,0,1,False,False,False,learnmachinelearning,1498487078,False,[deleted]
"Over 150 of the Best Machine Learning, NLP, and Python Tutorials I’ve Found",0,2,False,False,False,learnmachinelearning,1498503443,False, 
Number of neuron in hidden layer in MLP Backpropagation Neural Network,7,8,False,False,False,learnmachinelearning,1498511031,True,"Dear all, 

I have a question related to number of neuron in hidden layer. Since I have a 210 samples, with 7 input neurons and 1 output neurons (with 3 different classes). Base on the rule of thumb, choosing the number of neurons in hidden layer = (number of neurons from input + number of neurons from output) * (2/3)  I choose 1 hidden layer with 5 neurons but the result from cross validation is 0%. But when I choose 1 hidden layer with 100 neurons, average result from 10-fold cross validation is 89%

So I don't know what I am doing wrong on this. 

Thank you for reading this"
Question About GANs,0,1,False,False,False,learnmachinelearning,1498513752,True,"I recently implemented a simple GAN and am having trouble fully wrapping my head around the generator's loss function. With the discriminator, it can look at each image and adjust it's parameters to decrease the outputted likelihood for the ""fake"" input and increase the outputted likelihood for the ""real"", without involving **how** the generator creates the images.

With the generator, it's loss function is the cross entropy between the discriminators output and the goal probability. Does this mean that although the discriminator does not know about the generators inner workings, the generator must be tweaking its weights with respect to the discriminators weights? I guess maybe this is obvious, since the discriminator would have no way to know how to change itself if all it had to work with was a scalar probability.

I feel like if information is being transferred from the discriminator to the generator then it kind of goes against the analogy that's provided of a forger vs a cop. It's more like if a forger had intricate knowledge of how a cop detects forgeries? Just interesting since it seems like there's a pretty direct connection between the generator and the original training data, such that I can see it just learning to spit back the original training data. Or am I missing the point, and that the whole idea is to have GANs to approximate the distribution of training data as closely as possible?

Sorry if this was a bit rambley, just wanted to clarify a few things, hopefully someone can shine some light."
10 Places to Learn Machine Learning,0,1,False,False,False,learnmachinelearning,1498518116,False,[deleted]
10 Places to Learn Machine Learning,2,3,False,False,False,learnmachinelearning,1498518723,False, 
Learn Colors with your Baby along with Superheroes and Funny Creams - Kids Colors TV,1,0,False,False,False,learnmachinelearning,1498537510,False, 
How would I model this data for prediction?,7,3,False,False,False,learnmachinelearning,1498539203,True,"I've been reading about machine learning for a while, and I'm starting to form a really rudimentary understanding. I have a personal project in mind which I'd like to implement, perhaps using Keras. However, I'm not quite sure how I would model my network.

The input data is basically just a two-dimensional array; think of an excel sheet with about a dozen columns and thousands of rows. The rows are a series of measurements taken at specific intervals, say every five minutes. For now, the output would be just binary 1 or 0 denoting whether a certain value outside the input data increased or decreased.

How would I go modeling this? I can wrap my head around the idea of ""independent"" input data where each row would be independent of the other rows, but in my case, they form a sequence. I'm interested of how the previous values affect the upcoming ones, and so the rows can't be processed in isolation.

Should my training data consist of multiple sheets? Or should I split the training data to smaller row sets, say, a hundred rows at a time against a given binary value? The purpose of training the network would be to predict future changes (whether the output value increases or decreases) based on the dozen or so input variables.

I hope I make at least a little sense here!"
I made a JavaScript/Node.js package for unsupervised machine learning: Gaussian Mixture Model,0,1,False,False,False,learnmachinelearning,1498543628,True,[deleted]
Brendan Herger | Machine Learning Techniques for Class Imbalances & Adversaries,0,6,False,False,False,learnmachinelearning,1498544744,False, 
Office Home Design,0,1,False,False,False,learnmachinelearning,1498549828,False, 
Alternatives to Back Propagation,11,12,False,False,False,learnmachinelearning,1498560608,True,"I am Wondering if there are any other techniques to train neural networks other than Back Propagation.. Please share if u are aware of any other techniques or variants .

Thanks"
An introduction to Support Vector Machines (SVM),0,18,False,False,False,learnmachinelearning,1498561048,False, 
Is Weighted Averages the Best Method for Aggregating Information?,0,3,False,False,False,learnmachinelearning,1498565808,True,"I'm working on a recommendation system. My system uses user's past rating data, to predict future ratings.      
         
I designed mathematical methods for generating recommendation algorithms that allows me to generate an unlimited number of recommendation algorithms (given a large enough set of relevant ratings).         
           
I intend to aggregate the results from all this algorithms to compute a final expected rating of the user. So I thought of taking the weighted averages of the expected ratings of each algorithm to use to calculate a final expected rating.           
           
Basically I either:          
1. Assign weights based on the amount of information (ratings collected).          
2. Assign weights based on the accuracy of the algorithm used.         
            
The algorithms arrive at their answer via different means, and it is possible that two may give the same answer, but they may take into account different information and/or use different inferential techniques on that information.       
          
So if an accuracy of 1 means there's no deviation between the algorithm's expected ratings, and the user's actual ratings, and an accuracy of 0 means there's maximum deviation between an algorithm's expected ratings and user's actual ratings, we may get $\{Al_1, Al_2, Al_3\}$ with accuracies of $(0.9, 0.85, 0.92)$.           
           
I have a minimum information and/or accuracy threshold that I would use to filter the algorithms to assign weights to (I have not yet figured out what this threshold would be, and as it may vary on a per user basis, I want to leave determining the threshold to an ML system. 
         
My question is this:       
>Is weighted averages the Best methods for me to aggregate the data provided by my various algorithms/infer from it?         
        
If not, what other methods are more apt for the problem at hand?"
I want to know how should i proceed with my project.,1,0,False,False,False,learnmachinelearning,1498573491,True,[deleted]
Benchmarking Random Forest Implementations | Data Science Los Angeles,0,11,False,False,False,learnmachinelearning,1498599846,False, 
How are Sigmoid/Tanh functions forgetting and including information in LSTMs?,2,2,False,False,False,learnmachinelearning,1498603295,True,"[So I posted on StackOverflow recently](https://stackoverflow.com/questions/44751800/how-are-sigmoid-tanh-functions-forgetting-and-including-information-in-lstms) and got a good response but I had some follow up questions that I'd love to share with you all. 

Essentially, I want to know how each gate decides what is important and what isn't. I feel like this is the missing link in my under"
Difficulty in understanding Backpropagation,3,1,False,False,False,learnmachinelearning,1498606861,True,"I get the general gist of backpropagation that, the resultant gradient of the outermost unit is propagated backwards to calculate the gradients of the inner units. I've been reading up on the intuition behind backpropagation (from [Stanford C231n](http://cs231n.github.io/optimization-2)) but I am having some difficulty in understanding the terms being used [here](http://cs231n.github.io/optimization-2/#intuitive):

>Notice that backpropagation is a beautifully local process. Every gate in a circuit diagram gets some inputs and can right away compute two things: 1. its output value and 2. the local gradient of its inputs with respect to its output value.

I'm guessing, ""its output"" refers to the output of the addition gate and the multiplication gate i.e., 3 and -12 respectively. But I'm not sure what the second point about local gradient refers to.

Any help would be greatly appreciated.

"
Instances where logistic regression performs better than any other sklearn model?,2,3,False,False,False,learnmachinelearning,1498610277,True,"Hi all,

I have a bunch of time series data I'm doing classification on. I used TPOT with a custom cv (walkforward time series split) to find the best performing model. Logistic regression was selected. I'm a bit surprised by this, given that most kaggle competitions using supervised learners are won by ensembles of newer models like XGB, etc. In fact, not only was logistic regression the best model but it was actually the only one that learned something meaningful (outperformed the others like RF, XGB, etc. by > 5% where 60% is the best accuracy it achieved).


My expertise is mostly in deep networks, not as much the stuff dealt with by sklearn, but in this case the training data is *very* limited and quite noisy. What should I take away from logistic regression being the best classifier? Can I use this knowledge to inform my design of other classifiers that could perform better?"
Why Is NumPy Only Now Getting Funded?,0,12,False,False,False,learnmachinelearning,1498623471,False, 
Using RuleFit Ensemble Models Is About to Become Very Important,0,3,False,False,False,learnmachinelearning,1498623728,False, 
TWIL (This Week I Learned) - Share something new that you have learned this week!,7,10,False,False,False,learnmachinelearning,1498633871,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
"Those of you running complex RNNs/LSTMs, what hardware specs are you working with?",3,7,False,False,False,learnmachinelearning,1498657321,True, 
Introduction to collaborative filtering,5,16,False,False,False,learnmachinelearning,1498675057,False, 
Where should I Begin?,9,5,False,False,False,learnmachinelearning,1498683428,True,"I'm a Recent High School Grad, I had Taken CS in HS with some hands on Experience in Java, I've purchased some books like, 

Introduction to Algorithms, Fundamentals of Neural Networks: Architectures, Algorithms and Applications, 1e by Laurene Fausett, 

Artificial Intelligence 3e: A Modern Approach by Stuart Russell and Peter Norvig, 

I'm Starting on them but things like Sigmoid Functions and the Complex formulae and functions, I can't get my head around them, I can read what they do but can't visualise or completely understand what they do and how to apply them in a Program, I also know that they are outdated and we are supposed to use ReLU or Leaky ReLU if we're getting lots of dead neurons but didn't find any books that cover them.


My Calculus is on the Weaker side, I've thought about getting a Multivariable Calculus book but Haven't got around anything worthwhile yet, I welcome any recommendations.

and I haven't started independently programming yet, I did some Arduino projects back a year but nothing special, How should I get started on this, I've got Sublime Text 3 as a Text editor, I'm on Windows, I've got Python and TensorFlow running on my GPU(GT 740M), 

The thing I'm stuck on is Workflow, How is this supposed to Work, How can or Where can I get data sets which I would like to experiment on, Can I create my own data sets? if so, how, Where can I get resources for beginners to learn to use NN's for Pattern Recognition and Insight Generation, I know I can Google these but whenever I do, One thing leads to another and I get lost and loose my confidence and Defer it.

Help me out Guys, I LOVE Machine Learning and AI, It got me out of an Existential Crisis, It literally Gave me a reason to Live, I find it Extremely Fascinating, It redefines what it means to be a conscious being, It Redefines Intelligence itself, I wanna be a part of it."
Trial Run of a Turret Type Milling Machine (Make Bridgeport),0,1,False,False,False,learnmachinelearning,1498684882,False, 
CBOW and Skip-Gram,0,2,False,False,False,learnmachinelearning,1498687115,True,[deleted]
PyGame Project,5,1,False,False,False,learnmachinelearning,1498690300,True,"Hi Guys

I just made a game with a cannon that shoots balls and a target that randomly pops up on the screen. The point of the game is to point the cannon at the correct angle to hit the target. My goal is to have the program play by itself. I was thinking that the program should shoot randomly and every time it hits the target it saves the (x,y) position of the target and the angle that it was shot at. What should I do with this data?

Could I plot the points in 3 space and do linear regression so then I can approximate the angle based off the position? I would also like to watch the program evolve in real time. I am hoping you guys can point me in the right direction. "
Concreting,0,1,False,False,False,learnmachinelearning,1498695722,False, 
A compiled list of resources for learning Machine Learning!,4,60,False,False,False,learnmachinelearning,1498696014,True," A while back, I started compiling some resources on Machine Learning from different colleges and around the web. I realized that other people might find this helpful, so I created this doc to share. I made it editable, feel free to add anything you all have found helpful in your learnings as well!

https://docs.google.com/document/d/1qhjVLzwnUwrrsQLZOuVBBZ4bq_k0YkDUkFIS-YcaV4o/edit?usp=sharing

*EDIT*: Had wrong edit permissions on, sorry about that! Should be accessible now."
Making sense of these scores for a ensemble/voting classifier?,0,1,False,False,False,learnmachinelearning,1498709042,True,[deleted]
Loss function too low?,10,2,False,False,False,learnmachinelearning,1498740630,True,"I am using siamese convolutional networks for an image similarity problem. I use the contrastive loss function from LeCun's [paper](http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf).

The issue is that during training, the loss quickly goes down from ~1 values to ~1e-2 values, but then it hits a wall. In most training problems, this would be ok since 1e-2 is a very low loss, and the resulting accuracy of your predictions would be enough. However, in my case, looking for a good threshold to make a decision between matching/no matching is still too difficult, even with such a low loss.

My point is, when the loss function is that low, does the network actually keep training? I feel like (with all other parameters equal) weights updates with that low loss are very slow/useless.

FYI: My only dataset pre-processing step is removing the mean image of the training subset from all subsets. "
"[x-post from /r/MLQuestions] Giving Neural Networks a ""wild card"" variable to push all the minute factors and variables that aren't being accounted for?",0,2,False,False,False,learnmachinelearning,1498743639,True,"I'm quite new to neural networks, so please excuse my novice language and assumptions, but I noticed a problem when doing research into how neural networks work. I understand that you want to minimize the number of factors a neural network has to account for because the Big O notation on that makes computers leak acid (going on a tangent: is there an official Big O notation for the various neural networks?). 

But the problem I see is that the neural network is attempting to adjust the weights of the factors it is given to account for variables it doesn't even have. Basically, the way I see it, the computer is looking at that last 10% of the final product it can't figure out, and then incorrectly assuming that it is a part of the variables it already has, that it is missing. Now, of course, I'm sure that, by the very nature of neural networks, various combinations of factors can reasonably account for the missing ones... but still, I feel like it would be beneficial to know how much of the output isn't a part of the factors it is given. 

For instance, borrowing from ComputerPhile's example, say that you're trying to figure out house prices based off of various factors. The computer's estimates for house prices are off slightly based on the missing factors. So, what I am suggesting (or asking what libraries/types of networks support this, because I'm sure I'm not the first to question this) is that the computer provides an estimate range based on the maximum and minimum it has been off by, and this range is developed *after* training so it doesn't give ranges to things it doesn't have to. For instance, say the costs of realtors range from $200-$800, $800 would be added to the estimate range maximum, and $200 to the minimum.

What is the name of this ""grey estimation"" area? Are there libraries or certain types of neural networks that account for it, acknowledging that there are ""random"" variables? What is it about this post that makes me look drunk, high, arrogant, or otherwise mentally incapacitated?

**TL;DR - Neural networks can figure out variables, but can they figure out constants or ungiven random factors?** "
"Getting started on Bayesian ML, RL and GANs",1,12,False,False,False,learnmachinelearning,1498745874,True,"Hello,

I see a lot of resources for DNNs like RNNs and CNNs. I want to learn more about probabilities graphical models, RL and GANs. Can someone help me carve out a good path to get started with papers / classes / books on the above ? "
Policy gradients without a value function,1,4,False,False,False,learnmachinelearning,1498746216,True,"If I'm using a policy gradient method without a value function, am I essentially limited to a Monte Carlo method (ie REINFORCE)?  

I don't quite understand how you could maintain an objective function without having a value function, or sampling return directly (ie MC)."
[Question] Has anyone successfully setup AWS spot instances to reduce costs?,4,2,False,False,False,learnmachinelearning,1498752535,True,"I rent a p2 instance on AWS for my side projects. My monthly bills are increasingly more expensive, mostly due to the demand prices for the instance, rather than storage costs. For a side project it's getting uncomfortably pricey. I'm already on the free-tier student account."
Method to determine what factors contribute to a target in a data set?,4,1,False,False,False,learnmachinelearning,1498755851,True,"Hi!
I started learning ML in python the past few weeks, I've done mostly supervised learning algorithms like knn, logistic regression, decision trees. Over the past few days I've been using a dataset that contains the information of meteorite landings such as geolocation, size, mass, type, year and one column that says whether the meteorite was degraded or not. What I'm trying to figure out is a way to determine which of those factors contribute the most to the meteorites degradation. 
How would I go to be able to see this?

Thanks! "
Getting started with machine learning,4,17,False,False,False,learnmachinelearning,1498767711,True,"Hey, I'm currently a CS major at the undergraduate level and I was wondering what else I could do to get started with machine learning. I discovered the wonders of machine learning and since then it seems to be the CS topic I'm most interested in. I'm currently taking the Andrew NG course on coursera. What else can I do to try and awaken or find this passion (if it does truly exist) for machine learning and learn more about it? Also, the deep learning stuff does seem the most interesting to me."
A conceptual map I made of the basics of supervised learning.,0,37,False,False,False,learnmachinelearning,1498771793,False, 
Please let me know if I am on the right track of being an NLP Expert,1,1,False,False,False,learnmachinelearning,1498776268,True,"I am a college student(rising senior) and became interested in Natural Language Processing last semester. I decided to focus on studying this area this summer and become skilled in this area. I wanted to get some advice for studying this particular subject.

Right now, I am taking Andrew Ng's Machine Learning course on Coursera to get a sense of how Machine Learning works. After finishing this course, I am planning to take Standford's CS224n NLP course on Youtube and do its class activities. I am assuming AWS and Tenserflow is also important since they are included as topics of CS224n.

I want to know if my summer plan sounds reasonable. If not, could you please give me an advice of how to make a better plan. If this sounds reasonable, it would be great if you can add more or specify which part is particularly important in these areas.

Thanks in advance!"
"Face Recognition using VGG Deep Face (Caffe, C++)",0,1,False,False,False,learnmachinelearning,1498782126,False, 
Feeling pretty confident in my understanding of RNN/LSTM theory. Want to start translating that to code. Do you guys have any good examples that will help me ease my way in? (Using Tensorflow),0,2,False,False,False,learnmachinelearning,1498786134,True, 
Problem with using linear regression for classification?,1,1,False,False,False,learnmachinelearning,1498789657,True,"I've referred to [this](https://stats.stackexchange.com/questions/22381/why-not-approach-classification-through-regression) stack post regarding approaching linear regression for classification, but one thing that was unclear to me was the problem with adjusting the threshold. 

I've watched Andrew Ng's video as well, but I'm unclear as to what is the problem with using a threshold to apply linear regression for classification. In the case where h(x) > .5 doesn't work, what's the actual problem with lowering the threshold based off the inferred hypothesis?"
Word2vec for learning multilabel embeddings?,1,5,False,False,False,learnmachinelearning,1498795584,True,"I'm working with a very large dataset, on the order of 340 million label vectors. It's the complete data from delicious (a social bookmarking service that operated from 2003 to 2011), so there is an enormous amount of data but no annotation whatsoever beyond the tags (which I'm treating as labels, in the sense that any given bookmark can have any number of tags). My goal is to end up with an unsupervised method of hierarchical clustering of labels, which I plan to apply to a similar dataset, but I decided to start with this because I would have to scrape and parse the other dataset myself.

My question is around the adaptation of these embedding techniques to multilabel tasks. In my case, the order in which tags appear for a bookmark is irrelevant. Every tag in a vector is just as relevant to the others as another. So working with a context window doesn't really make sense. I've thought of some ways to modify the algorithm, and I'm wondering whether they're appropriate, whether this has been studied before, or if there's a more appropriate method altogether that I might try.

1. I could use the skipgram model, fix the number of labels as inputs, and just set the window size to the longest vector's length. I would need to modify the generation of skipgrams such that instead of k/2 previous words in the windows and k/2 following words being selected, k words would be chosen regardless of position. I'm mostly concerned about the training time here, my understanding is that this would not affect the math given that context windows of any length are necessarily cut short by the beginning and ends of sentences.

2. I could, in a sense, generate ""pseudo-sentences"" using multiple permutations of the vectors and adding them to the training set. This seems like it would be very difficult to do without affecting the sampling processes. Unless I generated every permutation of every vector, I'm introducing error into the process, and there's no way to do this without having the effect of changing the frequencies that tags appear in. Additionally, this would add a lot of data to train on.

I'm familiar with diffusion maps (difficult with this dataset, I don't believe it's possible to maintain sparsity in a QR decomposition, and I cannot store a dense matrix with my resources), word2vec, heard of glove but haven't investigated it...am I on the right track? Anything else that's appropriate? Thanks in advance for taking the time to read and respond."
YellowFin: An automatic tuner for momentum SGD,0,3,False,False,False,learnmachinelearning,1498805671,False, 
Weekly Show-off!,0,6,False,False,False,learnmachinelearning,1498806760,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
Implementation of synthetic gradient,0,2,False,False,False,learnmachinelearning,1498814858,True,"I have been following some blogs and came across synthetic gradient. Does anyone have implementation of synethic gradient using some of the frameworks(keras, tensorflow) or using python?"
How to Visualize Your Recurrent Neural Network with Attention in Keras,0,3,False,False,False,learnmachinelearning,1498831652,False, 
Why is the likelihood the reverse of the propability?,3,6,False,False,False,learnmachinelearning,1498837233,True,See definition https://en.wikipedia.org/wiki/Likelihood_function
Examples of using policy gradient with more than 2 actions?,0,1,False,False,False,learnmachinelearning,1498846379,True,"Hi,

Can anyone point me to the direction of where to find an example of using policy gradients in Reinforcement Learning where the number of actions is more than 2?

I've been going through [Karpathy's pong tutorial](https://gist.github.com/karpathy/a4166c7fe253700972fcbc77e4ea32c5). I want to do something very similar but the number of actions will be more than 2.

Obviously I need to switch the sigmoid to softmax. I'm not sure how to sample an action if there is more than 2. Also not sure how to calculate the gradient of loss with more than 2 classes."
Multi-class labels accuracy/precision evaluation?,0,1,False,False,False,learnmachinelearning,1498846679,True,"I have a dataset with 500 or so labels, where each data point can have multiple labels. Currently these are stored as vectors of 0's with 1's at the index of the label. Each vector can have anywhere from 1 to 10 or so labels.

The output of my neural net is also going to have 500 or so nodes, with the highest indexes being the predictions of the labels.

I was wondering what the best method for evaluating this model would be. Currently I'm thinking of just using correct predictions/total labels.

How would one implement this efficiently in tensorflow when using large batches for input? There's the tf.nn.top_k, but that seems to be one vector at a time. Is there another built in function for this sort of thing? "
Tensorflow - Neural Network Playground,0,30,False,False,False,learnmachinelearning,1498849420,False, 
What happens inside RNN Cell?,3,1,False,False,False,learnmachinelearning,1498885287,True,"I am a beginner so please bear with me. 

I am using RNN to predict whether a given sms is spam or not

In brief, the overview of trained model architecture is

1) The text data is cleaned and encoded. Longer sequences are cut down and shorter sequences are zero padded.

2) We feed in data of size (batch_size, max_sequence_length).

3) Using am embedding matrix, we get an embedding of size (batch_size, max_sequence_length, embedding_size)

4) The embedding is fed to rnn cell
cell=tf.contrib.rnn.BasicRNNCell(num_units = rnn_size)

5) The cell outputs output of size (batch_size, max_sequence_length, rnn_size) and state of size (batch_size, rnn_size)

6) We will transpose output to (max_sequence_length, batch_size, rnn_size) to get “output2”

7) Then from “output2” we will take only the last output obtained by every sequence i.e. (-1, batch_size, rnn_size) or (batch_size, rnn_size). This wiill be our “output3”

8) We will have a weight matrix of size (rnn_size, 2) and bias matrix of size (rnn_size,)

9) We will multiply weight matrix with output3 and add bias matrix

10) We will then use softmax function to get probabilities for two classes separately (logits). Hence the shape of logits will be (batch_size, 2)


I am finding it difficult to understand what exactly happens in RNN cell (Step 4). How I view it currently is as follows?

1) When first word of a sequence is fed to rnn cell, first unit takes in input and initial state and gives output and next state. The next state along with first word is fed to next cell which gives output and new state. This goes on until we reach last unit which gives output and last state.

2) Then second word comes in, and last state from step 1 becomes initial state.

3) So, for each word in a sequence, we get output from every unit of the cell and and state from last unit.

Am I viewing it correctly? 


Thanks in advance

EDIT:

Here is the code snippet in Tensorflow

cell=tf.contrib.rnn.BasicRNNCell(num_units = rnn_size)

output, state = tf.nn.dynamic_rnn(cell, embedding_output, dtype=tf.float32)

output2 = tf.transpose(output, [1, 0, 2])

output3 = tf.gather(output, int(output.get_shape()[0]) - 1)

weight = tf.Variable(tf.truncated_normal([rnn_size, 2], stddev=0.1), name='weights')

bias = tf.Variable(tf.constant(0.1, shape=[2]), name='bias')

logits_out = tf.nn.softmax(tf.matmul(output3, weight) + bias)

losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_out, labels=y_output)

loss = tf.reduce_mean(losses)

"
CAN (Creative Adversarial Network) — Explained,0,2,False,False,False,learnmachinelearning,1498890882,False, 
"Weekly Status Check Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",1,5,False,False,False,learnmachinelearning,1498893066,True,"Let's have a  meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
Which is the best place to learn theano?,12,10,False,False,False,learnmachinelearning,1498914959,True,"I want to learn it in the shortest amount of time.

 I am trying to understand a program written by my friend.

"
What's the difference between Stanford's CS224n lecture video 2015 version vs 2017 version?,2,13,False,False,False,learnmachinelearning,1498933216,True,"There are two versions of this video track list on Youtube; one is the 2015 lecture and the other one is 2017 lecture and the lecturer is also different. I was going to watch the newer one, but I realized it's from the Winter semester, so I have been worrying if the lecture is kind of rushing because winter or summer semester courses usually have time limit.

For those who have taken this course, what do you recommend ?"
The basics of random variables.,0,1,False,False,False,learnmachinelearning,1498940922,False, 
Building Keras powered OCR webapp,0,11,False,False,False,learnmachinelearning,1498960777,False, 
How much statistics do you really need to know?,3,8,False,False,False,learnmachinelearning,1498979268,True,"Hey everyone, I'm a newbie in the world of Machine Learning but I really want to learn as much as I can over the summer (I'm still a freshman in college :) ) I've taken Linear Algebra, Multivar Calc and I'm pretty familiar with python. I wanted to know if I should maybe read up on Statistics before taking an online ML course since I don't have too much experience in that. Or should I just cut to the chase and dive into the ML and figure things out as I go? Thanks! "
Mimicking human mouse movement?,0,5,False,False,False,learnmachinelearning,1498993876,True,[deleted]
Scikit-Learn - No True Positives - Best Way to Normalize Data,9,8,False,False,False,learnmachinelearning,1499019278,True,"Thanks for taking the time to read my question!

So I am running an experiment to see if I can predict whether an individual has been diagnosed with depression (or at least says they have been) based on the words (or tokens)they use in their tweets. I found 139 users that at some point tweeted ""I have been diagnosed with depression"" or some variant of this phrase in an earnest context (.e. not joking or sarcastic. Human beings that were native speakers in the language of the tweet were used to discern whether the tweet being made was genuine or not).

I then collected the entire public timeline of tweets of all of these users' tweets, giving me a ""depressed user tweet corpus"" of about 17000 tweets.

Next I created a database of about 4000 random ""control"" users, and with their timelines created a ""control tweet corpus"" of about 800,000 tweets.

Then I combined them both into a big dataframe,which looks like this:

,class,tweet
0,depressed,tweet text .. *
1,depressed,tweet text.
2,depressed,@ tweet text
3,depressed,저 tweet text
4,depressed,@ tweet text😚
5,depressed,@ tweet text😍
6,depressed,@ tweet text ?
7,depressed,@ tweet text ?
8,depressed,tweet text *
9,depressed,@ tweet text ?
10,depressed,@ tweet text
11,depressed,tweet text *
12,depressed,#tweet text
13,depressed,
14,depressed,tweet text !
15,depressed,tweet text
16,depressed,tweet text. .
17,depressed,tweet text
...
50595,control,@tweet text?
150596,control,""@ tweet text.""
150597,control,@ tweet text.
150598,control,""@ tweet text. *""
150599,control,""@tweet text?""t
150600,control,""@ tweet text?""
150601,control,@ tweet text?
150602,control,@ tweet text.
150603,control,@tweet text~
150604,control,@ tweet text.
Then I trained a multinomial naive bayes classifier using an object from the CountVectorizer() class imported from the sklearn library:

count_vectorizer = CountVectorizer()
counts = count_vectorizer.fit_transform(tweet_corpus['tweet'].values)

classifier = MultinomialNB()
targets = tweet_corpus['class'].values
classifier.fit(counts, targets)
MultinomialNB(alpha=1.0, class_prior=None, fit_prior= True)
Unfortunately, after running a 6-fold cross validation test, the results suck and I am trying to figure out why.

Total tweets classified: 613952
Score: 0.0
Confusion matrix:
[[596070    743]
 [ 17139      0]]
So, I didn't properly predict a single depressed person's tweet! My initial thought is that I have not properly normalized the counts of the control group, and therefore even tokens which appear more frequently among the depressed user corpus are over represented in the control tweet corpus due to its much larger size. I was under the impression that .fit() did this already, so maybe I am on the wrong track here? If not, any suggestions on the most efficient way to normalize the data between two groups of disparate size?"
Cost Function confusion,4,1,False,False,False,learnmachinelearning,1499031034,True,"Hello. I am new to ML and I've been taking Andrew Ng's Coursera course. There are several things that I am still confused with.

First, do we have to memorize formulas for all cost functions?

Second, in the lecture, it just introduces the formula with simple explanation. Are we supposed to know how they got derived?

Third, what exactly is the difference between the model and the cost function? I know that the model is the formula that we use to predict the output with the data that is not used in the trained set. Sometimes in the lecture, I feel like cost function is also used as the same meaning. Can someone help me to correct my understanding?

Thanks!"
Home Renovation,0,1,False,False,False,learnmachinelearning,1499046727,False, 
Are stacksocial machine learning bundles worth it?,6,5,False,False,False,learnmachinelearning,1499047741,True,"For example:

https://stacksocial.com/sales/intro-to-ai-machine-learning-bundle

Are bundles like these a good investment? I used to buy bundles when they were on sale, but I have found mixed quality, some courses are literally power point slides that someone is reading off of.

Just wondering what you'd recommend in terms of online courses found on the web. I know Udacity has a dedicated ML program and I'm sure there are tons of MOOCs out there as well. It would be nice to have some one's perspective on it if they have already taken a course or two.

Thanks.
"
Learn algorithms/data structures first before machine learning?,14,15,False,False,False,learnmachinelearning,1499072325,True,"Hey guys, would it be wise to first focus on just pure algorithms and data structures for a more solid base. If not, if I haven't learned linear algebra or multivariable calculus yet would it be recommended that I learn the necessary topics like gaussian distributions and multiplying vectors/matrices first or do some basic machine learning stuff(like sentdex's machine learning youtube tutorials) elsewhere? Thanks!"
Exact convolution over a stack of images.,1,4,False,False,False,learnmachinelearning,1499083619,True,"I need to run a convolution over a stack of images. What I want is to use this convolution operation as a sort of a learned-average over the corresponding pixels at each position. 
I see tensorflow has two types of padding for convolutions, one is SAME and one is VALID. 
If I use a kernel with one of the sizes exactly that of my stack and padding VALID, will it run over all the image pixels without inserting extra rows / columns (due to padding) ? "
Neural Network Performance Improvement Question,5,4,False,False,False,learnmachinelearning,1499084208,True,"I've been working on developing neural networks for a particular regression-type problem for quite a while now, but I seem to be stuck at a validation set loss function value (range, rather). I've gone through several rounds of adding variables which should contribute better to the prediction task (based on better understanding of the system), however the loss function value does not improve.

Mostly, the neural networks have ranged from 1-8 hidden layers with cascading amount of neurons. I decided I was going to try to intentionally overfit the data and then implement regularization. Well, I can't seem to overfit it. I've gone all the way to 100 hidden layers with a constant number of neurons (the same number as the number of inputs), and still no overfitting - the model doesn't get any better on the training data than it does on the relatively simple neural networks.

Any suggestions? I apologize if I left out any relevant information, please feel free to ask."
Preprocessing for semantic segmentation?,2,5,False,False,False,learnmachinelearning,1499100206,True,Do the state-of-the-art models for semantic segmentation crop the images while training or feed the entire image?
When the networks heartbeat stops. I have no idea how and why this happened.,0,1,False,False,False,learnmachinelearning,1499100922,False,[deleted]
Artificial Intelligence: Reinforcement Learning in Python,1,0,False,False,False,learnmachinelearning,1499105672,False, 
[Question] Deep Neural Network with 1000 hidden layers for signal/vibrating ?,0,1,False,False,False,learnmachinelearning,1499114893,True,"Since the signal data is too large, I usually use ANN with Backpropagation of 1 hidden layers after doing the statistical signal extraction for the classification problem. 

However, I heard with DN, we don't need to do feature extraction, but instead, raw input the signal data to the network. 

So I wonder if are there any recent research about which type of deep neural network for signal (I did look around but the answer is quite ambiguous) 

Thanks for reading :D "
Having trouble understanding how data is being initialized in this LSTM.,1,5,False,False,False,learnmachinelearning,1499129639,True,"First off, here is the github code I am working with:

https://github.com/llSourcell/wiki_generator_live/blob/master/democodewiki.ipynb

This is an LSTM that is generating wikipedia articles.

We see that the data is being initialized here:

    data = tf.placeholder(tf.float32, [batch_size, len_per_section, char_size])

I'm having trouble understanding how this actually works. Below I've defined each of the three parameters. 

    batch_size = number of samples that is going into the model at a time
    len_per_section = number of characters we want to read at a time
    char_size = number of unique characters in our training set. 

Now, The data variable is referenced here:


    #unrolled LSTM loop
    #for each input set
    for i in range(len_per_section):
        #calculate state and output from LSTM
        output, state = lstm(data[:, i, :], output, state)
        #to start, 
        if i == 0:
            #store initial output and labels
            outputs_all_i = output
            labels_all_i = data[:, i+1, :]
        #for each new set, concat outputs and labels
        elif i != len_per_section - 1:
            #concatenates (combines) vectors along a dimension axis, not multiply
            outputs_all_i = tf.concat(0, [outputs_all_i, output])
            labels_all_i = tf.concat(0, [labels_all_i, data[:, i+1, :]])
        else:
            #final store
            outputs_all_i = tf.concat(0, [outputs_all_i, output])
            labels_all_i = tf.concat(0, [labels_all_i, labels])

This is where I'm a bit confused. We are iterating through each `len_per_section` so does that mean we are providing 50 characters in each loop as we go through the batch? Even then, I don't know where the third parameter `char_size` comes into play. 

For more info, please see the link above. Any clarification would be much appreciated.          "
Stanford University CS231n: Course Projects Spring 2017,1,38,False,False,False,learnmachinelearning,1499131695,False, 
starting machine learning for beginners,3,2,False,False,False,learnmachinelearning,1499135359,True,"Hi, everyone 
I am comfortable with coding in python, I want to proceed Machine Learning. I don't know how to start and is there any good courses and resources for beginners, datacamp or data quest is good but you cannot learn "
"Reinforcement learning: for a DQN, how to build the training set used between online learning steps?",0,1,False,False,False,learnmachinelearning,1499162222,True,[deleted]
High school learning group,1,4,False,False,False,learnmachinelearning,1499166987,True,"Hey!  
I'm a high school student and I'm highly interested in Machine Learning.  
  
I'd like to form a study group for learning and, hopefully, competitions later on!  
So, if you want to join, feel free to msg. me!  "
Reparameterization trick for other non-normal distributions? (Example tensorflow code?),0,2,False,False,False,learnmachinelearning,1499182125,True,"Can anyone point me toward tensorflow code for the reparameterization trick for non-normal distributions? (uniform, beta, poisson, negative-binomial, etc?) Both for the sampling stage and the KL loss stage?

I am trying to understand and implement latent variables in tensorflow models. I roughly understand how the reparameterization trick works in principal, how it's implemented as a sampler, and included as a KL divergence in the loss. There are many, many, good examples online for the normal distribution and a few discrete distributions, but none that I can find for other distributions.

Normal examples (https://github.com/fchollet/keras/blob/master/examples/variational_autoencoder.py)

Gumbel example (http://blog.evjang.com/2016/11/tutorial-categorical-variational.html)

Bernoulli (https://jmetzen.github.io/2015-11-27/vae.html)

Beta? (https://github.com/enalisnick/stick-breaking_dgms)


Further, has the expansion of tf.contrib.distributions made this easier recently? Many of the online examples are a few years old and write out the math fully for the sampling and loss, and I've read that they've made the sampling direction differentiable but I'm unclear on how.

I'm cross posting this on Cross Validated (https://stats.stackexchange.com/questions/288776/reparameterization-trick-for-other-non-normal-distributions-example-tensorflow). Do you have any recommendations for where else would be appropriate to ask this kind of question?"
Designing your very own Neural Network right from scratch!,6,33,False,False,False,learnmachinelearning,1499183929,False, 
Why do we try to reduce the number of iterations?,6,2,False,False,False,learnmachinelearning,1499184781,True,As I was going through Andrew NG's course on machine learning I noticed he did stuff like stopping at 300 iterations instead of 400 and choosing learning rate alpha so as to reduce the number of iterations. So why do we stop early if by going on we get more accurate results? 
Naive Bayes - assumption of independence - what should you do?,1,1,False,False,False,learnmachinelearning,1499185189,True,"Hi all, 
NB classifier assumes/requires features are independent. In real life, especially with text classification where there could be thousands of features, it's unlikely all features will be independent of each other. I have seen guides and texts that say NB can perform well even if this assumption is not held, but not always.

That said, here are my questions:

1. How do we test for independence of features? When do we consider features to be dependent?

2. What do we do when we do find dependency?

Thanks for your insights!

"
Numerical Linear Algebra for Coders,0,9,False,False,False,learnmachinelearning,1499193461,False,[deleted]
Is octave for ML still a good choice to begin?,3,2,False,False,False,learnmachinelearning,1499198511,True,I was going through some tutorials of ML and found the one of coursera by Andrew Ng with very high ratings. It does seem pretty clear too only downside is it uses octave and the instructor says that it's easier to begin in octave and most ML programmers prototype in octave but I can see the tutorial is considerably old so is it still a good choice to continue beginning with octave or will I be better of starting out with python?
Big difference between validation and test f1 scores,1,2,False,False,False,learnmachinelearning,1499208405,True,[deleted]
Need pseudo code for a simple RNN from scratch?,1,2,False,False,False,learnmachinelearning,1499222926,True,"I want to learn the fundamentals of RNN and want to make one from scratch using numpy. Can any one share a simple RNN code or pseudo code for creating RNN from scratch.

>3 input nodes ,10 hidden nodes and 3 output nodes

At this stage of learning I want to understand how feed forwarding with time steps work in RNN and so back prop is optional."
Getting started with Tensorflow,6,2,False,False,False,learnmachinelearning,1499229556,True,"Hello,

I have a project to implement and utilize Tensorflow for an ETL company. I am very new to this and am able to code in Python. 

I have installed the Tensorflow, where is a good place to start to learn how to build neural networks etc with this? 

Looking forward to hearing back! "
TWIL (This Week I Learned) - Share something new that you have learned this week!,6,8,False,False,False,learnmachinelearning,1499238683,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
ML - theory vs practise?,5,3,False,False,False,learnmachinelearning,1499243231,True,"Hello guys,

I come from the engineering sciences and have recently started to get involved in ML and I am enjoying it a lot. The stuff is fascinating and fun to learn because it combines programming, statistics and math.

I started doing the Andrew Ng course and reading /r/machinelearning I've come to ask myself if this course is maybe a bit deceiving? The concepts and math in the course are very easy, in comparison when I read about ML there it seems like the whole field is entirely academic and a bit far from practise? Courses in my uni on these topics are almost entirely on the theoretical statistical models and the math behind it while the big MOOC courses are very practical and focus on the programming.

So which one is it? Can I be successful in this field without having a math/statistics background and are these online courses deceiving? Should I continue doing the courses or read books to get a better grasp of the math behind it? 

Sorry if this has been asked before but I noticed this disconnect and really wanna know before diving deeper."
How to calculate the equivalent kernel and stride for a multilayer CNN ?,2,1,False,False,False,learnmachinelearning,1499245815,True,"I am reading [this](https://arxiv.org/pdf/1609.03193.pdf) paper, and on page 3, at the very top, they say:

> The full
network can be seen as a non-linear convolution, with a kernel width of size
31280
and stride equal
to
320

To me this sounds like a single convolutional layer, with a kernel width of 31280 and a stride of 320 would produce an output of the same size as the above network. 

How does one compute the equivalent kernel width and stride for a general convolutional network? I have not figured this out yet."
difference between regular convolution and depthwise separable convolution,2,2,False,False,False,learnmachinelearning,1499254470,True,I'm trying to understand the difference between regular convolution and depthwise separable convolution . I read Xception paper but I couldn't actually get how depthwise separable convolutions decreases trainable parameters ? Can someone give me a concrete example of how it works ?
Recommendation for ml library or approach,8,1,False,False,False,learnmachinelearning,1499260271,True,I'm looking to build a simple ml project which basically looks to scan say a PDF(text) where I have stored keywords and then make a recommendation based on those keywords that I can then apply to a new PDF(text). Is there a specific approach or ml library that anyone would recommend to accomplish this? 
Learn K-NN algorithm with Scikit-learn and speed it with cython,3,14,False,False,False,learnmachinelearning,1499264114,False, 
"Need help understanding Time Series applications of kNN, SVM's,k-Means, and Classification/Regression Trees.",0,2,False,False,False,learnmachinelearning,1499270344,True,"In lots of papers for time series analysis, I see kNN, SVM, and Trees brought up as 'easy' or go-to for anomaly and modeling. I cannot for the life of me find an example that helps clear up the time aspect. It just seems to go against my understanding of these algos which doesn't help. If someone could share some simple examples that could maybe help clear this up that would be great."
Genetic Algorithms vs Unsupervised learning,1,4,False,False,False,learnmachinelearning,1499272752,True,"I have a forex trading algorithm that is performing fairly well but I don't believe is operating anywhere close to optimally. I would like to tweak certain parameters to optimize the profits of the algorithm over a certain time period. 

I suppose I need to use some type of neural network(lstm seems like a good candidate) and somehow feedback the results of the decisions to reward positive behavior and penalize negative behavior. I'm not really sure how to do this however. 

Does anyone know of any good resources to start learning how to do this? Maybe a Kaggle competition or just a good tutorial that is similar to what I've described?"
where can I get entire sklearn documentation and examples as ipython notebook?,2,6,False,False,False,learnmachinelearning,1499275167,True,"I have seen that all the sample codes are available as ipython notebook in sklearn. However, I want to know if there is an archive or something to download entire notebooks.

**EDIT**
Since they ipynb for all their samples but don't provide them in a collected archive for download.. I am thinking of scraping all of them for study.. Update if you guys  find anything
"
How I Built a Reverse Image Search with Machine Learning and TensorFlow: Part 3,0,15,False,False,False,learnmachinelearning,1499281213,False, 
Help Choosing Classes: Linear Programming vs Discrete Mathematics,2,1,False,False,False,learnmachinelearning,1499299500,True,"I have the option of taking one of these two classes at my local university. Which is the best for someone trying to be good at ML/DL? 

Descriptions:

Linear Programming:
Algebraic background. Transportation problem. General simplex methods. Linear programming and theory of games. Numerical methods. Offered in alternate years.

Discrete Mathematics:
Relations and operations on sets, orderings, elementary combinatorial analysis, recursion, algebraic structures, logic, and methods of proof. 
"
RL identification help,0,1,False,False,False,learnmachinelearning,1499305148,True,"I watched this video on tetris 

https://www.youtube.com/watch?v=xLHCMMGuN0Q

where he basically uses someones elses repo on his video 

https://github.com/IdreesInc/TetNet 

My question is what type of reinforcement learning is that script using? Is it using Q-Learning due to trying out all possible states? 

Bonus question? Is it possible to use Reinforcement Training on a ANN without evolution aka NEAT?

Thanks in advance for any help."
Question about training on multiple images,4,1,False,False,False,learnmachinelearning,1499311469,True,"I'm trying to learn ML fundamentals, so I don't just want to jump into a framework. I coded a fully connected network based on this [video](https://youtu.be/ILsA4nyG7I0?t=1338), and I'm stuck on how to feed it multiple images. I wrote the code where I can feed it a single 2x2 image and it does forward and back propagation and it seems to work. 

Now I want to train it on other 2x2 images while preserving the learned result from training on the first image. My pseudo code is (matlab):

    tol = 1e-3;
    alpha = 0.01
    data(1).img = [1 1 ; 0 0];
    data(1).truth= [1 0];
    data(2).img = [1 0 ; 1 0];
    data(2).truth = [0 1];
    for i = 1:2
        img = data(i).img;
        truth = data(i).truth;
        err=Inf;
        while err>tol
            net = forwardprop(net,img);
            err = sum(0.5*(truth - net.output)^2);
            net = backprop(net,truth,alpha);
        end
    end

So I have two, 2x2, images. One that is a horizontal line and one that is a vertical line. The way I have it coded above, I do them in series, i.e., use the computed weights of training on the first image as the starting point for training on the second image. It doesn't seem to converge on the second image, so I'm likely doing something wrong.

* Is this series approach to training the proper one, or do I need to do some sort of batch process where I forward and back propagate on both images simultaneously. 
* Does anybody have an reference that shows code and explain the math for this point in the training process?

I know this is a very simplistic example, but I need to start somewhere. Any help is very much appreciated.
"
Lessons to Be Learned When Machine Learning and Data Science Works Too Well,9,21,False,False,False,learnmachinelearning,1499311485,False, 
awesome python packages,0,1,False,False,False,learnmachinelearning,1499345164,False, 
Best practices for creating a classifier on spare data?,0,1,False,False,False,learnmachinelearning,1499347162,True,[deleted]
Best practices for training on sparse data?,4,1,False,False,False,learnmachinelearning,1499347208,True,"Hey all,

I have a bit of a problem, I'm trying to classify three different types of images, however one class is far more common than the other two by two orders of magnitude

Do y'all have any suggestions for training and testing on this data? Should I limit the training samples for the common class to be the same number as the other two classes so it gets some diversity, or would it be better to keep the ratios equivalent to the actual frequency that it'll encounter those classes?

Any and all help appreciated, thank you!
"
Main recommendation system algorithms and how they work,2,16,False,False,False,learnmachinelearning,1499349974,False, 
Need some clarification on Convolutional Neural Networks,4,0,False,False,False,learnmachinelearning,1499360428,True,"Hey guys! 

I'm pretty new to the whole machine learning so I'm sorry if these are super stupid questions but I do appreciate all of you! 

From what I understand... 

1. CNNs seem to be mostly used for being able to classify an image. Are they able to be used for other things? 

2. I was watching a tutorial that showed how someone used a CNN to self drive a car in gta. It seemed as if he was capturing his key presses and the game screen and then had the CNN predict what key to press based on the screen. 

Does that make any sense? 

3. Is there another type of machine learning I should reading up on if the goal is to make a simple game ai based on what appears on the screen? 

I looked into reinforcement learning but I'm looking for something where I want a certain action to occur based on what's going on with the screen.

And I feel like the different possibilities of actions that are able to occur is far too much for reinforcement learning

All your answers are super appreciated! 

Thanks :)"
Bolt Manufacturing on Traub A25 Automatic Screw Machine/Automatic Lathe machine,1,0,False,False,False,learnmachinelearning,1499363174,False, 
Configuring CNN Based on Q-Learning DNN,0,1,False,False,False,learnmachinelearning,1499366667,True,"Hello everyone!  
  
Got an interesting question for you guys. I'm working on making a neural network AI for a drop puzzle game (think puyo puyo and tetris) and it's going decently well. The AI is able to build decent combos and get good scores. The main issue that I'm running into is that it's not seeming to care about losing. IE, if it's near the top of the puzzle arena and it could make a move to lower it back down, it won't.  
  
Before I go into what I've tried, I'll go into the current figuration of the neural network. I feed the board itself as a Row Width x Column Width x Color Channel tensor. (Typically this means 13x6x5.) This is fed into a CNN where it is padded and convolved with either a 2x2 or 3x3 stride. It goes through a standard ReLU and into another convolution layer with either 2x2 or 3x3 stride. It's run through ReLU again then sent to 2 fully connected layers (both also ReLU) and finally to an output of n possible moves. (Typically 22.) When the CNN data is fed into the feed forward network, the information for the next block is also passed as a one hot feature set representing the color information of the block. (The block at this time only has one shape so it only needs the color data atm.)   
  
The move is chosen based on picking the highest valued legal move. IE, if the highest move isn't a legal move, it isn't chosen. (I originally had it set to give a negative reward with an illegal move but it didn't seem to be doing anything so I took it out for now since it would just choose the same illegal move over and over if the random value was too low.)  
  
I've tried setting a high negative reward value for the losing move to help disuade the AI from choosing it but to no avail. Part of the problem could be that the games last anywhere between 20-infinity moves(hard capped at 500 atm). I've also tried adding additional reward per turn based on how long the AI has been playing but this also hasn't seemed to help.  
  
The network is based off of the Deep Q Learning Network published by Deepmind and modified with Double Q learning. If anyone has any tips, they would be greatly appreciated."
"What are the best resources to learn machine learning thoroughly for someone who already has a strong background in linear algebra, vector calculus, and stats?",8,10,False,False,False,learnmachinelearning,1499385728,True,I have a MS in mech eng so have strong math background. Is there good resource for this particular background? 
Weekly Show-off!,13,3,False,False,False,learnmachinelearning,1499411123,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
Need help designing a ML syllabus for myself.,11,12,False,False,False,learnmachinelearning,1499428057,True,"ML novice here. I am a freshman undergraduate. I am fairly comfortable with C++, Java and Python and basic Algebra, basic Combimatrics, and High School Calculus. I recently started with Toby Sergan's 'Programming Collective Intelligence', which is great, but I feel doesn't go deep into a topic. I prefer books to MOOCs, however, if there is a free-to-use, public video library, like a YouTube playlist, I'll use that too. I prefer books that contain detailed analysis of a topic. Doesn't have to be in layman terms; if I don't understand something, I'll just ask somebody experienced to break it down for me. But the information must be present there. Hope I'm not being too demanding or/and picky. I could really use some advice on the matter. Can anybody recommend a book? Thanks for your time.

PS. - I've also gotten my hands on 'Elements of Statistical Learning' but it seems that the book uses R as its language for examples. Is there a Python version around as well, or a book that is similar to ESL but uses Python or Java as its primary language?"
"Question about ""boosting"" common terms in sklearn when doing text classification",2,8,False,False,False,learnmachinelearning,1499436841,True,"Hey ML Reddit,

I am currently building out a text classification system for work that classifies a job description as **IT, Management, Healthcare, etc**. It works by creating a TF-IDF matrix by using the TfidfVectorizer and then feeding it to the RandomForestClassifier (although I have used other classifiers).

The issue that I am running into is my classifier will see a job description with something like **""Store Manager - Manage and operate a local store...""** and **""IT Project Manager - Plan and manage IT projects...""** and classify them the both as **Management**.

What I would like to do is to do something that in essence tells the classifier that if it sees the terms **IT Project Manager** to classify it under the class **IT**. 

I understand in theory that I would need to increase the value in the TF-IDF matrix for the row/column intersection for the n-gram **IT Project Manager** and the class **IT**, but I was wondering if anyone had any examples on best practices/syntax to actually perform this?

"
[Python] Identifying subjects within sentences,2,4,False,False,False,learnmachinelearning,1499454443,True,[deleted]
What are some good resources/books for refreshing linear algebra?,8,13,False,False,False,learnmachinelearning,1499469480,True,"I would prefer topics highly relevant to machine learning. Or I guess more applicable.



*reviewing"
Help critique my ML curriculum!,7,15,False,False,False,learnmachinelearning,1499480757,True,"Hi everyone! I've been doing some research on how to get started on machine learning as a beginner and have come up with the curriculum below for myself to follow. It would be great if those proficient in ML, or even those currently learning, help to critique or provide suggestions. Additional courses, literature, programs, or advice would be greatly appreciated! It may be difficult to critique without having firsthand experience of each course or program, but I'm more concerned the with subject matter included than the courses themselves. As I go through each course, I may decide to change them if I feel that it is not pertinent to the goal or lacking in quality. There's no way I will become an expert after this, but I'm simply looking for a good starting point. I hope this will help others as well. 

 

As a point of reference, I've graduated with a B.S. in Mechanical Engineering, have taken several math courses (calculus, linear algebra, differential equations), and have taken a few programming courses (CS50, Intro to Comp Sci on eDX, CS 101 at University). I'm currently working part-time as a mechanical designer / energy analyst and have 40-50 hours a week to spare. 

 

For the curriculum, I've broken it up into 5 sections (programming, statistics, linear algebra, data science, and machine learning) which will be overlapping. I plan on taking 3 courses at a time starting with Udacity's Intro to programming, Stanford's probability and stats, and Udacity's linear algebra refresher while reading ""*An Introduction to Statistical Learning*.""

 

Here it is!

 

######**Curriculum:**

**Programming**

1. Udacity Introduction to programming https://www.udacity.com/course/intro-to-programming-nanodegree--nd000
 * Learn the basics of programming through HTML, CSS, and Python.

**Statistics**

1. Stanford Online: Probability and Statistics https://lagunita.stanford.edu/courses/course-v1:OLI+ProbStat+Open_Jan2017/about  
 * Broken into four sections: exploratory data analysis, producing data, probability, and inference.  

2. Stanford Online: Statistical Learning http://online.stanford.edu/course/statistical-learning-winter-2014
 * Introductory-level course in supervised learning, with a focus on regression and classification methods.
 * Lectures cover all the material in An Introduction to Statistical Learning, with Applications in R.

**Linear Algebra**

1. Udacity Linear Algebra Refresher Course with Python: https://www.udacity.com/course/linear-algebra-refresher-course--ud953

2. UAustinX Linear Algebra - Foundations to Frontiers [edx.org/course/linear-algebra](https://www.edx.org/course/linear-algebra-foundations-frontiers-utaustinx-ut-5-05x-0#ct-read-review-widget)
 * Connections between linear transformations, matrices, and systems of linear equations. 
 * Partitioned matrices and characteristics of special matrices. 
 * Algorithms for matrix computations and solving systems of equations. Vector spaces, subspaces, and characterizations of linear independence. 
 *Orthogonality, linear least-squares, eigenvalues and eigenvectors
	

**Data Science**

1. Udacity Introduction to Data Science https://www.udacity.com/course/intro-to-data-science--ud359
 * Focuses on Data Manipulation, Data Analysis with Statistics and Machine Learning, Data Communication with Information Visualization, and Data at Scale -- Working with Big Data
	
2. Udacity Data Science Nano-degree https://www.udacity.com/course/data-analyst-nanodegree--nd002
 * Learn to organize data, uncover patterns and insights, make predictions using machine learning, and clearly communicate critical findings.
	
3. (optional) UCSD Data Science Micro-masters Program (4 course program) https://www.edx.org/micromasters/data-science
 * Four courses: Python for Data Science, Statistics and Probability in Data Science using Python, Machine Learning for Data Science, and Big Data Analytics Using Spark. 

**Machine Learning**

1. Udacity Intro to Machine Learning https://www.udacity.com/course/intro-to-machine-learning--ud120
 * How to extract and identify useful features that best represent data, learn a few of the most important machine learning algorithms, and how to evaluate the performance machine learning algorithms.
	
2. Coursera Machine Learning by Andrew Ng https://www.coursera.org/learn/machine-learning
 * This course provides a broad introduction to machine learning, data-mining, and statistical pattern recognition.
	
3. (with job guarantee?) Udacity Machine Learning Nano-degree https://www.udacity.com/course/machine-learning-engineer-nanodegree--nd009
 *  Apply predictive models to massive data sets in fields like finance, healthcare, education, and more.

 

######**Literature:**

1. An Introduction to Statistical Learning http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf

2. The Elements of Statistical Learning: Data Mining, Inference, and Prediction https://web.stanford.edu/~hastie/ElemStatLearn/printings/ESLII_print12.pdf

 

######**Other (after curriculum):**
https://www.reddit.com/r/MachineLearning/wiki/index 

 

Let me know your thoughts! Have you taken one of these courses before? Think there's too little programming or know of a better course/program? Chime in! Would be really grateful for any feedback. 

**Big Thanks!**

-*sleepyowl*"
What are some good books for me to get into AI/Machine Learning/Deep Learning?,7,8,False,False,False,learnmachinelearning,1499483905,True,"I have literally no experience with AI/machine learning/deep learning, but I am really interested in getting into these fields. I have been learning python too recently and would love to contribute to open source projects on GitHub, but I guess first I have to read up. What are some of the best books on these topics?"
Thomas Huijskens - Bayesian optimisation with scikit-learn,0,11,False,False,False,learnmachinelearning,1499494465,False, 
"Weekly Status Check Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",0,1,False,False,False,learnmachinelearning,1499497510,True,"Let's have a  meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
"If I want to do a job related to NLP, do I need a Masters Degree?",1,2,False,False,False,learnmachinelearning,1499500649,True,"I am currently an Undergrad majoring in CS. I became interested in Machine Learning, especially in NLP, recently. I was wondering if I want to do a job related to NLP, do I need a Masters degree?
If so, do I need a research experience on NLP?
I would love any advice regarding my question.
Thanks!"
Shall I switch from Coursera Stanford Machine learning course to Stanford CS 229 for studying Machine Learning?,2,9,False,False,False,learnmachinelearning,1499502431,True,"I am self-taught and am willing to learn material within the scope of artificial intelligence.

I have visited the quite popular [Coursera Machine Learning course](https://www.coursera.org/learn/machine-learning/), but digging a little inside the reviews section, some learners who had fully completed the course declared that parts of this course were a bit superficial (some trivial assignments, very basic linear algebra, teaching syllabus not really exhaustive and so on).

I then discovered the [CS 229 course](http://cs229.stanford.edu/materials.html), which I assume to be more complete than the other, and perhaps like the real class taught at Stanford.

Does the CS 229 course contain all the material I need to learn its syllabus? (I wouldn't like to start studying it, only to find thereafter that some pieces are missing.) And furthermore, in what ways is it ""better"" than the alternative I suggested?"
"N00b here, need help with a strategy for identifying abuse of service accounts on >>50K Unix boxes.",6,11,False,False,False,learnmachinelearning,1499523963,True,"TL;DR - I want to learn ML with a real world problem of identifying anomalous process/process owner relationships in a large Unix fleet.  Halp.

I believe it's a pretty typical definition, but to be clear a 'service account' in our parlance is an OS account that is intended to be used by a running service, not by a human operator.  So, for example, the 'oracle' Unix account is fine to run the Oracle database, listeners, etc, but if it's running ssh or vim or less, we would want to flag that for review.

My plan is to start with simple process listings (e.g. 'ps auxww') as input, and approach this as a supervised classification problem.  I'll know which Unix account is associated with what process from the /bin/ps output, and I can do a lookup to determine if that Unix account is a human account or a service account.  This would be used for training.

For detection, I would pipe in the individual process listings and ask the system to classify it as human or service based on that information.  If the output matches the class of the actual process owner, then we're good to go, if it doesn't then we would flag that for review.

This is where I get stalled.  My intent is to use this problem, which is a real one i need to solve for work, as a way to drive my learning of ML.  The issue is that I am having difficulty settling on a strategy because I can't really find a direct example to draw from.  I'd like to explore both statistical/Bayesian methods as well as deep learning methods, and ultimately enrich the data with all sorts of other information (parent processes, open sockets, audit events, etc), but I'm stalled at the starting line.

Could one of you kind folks just bullet out an approach for me to get started?  What's a good framework and algorithm for me to use here?  I'm a security grunt by trade but have workable development skills in Java and am getting up to speed in Python.

Thanks in advance!

edit: Some sample data for reference.  In this case 'hadoop' would be a service account and 'n00b' a human account.  (Note that hadoop has a shell and TTY about 12 lines down, this would be no bueno and should flag a review, but is also something that could be done with a simple rule-based system.  However, hadoop also has a jupyter instance running.  That's a bit more domain specific and the security team might not realise that it's less ususal for a service to run and also worthy of flagging for review.  That is the type of thing I'd like to find with this system.)

    USER     TTY      STAT START   TIME COMMAND
    daemon   ?        Ss   Apr02   0:00 /usr/sbin/atd -f
    root     ?        Ss   Apr02   0:12 /lib/systemd/systemd-logind
    root     ?        Ssl  Apr02   2:38 /usr/lib/accountsservice/accounts-daemon
    message+ ?        Ss   Apr02   0:03 /usr/bin/dbus-daemon --system --address=systemd: --nofork --nopidfile --systemd-activation
    syslog   ?        Ssl  Apr02   0:46 /usr/sbin/rsyslogd -n
    hadoop   ?        Sl   May20  70:43 /usr/lib/jvm/java-8-oracle/bin/java -cp /opt/spark/conf/:/opt/spark/jars/* -Xmx1g org.apac
    hadoop   ?        Sl   May20  69:48 /usr/lib/jvm/java-8-oracle/jre/bin/java -cp /opt/spark/conf/:/opt/spark/jars/* -Xmx1g org.
    hadoop   ?        Sl   May20 354:28 /usr/lib/jvm/java-8-oracle/bin/java -cp /opt/spark/conf/:/opt/spark/jars/* -Xmx1g org.apac
    hadoop   ?        Sl   May20  89:24 /usr/lib/jvm/java-8-oracle/jre/bin/java -cp /opt/spark/conf/:/opt/spark/jars/* -Xmx1024M -
    root     ?        Ss   12:17   0:00 sshd: hadoop [priv]
    hadoop   ?        S    12:17   0:00 sshd: hadoop@pts/1
    hadoop   pts/1    Ss+  12:17   0:00 -bash
    root     ?        S    Apr02   0:00 [jfsIO]
    root     ?        S    Apr02   0:00 [jfsCommit]
    root     ?        S    Apr02   0:00 [jfsCommit]
    root     ?        S    Apr02   0:00 [jfsCommit]
    root     ?        S    Apr02   0:00 [jfsCommit]
    root     ?        S    Apr02   0:00 [jfsSync]
    hadoop   ?        Ss   May01   0:00 /lib/systemd/systemd --user
    hadoop   ?        S    May01   0:00 (sd-pam)
    hadoop   ?        Sl   May01  48:31 /usr/bin/python /usr/local/bin/ipython notebook --no-browser --port=7778 --ip=*
    hadoop   ?        Ssl  May01  21:26 /usr/bin/python -m ipykernel -f /run/user/1002/jupyter/kernel-3ba06e94-c8b7-48f3-a9a9-f137
    hadoop   ?        Sl   May01 199:49 /usr/lib/jvm/java-8-oracle/bin/java -cp /opt/spark/conf/:/opt/spark/jars/* -Xmx1g org.apac
    hadoop   ?        Ssl  May01  21:27 /usr/bin/python -m ipykernel -f /run/user/1002/jupyter/kernel-42a5036f-26cd-4053-b665-f1f3
    hadoop   ?        Sl   May01 164:43 /usr/lib/jvm/java-8-oracle/bin/java -cp /opt/spark/conf/:/opt/spark/jars/* -Xmx1g org.apac
    hadoop   ?        Ssl  May01  22:24 /usr/bin/python -m ipykernel -f /run/user/1002/jupyter/kernel-5eb762ad-72dc-4eeb-b946-a6f9
    hadoop   ?        Sl   May01 164:36 /usr/lib/jvm/java-8-oracle/bin/java -cp /opt/spark/conf/:/opt/spark/jars/* -Xmx1g org.apac
    root     ?        Ss   Jul06   0:00 sshd: n00b  [priv]
    n00b     ?        S    Jul06   0:10 sshd: n00b @pts/0
    n00b     pts/0    Ss   Jul06   0:12 -bash
    n00b     pts/0    S    Jul07   0:01 /usr/bin/python /usr/local/bin/ipython notebook --no-browser --port=7777 --ip=*
    hadoop   ?        Sl   May20 134:21 /usr/lib/jvm/java-8-oracle/bin/java -Dproc_namenode -Xmx1000m -Djava.net.preferIPv4Stack=t
    hadoop   ?        Sl   May20 113:18 /usr/lib/jvm/java-8-oracle/bin/java -Dproc_datanode -Xmx1000m -Djava.net.preferIPv4Stack=t
    hadoop   ?        Sl   May20  58:24 /usr/lib/jvm/java-8-oracle/bin/java -Dproc_secondarynamenode -Xmx1000m -Djava.net.preferIP
    hadoop   ?        Sl   May20 590:35 /usr/lib/jvm/java-8-oracle/bin/java -Dproc_resourcemanager -Xmx1000m -Dhadoop.log.dir=/opt
    root     ?        S    Jul07   0:04 [kworker/2:2]
    hadoop   ?        Sl   May20 219:42 /usr/lib/jvm/java-8-oracle/bin/java -Dproc_nodemanager -Xmx1000m -Dhadoop.log.dir=/opt/had"
Tensorflow Documentation as PDF,0,5,False,False,False,learnmachinelearning,1499533582,True,"Does Anybody have a pdf version of Tensorflow. I tried generating the docs but i get error while generating it. Thanks
"
Probability Distribution Function explained,0,1,False,False,False,learnmachinelearning,1499552276,False,[deleted]
"How to install NVIDIA CUDA 8.0, cuDNN 5.1, Tensorflow, and Keras on Ubuntu 16.04",4,2,False,False,False,learnmachinelearning,1499556367,False, 
A Neural Network in 10 lines of C++ Code,6,20,False,False,False,learnmachinelearning,1499557260,False, 
Diabetic retinopathy detection tutorial with Tensorflow,0,10,False,False,False,learnmachinelearning,1499559523,False, 
Suggestions for PC specs for machine learning development?,9,1,False,False,False,learnmachinelearning,1499559782,True,"I'm currently in school for programming, and my parent offered to buy me a laptop for ~$1000. I'm wondering what I should look or in a PC, if I want to learn machine learning?

 

I plan to post to r/suggestalaptop, but I wanted to find out what specs I should ask for first.

 

I'm asking, since the r/learnprogramming faq suggests that: ""If you're specifically interested in doing machine learning, natural language processing, or graphics (including game development), you may want to consider purchasing a machine with a GPU. While you don't need a GPU to do any of these things, you can often speed up your code by carefully writing it so that it takes advantage of GPUs (when possible).""

 

The current minimum specs I'm considering now (per r/learnprogramming's faq) are as follows:

•	Intel i5 CPU (3.0+ GHz)

•	4+ GB RAM

•	200+ GB Hard drive

•	(Optional) A solid-state drive

Any advice on specs, or even personal experience with specific laptops, would be greatly appreciated!"
Best Algorithm/Technique for this problem?,2,1,False,False,False,learnmachinelearning,1499567358,True,"What I want to do is match existing (but soon expiring) government contracts to companies in a database of registered government contractors. The goal is to match each contract to the company best positioned to win it when  it is open for competition. 

The idea I have is to train a model to recognize companies that are well suited for a particular contract by using training data consisting of past contracts and the company that won it. The fields that I'll be working with are strings and integers. Some of the fields are free text, where I would need some kind of similarity function, and some of the fields are limited to a discrete set of values. 

What kinds of algorithms or techniques would be most useful for this problem? I'm a beginner with machine learning."
Probability Distribution Function explained,0,1,False,False,False,learnmachinelearning,1499607842,False,[deleted]
Elements of Statistic Learning Study Group?,10,11,False,False,False,learnmachinelearning,1499616370,True,"I want to read the book but I find it too hard, I think a study group might be good. We could do it on slack or on discord. 
Anyone interested?

Edit: Discord it is. pm me for invitation link. :)
"
Adapting TensorFlow MNIST tutorial to predict 2D Boolean Array,3,3,False,False,False,learnmachinelearning,1499623087,True,"The past few weeks I have been attempting to adapt the MNIST tutorial to my specific use case (I'm new to machine learning). The tutorial uses a lot of use case specific functions that only apply to the MNIST dataset example. I have a dataset of chemical information that I would like to use as a test project.

The idea is to input into TensorFlow a NxN array (using 7x8 as simple example) array consisting of floats with some distance information and the output would be a NxN boolean array of the same size with 0 for false and 1 for true for the corresponding atom in the input array.

Example 7x8 Input Matrix :

    1., 0.0, 2.4, 3.5, 6.5, 8.5, 9.5, 8.3
    2., 2.4, 0.0, 6.5, 1.3, 1.2, 3.3, 8.1
    3., 1.4, 5.5, 0.0, 2.2, 1.3, 2.3, 3.2
    4., 2.2, 3.1, 3.2, 0.0, 1.1, 0.2, 3.0
    5., 1.1, 1.2, 3.1, 6.4, 0.0, 1.1, 0.7
    6., 2.2, 2.1, 3.1, 7.9, 8.1, 0.0, 8.1
    7., 2.1, 4.2, 6.4, 5.2, 6.3, 8.1, 0.0

Example corresponding 7x8 true/false training data. This is the target class or 'y_':

    1., 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0
    2., 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0
    3., 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0
    4., 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0
    5., 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0
    6., 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0
    7., 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0

I have access to a very large dataset. I'm parsing through the whole file and building a python list of 2D NumPy Arrays for both my input layer (x) and example output layer (y_).

Here is my adapted model so far that does not work:
    
    def get_batch():
        #parse code and build list of 2D NumPy Arrays for both 'x' and 'y_'
        return list1, list2

    # x will be the input matrix flattened (7x8)
    x = tf.placeholder(tf.float32, [None, 56])

    # Define the weights (initial value doesn't matter since these 
    will be learned)
    W = tf.Variable(tf.zeros([56, 56]))
    b = tf.Variable(tf.zeros([56]))

    # Predict output matrix
    y = tf.nn.softmax(tf.matmul(x, W) + b)

    # Actual output matrix from the training set
    y_ = tf.placeholder(tf.float32, [None, 56])

    # Calculate loss and optimize
    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))
    train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)

    sess = tf.InteractiveSession()
    tf.global_variables_initializer().run()

    a, b = get_batch()
    train_len = len(a)

    # Training
    for i in range(train_len):
        batch_xs = a[i]
        batch_ys = b[i]
        sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})

    # Test trained model
    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

    # This part is unclear. MNIST uses helper functions for this...
    cumulative_accuracy = 0.0
    for i in range(train_len):
        acc_batch_xs = a[i]
        acc_batch_ys = b[i]
        cumulative_accuracy += accuracy.eval(feed_dict={x: acc_batch_xs, y_: acc_batch_ys})
    print(""test accuracy {}"".format(cumulative_accuracy / train_len))

When I run this I get:

    test accuracy 1.0

...which I know is not correct. What am I doing wrong? I would really appreciate any guidance/knowledge you can share as this has been quite frustrating. I know there is something I'm not quite understanding here. Please let me know if there is any clarification needed. Thanks!"
How would I implement the segmentation algorithm described in this paper?,0,1,False,False,False,learnmachinelearning,1499629487,True,[deleted]
Probability Distribution Function explained,0,1,False,False,False,learnmachinelearning,1499635823,False, 
When not to use deep learning,0,2,False,False,False,learnmachinelearning,1499645872,False,[deleted]
When not to use deep learning,1,2,False,False,False,learnmachinelearning,1499647984,False, 
Tutorial: Logistic Regression using Python,0,10,False,False,False,learnmachinelearning,1499648840,False, 
Kmeans clustering algorithm with Python,0,0,False,False,False,learnmachinelearning,1499650479,False, 
Videos for Stanford's CS109?,4,1,False,False,False,learnmachinelearning,1499651589,True,"I'm watching Andrew Ng's CS229 online and getting a little lost in some of the probabilities. It lists CS109 as a prerequisite but I've been unable to find the videos online.

Are they only for enrolled students? Anyone know where I could get an adequate refresher on probability and stats?"
Learning Machine Learning with a Good Mathematical Background,1,2,False,False,False,learnmachinelearning,1499658072,True,[deleted]
I know this is anything too special just finished a javascript 3 layer neural network from scratch as a learning tool.,6,24,False,False,False,learnmachinelearning,1499659407,False, 
Downloading all English books from gutenberg.org with Python,0,6,False,False,False,learnmachinelearning,1499672572,False, 
Free eBook: Mastering Machine Learning with scikit-learn (PDF/ePub/Mobi),0,1,False,False,False,learnmachinelearning,1499673201,False, 
"Test new strategy here, Great place to learn",0,7,False,False,False,learnmachinelearning,1499686722,False, 
Gender Classification with Machine Learning (Random Forest and Python),2,10,False,False,False,learnmachinelearning,1499689517,False, 
Introduction to Machine Learning! Everything you need to know,4,12,False,False,False,learnmachinelearning,1499691676,False, 
open source machine learning track by members of subreddit,0,3,False,False,False,learnmachinelearning,1499694416,True,"Hi All
I have been struggling to find a comprehensive track based on open sources like coursera/edx or other free MOOCs. 
I request the members of this subreddit to create a such an open source track just like the one in Dataquest or datacamp. The idea to get from A-Z. 
It can include MOOCs, Books, Tutorials, Problems, completitions or any medium that is open to all for free. We can do this for both R and Python."
Alternative Face v1.1 - YouTube,2,1,False,False,False,learnmachinelearning,1499703379,False,[deleted]
Introducing /r/LearnMachineLearning Slack Channel!,0,1,False,False,False,learnmachinelearning,1499704182,True,[removed]
Introducing /r/LearnMachineLearning Discord Chatroom!,1,28,False,False,True,learnmachinelearning,1499707309,True,"Hello, learners of machine learning

We are glad to announce a dedicated Discord server for /r/LearnMachineLearning. You can join through https://discord.gg/G3rvFKF. 

Discord, a real-time communication tool, can complement our subreddit in several ways:

- Non-technical discussion involving machine learning
- Bouncing off quick ideas for your project
- Dedicated channels for niche interest groups such as an online-class study group or a specific ML project group

Please use this post for any suggestions or questions."
Help with Fuzzy Random Forests in R,0,2,False,False,False,learnmachinelearning,1499712807,True,"Hey Reddit! I'm trying to learn how to classify objects with machine learning. I have to use R to create a fuzzy random forest, but I've never actually gotten the chance to implement ML algorithms. Therefore, I have no idea how to actually create and fuzzy random forest in R. Can someone send me an example piece of code in R that will show me what I need to do? Thanks!!!"
Top 30 Tips For Machine Learning and Data Science Teams,0,2,False,False,False,learnmachinelearning,1499727573,False,[deleted]
How to use custom Data with pixelCNN?,2,3,False,False,False,learnmachinelearning,1499727676,True,"I'm trying to use https://github.com/openai/pixel-cnn on Ubuntu 16.04, and I have set up all the dependencies and can train on the cifar 10 dataset, but I'm unsure of how to train on a custom dataset.

I tried mimicking an imagenet dataset, but since I'm using grayscale, it has an issue when tensorflow tries to resize the tensor. Is there an easier way to do this?"
What books/resources to supplement Andrew Ng's course?,3,22,False,False,False,learnmachinelearning,1499737260,True,[deleted]
Best GPU Manufacturer for ML?,5,1,False,False,False,learnmachinelearning,1499739801,True,"So I currently have a system with a 660ti in it, and I am planning on upgrading. I've been getting into machine learning and more specifically learning Tensorflow. So, I was wondering if I would benefit more from buying a new Nvidia GPU vs a new AMD GPU. My budget for a new card is around $400 USD. 

Thanks in advance!"
Curated List of Great AI and Machine Learning Resources from Around the Web,0,1,False,False,False,learnmachinelearning,1499740132,False, 
Downloading more than 20 years of The New York Times,9,18,False,False,False,learnmachinelearning,1499744127,False, 
New CS224n: Natural Language Processing with Deep Learning,2,17,False,False,False,learnmachinelearning,1499749472,True,Stanford has started a new version of [CS224n: Natural Language Processing with Deep Learning](http://web.stanford.edu/class/cs224n/) with both Chris Manning and Richard Socher. Are you looking forward to watching it?
"New to machine learning, need help in implementing a Decision Tree learner",1,7,False,False,False,learnmachinelearning,1499757528,True,"Hi all, I'm new to machine learning and currently taking a course on machine learning. We are currently on a project that requires us to build a decision tree learner. However, my instructor barely touches on the topic and sends us links for us to read on instead. Therefore I'm looking for help in this subreddit, wish someone could help me in this project :) Btw it would be helpful if someone can do it like /r/explainlikeimfive

We are given an .arff file that includes null and missing attributes. I tried loading it up onto python but the output array is all messed up. Is that supposed to happen? If it is, how am I suppose to clean it up? Secondly, how am I suppose to deal with the null and missing attributes? Am I suppose to input the data as so without caring about the missing attributes?

Thanks!"
free course on machine learning for traders,0,1,False,False,False,learnmachinelearning,1499762329,False, 
Tutorials on predicting MULTIPLE future values of a time series?,0,2,False,False,False,learnmachinelearning,1499771537,True,"Hi! I've encountered an interesting problem yesterday. Basically, I need to predict some seasonal data (time series) for several days into the future. I need to do this with neural networks (this is part of the difficulty, I cannot use common methods like ARIMA here).

To my surprise, all the tutorials I found deal with prediction of just one future value. I feel confused: what is the use of knowing just one next value? Even weather forecasts usually give information for 1-2 weeks!

I haven't found any relevant tutorials, so I tried three approaches:

- Predict one value from previous i-N...i values, then include the predicted value as the ith input value, predict next one, and so on. I use LSTM here, and after a few iterations the prediction becomes very wrong.
- Train N different feedforward NNs to predict values i+1, i+2, ..., i+N based on the same input data. The plot of this abomination looks much more tolerable, but very imprecise. I suppose this is because my data is seasonal, and I only feed past values to my NNs, not seasonal features.
- Use a feedforward NN that predicts a value of particular day in particular month. Again, it looks tolerable, but imprecise, because I only feed it seasonal features, not values.

I don't really understand how to compose an input vector that would contain *both* values and seasonal features (like month and day) and what exactly it should contain.

So, are there any tutorials that actually deal with predicting more than one value?"
Image Augmentation for Deep Learning using Keras and Histogram Equalization,0,4,False,False,False,learnmachinelearning,1499776164,False, 
Number and size of hidden layers?,2,4,False,False,False,learnmachinelearning,1499784909,True,Have you come across a good tutorial on choosing the number and size of hidden layers in a neural network? Everything I've come across makes no mention of _how_ to go about choosing the number of hidden layers and the sizes of those layers. TIA
Deciding between naïve bayes classifier and bayesian belief network,0,1,False,False,False,learnmachinelearning,1499787757,True,"How exactly do you decide which one should you use, if you don't know whether dependencies among attributes exist or not?"
Review of Udacity Machine Learning Nano Degree,0,32,False,False,False,learnmachinelearning,1499793960,False, 
Deep Learning - SSD / object detection training data questions,0,1,False,False,False,learnmachinelearning,1499796718,True,"Hi all,
I'm working on creating my first object detection model with Tensorflow and have a few questions about the input data I need to use to fine tune an existing SSD / Faster RCNN / etc model.  Any info or links you have would be helpful. 


1. Do I need bounding boxes for all items I'm trying to detect within an image?  So if I'm training an object detector for identifying cats and dogs and an image contains both a cat and a dog, do I need to have bounding boxes around both?  

My understanding is that you do need ground truth boxes that identify all items in all images, but looking through the COCO dataset, they have pictures of a market with 100 or so apples and they are all not labelled -- so does this negatively affect training, or is my understanding wrong?

2. Lets say I have one dataset of just dogs with bounding boxes, and one with cats with bounding boxes.  Some images in the dogs dataset contain cats (like in the example above).  What impact will cropping my dataset down to just the dogs have and making the new ""bounding box"" the full image? I'm guessing you lose a lot of 'context' but could this be a valid strategy?  For data collection purposes its much easier to get data in this form.

3. Around how many examples for each category should I look to have (before data augmentation) to fine tune a pretrained SSD model from a similar dataset? Just looking for a general estimate -- 200 per category? 1,000? 10,000? In the tensorflow object detection code they have an example of finetuning SSD to a pets dataset with 200 images in each category. Is this amount of data standard or is this low?

Thanks!"
Am I going about this the right way?,0,1,False,False,False,learnmachinelearning,1499800433,True,"Hey guys!

I'm trying to set up a simple CNN that is able to classify images based on the button that was pressed at that time.

So let's say in a game of snake where I need to move the snake to a red square on the map

When I press the UP key I save a screenshot of the game into a folder named UP and I do the same for when I press DOWN, LEFT, and, RIGHT.

Is it then possibly for a CNN to figure out how to classify these images correctly and to then eventually learn that I tend to press these buttons based on where the red square is.

Does this make any sense at all? Is this even a feasible idea? Is a CNN the right way to go about doing this?

Thanks!"
Could anyone help me with Tensorflow Actor-Critic Pong agent?,0,2,False,False,False,learnmachinelearning,1499800674,True,"Hi!

I am trying to implement actor-critic reinforcement learning agent in Tensorflow with OpeanAI Gym, but my model seem to stop learning fairly quickly and stays at approx. -20 mean reward. Could anyone help me to spot a bug in the implementation (~250 lines of code)?

Here is the code: https://gist.github.com/kernelmode/d49281b85fa61d13f969bbba99af1b38

Loss and discounted reward plots: https://ibb.co/gopFKa"
[Question] Feeding raw signal data into a Deep Belief Network in Python?,1,2,False,False,False,learnmachinelearning,1499801721,True,"I have a question regarding inputting raw signal data into a Deep Belief Network. The nature of input data includes 1,000 signal data of 3 classifications. Each signal data has 6 features and contain 10,000 samples in it. Instead of using statistical feature extraction (which will extract the RMS, mean, max, kurtosis, etc of those signal data) and feed it into a standard Neural Network to do the classification task, I wonder can I feed the Deep Belief Network with 3 hidden layers with X = [1,000 x 10,000; 6] and y = [1,000 ; 1] matrix to do the classification task ? If it's possible, how can I map X correspond to y? Thank you all for reading my questions"
Implementation of Deep Q-Learning to Learn how to play a simple game written in python.,0,2,False,False,False,learnmachinelearning,1499805179,False, 
A simple example of a self-driving car using DeepGTAV,2,10,False,False,False,learnmachinelearning,1499808228,False, 
Monthly ELI5 (Explain Like I am Five) Thread,0,2,False,False,False,learnmachinelearning,1499815217,True,"Top comments need to be in the format of: `ELI5 $CONCEPT_NAME` and the replies should provide a clear explanation in a layman's term.
Here are the relevant rules from /r/explainlikeimfive breaking down the meaning of ""ELI5"":

- E is for Explain - merely answering a question is not enough.

- LI5 means friendly, simplified and layman-accessible explanations - not responses aimed at literal five-year-olds.
"
Looking for tutorials for more advanced AI algorithms implemented in keras?,1,2,False,False,False,learnmachinelearning,1499832769,True,"There are many tutorials for basic deep learning application in keras but there are very few projects which implementes keras in advanced algorithms such as [GAN](https://medium.com/towards-data-science/gan-by-example-using-keras-on-tensorflow-backend-1a6d515a60d0). I am looking for keras projects with tutorials implemented for advanced algoirthms such as pix2pix, face2face, cycleGAN, stackGAN and many more. Can some one share a tutorials or projects of keras implementation for advanced AI projects?"
K-fold cross validation - What does averaging mean in Keras?,4,3,False,False,False,learnmachinelearning,1499833976,True,"I have been reading about K-fold cross-validation and it has been suggested that the results of the K-fold validation should be averaged (like [here] (https://stats.stackexchange.com/questions/52274/how-to-choose-a-predictive-model-after-k-fold-cross-validation#comment102171_52274)).


What does it mean in practical terms? Should the weights from these K-1 tests be added and divided by K-1 to get an average representation?
  "
TWIL (This Week I Learned) - Share something new that you have learned this week!,4,1,False,False,False,learnmachinelearning,1499843114,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
How to find areas in data with high variance?,2,2,False,False,False,learnmachinelearning,1499849714,True,"Sorry misleading title, I mean areas that are inconsistent.

Hi,

let's say I have a data set with categorical labels for classification. Now in the space of the data, I have areas where the labels are very consistent, like everything with x>5 almost everything is labeled ""A"" and x<5 almost is labeled ""B"". So all is fine. But lets say there are some areas where the data is very inconsistent and mixed, like let's say in 7<x<9 the data is very mixed.

Is there an algorithm that finds such problematic areas?

Thank you"
Dataset containing hands and fingers with bounding boxes?,0,1,False,False,False,learnmachinelearning,1499856963,True,"Hi,

I want to train an object detector network for detecting hand movement and gestures. Is there any well-annotated image dataset with hands and fingers with bounding boxes?
Thanks in advance!"
Questions on Large Scale machine learning frameworks?,0,1,False,False,False,learnmachinelearning,1499862120,True,"What are the best large scale machine learning framework? We are thinking of Spark with scala or python? What is the preferred language specially for machine learning systems on spark?
Can we use the skikit learn, numpy libraries of python directly? If yes wouldn't that be an advantage over scala?"
Approach to few shot learning,0,3,False,False,False,learnmachinelearning,1499862136,True,Which could be an easy solution for a few-shot learning approach for object detection. I want to build a object detector that can learn new classes using supervision of few examples.
Text classifier algorithms: overview with tutorials,0,16,False,False,False,learnmachinelearning,1499863128,False, 
A deep learning and reinforcement learning library.,0,1,False,False,False,learnmachinelearning,1499866050,False,[deleted]
A deep learning and reinforcement learning experimentation library on top of tensorflow.,0,7,False,False,False,learnmachinelearning,1499866683,False, 
propability of classification with random forest,0,3,False,False,False,learnmachinelearning,1499866834,True,"Random forest, if i understood this correctly, consists of decision trees, that all classify the same problem. Based on these classifications the random forest decides which class is most often 'picked' by the decision trees. I hope thats right so far ;)  Can this classifier return, how often a class was 'voted' by the decision trees?"
Mimic Snapchat Filters,0,10,False,False,False,learnmachinelearning,1499877554,False, 
How to find variable importances by category?,0,3,False,False,False,learnmachinelearning,1499879618,True,"Currently I am performing classification of data into different known categories using a Random Forest classifier from the sklearn library.

I can use the Random Forest model to get overall importance rankings for each of the features for separating all the categories from one another. But is there a way to find what features are most important to classifying a specific category?

For example, if I had features alpha, beta, and gamma, and categories A, B, and C, I would want to know if say the most defining characteristic of category C is that it has distinctly different values of feature beta than categories A and B do.

Is there any way to get this sort of information using a Random Forest classifier or other method?"
Status of generative pre-training,0,4,False,False,False,learnmachinelearning,1499888199,True,"Hi,  
I'm currently working with datasets which usually contain something in range of 1-40k labeled data and 20k-2kk unlabeled.  


I remember from [hinton classes](https://www.coursera.org/learn/neural-networks/lecture/cxXuG/shallow-autoencoders-for-pre-training-7-mins) that using generative models (rbm, shallow autoencoders) could improve neural net performance.  


Since this classes are quite old I'm interested in learning what are the state-of-art methods to improve classification with unlabeled data."
Building a Web Scraper with Python and Beautiful Soup,0,1,False,False,False,learnmachinelearning,1499888861,False, 
Tensorflow with GPU worth it?,6,8,False,False,False,learnmachinelearning,1499890428,True,"Hello guys, 

I'll make this snappy. I am going to install Tensorflow on my new PC and want to use the GPU version as I have a GTX 1060 which should meet all requirements. 

As outlined in the link below, I need to install CUDA and cuDNN. I'm just wondering is it worth it? Apparently CUDA speeds up other processes such as video editing, so I am just wondering should I go ahead with it? 
https://www.tensorflow.org/install/install_windows#requirements_to_run_tensorflow_with_gpu_support

Also, I usually use Python 2.7, is it only supported with 3.5? "
"I am always doing that which I cannot do, in order that I may learn how to do it. – Pablo Picasso",0,10,False,False,False,learnmachinelearning,1499895878,False, 
Super beginner question: Are CNNs by their nature probabilistic?,5,3,False,False,False,learnmachinelearning,1499910485,True,"I was working on a project on the CIFAR dataset and was having trouble getting to 50% accuracy, regardless of probability drop rate, epochs, standard deviation, layers, pooling parameters. Nothing. The network would often hit a ceiling and stick there for the remainder of testing after about 25 epochs.  
 
Is this due to random chance? Would I just get lucky and hit 50% accuracy at some point? Or should I keep tweaking my parameters?    "
Keras models for Matlab Neural Network toolbox,1,4,False,False,False,learnmachinelearning,1499919509,True,"Matlab has three types of models in the Neural Network toolbox as listed [here](https://www.mathworks.com/help/nnet/gs/neural-network-time-series-prediction-and-modeling.html).

1.  y(t) = f(y(t – 1), ..., y(t – d), x(t – 1), ..., (t – d))

2.  y(t) = f(y(t – 1), ..., y(t – d))

3.  y(t) = f(x(t – 1), ..., x(t – d))


The 1st model can be simulated using LSTM. How about the 3rd model?"
Feature engineering for encrypted data,3,3,False,False,False,learnmachinelearning,1499944966,True,"Hello everyone,
I am a beginner in the ML field and I am participating in an online competition that involves encrypted data. Basically i do not know what the features are, other than they follow time series. Do you have suggestions on how to perform feature engineering to increase the performance of the models that I use?"
Machine Learning - Hands-On Python and R In Data Science,4,5,False,False,False,learnmachinelearning,1499964832,False, 
TFStage: TensorFlow Project Scaffolding,0,1,False,False,False,learnmachinelearning,1499970400,True,"Hello! We spend a lot of time in TensorFlow and by far the most time-consuming task is setting up the project. To mitigate this we built a scaffolding tool that writes a lot of the boilerplate code for us.

Check it out here: https://github.com/fomorians/tfstage

(Currently, it does not support Windows but we'd love a pull request from a Windows user.)"
Finding hardcoded passwords with Machine Learning,1,0,False,False,False,learnmachinelearning,1499970959,True,"I am trying to find hard coded passwords in some repositories and I have written some regex that is able to find them.

However there are false positives, and I wanted to lower these as much as possible.

I was wondering if this would be a worthwhile endeavor to try out with machine learning. It would be supervised and based on natural language. I just don’t know if the effort is worth the reward, or if it would even be possible."
Newbie needs help choosing the right learning resource.,3,5,False,False,False,learnmachinelearning,1499980762,True,"I've got `Fundamentals of Machine Learning for Predictive Data Analysis` and `Elements of Statistical Learning`. I prefer the book that covers as much ground as possible, in terms of algorithms and techniques used by ML experts. Deeper insight into a topic at the cost of a few more words is okay by me. Basically, I don't want the book to just breeze over important topics. Math, when crucial, doesn't hurt either. I'm comfortable in Python, Java and C++. Which book should I pick? Thanks."
Need advise on approach to NLP and timeseries data,0,2,False,False,False,learnmachinelearning,1499996275,True,"I have gathered and cleaned a fairly large data set of text data (somewhere between 1-2 million rows currently) that I want to train a model on that predicts the value of something that varies over time. The text data theoretically should have some relation to the timeseries data. My main concern is that the model I train won't  be able to look far enough forwards to ""learn"" how to predict successfully. I've used LSTM before and want to employ a similar method. When I used LSTM, the model looks a certain distance forwards/backwards from the current word in a sentence. Now, I want the model to look a certain distance forward into the timeseries value data. It doesn't make sense to have the machine learn word embeddings or context which is normally done to predict the next word in a sentence or generate language, etc. Instead, it would make more sense to learn the sentiment of a post as one or more features like ""positivity"" or ""negativity"", and/or counting frequencies of certain keywords. Then see if those values predict higher/lower timeseries values. 

The trick is that the timeseries values are relative, so it can’t be looking at the observations in a vacuum, or else the high points in the timeseries data would dominate the model and probably break it.

Does anyone have any familiarity with a solving a problem like this? I would like to implement this in Python."
Newbie Q: Picking first computing cluster?,4,7,False,False,False,learnmachinelearning,1500011176,True,"Hey all, 

so my personal learning projects, I am finally running into processing speed issues (currently at ~45 minutes, but quickly growing). 

The present projet is in R, but also doing a fair amount of Python

What is a good first place to park my projects online to speed up computation / offload it off my personal computer. I am (of course) hoping to find some unicorn that balances low cost, high performance, and high ease of use. 

Any resources that would get me started? 

Thanks"
Weekly Show-off!,1,2,False,False,False,learnmachinelearning,1500015938,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
Good prerequisites for deep learning?,9,16,False,False,False,learnmachinelearning,1500051904,True,"I tried the deep learning book by Goodfellow, Bengio, and Courville, but I felt like their explanations of probability and tensors were confusing. I never made it past the intro chapters where they review those concepts.

I majored in math but forgot almost everything except for the most basic probability. Also, I never learned about tensors in college. Anyone know of good reviews / intros for these subjects?
I spent a couple of hours trying to find material on tensors via Google and it seemed like every explanation I could find of what the hell a tensor is was always super convoluted.

I feel like it would be cool to make my own models, so I'd like to understand this stuff, not just muddle through enough to use other people's models. I don't want to dedicate my morning learning time to a couple months of taking myself through a prob & stats textbook if I don't have to, though, and don't want to spend another couple of months building up to figure out what a tensor is, either, especially given that it seems the use in deep learning is non-standard.

Do I just have to suck it up and work through a full textbook on probability and stats to refresh my memory, plus find out what kind of textbook will give me knowledge of tensors and work through that, too? If I do, then what's a solid textbook for tensors? Spivak's Calculus On Manifolds?

Thanks, everyone!"
Yet another 'which algorithm?' question,11,3,False,False,False,learnmachinelearning,1500057175,True,"I would like to create a ml/dl application that can (after training) transform an input image into a modified (i.e. transformed) output image. The _transform_ to be learned could be as simple as removing color from the input image (but will probably be more complex than that).

I already have a large set of ""before"" and ""after"" images that I can use in a supervised learning scenario.

In summary: 

1. learn how to transform image A into image B (as closely as possible)
2. use the trained model to apply the transform to any image.

Does there already exist an algorithm that I can use as I starting point? Would a simple DNN suffice?

I am still very new to ml/dl so I hope the above explanation wasn't too painful for you.

Lastly, I do not expect this to be useful... I am using it as a way to do something ""real"" with ml/dl.

Thank you in advance"
Trouble estimating time series from multi-dimensional inputs,1,2,False,False,False,learnmachinelearning,1500060816,True,[deleted]
Question: Creating word vectors for an RNN/MLP,7,6,False,False,False,learnmachinelearning,1500062764,True,"Hi there, I'm conducting a summer project and at this stage, I am trying to test various models for a sentiment classification task. I was advised a good comparative test would be:

""Using pre-trained word vectors as input (e.g word2vec or GloVe) versus letting the RNN or a Multi Layer Perceptron learn these vectors as part of the task.""

I am reasonably familiar with word2vec and GloVe in that they are word embeddings based on cosine distance found by analysing very large corpora. As far as I am aware you can choose a word2vec model and if you load it, it comes pre-trained and it will just fit those word embeddings to your corpora?

For the second part,  e.g.  letting the RNN or an MLP learn these vectors as part of the task, I am not sure how to do this. With word2vec, I think it's just as simple as loading in a pre-trained model but how do I convert raw text to features which can be used in RNNs?

I've read about the embedding layer in Keras, in that it converts positive integers (indexes) into dense vectors of fixed size. So my main question is how do I turn my raw text to positive integers which can be used in the embedding layer?

Sorry if this sounds all over the place, I'm a little confused. Most tutorials I can find are loading in data which is already pre-trained so I am missing the processing stage. 

For clarity, my data consists of 2 columns, 'ratings' and 'text' (where ratings is 1-5 and text is a raw text review). Any help/guidance would be greatly appreciated, thanks! "
Predicting Stock Prices with Linear Regression,3,9,False,False,False,learnmachinelearning,1500070642,True,"Hey guys!
I am just getting into ML and have been following [sentex's](https://www.youtube.com/results?search_query=Practical+Machine+Learning+Tutorial+with+Python+p.7+sentdex++sentdex) machine learning stock prediction tutorial.

As I am learning more, I am trying to build a semi-accurate stock price predictor, but I have run into some problems.

Here is my code: https://gist.github.com/samayshamdasani/54dfa47845873444139fc147027399d3


1.) Should we be ""forecasting"" our stock prices by training on ""shifted"" data? In other words, should we be setting tomorrow's forecasted price to 30 days before, and then training on it. Would this lead to accurate pattern recognition?

2.) I am having trouble plotting the data. Based on what I can understand, the prices are indeed being predicted, but I am missing the 1% of stock prices, which I use to train as it is not being plotted on the graph. If you run the code, you will see that I can get data from today(add (+) in shift instead of (-) in line 17 and look at tail), but the shift is not letting me graph that 1%. For example, the real prices for July 14th aren't appearing, or even any date in June is wrong as it's showing the predicted data, not data we already know.

Any help or guidance is greatly appreciated. Thank you all!"
"Weekly Status Check Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",2,7,False,False,False,learnmachinelearning,1500102310,True,"Let's have a  meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
German Database with Sentences that describe a location,0,1,False,False,False,learnmachinelearning,1500135181,True,"Hi,
Im writing a ""paper"" for high school, in which I try to crawl a news site for a specific topic. I already trained a classifier, thats able to predict if a sentence treats the topic im trying to filter from the website and it works pretty well (~80-90% accuracy on real data) although I only trained it on 400 features. It took me really long to find 400 training sentences and classify them myself before being able to train the classifier. 
Now I want to filter the location a certain event took place but I dont want to write down 200 sentences that contain that information and 200 that dont to be able to train a classifier again. So does anyone know a website that has such training data (in German:D)?"
Learn about Expected Value - part I,0,3,False,False,False,learnmachinelearning,1500139040,False, 
Deep Learning Made Simple [Part 1],4,41,False,False,False,learnmachinelearning,1500139748,False, 
"What's the demand for a ""all about ML"" website?",7,10,False,False,False,learnmachinelearning,1500146542,True,"I've noticed a lot of people that wish to get into ML struggle with various aspects that end up being hindering, as usually they lack some sort of basis.. Whether it's a solid understanding of linear algebra, statistics theory, or whatever else it may be.

As somebody who struggles with ADHD and unable to attend most of my lectures at my university, I've had to resort to teaching myself in preperation for the exams.. Thus I have a mountain of resources for self-study (A-Z) that I am willing to share and teach.

How does the demand look like for a website which compiles external resources for self-studies (Math, CS, and ML) but also hosts original crash course content akin to the textbook articles on electronics at allaboutcircuits.com/textbook/ ?

I've looked into Udacity and BDU from IBM, and find both to be very lackluster (personal taste), and they gloss over subjects too much. Afterall, it takes atleast 5 years for somebody to earn their MSc in Machine Learning.

Note: I am studying MSc Biomedical Engineering but specializing in Neural Networks (considering PhD studies). I will need help from others in filling out other areas past the basics. Only took one course in statistics so far."
Tips for tackling the math in ESL.,10,7,False,False,False,learnmachinelearning,1500154572,True,"I'm a ML newbie. I recently picked up Elements of Statistical Learning. Already a few chapters in, and I find the mathematics involved to be a bit intimidating. I'll appreciate any tips for making through the book. It's not like I find Maths uninteresting or anything. I like crunching numbers. I just feel a bit underarmed when dealing with the proofs and derivations given in the book."
Learning Deep Learning with Keras,1,8,False,False,False,learnmachinelearning,1500195528,False, 
Learning Machine Learning — Probability Theory Fundamentals,0,27,False,False,False,learnmachinelearning,1500203401,False, 
"Issues with Batch Sizes, Training, and Combining Different Model Types in Keras",0,3,False,False,False,learnmachinelearning,1500230964,True,"I'm having trouble training a two part neural network in keras. 

My model is made up of two parts, embedding for user and context, and an LSTM going over user actions with timestep information. Using large batch size = 4096, I can effectively train a stable network over many epochs, but only to a val score of 0.63 in binary cross entropy. 

With batch_size = 128 or 256 I can very quickly get a better score of 0.615, but it would take me literally days on a high powered GPU to complete a single epoch. 

I have tried a two step process where I start with small batch sizes until val loss flattens, and then switch to a large batch fit, but this almost always blows up my loss immediately even with lr somewhere like 1e-10 on first epoch. 

I have also tried using SGD, RMSprop, Nadam. I have tried messing with model size, extreme regularization, no regularization, stupid small and stupid big models as well. 

Can any one provide me some advice? "
Implementing backprop (for Coursera/Andrew Ng class) and I get the wrong gradient for my hidden layer. What am I doing wrong?,1,5,False,False,False,learnmachinelearning,1500235718,True,"For Week 5 of Andrew Ng's ML class on Coursera, the homework assignment is to implement backpropagation -- specifically, we have to implement a cost function:

- for a 3-layer (one hidden) neural network
- that returns the cost at a given input
- as well as the gradient for the hidden and output layers at that input

This is what I've done so far (haven't implemented regularization yet, that's next):

https://gist.github.com/davidwallacejackson/48d66269151854bcd5398a442231fdb8

As you can see from the comments, I tried a vectorized implementation as well as an iterative one. I got the same result both times: `Theta1_grad` (for the hidden layer) is off the expected values a bit, but `Theta2_grad` (for the output layer) is correct.

So as I understand it, the process here is supposed to be:

* compute the output error as `truth - hypothesis`
* compute the hidden layer error as: `(Theta2' * err_output) .* sigmoidGradient(Theta1 * input)`
* compute the output layer's gradient as `(1/number_of_training_examples) .* (err_output * activation_hidden)`
* compute the hidden layer's gradient as `(1/number_of_training_examples) .* (err_hidden * input)`, excluding the bias unit from `err_hidden`

Any idea what I'm doing wrong here?"
Machine Learning,4,1,False,False,False,learnmachinelearning,1500257790,True,"Hey guys, I am working through kmeans on the iris dataset to right now as I was told it is a pretty great start for machine learning. What are your suggestions? Is kmeans a good start? What else would help me understand all these statistical terms (i.e. Supervised vs unsupervised learning, regression, linear regression, etc.)? Do you have any articles I could read that teach someone like they are stupid? Because I kind of am when it comes to all this. Thanks so much ahead of time!"
XGBoost - scale_pos_weight,5,5,False,False,False,learnmachinelearning,1500294650,True,"Hey,
I am currently trying XGBoost on a highly imbalanced dataset. 
For this reason I use the scale_pos_weight parameters:
https://github.com/dmlc/xgboost/blob/master/doc/parameter.md (scroll down) and https://github.com/dmlc/xgboost/blob/master/doc/how_to/param_tuning.md

Now I see that when I set scale_pos_weight to sum(neg)/sum(pos) training will slow down a lot and not be better (usually equally as good or even worse as scale_pos_weight = 1). But with scale_pos_weight=1 the classifier does run only for 20-100 estimators before the training loss stop increasing (for val it's actually like 10-20 epochs).

I am completely new to XGBoost so I am wondering what/whether I am doing something fundamentally wrong!"
Machine Learning Crash Course: Part 4 - The Bias-Variance Dilemma,1,6,False,False,False,learnmachinelearning,1500302002,False, 
Question about training accuracy in tensorflow,5,1,False,False,False,learnmachinelearning,1500311971,True,"Sorry for the newbie question.   

To give some context, I am currently training a CNN implemented with tensorflow for a segmentation project. The data I use is pretty noisy and hard to get, meaning I have few training examples.   

The accuracy reported during training was around 95%.   

I tested the model, but it produced very poor results on the validation dataset.    

I then tested it on the actual training data, expecting a decent result, but it produced similar results to the validation dataset.    

So, my question is, how come the network wasn't able to segment it's own training data when it reported a high accuracy during training?"
Newbie Question: Monitoring a signal for changes with an ANN,4,2,False,False,False,learnmachinelearning,1500332162,True,"I've only ever done basic ANNs that deal with non-changing datasets (for example simple OCR on small images).

What I would like to do is train a Neural Net to monitor and detect changes in audio signals at a specific frequency. I was going to perform an FFT and lock to where the signal is strongest to produce a single floating point input into the ANN. The input will either be high or low (though the amplitude may vary, and there will be some noise). I would like to detect groups of defined characters, a bit like morse code.

Could someone ELI5 to me the principle of training a Neural Net to monitor a stream and detect changes in it? A high level overview would be really great. Thanks in advance!"
Markov Decision Process such that Value Iteration takes longer than 50 iterations to converge?,2,1,False,False,False,learnmachinelearning,1500371429,True,"Exercise from a class I'm following along with. There should be at most 3 states and 2 actions. I'm pretty stuck here, any hint is appreciated. "
How to tell Keras which column in a Pandas DataFrame to predict?,14,6,False,False,False,learnmachinelearning,1500384314,True,"Hi there. I'm new to machine learning and trying out a toy problem to give me something to play with.

I have some historical stock data I'm trying to use to train an LSTM model. I've chosen this as it's an area I'm familiar with.

I have a Pandas DataFrame with data which looks something like this, resampled down to 15 minute intervals:

datetime | open | high | low | close | volume | close_pct | open_pct | feature1 | feature2 | feature3 | ...
---------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------
2017-06-14 09:00:00 | 0.139740 | 0.140062 | 0.139600 | 0.140000 | 89.612122 | NaN | NaN | -11.976234 | NaN | NaN | ...
2017-06-14 09:15:00 | 0.140062 | 0.140151 | 0.139574 | 0.139730 | 280.848022 | -0.001929 | 0.002303 | -216.932312 | 8.907914e-05 | ... 
2017-06-14 09:30:00 | 0.139730 | 0.140309 | 0.139730 | 0.139918 | 118.757195 | 0.001345 | -0.002370 | -297.108398 | 1.580119e-04 | ...

There are 101 columns in total.

The examples and tutorials I'm following all seem to presume that we want to predict all of the columns in the upcoming data. I don't care about any of the feature columns, I just want to predict what the high_pct change or low_pct change will be. Do I need to define a loss function?

I have a feeling I may be misunderstanding something fundamental.

It's probably not useful but here's the model I've started with so far:

    model = Sequential()
    model.add(LSTM(32, return_sequences=True, input_shape=(None, 101)))
    model.add(LSTM(32, return_sequences=True))
    model.add(Dense(101, input_dim=300, activation='softmax'))
    
    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])
    
    model.summary()

Can anyone suggest where to go next with this? Or even just some keywords for the kind of things I need to be reading up on to help me understand better?

Thanks loads for any help.

Edit to add, I'm running the fit function:

    model.fit(X_train, y_train, epochs=20, validation_split=0.05)

But I'm getting nan for the loss score:

    Epoch 20/20
    19/19 [==============================] - 0s - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00"
Interpretation of linear regression,2,2,False,False,False,learnmachinelearning,1500384352,True,"I have no experience and am having trouble interpreting my results even after quite a bit of googling.  Any insight is appreciated.

Trying to predict traffic.  Using 6 predictor variables. ~2,500 data points.

Evaluation results:
Mean Absolute Error	2675.118382
Root Mean Squared Error	3563.192662
Relative Absolute Error	0.472508
Relative Squared Error	0.248475
Coefficient of Determination	0.751525

Thoughts on interpreting?  Thanks again!
"
"just finished Ng's course, some questions:",3,1,False,False,False,learnmachinelearning,1500394825,True,"The course was a 30k ft flyover of concepts related to ML, with a dabble in each highlighted type. I have a list of questions I'd like to ask generally, perhaps you know or would like it answered as well.

1.  I know despite the final video's declaration that I'm now an expert that I am not an expert. In terms of professional baseball leagues, am I single-A? Double-A? Dad Softball league?

2. Looking briefly at some recommended courses after this one, I see mostly NN stuff. I got the notion from the course that SVM was actually more powerful? What is the best direction to take?

3. I was surprised to not see anything regarding evolutionary algorithms- but EA seems to be more open-ended? I'd think EA is ML, but doesn't have a binary classifier or global cost function?

4. The end of the Ng course touched on chaining ML methods to get complex solutions. How important is being a good designer of this solutions vs being an SME in a particular ML method?

5. Is there any value in the code I wrote in Octave for the course? Is Python the language of choice moving forward? 

Thanks! If you're wondering- I'm a NASA engineer slash developer for ISS and Orion, doing orbit determination (kalman filter, astrodynamics, etc). I want to get out of SW dev and into analysis/research, and I'd like to explore ML solutions to OD/space problems. "
Udacity Deep Learning Nanodegree Review,18,23,False,False,False,learnmachinelearning,1500397494,False, 
"I think this is a feature extraction problem, but I'm not sure.",4,3,False,False,False,learnmachinelearning,1500398609,True,"Hey guys.

So here's the deal. I have documents that contain blocks of text that are unlabeled. Each block of text can be one of several types (Classifier problem?), or noise. Within each of these specific types of text blocks I want different types of information.

My first thought is to build a text classifier to identify the type of text blocks and then use either machine learned models or regex styled expressions to pull out the desired text based upon the label my classifier(s) gives me.

I believe I could also use vectors and tensor flow to process the whole document at once.

I'm not sure if I am looking at this problem right. Do you think either of these solutions would work, or if there is a better easier one? I really have no idea what I am doing. 

"
Free Online 6 months Training Program in Machine Learning (Knowledge from 20 ML Books will be Integrated Iteratively),1,2,False,False,False,learnmachinelearning,1500407265,True,https://www.youtube.com/watch?v=n8xI-g3shXc
Tensorflow repo to train Humanoid environment in Gym?,0,2,False,False,False,learnmachinelearning,1500412815,True,"Title says it all: is anyone aware of a repo that will train the Humanoid environment in OpenAI's Gym, preferably via a cutting edge technique like A3C or TRPO?

I've found:

* Plenty of [Tensorflow repos that train Atari environments](https://github.com/NVlabs/GA3C), but they're not adapted to the continuous controls that are needed for Mujoco environments

* A [Theano repo](https://gym.openai.com/evaluations/eval_i3x1JpReRukTZrznxypCw) that trains agents on Mujoco environments

* [Tensorflow continuous-control TRPO repos](https://github.com/ilyasu123/trpo) that have not, seemingly, been shown to successfully train an agent on the Humanoid environment.

Any pointers?"
Tips for creating functions in R,0,4,False,False,False,learnmachinelearning,1500420519,False, 
How long do text generation LSTMs typically take to successfully train?,2,1,False,False,False,learnmachinelearning,1500422583,True,"Here is my current output:

    training loss at step 4350: 2.26 (2017-07-18 16:59:30.000921)
    Text generation at step 4350: 

    I plan to make this world a better place thie!
    Man d, n, goworeshe at ie urofrsen?
    A ve I ouraken coun-
    Ma hachererankes es
    Thenlle y y co w,
    Yemy d send we st'sest achare; culit frpeth'; ty
    A:
    CI pen,
    Astre venge, athuged!
    Thyobedo nouch I a t ur coun aretruce?-s lld llaknofller dy nes, aly pe t'd I d atord.
    Heage o be main y tre; Mal'l.
    A tro y lll, fitous?
    Yed bu akis, pre bee, o amavew-'s; towemy,
    Cisus: ad wh u y y s lyofouted arotowo lly s s r tt as
    Firyowow vespefrey f weneald y thelourendrst ale are nn gus, fas
    
    NI y th fins th

I'm working with 1.1MB worth of shakespeare text and am a bit surprised its taking this long to produce reasonable results. 

This is my first time working with text generation so I'm not sure if this is normal or if there is something wrong with my model. "
How to debug and diagnose Machine Learning problems,0,23,False,False,False,learnmachinelearning,1500426645,False, 
Audio machine learning for TensorFlow?,2,3,False,False,False,learnmachinelearning,1500427834,True,"We are a group of students planning to make an intelligent system that identifies and plays out the name of the animal given the audio input of the sound that certain animal makes. 
We want the system to learn that if you say ""arf arf"" or ""woof woof"" you are referring to a dog. 
The problem is that we have absolutely no background in machine learning and have no idea what the best algorithms/APIs there are. 
We do know how to code in Java and have been exposed a little bit to TensorFlow but other than that we have nothing. We've been stuck on researching for weeks now and we've hit a dead end. We'd really appreciate some help"
"After 4000+ Iterations, LSTM is still not generating legible text.",4,3,False,False,False,learnmachinelearning,1500436786,True,"I'm having trouble understanding why my model is not producing reasonable results. I've read [karpathy's][1] post on text generation and it seems like he is able to produce great results by 2000 iterations. 

I'll break down key aspects of my model.

[data][2] (1.1 MB of shakespeare text):

    #vectorize our data
    len_section = 50 #how much data we feed at a time
    skip = 2 #how many char places we move (this helps when you dont have much data)
    sections = [] #we need to store the sections somewhere 
    next_chars = [] #basically the label 
    #we are inputting 50 characters to predict the next character
    
    for i in range(0,len(total) - len_section, 2):
        sections.append(total[i:i+len_section])
        next_chars.append(total[i+len_section])
        
    X = np.zeros((len(sections), len_section, char_size))
    y = np.zeros((len(sections), char_size))
    
    for i, section in enumerate(sections):
        for j, char in enumerate(section):
            X[i,j,char2id[char]] = 1
        y[i, char2id[next_chars[i]]] = 1

structure:

    batch_size = 512
    max_steps = 72001
    log_every = 1000
    save_every = 50

    hidden_nodes = 1024

variable initialization:

    graph = tf.Graph()
    
    with graph.as_default():
        global_step = tf.Variable(0)
        
        data = tf.placeholder(tf.float32, [batch_size, len_section, char_size])
        labels = tf.placeholder(tf.float32, [batch_size, char_size])
        
        #watch videos on this
        #initialize weights
        w_ii = tf.Variable(tf.truncated_normal([char_size, hidden_nodes], -0.1, 0.1))
        w_io = tf.Variable(tf.truncated_normal([hidden_nodes, hidden_nodes], -0.1, 0.1))
        b_i = tf.Variable(tf.zeros([1, hidden_nodes]))
        #Forget gate: weights for input, weights for previous output, and bias
        w_fi = tf.Variable(tf.truncated_normal([char_size, hidden_nodes], -0.1, 0.1))
        w_fo = tf.Variable(tf.truncated_normal([hidden_nodes, hidden_nodes], -0.1, 0.1))
        b_f = tf.Variable(tf.zeros([1, hidden_nodes]))
        #Output gate: weights for input, weights for previous output, and bias
        w_oi = tf.Variable(tf.truncated_normal([char_size, hidden_nodes], -0.1, 0.1))
        w_oo = tf.Variable(tf.truncated_normal([hidden_nodes, hidden_nodes], -0.1, 0.1))
        b_o = tf.Variable(tf.zeros([1, hidden_nodes]))
        #Memory cell: weights for input, weights for previous output, and bias
        w_ci = tf.Variable(tf.truncated_normal([char_size, hidden_nodes], -0.1, 0.1))
        w_co = tf.Variable(tf.truncated_normal([hidden_nodes, hidden_nodes], -0.1, 0.1))
        b_c = tf.Variable(tf.zeros([1, hidden_nodes]))    
        
        def lstm(i,o, state):
            input_gate = tf.sigmoid(tf.matmul(i, w_ii) + tf.matmul(o,w_io) + b_i)
            output_gate = tf.sigmoid(tf.matmul(i, w_oi) + tf.matmul(o,w_oo) + b_o)
            forget_gate = tf.sigmoid(tf.matmul(i, w_fi) + tf.matmul(o,w_fo) + b_f)
            memory_cell = tf.sigmoid(tf.matmul(i, w_ci) + tf.matmul(o,w_co) + b_c)
    
            state = forget_gate * state + input_gate * memory_cell
    
            output = output_gate * tf.tanh(state)
            return output, state
        
        output = tf.zeros([batch_size, hidden_nodes])
        state = tf.zeros([batch_size, hidden_nodes])
    
        for i in range(len_section):
            output, state = lstm(data[:,i,:],output, state)
    
            if i == 0:
    
                outputs_all_i = output
                labels_all_i = data[:, i+1, :]
                
            elif i != len_section-1:
                outputs_all_i = tf.concat([outputs_all_i, output],0)
                labels_all_i = tf.concat([labels_all_i, data[:,i+1,:]],0)
                
            else:
                outputs_all_i = tf.concat([outputs_all_i, output],0)
                labels_all_i = tf.concat([labels_all_i, labels],0)
                
        w = tf.Variable(tf.truncated_normal([hidden_nodes, char_size], -0.1, 0.0))
        b = tf.Variable(tf.zeros([char_size]))
        
        logits = tf.matmul(outputs_all_i, w) + b
        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels=labels_all_i))
        
        optimizer = tf.train.GradientDescentOptimizer(10.).minimize(loss, global_step=global_step)
        
        ###########
        #Test
        ###########
        test_data = tf.placeholder(tf.float32, shape=[1, char_size])
        test_output = tf.Variable(tf.zeros([1, hidden_nodes]))
        test_state = tf.Variable(tf.zeros([1, hidden_nodes]))
        
        #Reset at the beginning of each test
        reset_test_state = tf.group(test_output.assign(tf.zeros([1, hidden_nodes])), 
                                    test_state.assign(tf.zeros([1, hidden_nodes])))
    
        #LSTM
        test_output, test_state = lstm(test_data, test_output, test_state)
        test_prediction = tf.nn.softmax(tf.matmul(test_output, w) + b)
        
        saver = tf.train.Saver()

training and testing:

    with tf.Session(graph = graph) as sess:
        tf.global_variables_initializer().run()
        offset = 0
        
        for step in range(10000):
            
            offset = offset % len(X)
            
            if offset <= (len(X) - batch_size):
            
                batch_data = X[offset: offset + batch_size]
                batch_labels = y[offset:offset+batch_size]
                offset += batch_size
                
            else: 
                to_add = batch_size - (len(X) - offset)
                batch_data = np.concatenate((X[offset: len(X)], X[0: to_add]))
                batch_labels = np.concatenate((y[offset: len(X)], y[0: to_add]))
                offset = to_add
                
            _, training_loss = sess.run([optimizer, loss], feed_dict = {data : batch_data, labels : batch_labels})
            
            #if step % 10 == 0:
            #    print('training loss at step %d: %.2f (%s)' % (step, training_loss, datetime.datetime.now()))
    
            if step % save_every == 0:
                saver.save(sess, checkpoint_directory + '/model.ckpt', global_step=step)
                
            if step %save_every == 0:
                print('training loss at step %d: %.2f (%s)' % (step, training_loss, datetime.datetime.now())) 
                print('Text generation at step %d: \n' % (step))
                offset = 0
    
                test_start = ""I plan to make this world a better place ""
                test_generated = test_start
    
    
                #for every char in the input sentennce
                for i in range(len(test_generated) - 1):
                    #initialize an empty char store
                    test_X = np.zeros((1, char_size))
                    #store it in id from
                    test_X[0, char2id[test_start[i]]] = 1.
                    #feed it to model, test_prediction is the output value
                    _ = sess.run(test_prediction, feed_dict={test_data: test_X})
    
    
                #where we store encoded char predictions
                test_X = np.zeros((1, char_size))
                test_X[0, char2id[test_start[-1]]] = 1.
    
                #lets generate 500 characters
                for i in range(500):
                    #get each prediction probability
                    prediction = test_prediction.eval({test_data: test_X})[0]
                    #one hot encode it
                    next_char_one_hot = sample(prediction)
                    #get the indices of the max values (highest probability)  and convert to char
                    next_char = id2char[np.argmax(next_char_one_hot)]
                    #add each char to the output text iteratively
                    test_generated += next_char
                    #update the 
                    test_X = next_char_one_hot.reshape((1, char_size))
    
                print(test_generated)

 I've done quite a bit of research and this seems to follow the basic LSTM structure. Any feedback would be much appreciated. 

  [1]: https://karpathy.github.io/2015/05/21/rnn-effectiveness/
  [2]: https://github.com/karpathy/char-rnn/tree/master/data/tinyshakespeare"
TWIL (This Week I Learned) - Share something new that you have learned this week!,0,2,False,False,False,learnmachinelearning,1500447922,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
How to draw the model architecture (cnn's)?,2,2,False,False,False,learnmachinelearning,1500451186,True,Which tool do you to draw your model architecture in your publications?
"I have a machine-learning code written with Numpy, and I would like to try using GPUs to increase speed - what is the best & shortest way to do that?",5,7,False,False,False,learnmachinelearning,1500451564,True,"it seems that pytorch is a very good platform - though I am still unsure how hard it would be to translate my (roughly 1,000 lines) code from numpy to pytorch, or if there’s any guide to help with that specific purpose, or any better way to achieve GPU utilization"
Auto-Encoder unsupervised fraud detection,0,1,False,False,False,learnmachinelearning,1500456171,True,"I have 6 features, 4 of which are discrete (take integer values between 0 and 5 in general) with the other 2 being continuous. 
I want to use an auto-encoder for feature extraction (2 dimensions) 
Assuming that the majority of users are honest users, I am hoping to cluster users in 2 categories using DBSCAN: a denser Normal use cluster and a less dense Aberrant behaviour cluster.
The problem I m having is that I expected one blob of data with a strong density in some point and slowly decreasing density elsewhere that would make it easier for me to cluster into 2 categories, this is an example of what I'm talking about: 
http://imgur.com/SCqOb0J 
But instead, I had a result with several separate clusters. I noticed that the discrete features are accounted for more than the continuous features. Which makes sense, in order to reduce the loss, the auto-encoder will better reconstruct the discrete features because it is easier to do so. 
I made a heatmap for each feature and this is what it looks like for the first feature (most users have a value of 0, 1 2 or 3) : http://imgur.com/FKTdGiS I feel that this result is no better than manually binning data in several classes. 
And this is what it looks like for a continuous feature: 
http://imgur.com/t01QCCm 
Is my approach relevant to solve the problem or is it flawed ? 
How can I get just one blob of data with basically two regions : small values overall, big values overall ?"
Hardware for hobbyists?,5,8,False,False,False,learnmachinelearning,1500465699,True,"I have been reading up and trying out some different models in keras, but as the network grows more complex, it takes much longer to train (obviously). I frequently seem to run into out of memory problems with python crashing after a few hours. Is there no other way for trying out things other than building a high-end system or rent VMs with GPUs on AWS/Azure (Both options seem very expensive)?"
Challenges in Deep Learning,0,1,False,False,False,learnmachinelearning,1500471758,False, 
The limitations of deep learning,4,27,False,False,False,learnmachinelearning,1500476197,False, 
How does 1D convolution work when applied to a 2D image?,0,1,False,False,False,learnmachinelearning,1500477060,True,"I am trying to understand what exactly happens when I apply a [1D Convolution](https://www.tensorflow.org/api_docs/python/tf/nn/conv1d) to a 2D array. This is further complicated by the fact that

> Internally, this op reshapes the input tensors and invokes tf.nn.conv2d.

Naively, I was expecting a 1D convolution to have a 1xN dimensional kernel (a vector of length N), that would get applied to the matrix row by row and the results would be concatenated into another vector. But this does not happen, if my input is 

[ batch, in_height, in_width] 

(you squeeze the channels to have a 3D input), 

the output is of shape

(batch, in_height, number_of_filters). 

Could someone please explain how the 1D conv kernel go across the rows or columns of the matrix and what happens to the convoluted results? I fail to have an intuitive understanding. "
Linear regression simulator will help you understand how linear regression algorithm works.,0,1,False,False,False,learnmachinelearning,1500491227,False,[deleted]
Linear regression simulator will help you understand linear regression using gradient descent.,2,3,False,False,False,learnmachinelearning,1500491828,False, 
Having to reboot machine after training/using a model,2,5,False,False,False,learnmachinelearning,1500492366,True,"Does anyone else have recurring problems with their Nvidia GPU after using it for some machine learning task? Anytime I train a model using either Nvidia DIGITS or YOLO dark net, I have to restart my computer. If I try to run a different example or train a different model right after the first training attempt, I get an error from CUDA related to memory usage. 

I've looked online and haven't found a reliable answer other than ""restart your computer"". Rebooting my computer works, but it's cumbersome and still only allows me to use my Nvidia card for one training session before having to restart again. I have a Nvidia GTX 1080 with 8 GB of memory, so I feel like this shouldn't be a problem - especially when I run nvidia-smi and it tells me I'm using less than 1 GB of memory after a training session or other ML related task. 

Is having to constantly restart your computer something that comes with working in machine learning, or is there something wrong with my software? 

**Update**: It seems like this only happens after my computer goes into ""suspend mode"". After waking from suspend mode, I get ""30 vs 0 success errors""  and ""allocation 0"" errors with CUDA. Preventing my computer from going into suspend mode allows me to run multiple training attempts without failure. Really strange. 
"
using SMOTE/TomekLinks on imbalanced data sets - any pitfalls or hidden dangers I should be aware of?,0,2,False,False,False,learnmachinelearning,1500501634,True,"The title pretty much says it all. I've been utilizing both SMOTE and TomekLinks to improve the performance of a classification algorithm, but machine learning is kind of new to me.  I did as much reading as I could find on both techniques to try and understand them better, but in case I missed something, is there anything I should be aware of in terms of hidden dangers or anything like that in applying these methods?"
How to overfit data?,2,7,False,False,False,learnmachinelearning,1500512983,True,"Hello
I am running a regression problem with keras/tensorflow with 14 13 inputs features and 3 output features. The 'loss value (MSE)' reduces quickly first and then plateau's out. I want to achieve the minimum loss and dont want to worry about validation loss for now. 
I am using a 100x50x50 network to begin with. What can i do to overfit the data and achieve minimum loss?  

The loss with 1000x500x500 looks like [this] (http://imgur.com/a/sztj5) and fit is poor like [this] (http://imgur.com/dgmb4xv)"
Tensor decompisition:why?,0,3,False,False,False,learnmachinelearning,1500530061,True,"Hey guys, I'm new to Machine Learning, can anyone expain me, why do we use different decomposition techniques(PARAFAC, Tucker) in multidimensional arrays? I know one reason is to compress the data, but what are some other reasons? Do factors themselves have any physical meaning?"
I need some assistance with creating a bot to play a snake game I made.,5,6,False,False,False,learnmachinelearning,1500547379,True,"So I created snake in python using the pygame library. It took me a while to do it but I made it with the intention to use machine learning to solve it later. So now that the game is fully working and functional, I need to start creating the bot to work with it. There are a few faults I can already see however. I need my bot to be able to see the grid and where the snake is and the item the snake collects is but whenever I use the import function to import my snake game, the game is ran; not necessarily bad on its own but whenever I put a command afterwards such as print (""hello world."") It isn't ran until after the game has closed which is pointless because I want the game and the bot to run simultaneously.

Also I'm going to be using keypresses as my inputs. But I can't find a good way to simulate keypresses in python (using Ubuntu.)

This is the subreddit which I thought this post would make the most sense in.

"
How to *properly* normalise data for deep learning?,3,12,False,False,False,learnmachinelearning,1500548822,True,"Hello!

Data standardisation is a must-do before feeding it into a deep neural network, otherwise you quickly saturate your neurons and cannot predict anything. I've been however stuck on *how* to do it. My problem consists of:

- Two classes
- 58 strictly positive variables, with different scale and units
- Balanced training set of 2M sample (50% per class)
- Very unbalanced real-life application, 1 signal event for 1000 background events

I have two mathematical methods to normalise, and I tried both:

- Shift the mean to 0 and standard deviation to 1, for all variables independently (~ Standardisation)
- Divide each variable by its maximum value, effectively shifting it to the [0;1] range. (~ Normalisation)

But then, how to apply these? 

My first try was to use Standardisation on both the training set and the testing set separately. However, I noticed that this would lead to very bad results as soon as I introduced imbalance in my test set (<50% precision for a 1:100 ratio). I figured out that this was because this normalisation was ""blurring"" the differences between the two classes.

The second try was to apply Standardisation on each class independently for the training set, and then on the full data for the test set (I am not supposed to know the ""truth""). Results got even worse. 

Third try was to save the mean and standard deviation of the training set and apply it on the test set, effectively normalising by the same scale. While the results were better, it is still not applicable to my problem. Plus, I am leaking information from my train set into my test set.

I then tried to normalise instead of standardise, and the results were mostly comparable on each case.

So ... how would you do it?"
Advanced neural-style options?,2,4,False,False,False,learnmachinelearning,1500551839,True,"Hi everyone.

I've been working with the Torch implementation of neural-style for artistic style transfers on an Ubuntu box and I have a couple of questions that I haven't been able to answer perusing the forum. Can you help?

1. Is there any way to save the results of the source image analysis? I'd like to be able to batch process a number of images using the same style source – is there any way to save this data rather than have it run new analysis every time (I assume this is what all those popular style transfer apps are doing)
2. Is there any way to teach direct comparisons? In other words, instead of just inputting general paintings and converting a photo of a face that way, could I somehow feed in 1:1 direct pairs of images (a photo of a face and a painted version, a photo of a tree and a painted version, etc.) to enable it to better output a similar style?

I'm new at this and still learning, so any advice at all would be greatly appreciated.
"
Data Structures Related to Machine Learning Algorithms,0,11,False,False,False,learnmachinelearning,1500560133,False, 
Recommendation for intuitive machine learning tutorial(s).,6,7,False,False,False,learnmachinelearning,1500566892,True,"I have tried many times to learn more about and become proficient in machine learning through different courses and books. I have tried Coursera and Udemy as well as guides for different frameworks like Theano. While going through the tutorials, most of the concepts make sense, if I try to explain them to someone else or apply them to other problems, the intuition just doesn't seem to stick with me. I feel like it shouldn't be that hard considering I have a fairly strong background in both general-purpose programming as well as mathematics.

What tutorial, course, or guide do you recommend that will provide me with the intuition I need (preferably with programming, but it could just be math)?"
Becoming a Data Cook: What Data Preparation means for Data Scientists,0,18,False,False,False,learnmachinelearning,1500568276,False, 
Social network analysis - where should I start - NetworkX or Deep Learning?,2,4,False,False,False,learnmachinelearning,1500575232,True,"Heya,
Got some data about relationships between people on what you might call a social network. Who's connecting with whom (connections can be one sided, like following someone on twitter but not being followed back by her/him, or two sided). I thought it would be a great opportunity to start learning a little about network analysis, like identifying influencers, see 'group' sizes, etc. Where should I begin? I'm a Python guy. I know there's the NetworkX library for python, but am I better off to start straight from DL approaches? If so - which and what? Appreciate your insights on where one would start his journey analyzing networks.

Thanks!!"
How would you set up a computation server?,6,2,False,False,False,learnmachinelearning,1500582722,True,"My boss got a computer with an i7-7700k, 32gb ram, GTX 1080.  I'd like to take full advantage of it for my machine learning / deep learning duties.  How would you recommend I set it up?  I don't expect to have more than a couple of users at any given time, and could easily only see a single user at a time most of the day.

I've been thinking I'd install Ubuntu (16.04?) as the OS.  I'd use anaconda w/ python 3.6 and then I'd install jupyterhub for actual access.  I'd use the GPU version of TensorFlow and pyTorch and also install Keras on top of TensorFlow.

Is this a sensible setup?  If you were installing, how would you set it up?  Know of any good guides to walk through the process so I'm not doing it blind?"
19 MOOCs on Mathematics & Statistics for Data Science & Machine Learning,2,34,False,False,False,learnmachinelearning,1500612350,False, 
Weekly Show-off!,4,2,False,False,False,learnmachinelearning,1500620720,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
hey what's currently the best ai that understands human language the best and most efficiently and most effectively?,1,5,False,False,False,learnmachinelearning,1500625707,True,hey what's currently the best ai that understands human language the best and most efficiently and most effectively?
How to update this Tensorboard Demo?,0,3,False,False,False,learnmachinelearning,1500640451,True,"To learn Tensorboard, I'm following this [demo](https://github.com/llSourcell/Tensorboard_demo/blob/master/simple.py)

Unfortunately, it's a little outdated. I replaced as much of the summary functions I could with the new ones. However when I run the file, there is an error that says:

    InvalidArgumentError (see above for traceback): Shape [-1,28,28,1] has negative dimensions
	 [[Node: Placeholder_63 = Placeholder[dtype=DT_FLOAT, shape=[?,28,28,1], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]"
Learn to Build a Realtime Recommendation Engine using a Graph Database,1,11,False,False,False,learnmachinelearning,1500640662,False, 
Knn - Image clasification,0,2,False,False,False,learnmachinelearning,1500643470,True,"Hello,

I am looking for a method to do image clasification in sub-classes of clasified images. As an example: Lets say we have to do the kaggle competition on Dogs vs. Cats. I first build a CNN clasifier to correctly clasify if an image is of a dog or a cat, then when it is classified I want to take that image and find similair ones. Lets say I have a black cat with a white tail, I have correctly clasified it as a cat but then I want Knn on that image to find similar images of black cats with a white tail. What kind of Knn should I use for this?

Thanks."
Learn How to Build a Speech Recognizer,0,11,False,False,False,learnmachinelearning,1500643947,False, 
"here are rules for ML to communicate clearly (first draft), please send feedback or clarification",0,0,False,False,False,learnmachinelearning,1500671191,True,"we all know that humans are bad at communication:

* transferring information (communicating)
* receiving information (listening)

ML would do significantly better

im going to focus on the top 3 most important things about communication

---

#1 - always use examples over abstractions

* the ML always uses examples over abstractions -- because examples are much more clear than abstractions

---

'ml paradise' is abstract, and is an abstraction

an example of 'ml paradise' is 

> a character in a video game, the character is computer-generated

a more specific example is this video about 'creating elizabeth'

> https://www.youtube.com/watch?v=Z6uwI_MOjjc

there are billions to infinity of examples/instances for 'ml paradise'

---

the word **'an example'** is abstract

the word **'a more specific example'** is also abstract

this is a fundamental problem with language and communication, and there are no better words to describe the 'more specific example'

**than by showing the example itself via a combination of words**

---

* in the title, instead of '**here** are rules for',

* it could've said '**these** are rules for'

both 'here' and 'these' are abstract, un-quantifiably so

* 'here' refers to the entire post, but 'these' may indicate that entire post talks only on the rules, when the entire post the rules are 95% of the post, not 100%

* so 'here' seems to be a lil bit better, with this possible marginal difference but

there is not any significant difference between these two words, making having 2 words that able to be used in this context -- redundant and unnecessary

this possible and slight level of uncertainty in the semantics is unnecessary, and cause many many problems in clear communication -- for the purposes of clarity 

**this is one of many many problems with abstractions**


---

#2 - section things (best way to structure)

* sections adds visual clarity  

* & when speaking, adds conceptual clarity 

---

the 3 major sections here are clear

and when talking, they should verbally be broken up into sections, as in:

* 'the first rule is to use examples over abstractness like..'

digital information is significantly more superior to verbal information for many reasons:

* one being that we can easily see the information

---

#3 - everything has to be consistent

this post shows consistency:

* words are used with the same meaning

* the sections are structured similarly 

* the syntax is perfectly consistent 

* & everything (will edit more later)


---

# for listening

#1

* the single most important thing is that the ML cannot assume too much

humans do this more often than is needed, some of which is due to their evolutionary bad communication skills

and largely because almost nobody ever really learned specifically how to communicate clearly

---

**you're welcome to send any proposed rules with the examples/reasons why they are near the top of the most important things about communication**

"
Podcast on why we need more AI researchers and how you can become one too,0,27,False,False,False,learnmachinelearning,1500677134,False, 
Recommender systems: Pros and Cons of neighborhood-based methods,0,3,False,False,False,learnmachinelearning,1500681258,False, 
Can You Answer These Common Grammar Mistake Questions?,0,1,False,False,False,learnmachinelearning,1500703542,False, 
"Weekly Status Check Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",5,6,False,False,False,learnmachinelearning,1500707109,True,"Let's have a  meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
How to store preprocessed data for fast access from Tensorflow?,8,9,False,False,False,learnmachinelearning,1500721710,True,"I am working on an audio dataset. Each file requires a lot of preprocessing (trimming, STFT, lowpass filtering, etc.). I am able to take any audio file and convert it to the final tensor that will go into my Tensorflow model. Now I want to save these tensors in a binary format so that I will not need to re-preprocess all the files each time I run an experiment. 

I used to save them as a single numpy array but I am not sure this is the best approach. TFRecords documentation did not help. I would like to save all the data as a single tensor with dimensions [num_examples, feature0, feature1, feature2, ...] but I am open to suggestions if there is a better way."
Jefferies gives IBM Watson a Wall Street reality check,0,7,False,False,False,learnmachinelearning,1500739875,False, 
Looking for help with ML algorithm for evolution of musical dataset,1,3,False,False,False,learnmachinelearning,1500743592,True,"Hi All! I was wondering whether you'd be able to point me in the right direction. I am a sound artist (www.iskraexperiment.com) and I'm looking to implement ML in my work.

I don't have any ML experience, although I have programming experience (mostly C++, a lot of Linux scripting - bash, some python, a touch of Haskell). I am quite open to learn a new language if required.

My apologies if this specific question has been asked before - I searched this forum and couldn't find anything similar. It is quite hard to research this subject for me without the knowledge of proper terminology.

What I am looking for is to program a tool which would work as follows:

1. I start with a specific data set. The data set consist of a integers or floats. The size of data set can be anything between a few variables and hundreds of variables (if not thousands). The data could describe a variety of things - it doesn't really matter at this stage - it could be specific synth parameters, note pitch, rhythms.

2. The ML algorithm produces a few variations of the current data set. The amount of variations should be adjustable (between 2 and any other arbitrary amount).

3. A separate algorithm (independent and outside the scope of this question) picks the most desirable outcome. Alternatively the user picks the best outcome.

4. The ML algorithm produces further variations, evolving the data set based on the choice from step 3.

Steps 3 and 4 repeat until a satisfactory data set is achieved (either decided by the user or another algorithm).

I would appreciate if you could point my research in the right direction - I have a feeling that the above algorithm is general enough a specific software solution already exist (albeit it might need to be customised to my specific requirements).

Thank you!"
"This post is a Beginners Guide to Machine Learning, Artificial Intelligence, Internet of Things (IoT), Natural Language Processing (NLP), Deep Learning, Big Data Analytics and Blockchain. Additionally, I have also listed some of the Best Online Courses.",6,53,False,False,False,learnmachinelearning,1500744166,False, 
Learn about Expected Value - part II,0,1,False,False,False,learnmachinelearning,1500777398,False, 
I accidentally compiled my ANN learning resources in a reddit comment. Thought it would be helpful to post here!,0,12,False,False,False,learnmachinelearning,1500785887,False, 
2 Deep Learning in Production Workshops in New York City This Week,0,1,False,False,False,learnmachinelearning,1500807700,False, 
Is this a machine learning problem?,4,4,False,False,False,learnmachinelearning,1500807784,True,"Hi,

I would like to predict the chances to win on a specific day in the week for a particular player in the game League of Legends. 

Based on the history of this player how he performed on specific week days I want to make my predictions. 

I already started fetching and preparing the data. By now I just asked myself, is this even possible with machine learning ? And if so, how difficult do you think this is ? 

I wantd to challenge myself with a side project like this to get deeper into machine learning. I did  read a lot about machine learning already and implemented basic techniques and did simple datasets on kaggle. Side projects like this help me a lot more to learn, since it's also very fun to me and keeps me motivate."
Career advice needed.,1,1,False,False,False,learnmachinelearning,1500818910,True,"Hi. I'm from an engineering background. Electrical. So some maths not so much stats.

For the past year I have been working for an IT solutions firm, that provides IT-business solutions to large and small scale clients. I have been mainly reporting and building dashboards on Qlik tools, primarily Qlik Sense. 

Here comes a couple of questions, but before that I'll tell you:


What I know:

In this job, I do enjoy understanding the business issues, reading about and understanding the industry, understanding the company's workflow, and the questions they want answered. But all of that usually entails building a data model and presenting what can be derived from their data onto a dashboard to give them their figures. It does not for the most part pose a challenge and neither does this sort of job put me in the position of advising the business as to what decisions they could make to potentially solve their issues and improve their current standing. I am merely reporting what I can see from their data.

Which is the part that I do not enjoy so much. So I was thinking of switching up.

From what I understand about the business analytics spectrum, the next stage of business analytics, after dashboarding, is predictive modelling. Which i enjoyed being a part of in one of my projects, this part was handled by a different team but due to my curiosity I was in on every step of the way.

So far I had been working on business intelligence, but this part deals with data science along with business analytics. I'm going to call this business analytics from now on.


What I believe:

I believe since ML and predictive modelling in R and Python don't really give a very presentable picture, there must be some tools or software that these are used in conjunction with in the actual industry to study the insights given by these methods. Maybe Qlik sense or other such BI tools.

Is that really so?

If not, then, what do, say, retail stores or FMCG companies, that utilize such models to predict how much stock they need for the 4th of July sale use to report, understand and drive business decisions.


What I don't know:

I recently completed a course on inferential statistics in order to get started with machine learning. Next step in my view would be starting any of the machine learning courses online, accompanied by learning R/Python.

Please tell me if I am on the right track with my pursuit of business analytics and machine learning.

Another question that I have is what sort of profiles exist in the market regarding this kind of business analytics, like financial analyst, retail, consulting etc.

There are further research oriented jobs in this field, if we leave out business analytics from ML, but I think that would require a higher degree in those fields, which I may be considering. What sort of jobs will I be looking at if I pursue an MS in data science?


Sorry for the wall of text. I have a few more questions but I think this much is enough for now. I'll followup if someone replies to this post."
Avoiding being a ‘trophy’ data scientist – Models are illuminating and wrong,1,15,False,False,False,learnmachinelearning,1500821649,False, 
"A paradox of RBM is despite weights being symmetric, it learns asymmetry depending on inference up vs down. Whats a norm func to fix this?",0,1,False,False,False,learnmachinelearning,1500824381,True,"Example: If the first node in each layer is always on because a huge weight is between them, then nodes in the next higher or lower layer can have weights that always raise or lower the chance they are on regardless of combinations of other nodes (like node bias is used for).

Example: If layerX usually has 20% of its nodes on and layerY learns to have only 10% of its nodes on, then 10% is so small that weightedSums are usually near 0 so sigmoid of that is usually near .5 so inference back to layerX gets around 50% of its nodes on and cant learn to do 20%. Unless its normed against this.

I imagine such a func could somehow be designed using statistics of how often each pair of nodes, 1 in each adjacent layer, are all 4 combinations (0 0, 0 1, 1 0, 1 1), and compare that to their weights. The weights of 1 node dont tell statistics of the node since other nodes past those weights (such as inference down then up to siblings) affect the combinations they're on and how often they're on. You may have a very high weight with some node thats rarely on, so you cant tell from the weights alone."
Hello,0,0,False,False,False,learnmachinelearning,1500824758,True,[removed]
Unsupervised learning on classification of unlabelled Physics data,0,6,False,False,False,learnmachinelearning,1500825667,True,"I'm a physicist so machine learning is something that caught my interest as being a potential useful tools for data analysis in physics.

An idea I have is to use unsupervised learning to classify a set of experimental data I have. A very simple case would be classifying a set of event in my data as either signal or background(hopefully I can expand this to discover new things through it). I know the best way for this kind of problem would be supervised learning with large set of training data. However a problem I have is that to produced those training data I would have to do is Monte Carlo simulation which can take quite a while. Data collection is quite difficult as the very thing I need to do is the identify it which is the aim of using machine learning in the first place.

Given that The only way for me to produce the simulation is via Geant4 simulation(physicist toolkit) and some experiment to compliment the simulation which is extremely laborious task(time consuming) and difficult(requires approval and detail planning as not to disrupt the ongoing experiment). I am not going into further details beyond this due to its complexity of explaining the physics. 

My question would be how should I tackle this idea in order to achieve the goal of what I want in classifying a set of data that is yet being classified. Since The raw data Im handling is in .root, the best way I feel is using python so I can use the ML libraries but I have no idea how should I do this properly.

TLDR:- make a program based on unsupervised learning to classified a set of unclassified data."
Learn Data Science with Josh and Micky,0,1,False,False,False,learnmachinelearning,1500837542,False,[deleted]
Learn Data Science with Josh and Micky,0,0,False,False,False,learnmachinelearning,1500838360,False,[deleted]
The Importance of Random Initialization of the Weights. Evidence.,0,2,False,False,False,learnmachinelearning,1500840399,False, 
A Student's Guide To Preparing For A Machine Learning/ Data Science Interview,2,11,False,False,False,learnmachinelearning,1500844784,False,[deleted]
Learn Machine Learning with Josh and Micky,0,3,False,False,False,learnmachinelearning,1500863014,False, 
"With QLearning, how to enforce a constraint of ""don't take this action again""?",2,2,False,False,False,learnmachinelearning,1500875967,True,"If I have a task to learn, where there are N actions, and each action should only be taken once (once and only once), i.e. it is no-op to do it again. How do I make the agent learn this concept? Right now my agent seems to love retrying the same no-op action many times in a single episode, so that given n_steps to iterate, 95% of the time is doing the no-op action.

Currently the rewards I set it as:

- END_GAME_WIN = 1  # terminal
- END_GAME_LOSE = -1  # terminal
- ONGOING = 0  # mixture of good actions and ""no-op"" actions.

I also tried something like this:

- END_GAME_WIN = 1000  # terminal
- END_GAME_LOSE = -1000  # terminal
- ONGOING = 0  # good action, but game continues
- NO-OP = -1  # NO-OP action, don't waste time

I picked 1000 because most of the time a single episode ends within 200 steps normally, so 1000 and -1000 should be good clear signal.

I'm quite new to RL appreciate the pointers!"
Any good Machine Learning and Analytics MOOCs that teach using Python as Primary language ?,18,16,False,False,False,learnmachinelearning,1500893501,True,"The best ones are using R and MATLAB, are they any other MOOCs with similar quality which use Python as primary language in the course?"
Deep learning setup on Windows 10,2,1,False,False,False,learnmachinelearning,1500910146,False, 
Any good tutorials on building an AI to play games?,3,18,False,False,False,learnmachinelearning,1500929943,True,"I was curious if anyone knew of resources to look at for building an AI that **learns** how to play a game-- something similar to MarI/o: https://www.youtube.com/watch?v=qv6UVOQ0F44

It would likely be more simple, but I think it would be cool to use a neural network and a pixel display as the input layer.

Any suggestions would be awesome!"
Join the /r/LearnMachineLearning moderation team!,5,7,False,False,True,learnmachinelearning,1500940670,True,"/r/LearnMachineLearning is looking for passionate redditors who can help moderate this subreddit. 

We need the most help in the following responsibilities:

- General moderator: Respond to reports and spams. We are looking for redditors who have experience in moderating other subreddits.
- Wiki moderator: Responsible with providing guideline and maintaining the wiki pages. We are looking for a machine learning expert who is passionate in educating machine learning to others

Please send your application as a comment here or as a [message-to-mod](https://www.reddit.com/message/compose?to=%2Fr%2Flearnmachinelearning). Please include which role you are interested in as well as your background that you think is relevant such as your experience in community moderation and in machine learning.

By having extra members in our mod team, we hope to address the following issues we identified for our sub:

- Low-effort posts or vague questions that don’t include enough details to be educational : these will be promptly removed by the moderators
- Repetitive questions : Common questions can be compiled into a FAQ page and simply redirect the question to that page. Also, given that most of the repetitive questions are from literal beginners (a.k.a. “how do I get started with machine learning” type of questions), a wiki page on how to get started should alleviate the influx of such questions. 
- Organization of reddit posts : With our new moderation team, we will slowly roll out features such as post flairs so that the subreddit is more organized and easier to browse

:)"
Horizontal Bands in GloVe,2,1,False,False,False,learnmachinelearning,1500943568,True,"In the ""visualization"" section of [GloVe's website](https://nlp.stanford.edu/projects/glove/), they write:  
>The horizontal bands result from the fact that the multiplicative interactions in the model occur component-wise. While there are additive interactions resulting from a dot product, in general there is little room for the individual dimensions to cross-pollinate.

>The horizontal bands become more pronounced as the word frequency increases. Indeed, there are noticeable long-range trends as a function of word frequency, and they are unlikely to have a linguistic origin. This feature is not unique to GloVe -- in fact, I'm unaware of any model for word vector learning that avoids this issue.

I don't know what they're describing in the first paragraph at all (what interactions are they referring to? what does it mean to cross-pollinate?). Can anyone clarify?

Also, why are these unlikely to have a linguistic origin?"
Basic question: kernels and negative data,0,1,False,False,False,learnmachinelearning,1500948015,True,"If this is the wrong subreddit, can you point me to the correct one?

I have started learning about kernels and from what I have seen none of the (standard ) kernels seem to work with negative data.  E.g., exp(-||x-w||^2 /alpha^2 ) outputs (0,1].  (1+w^T u)^p outputs positive only for certain values of p and for others it is biased towards positive values.  

I feel as though I am missing something."
What is the rationale behind this toy GAN,1,2,False,False,False,learnmachinelearning,1500951608,True,I was searching for a simple GAN and got this [link](http://blog.evjang.com/2016/06/generative-adversarial-nets-in.html) . The author used a simple `1-D normal distribution` to simulate GAN. I know what GAN is but dont know how and why `1-D normal distribution` is used as a toy example. Can some body explain it in simple english?
Discord™ Artificial Intelligence (official Discord server of /r/learnmachinelearning),0,2,False,False,False,learnmachinelearning,1500951751,True,[removed]
Which is the best place to learn Tensorflow?,6,14,False,False,False,learnmachinelearning,1500958521,True,I am good with python but tensorflow feels foreign to me.
Lessons learned from building a Hello World Neural Network,0,2,False,False,False,learnmachinelearning,1500970042,False, 
37 Reasons why your Neural Network is not working,0,22,False,False,False,learnmachinelearning,1500971716,False, 
Can I use a 3d image to do some machine learning?,2,5,False,False,False,learnmachinelearning,1500978663,True,"Hello

Long story short, I am implementing a 3d face recognition system.
The current approach I am thinking about is the following:

1) use openCV to extract faces using computer vision. This will give 2d images that I can stitch together to try to obtain a +/- 360 view of ones head. (using a panorama mechanism)

2) use point cloud library (http://pointclouds.org) to create a 3d model of those stitched 2d images.

3) input this 3d model to a machine learning algorithm (CCN?), using tensorflow.

The last step (3) will be used to do the actual recognition. 
Could someone share their insights about whether this is the best way to proceed or whether there might be an easier  **robust** intermediate step?

Thanks

"
"Which Model or which Machinelearning technique do I need to learn, if I want the Model to improve over time instead of retrain and update the Model?",7,4,False,False,False,learnmachinelearning,1500984357,True,"Example:
If I use imagenet i can improve it by training it on new labeled images.
Retraining will then improve my Model (in this case the network)

But how can I achieve constant improvement? I am looking for something I can reward for a correct assumption and penalize for a wrong assumption, where this penalization will im prove the model instead of retraining it"
Facebook like Face recognition Project,0,1,False,False,False,learnmachinelearning,1500994578,False, 
How much statistics do I need to know to do machine learning?,4,2,False,False,False,learnmachinelearning,1500995962,True,"I'm mostly self-taught but have been trying to build up a foundation in math so that I can understand machine learning. I took calc1 and calc2. I just finished elementary linear algebra.

[Elementary Linear Algebra](https://www.amazon.com/Elementary-Linear-Algebra-Ron-Larson/dp/0618335676/ref=sr_1_1?s=books&ie=UTF8&qid=1500992612&sr=1-1&keywords=0618335676) was a 465 page book and that took me seven months at two hours a day. [Elementary Statistics](https://www.amazon.com/Elementary-Statistics-12th-Mario-Triola/dp/0321836960) is what I'm thinking of reading to learn statistics and it's a 767 page book. So it would take me over a year to finish that whole book.

I'm afraid there will be disparate topics and by the time I get to page 700 I won't remember anything about page 200. In other words, I don't know which sections to read and which sections to ignore. Since I'm self-taught I could really benefit from your advice about what I should focus on."
To go from complete zero to deep learning. Contributions required !!,12,30,False,False,False,learnmachinelearning,1501008662,True,"This community should make a path/track to answer the question using completely open source courses, books(to learn) and challenges(to practice) organized in the required order so that we anybody can directly jump to that. We can further add it to the sidebar for everybody's benefit. 

The Idea is to start with 3 parts:

1. Coding (Python/R) - Theory and practice 
""Give suggestions""
2. Statistics - Theory
""Give suggestions""
3. Basics of data analysis
""Give suggestions""

After this, Implementation of Stats theory in Challenges and datasets would be the main focus in the language of your choice.

The second part of the learning curve is diving into the ML theory and implementing it via kaggle/open source challenges. 

1. Andrew Ng course 
2. titanic kaggle challenge
""Give suggestions""

The third part would be the transition to deep learning.
""Give suggestions""

The idea is to create a balance of theory and practice which makes the entire process much more enjoyable. The track could span over a year if required.

Edit: made some major edits."
"What technique to use for machine output? (writing digits, drawing trees etc.)",1,0,False,False,False,learnmachinelearning,1501011620,True, 
Discord™ Artificial Intelligence (official partner of /r/learnmachinelearning),0,2,False,False,False,learnmachinelearning,1501029627,True,"We welcome all of those interested in imaginative discussion of artificial intelligence, machine learning, and natural language processing. Unlike many servers on Discord we are oriented toward academics and professionals and as such we try to keep conversations intelligent and on-topic as much as possible. If you know anyone that may be interested in joining, please link them to https://discord.me/ai for an invitation.

We hope you enjoy your stay.

website: https://ai-lab.xyz/ direct link: https://discord.gg/CbVJYtz"
Forward Propagation vs Regression,5,3,False,False,False,learnmachinelearning,1501048094,True,"How is forward propagation on NN different from regression? In forward propagation, we multiply each node layer by a set of parameters and add a bias unit.

So in the end, the result will be a linear function of all of the parameters, which can be done with regression. "
TWIL (This Week I Learned) - Share something new that you have learned this week!,1,4,False,False,False,learnmachinelearning,1501052714,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
Help me with next step,2,6,False,False,False,learnmachinelearning,1501070821,True,"Guys I am in my final year of bachelors from mechanical engineering, I am learning about Neural Networks from 7-8 months, I've got a good thorough theoretical knowledge through the months, I am very interested in deep learning, now I have started with Tensorflow documentation.
I intend to make several projects using TF and OpenCV through the next year.
The problem is the mass recruitment phase has begun in my college, I just don't want to go in that when I'm focused on ML, Everyone is forcing me to atleast take the prep classes for interview and get a backup job, but it's taking all my waking hours and no time for working on ML. 

All in All, TL;DR is I now have even less time than ever, even if I rebel everyone, All I've got is less than 9 months to work on my ML skills, Please suggest a best working plan that could land me a good job so that I can be independent, able to make my own decisions freely and pursue this passion even further."
Keras-GAN - Easy to follow implementations of Generative Adversarial Networks in Keras,5,17,False,False,False,learnmachinelearning,1501072226,False, 
What Makes Advanced Analytics and Machine Learning So Great,0,9,False,False,False,learnmachinelearning,1501072383,False, 
The future of deep learning,0,11,False,False,False,learnmachinelearning,1501078998,False, 
What makes fine-tuning/transfer learning so immediately effective?,3,4,False,False,False,learnmachinelearning,1501088508,True,"Figures illustrating my situation are [shown here.](http://imgur.com/gallery/EifE4)

I'm working on an image classification problem, and I decided to use a pre-trained base model (InceptionV3) and train my own top model to attach to the end of it. My process looks something like this:

1. Load InceptionV3 without the top layers (so it doesn't perform classification, merely acts as a feature extractor)
2. Use these bottleneck features as input for my own top model
3. Train my top model (after 50 epochs, I had a training accuracy of  98.0% and validation accuracy of 9.97%)
4. Save my trained top model
5. Use pre-trained base model and top model as one network, freezing the bottom 250 layers (so I train only the top two inception blocks and my entire top model, [as shown here](https://keras.io/applications/)).

During the training phase with the bottleneck features as input, my validation accuracy was around 10%. After only one epoch of fine-tune training, I saw validation accuracy of 83%. What makes this process so effective so quickly? I would be less surprised if I saw accuracy start at 10% and go up from there, but I simply can't understand how it's so effective so fast. Can anyone provide any insight?"
Question about performance drop in Q-Learning implementation.,2,4,False,False,False,learnmachinelearning,1501105846,True,"I found a really nice example of Q-Learning using OpenAI Gym and Keras. I have been running the algorithm for a few days now and I've noticed that the performance of the predictions seem to peak about 80% through the 1000 episode run and then seem to degrade. The link to the code is below, I've tweaked a number of parameters but I can't figure out why the performance is declining. Any hints or ideas would be welcome.

https://github.com/keon/deep-q-learning/blob/master/dqn.py"
A collection of best practices for using neural networks in Natural Language Processing,0,4,False,False,False,learnmachinelearning,1501114647,False, 
Machine Learning in High-Frequency Algorithmic Trading.,2,19,False,False,False,learnmachinelearning,1501118454,False, 
What you need to know before you board the machine learning train,0,1,False,False,False,learnmachinelearning,1501132803,False, 
Lessons Learned From Benchmarking Fast Machine Learning Algorithms,0,4,False,False,False,learnmachinelearning,1501163879,False, 
Total newbie questions about Feedforward neural network on malware classification problem,9,3,False,False,False,learnmachinelearning,1501169632,True,"I'm currently working on my final year project, Malware Classification using Neural Nets. I have performed my data gathering and labeling (into benign or malicious files) and I was planning on using the windows API calls by each sample to create a binary feature vector.

However, as I iterated through all of my sample set (18,000 malicious, 4,000 benign) the total list of unique API calls generated was over 65,000, thus raising a concern regarding the dimensionality. 

Now I was wondering, is it deemed feasible to even follow this course, and create a binary feature vector for the function calls present for each sample and pass it into my neural net or should I be looking at some other features to take into consideration, or perform some form of dimension reduction to reduce the feature size?

I am also clueless on the number of hidden layers & neurons per layer that I should be using... is there an actual way to determine this or should I just be playing with the numbers to land on some numbers. Initially, I was planning to have two hidden layers with 500 neurons each.

Do forgive me for my total newbie questions ..."
Where to start?,16,11,False,False,False,learnmachinelearning,1501172178,True,"Hi everyone,

I need some advice on how to get into ML. I have a bachelors in CS from a no-name university. I had a pathetic math background in my undergrad. We only had 1 math course! 

I also haven't done any stats. So my math foundation is weak. I am comfortable in programming principles and know iOS app development. I am also comfortable programming in C++, game development with unreal engine is my hobby. 

I need guidance on how I can proceed with learning ML. I need to work on my weak math background. So I'm taking [MIT's Linear Algebra OCW](https://ocw.mit.edu/courses/mathematics/18-06sc-linear-algebra-fall-2011/) . After this I should take a stats course? And what next? After these two maths courses, can I take Andrew NG's ML course on iTunes U? 

I am planning on pursuing a PhD focusing on ML, but I want to get up to speed with my weak math background. What would you recommend? In addition to C++ I will need to learn python. 

I really need a study plan so I can get something done. I don't want to wait till starting my PhD. I want to show my interest in ML beforehand. 

Also, I am sort of torn between HPC and ML for specializing in CS. Thoughts? "
Data Science and Machine Learning with Python and Spark,1,5,False,False,False,learnmachinelearning,1501187301,False, 
Help Understanding a Reinforcement learning implementation,1,1,False,False,False,learnmachinelearning,1501192600,True,"I'm just learning some reinforcement learning on OpenAI gym and I found a solution to the cartpole problem that seems to be outperforming any others I've seen using very little code. Can anyone help me determine what algorithm is being used here? I can't seem to map it back to any of the ones i know yet

https://gym.openai.com/evaluations/eval_rli1PxgRv2d9TNIOX1W8Q"
Two questions: Do you have to remove the features in your test set that you removed in your training set? Do you need to perform data transformations like log transform on the test set if you performed it on the training set?,4,3,False,False,False,learnmachinelearning,1501193417,True,"Thanks!

edit: actually, I have a third question, should standardization and normalization be applied to all features of a feature set? (assuming these are numerical features)

editx2: dang, one more question, do things like log transforms need to occur before normalization/standardization, or should they be applied after those?"
How do i make a machine to find if a condition is met?,5,1,False,False,False,learnmachinelearning,1501201432,True,"I have a problem. Imagine a card game where you shuffle a couple of playing card decks, then you draw cards until some condition is met, the order of the cards drawn is irrelevant. This is a simplification of a bigger problem where each card has an effect on the game and interact with the other cards. I want to create a funcion/algorithm/machine that i can train to check if that condition is met. The condition itself is very complex.  
My input is a list of drawn cards and my output is a boolean true if the condition is met, false if not. 
What should i use? How should i format my input?

Thanks for the help"
Question regarding Udacity's AI Nanodegree,7,11,False,False,False,learnmachinelearning,1501216472,True,"I'm a software engineer with interest in pursuing a career in applied ML, potentially in NLP or computer vision. I took Andrew Ng's excellent coursera MOOC and recently started Udacity's AI Nanodegree. From the syllabus, it seems like it's going to be a while before it starts covering deep learning concepts. Right now I'm learning about game playing, mimimax, alpha-beta pruning, searching, etc. I've been wondering, as I write a sudoku solver, will this seemingly foundational knowledge prove useful when I start exploring deep learning methods more in-depth later? The second part of the course goes into deep learning,  I believe, which suggests it will, but would love to hear your thoughts."
Counting fingers with a CNN,0,1,False,False,False,learnmachinelearning,1501222436,False,[deleted]
How many fingers am I holding up? A beginners project with CNNs,10,39,False,False,False,learnmachinelearning,1501223094,True,"I've just been learning about convolutional neural networks and put together a small project to take video and tell you how many fingers are being held up. 

This is my first time using machine learning for a dataset I've created and implementing it into some sort of application. I'm really happy with how it turned out and excited to share my progress. Feedback welcome. https://github.com/jgv7/CNN-HowManyFingers"
Weekly Show-off!,0,2,False,False,False,learnmachinelearning,1501225527,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
An oddity I encountered with weights and biases [more details inside],2,4,False,False,False,learnmachinelearning,1501253605,True,"I was reading this tutorial, 

https://aqibsaeed.github.io/2016-07-07-TensorflowLR/

a simple intro to tensorflow linear regression with a basic numerical dataset with a normally distributed target variable. I went through the tutorial and reproduced the authors results. Upon doing so, I realized that the author was not actually creating an additional bias variable, and instead the author included another feature in the form of 1's. I decided to 'fix' this by creating a separate tensorflow bias variable and adding it to the result of x*W, but when I did, my mean squared error shot up from the authors by roughly ~20%!

I was surprised, since I found another author that did it my way as can be seen here:

https://medium.com/@saxenarohan97/intro-to-tensorflow-solving-a-simple-regression-problem-e87b42fd4845

Why is this? How can this be? Is this the discovery of the century? Is this just a quirk of tensorflow's backprop algorithm? Please help a noob figure this out!

edit: to clarify, the former's blog has a MSE of around 20, whereas the latter's blog has a MSE of around 70, with similar gaps for the validation and test sets"
I recently wrote my first data science project and made a bunch of mistakes. Here's what I learned:,3,9,False,False,False,learnmachinelearning,1501258163,False, 
Learning Machine Learning and NLP from 187 Quora Questions,0,1,False,False,False,learnmachinelearning,1501270656,False, 
Developing a Machine Learning Engineering Project,0,1,False,False,False,learnmachinelearning,1501274650,True,"Hey guys,

So I have recently what I think is the distinction between data scientists and machine learning engineer and I want to start doing some projects in that scope.

* Data Scientist -- Develops insights from data that will be presented to business stakeholders. Uses already created machine learning algorithms and/or statistical modeling. 

* Machine Learning Engineer -- Develops platforms to work in unison with other software in the company that uses data to develop insights.

**If this is not what you believe a ML Engineer does or there is more PLEASE PLEASE let me know**

Anyways, I wanted to try and dabble in some Machine Learning Engineer work. Can anyone give me feasible ideas or real examples or tutorials on Machine Learning Engineering work? Thanks!"
Why Elon Musk Is Wrong About AI Safety,0,1,False,False,False,learnmachinelearning,1501277543,False,[deleted]
[Question] How project Magenta self evaluate its prediction without overffiting and bias?,0,1,False,False,False,learnmachinelearning,1501280807,True,"Hi,

Could someone explain how does Google's Magenta (project that generate music) keep improving from each epoch without just completing mimic the music used to train it? Is this a sort of ad-hoc function used to evaluate the training or is there a set of techniques? 

Thanks in advance"
Why do additional epochs help train a model if it's seeing the same data?,6,1,False,False,False,learnmachinelearning,1501288021,True,"Title is pretty self explanatory. I was wondering why loss goes down as more epochs are run. If it's the same data, then what difference does it make for the model? Thanks!"
AI Is Not Magic. How Neural Networks Learn,1,37,False,False,False,learnmachinelearning,1501307242,False, 
"Weekly Status Check Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",1,6,False,False,False,learnmachinelearning,1501311918,True,"Let's have a  meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
What's a good feature vector for image classification?,1,3,False,False,False,learnmachinelearning,1501334407,True,"I've just recently started to play around with implementations of various machine learning techniques. I want to classify images in a binary way, i.e. the learner should be able to tell if a given image is depicting a certain thing or not.

Now, simply using each pixel's RGB-values and combining them into one huge feature vector seems a bit lazy, and intuitively I'd say that this kind of feature vector contains too much noise to extract any useful information from it. I tried using certain characteristic values (such as the average brightness) to reduce the number of features, and using SVM I could bring the average error down to about 1/3, with a training set of ca. 130 images. However, I feel that my naïve way of choosing those characteristic values meant that I lost quite a bit of information along the way, and while an error of 1/3 certainly is better than guessing, it's still bad.

Are there any general approaches to extracting useful information from an image? Or is professional image recognition software simply so good that it can deal with every pixel's RGB-value as a feature vector?

I'm sorry if that's a dumb question, but while I'm fairly comfortable with the underlying maths of machine learning, there's just so much stuff going on when it comes to the actual implementation that I didn't get any answers from googling my questions.

Thank you! :)"
Should I be using machine learning for this? Any suggestions.,1,2,False,False,False,learnmachinelearning,1501336984,True,"I have a site where users can list items for sale. The problem is that the sizes amongst product categories are pretty complex. There are various measurements that are sometimes filled in differently, and would be laborious to make users enter them in a rigid fashion.

I'd like to be able do something like:

*Given*

- 13.5"" Product A For sale
- Hey I have a 13.5"" product a for sale, It was purchased in 2009, and it has measurementB of oversized, this item would be great for everyone, and you should buy it.

*Result*

I'd like to extract from the text these sizes in the appropriate context, and map them to generalized values in my database. so in this example i'd like to see:

- Size 1: 13 1/2 inches
- Size 2: oversized


**Questions**

- Given I have sufficient <post descriptions> -> <sizes> mappings already, would this be a good fit for a supervised machine learning model? 

- Should I just use stemming to handle the 15.5"" -> 15 1/2 inches issue?

- Should my data source contain be as restrictive as possible, for example, should it look like


```description, size```

```hey this is a 15 1/2 inch item with measurementB of 12 inches, 12 1/2```

or should it be restricted like so:

```description, size```

```measurementB of 12, 12```

```12 measurementB, 12```
"
Is my understanding of kernels correct?,2,1,False,False,False,learnmachinelearning,1501347882,True,"So I keep seeing the kernel function described as a ""similarity measure"" in the feature space, but that doesn't make much sense to me, because it's supposed to be equal to the dot product of two points in the feature space, which doesn't make sense as a similarity measure unless all points in the index space have the same measure after being projected into the feature space. So the way I interpreted it is that the actual ""similarity measure"" of x and y in the feature space is |phi(x)-phi(y)|^2 = (phi(x)-phi(y)) dot (phi(x)-phi(y)) = (phi(x) dot phi(x))-2(phi(x) dot phi(y))+(phi(y) dot phi(y)) = k(x,x)+k(y,y)-2k(x,y) or the square length of their distance in the feature space. Am I missing something? I understand how being able to compute the dot product of any two points in the feature space as a function of their dot product in the index space is useful for SVMs and other purposes. I just don't quite understand why the kernel is described as a ""similarity measure"" which makes me think I may be missing something."
A smarter Chatbot Project,0,8,False,False,False,learnmachinelearning,1501348332,True,"So I am working on building a smarter chatbot. I am trying to figure out the best way to make it really work and I want to work with as much prepackaged work as I can. 

The way I want it to work is to use natural language processing to understand the topic and perspective that the other person is coming from in a specific query. 

From that I want it to have a handful of different data-sets that are trained using markov models to generate answers given set keywords. Ideally it would be a markov model that could be ""seeded"" with keywords identified from the query. 

Then I want a natural language classifier to pick the best of those answers that were generated by the markov models to actually send out as a response. 

All of that I want to be only a segment of the chatbot which learns in the more traditional chatbot way by just listening to the other side of the conversation. 

So in order to do that I would need a decider to choose when to generate new responses or when to use the old ones that are already known. 

Right now I am just trying to piece together exactly how I would make all of this work without having too many different training data-sets and different models running at the same time. I am also trying to think of ways to keep the chatbot from learning opposing perspectives while still learning new ways to talk about its own perspective. 

This is really just thinking publicly, let me know what you guys think.  Oh, and I am working in python. 
"
[X-post]: Nested features and hierarchical Bayesians,0,1,False,False,False,learnmachinelearning,1501353855,False, 
Deep NLP: RNNs and Word2Vec (audio) ML Guide Podcast,0,14,False,False,False,learnmachinelearning,1501357727,False, 
Beginner Neural Network Blog!,0,2,False,False,False,learnmachinelearning,1501362599,False, 
Why don't all Convolutional Neural Networks for Image Recognition use Inception?,4,7,False,False,False,learnmachinelearning,1501365781,True,"I'm a beginner to machine learning who has recently reviewed the submissions for the ImageNet Large Scale Visual Recognition Challenge (ILSVRC). Have seen the GoogLeNet and other Inception based submissions, I was left wondering why Inception modules are not more commonly used outside of this competition? Unlike ResNets, I rarely them used for any application other than this."
Are there any book recommendations for Machine Learning or Natural Language Processing?,6,14,False,False,False,learnmachinelearning,1501366212,True,"So I have a job I'm starting soon, and I spoke to the team, and they said these are relevant topics for the kind of work I may be doing. I want to use the free time I have now to familiarize myself with these concepts (I took an ultra-beginner ML course in school), so I was wondering if there were any book recommendations for these topics (preferably at a beginner level)?"
Question: What is the difference between convolutional neural networks and regular neural networks?,4,7,False,False,False,learnmachinelearning,1501375888,True, 
can someone explain intuitively what the output of an RNN/lstm layer is?,3,8,False,False,False,learnmachinelearning,1501375996,True,"Lets say you set the output to  512 features, what exactly are you getting back?
When I use pytorch I pass in mini batches of 128  strings.

so the output is 128 X512, but what does that 512 mean exactly?
From all the RNN examples I've seen , Idont usually see the RNN output passed into another layer, are there other ways to process the RNN layer?"
Learn about Variance - part I,0,11,False,False,False,learnmachinelearning,1501376989,False, 
Is it a good idea to try do a machine learning project to the same scope of the projects in Stanford CS229?,4,9,False,False,False,learnmachinelearning,1501388728,True,"I'm an undergrad in computer science and I'll have to a final year project for my last year. My idea is to build an application that will use machine learning techniques to try make predictions about something in the English Premier League(a soccer league in England) by using data from past years. 

The time I would have for this project is a year, I have done courses in discrete math, algorithms, introduction to AI, and data mining already."
"Solutions to ""Learning From Data""",1,4,False,False,False,learnmachinelearning,1501404482,True,"Hi all,

I'm currently taking [this course](http://work.caltech.edu/telecourse.html) taught by Yaser S. Abu-Mostafa however I'm having trouble with the homework questions. The only solutions I can find online are for the edX variant of the course (which has different homework from looking at the answers) and the provided solutions only show the correct answer, no working out.

Doe anyone have a link to some solutions?

Thanks,"
Why/how do support vector machines optimize for the largest margin?,0,5,False,False,False,learnmachinelearning,1501434544,True,"I'm working through Andrew Ng's machine learning class on Coursera. In his lectures on SVMs, he introduces the cost function as a kind of simplification of the one used in logistic regression:

http://imgur.com/a/wChLd

Later on, he explains that by ""requiring"" `z>1`(for `y=1`) or `z<1` (for `y=0`), rather than `z>0`/`z<0` for normal logistic regression, SVMs optimize for a more extreme or more confident classifier. Or at least, that's what I got out of it.

But that doesn't make much sense to me: looking at the cost function graphs, it seems like the SVM gives no incentive to be confident beyond a certain point -- where the graph flattens out -- while ordinary logistic regression will always reward greater confidence in the right answer, even if only a little. Can somebody help me understand what I'm missing here?"
Q Learning - Decreased performance over longer time periods.,0,2,False,False,False,learnmachinelearning,1501438971,True,I'm training a neural net to play the Acrobot game on OpenAI gym. I'm toying with new learning rates and I'm seeing fairly good performance at about 3000 episodes but after that the learning rate starts to slowly drop off and it starts to perform worse. Does that mean my hyperparameters are incorrect or is that expected if the algorithm is trained for too long? I thought that the algorithm should plateau but not decrease. 
Training an neural net with a gradient rather than distinct categories?,0,1,False,False,False,learnmachinelearning,1501441162,True,"I'm trying to teach a CNN something fairly complicated. I was thinking that if I included some ""almost, but not quite"" data points, it might help it see what it was supposed to be looking for.

If I train it with, 0, .8, and 1, will it understand that it's a gradient, or will it see it as 3 different categories?

If I go this route, will I need a bigger dataset than I would if it were just binary?

Thanks."
Cutting Edge Deep Learning for Coders—Launching Deep Learning Part 2,1,30,False,False,False,learnmachinelearning,1501444412,False, 
"I have multiple CNN's, are there any good papers out there that describe efficiently merging their outputs? [more inside]",3,2,False,False,False,learnmachinelearning,1501468230,True,"I have 4 images that basically describe an object, and so I've decided to apply a few CNN layers to each image input. However, once I do this, I get 4 outputs. Ideally, I could use another layer to merge these outputs, and continue processing using a couple more CNN layers and then finally an affine layer to reshape into the appropriate output.

The merge step is what is unknown to me. Does anyone know of a paper describing this? Normally, I would just concatenate the outputs into one big square, but that feels very naive to me, and for the most part my naive solutions are everyone elses stupid as hell solns! 

Thanks!

edit: also, some key words to search for would be just as appreciated, afaik this process is a 'merge' but maybe there's a fancier term for it in literature?"
Suitable algorithm for production scheduling,0,1,False,False,False,learnmachinelearning,1501508597,True,"TL;DR: a basic genetic algorithm is probably not a good solution for production scheduling, what else is then? What kind of algorithm do the commercial solutions use?

 

I need an algorithm, that is able to take into consideration multiple requirements (described lower).
The output is an array of machines, each machine has operations, that will be performed, attached to it. This together makes a timeline:

Machine one: Operation A (start 0, end 20) Operation B (start 20, end 40)

Machine two: Operation B (start 5, end 20)

...

There's a basic product path like this:

to make 20Kg of A, you need 50Kg of B, to make 10Kg of B you need 100kg of C... 

For basic operation, we have defined on which machine is it performed, how much product does it make for a period of time, cost and resources. 

The time period is not fixed - we can scale it up or down (but we have to scale resources as well)

Since this is still pretty simple, this algorithm should work just about right: 
https://frepple.com/docs/2.2/technical-guide/planning-engine/planning-algorithm.html

But there's more, of course. 
Mainly, there's a thing called ""cleanings"". That means, that there are rules like ""if you were making product B and you want to make product C now, there has to be cleaning taking 7 hours performed"". 

We want to avoid these cleanings as much as we can. 

Then we have ""mixing"" operations: if we are mixing something, the time is constant (eg 30 minutes) and only the amount produced (and resources consumed) can vary (min, max). 

Other key points:

- we have multiple orders with multiple products ordered. Each order has a deadline

- everything is in minutes, we plan for about a month (yeah, approx 43 800 minutes)

- we have about 30 machines (yeah, 30 * 43 800 - now calculate the possible combinations...)

- products have shelf lifes

- we want to move operations as close to deadlines as possible (VERY IMMPORTANT)

- workers

	- how many workers do we need for a machine to operate (minimum, maximum, optimum - if it's not 
optimal, penalty is applied)

	- workers have multiple ""classes"" (baker, packer...)

	- for each worker, we have timespan of availability (eg. from 10, to 60)

- we can set fixed operations (so we only generate plans with them ""fixed"" to the particular time and machine)
- the operations should be grouped together, because if we stop the machine for a few minutes and then continue again, it's not very effective

There are probably other things that I forgot, but this should give you an idea about how complicated this is. 

 

Initially, I've tried this: https://developers.google.com/optimization/. This, however, isn't able to handle cleanings, so no chance here.

Currently I use a basic genetic algorithm. I generate a 1000 plans, then a basic mutation and selection of operations is performed. Fitness is calculated with money -
cheaper means better. There's a cost for everything - production, cleanings, order penalties... 

Anyway, this approach doesn't seem to be good enough. With a few generations (like one or so), the result is just way too random. Calculating more 
generations is nearly impossible (VERY time consuming) probably because of the number of possibilities. 

 

There has to be a better approach than this. What kind of algorithm do the commercial solutions use?"
Brain-like computing comes closer with neuromorphic nanomaterials for A.I. retina,7,6,False,False,False,learnmachinelearning,1501513830,False, 
Is my derivation for gradient descent in linear regression correct?,2,1,False,False,False,learnmachinelearning,1501513943,True,"I wrote this derivation for gradient descent in linear regression. Is this correct or not?

		###Linear Regression with Gradient Descent###
		x,y =some data

		a=initial_random_value
		b=initial_random_value

		#Output prediction#
		out = ax+b

		#Error J
		J = 1/2*(y-out)^2
		J = 1/2*(y-(ax+b))^2

		##Partial derivative calculation##

		f = y-out
		f = y-(ax+b)

		J=1/2*(f)^2

		#Finding partial derivative first step
		dJ/df = 2*1/2(f)^(2-1)
		dJ/df = f

		#Finding partial derivate second step
                f = y-(ax+b)
                f =  y-ax-b 
		#for a
		df/da = y-ax-b  #y,x and b are constant
		df/da = 0-x-0
		df/da = -x

		#for b
		df/db = y-ax-b  #y,x and a are constant
		df/db = 0-0-1
		df/db = -1

		#Parial derivate of J with respect to a
		dJ/da = dJ/df*df/da
		dJ/da = f*(-x)
		dJ/da = (y-out)*(-x)

		#Parial derivate of J with respect to b
		dJ/db = dJ/df*df/db
		dJ/db = f*(-1)
		dJ/db = (y-out)*(-1)

		##Updating parameters a and b ##
		a = a - dJ/da
		a = a - (y-out)*(-x)

		b = b - dJ/db
		b = b - (y-out)*(-1)"
Continuous numerical problem - What technique to use?,7,6,False,False,False,learnmachinelearning,1501514896,True,"I'm facing a problem i will describe to the best of my abilities here:

A group worker has to complete some manual tasks, serially (not as a team). The main purpose of the model is to predict the time it takes for each worker to to complete the tasks. I have a large labeled training set.

An example task could be to A four times,  then do B three times. The total amount of time it would take to complete the task is a non-linear problem, as it takes more time to do A four times, than four times the time it takes to do A once. Further some workers may have different techniques to completing the tasks, which the model would have to account for.

So, I'm left with a continuous numerical estimation, which I would usually do by building a regression model, but since I have a hard time specifying a model that makes sense intuitively, im trying to explore the world of supervised ML. Im aware of some of the techniques commonly used, but would love a little guidance.

how would you approach this problem?
what techniques would most likely succeed at this?

thanks alot"
Having trouble with conceptualizing implementation of non-time series data and time series data into an RNN,0,1,False,False,False,learnmachinelearning,1501515627,True,"I am having some trouble wrapping my head around how to attack this deep learning question. I have a data set of users, tracked over time who have made grocery store purchases on various days, and have not entered the store on most days. The data is stored as a daily time series. The data set also has information about the users themselves, including height, sex, and age, which is assumed to be constant for the purposes of this exercise. I want to predict, based on all of this information, the probability of them entering the store tomorrow.

I know that using an RNN, most likely with an LSTM is the best way to predict that probability given the TS data of when users enter the store and when they don't. However, I'm not sure how to implement both the purchases made on each day, and the user data.

If you have any suggestions, or even can point me to a similar sounding example so I can understand this better, that would be great!"
Noob Question: why tf.math?,3,2,False,False,False,learnmachinelearning,1501524370,True,What is the difference between using tensorflow's math functions (like tf.add or tf.subtract) and using regular operators? Is it faster? does it help with visualization in tensorboard? I've been searching online and only found one answer on stackoverflow saying there is no difference. If that's the case then why did tensorflow include it at all?
Probability mapping in Image to Image translation?,0,1,False,False,False,learnmachinelearning,1501525716,True,This is might be a stupid question but in traditional GAN's we sample from a known distribution like Gaussian Distribution and model a network to approximate it to a distribution we want. Then we had cGAN's where we augment a condition with Z(latent vector sampled from Gaussian) and based on the condition we approximate the distribution. Recent papers like image to image translation are dropping the latent vector and only using the condition as the input. So what are we mapping in this case? 
Can a DNN learn integer addition?,1,1,False,False,False,learnmachinelearning,1501526388,True,"I'm just starting out in ml/dl and was trying to think of a set of problems I could use to practice. I started wondering if it would be possible to train a model to perform integer addition (even if the magnitude of the addends are fixed, e.g. each addend is between 1000 and 2000).

I'd have to choose a workable representation for the input into the model (not sure what that would be though) and I'd want the output to be the result of adding together the two input integers.

Is this something a DNN can learn? TIA"
Issues with environment when reproducing research code,4,1,False,False,False,learnmachinelearning,1501526643,True,"I've been trying to reproduce the code found here: https://github.com/openai/improved-gan, with respect to the ""Improved GANs"" by OpenAI, but I'm having a lot of trouble setting the environment (a docker container)... I just can't make Theano work properly with this code. I created a Docker container to test it, but a segmentation fault is raised when I use the stable version of Theano installed using conda... Some posts suggest to use the development version of Theano instead, but when I update it, Theano can't find the Cudnn anymore (gpuarray/dnn.py"", line 98, in _dnn_lib raise RuntimeError('Could not load cudnn library') RuntimeError: Could not load cudnn library) . If someone have some background with Theano/lasagne/docker could help me I would appreciate it a lot. If requested I could paste my dockerfile, or anything that could help."
Creating a 6-week ML Internship,3,14,False,False,False,learnmachinelearning,1501541561,True,"TL;DR: I've got a software engineering intern for 6 weeks and I want to use his limited experience (and my limited experience) to create a program where we both benefit. How can I best prepare for this kid to not waste our time?

Hi there, 

I'm currently a Data Analyst at a startup and I've got a college Senior looking to do ML at my company. He's only got 6 weeks with us and I want to give him an ML project that could at least validate whether we continue investing in ML after he is gone. 

My experience: I know the basics. I've completed the Coursera's ML course and I'm brushing up on my stats and python before getting more in depth with algorithms.

His experience: Python + stats. No ML.

I'm worried that it'll be the blind leading the blind, but I figure it could be good experience in directing an ML project and at least teach him about some of the basics to start his portfolio. I'm hoping I could point him in the right direction and he can at least get something started:

1. Crash course into ML 
 - Review logistic regression and recommender systems.
 - Get comfortable with scikit + other libraries.
2. Review feature set and algorithms to test
 - Start drafting the necessary feature set to look at 
 - Review the algorithms we'd like to test and get started asap
3. Building up the algorithms 
 - Leave time for the actual engineering and proper testing in between.
4. Analyze and tweak algorithms
 - Review the results of the algorithm and where they'll fit. 
5. Leave time for more analysis OR work on k-means implementation of the algorithm.  

Is this a good plan? How can I improve it?"
How Neural Networks Work for Beginners,4,23,False,False,False,learnmachinelearning,1501560557,False, 
Well Written Sample Tensorflow Neural Net Using External Data?,2,2,False,False,False,learnmachinelearning,1501560923,True,"I'm new to Tensorflow, and after going through the tutorials with the MNIST data, I've moved on to using real data. While I can import and process the data correctly, I've been failing in various creative ways to correctly replace the built in MNIST datas et with processed numpy arrays. Does anyone know of any good, well documented, modular Tensorflow sample code that's built off external data that I could take a look at? Every tutorial/sample code set I've found in Tensorflow uses the built in MNIST data set."
"[tensorflow] easy question: In order to turn off gradient descent, does one only need to remove the optimizer's train step from the list of variables in sess.run",0,2,False,False,False,learnmachinelearning,1501562270,True,"I honestly couldn't find the answer to this question in their documentation, nor was I able to come up with a search query to get an answer as well. I'm wondering, because I'm getting an strangely high accuracy for my test and validation sets"
[TF] Same 2x2 local connections across larger 2D matrix,1,1,False,False,False,learnmachinelearning,1501564896,True,[deleted]
[CS224N] Having trouble figuring out the dimensionality of the W matrix,0,1,False,False,False,learnmachinelearning,1501569371,True,"In this particular video https://youtu.be/uc2_iwVqrRI?t=28m3s , Richard mentions that we train both the weights and word vectors in the context of the center word for a particular classification task (in this case it is named entity recognition). 

With word vector dimensionality of d, and window size of 5, the input vector to cost function is R^5d, so the w vector should also be R^5d for the dot product W.x to work fine. 

However, at a later point in the video, precisely at https://youtu.be/uc2_iwVqrRI?t=32m40s, the total size is said to be R^(Vd + Cd) shouldn't it be R^(Vd + 5Cd) ?"
Detecting fraudulent registration,0,2,False,False,False,learnmachinelearning,1501572950,True,"Recently the company's website was flooded with malicious registration, where a few people signed up for hundreds of accounts to win an online lottery. Our investigation shows the source may be a group of employed workers (like a click farm), in addition to some sophisticated software (or still, paid humans) that can circumvent the CAPTCHA. We now need to recognize such accounts and disable them, and establish a mechanism to prevent similar incidents in the future. We hope machine learning may come to our rescue.

Please advise on feature selection and suggested model. Our record of accounts include all common fields, like username, contact method, etc., but with notable absence of source IP / device identifier.

If you are unclear whether a specific field is available, please comment below. If you think ML won't be effective on this, please kindly propose your recommendation."
Car steering mechanism explained in 60 sec (Rack and pinion steering mechanism),0,0,False,False,False,learnmachinelearning,1501573817,False, 
keras LSTM for sequences of mixed length,1,3,False,False,False,learnmachinelearning,1501577132,True,"SO, I'm trying to build an LSTM with keras where my input consists of multiple sequences of different lengths. Each sequence corresponds a customer and includes information about his purchases per month ever since he became a customer. The goal is to predict his behavior during the next month. I'm facing the following problems: 

* How do I need to format my input?  For the time being it is loaded as a 2D numpy array with columns [email, months_purchases, next_months_purchases]. The 3rd column is the one I want my network to predict. So, I was wondering how will the network be trained without mixing points from different sequences? Is this the correct way to feed the input?

* How to deal with uneven sequences? I thought about setting batch_size = 1 but I'm not sure if this is correct. 

Example code:

    # input size: (3496,3)
    input_data = pd.read_csv(...)
    train_size = int(len(input_data) * 0.75)
    test_size = len(input_data) - train_size
    train, test = input_data.values[0:train_size,:], input_data.values[train_size:len(input_data),:]
    print(len(train), len(test))
    X_train = train[:, 0:2]
    Y_train = train[:, 2]
    X_test = test[:, 0:2]
    Y_test = test[:, 2]

    X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))
    X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))  
    model_rnn = Sequential()
    model_rnn.add(LSTM(20, return_sequences=False, input_shape=(None, 20)))
    model_rnn.add(Dropout(0.2))
    model_rnn.add(Dense(1)) 
    model_rnn.add(Activation(""sigmoid""))   
    model_rnn.compile(loss='binary_crossentropy', optimizer=""Adagrad"")
    model_rnn.fit(X_train, Y_train, batch_size=1, epochs=100, shuffle=1)"
Recommended CS courses?,0,8,False,False,False,learnmachinelearning,1501590400,True,"Currently studying ML for my master's and specifically specializing in Deep Learning for medical applications as my background is a BSc in Biomedical Engineering. Because of this, I have very limited actual CS knowledge apart from basic programming (Matlab, Python, Java, and 'Data Structures and Algorhitms') and math (linear algebra, probability theory and statistics theory, univariate and multivariate analysis, and analytical and numerical methods for differential equations).

Which courses or domains are recommended for somebody like me to learn? Parallell programming in CUDA? Distributed systems?"
Machine Learning Translation and the Google Translate Algorithm,1,29,False,False,False,learnmachinelearning,1501592159,False, 
Looking for a steady diet of ML? Check out This Week in Machine Learning & AI! Great for all expertise levels!,0,1,False,False,False,learnmachinelearning,1501602360,False,[deleted]
Looking for a steady diet of ML? Check out This Week in Machine Learning & AI! Great for all expertise levels!,0,1,False,False,False,learnmachinelearning,1501603302,False, 
Interview tmw with Construction supply distributor. Any ideas on ML projects to propose?,0,0,False,False,False,learnmachinelearning,1501604202,True,I have an interview tmw with a company that is a distributor of construction supplies.  ML is not one of the job requirements but I'd like to suggest some ways it might be used in their business.  Any ideas would be appreciated!
Hyperparameter Optimization - The Math of Intelligence #7,2,5,False,False,False,learnmachinelearning,1501617988,False, 
"20 questions game, question, and answer using Wikipedia, new to NLP.",0,1,False,False,False,learnmachinelearning,1501625940,True,[deleted]
TWIL (This Week I Learned) - Share something new that you have learned this week!,3,5,False,False,False,learnmachinelearning,1501657514,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
Building an LSTM to predict prices but predictions are coming out in a straight line,13,10,False,False,False,learnmachinelearning,1501663528,True,"I'm in the process of building an LSTM to predict prices based on a few data sets. In the process, I converted Python 2 to 3 (mainly by converting xrange to range) but the predictions are coming out in a straight line. Any assistance or idea why? Code can be found here: 

[link](https://github.com/Jsauc/effective-sp/blob/master/Model%2B1%2BSnippet.ipynb)

Appreciate the help!"
How to approach recognizing a single individuals handwriting?,5,12,False,False,False,learnmachinelearning,1501667281,True,"So, I have a lot of documents in form of images that contain handwriting by a single person. As it is a historic font which isn't used anymore, classic OCR is out of question. Also he has a very messy style of writing, but once you get used to reading it it is all intelligible. 
 
I'd like to use machine learning to automatically transcribe documents he wrote based on an example data set which I would transcribe manually. After having google around a bit, most results I found were all about having machine learning for recognizing or generating modern handwriting in general, no matter your individual style. In my opinion this is a much harder problem with very different challenges than what I want to have. 
 
I guess the first step would be to create my own dataset? Are there any tutorials on how to do this? Or is there a better approach?"
Can a simple Neural net capture two time series data correlation without explicit feature extraction?,1,4,False,False,False,learnmachinelearning,1501680516,True,"I expect some pattern only when correlation between the two series rise. But the correlation only occasionally rises beyond a certain threshold and the correlation period changes too. 

Can a simple ANN capture this ?

Thanks."
Examples for LinReg and LogReg,7,8,False,False,False,learnmachinelearning,1501706406,True,"Hello friends, I would like to ask a somewhat simple question yet I have no idea where to or how to search - examples for Linear Regression and Logistoc regression. I have just completes week 3 of Andrew Ng's course and even though the programming assignments are good for practice and can be well studied, I wonder if there are any specialized data sets with known regressions so that one could practice some more, in a manner of school/college education. Thank you very much in advance, I hope you all have a great HumanLearning MachineLearning day"
Mini Batch Gradient Descent and Local Minima,0,1,False,False,False,learnmachinelearning,1501709427,True,[deleted]
Trying to implement a seq2seq Model but not with words.,0,1,False,False,False,learnmachinelearning,1501716650,True,"My input and output sequences are 4d feature vectors. All the seq2seq tutorials around focus on natural language and assume I have a bunch of words, so I have to do some kind of embedding, or one-hot encode all the words etc.

What should I do to get the most out of, for example, a Bidirectional LSTM? Should I just feed my sequence of feature vectors and define the loss function over the sequence of expected output feature vectors? What type of loss function should I use? Or better yet, is there a resource for this type of seq2seq models that you can point me to? Thanks."
Trying to implement a seq2seq Model but not with words.,0,4,False,False,False,learnmachinelearning,1501716665,True,"My input and output sequences are 4d feature vectors. All the seq2seq tutorials around focus on natural language and assume I have a bunch of words, so I have to do some kind of embedding, or one-hot encode all the words etc.

What should I do to get the most out of, for example, a Bidirectional LSTM? Should I just feed my sequence of feature vectors and define the loss function over the sequence of expected output feature vectors? What type of loss function should I use? Or better yet, is there a resource for this type of seq2seq models that you can point me to? Thanks."
"What's the difference between Deep Neural Network, MLP and ANN?",8,3,False,False,False,learnmachinelearning,1501775191,True, 
Train your deep model faster and sharper — two novel techniques,0,34,False,False,False,learnmachinelearning,1501777079,False, 
Can data predict fashion trends?,0,1,False,False,False,learnmachinelearning,1501797201,False,[deleted]
I would like to learn more on deep learning but...which language should I start with? Python? Java? Something else?,16,6,False,False,False,learnmachinelearning,1501801092,True, 
Is the learning rate supposed to get exponentially smaller the more variables in the hypothesis?,6,3,False,False,False,learnmachinelearning,1501828580,True,"My hypothesis looks like this: θ0 + θ1*x

Using gradient descent, I wrote a linear regression program that would give me the values of θ0 and θ1 and it works pretty well in finding the equation of the best fit line. My learning rate for this is around 0.0001

BUT, when I introduce θ2 and want to make my hypothesis θ0 + θ1*x + θ2*x^2, I need to adjust my learning rate or else stuff starts diverging. I had to change my learning rate to .000000008, but now training is so slow. Is this how training for linear regression supposed to be? I can't imagine having even more variables such as θ7, θ8 or even θ10 since there seems to be an exponential correlation.

For anyone curious, my cost function is (1/2m) * summation(m, i=1)*(h(x^(i) ) - y^(i) )^2 and I'm using 100 data points of training data"
Weekly Show-off!,0,1,False,False,False,learnmachinelearning,1501830328,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
HELP with Turing test for poetry ...,2,1,False,False,False,learnmachinelearning,1501848494,True,"I'm currently taking a course in Text Mining, but struggling with the program I'm writing for my exam. 
I do not have any previous experience with coding, but basically I am trying to figure out a way to create a Turing test that classifies a poem as either made by a human or by a computer. 
I already have my dataset...I think. But I am having some issues in figuring out how to train the classifier to focus on stylistic differences and similarities in the poems...
Or if anyone could just look at my code and tell me if I'm in deep waters. I really have no idea what I am doing, haha..

a stressed out student

https://github.com/Flirona/codeissues/blob/master/Code"
Training own image set - best approach,4,4,False,False,False,learnmachinelearning,1501850970,True,"I'm a beginner in ML, almost done with Andrew Ng's ML course, and eager to start working on my own little project.

What I'd like to to do is the following:

1. Building my training set: Take pictures of cases filled with dvd's with the spines of the dvd's facing me. I then need to break down that image into the individual images of the dvd spines. (OpenCV?)

2. The individual spines will then have to be coupled with their EAN (this will be a one time manual process for each dvd)

3. When I take picture of a new supply of dvd's, my goal is to
 have my algorithm identify the dvd's just by analyzing that image (consisting of dvd spines) and compare it to my training set.

I've looked at Tensorflow for the image classification, but I would really appreciate if anyone can give me some pointers on how to approach this. I'm not tied to Tensorflow, so If there is a better option than Tensorflow I can go with that."
Machine Learning -Hands On Python and R In Data Science,16,14,False,False,False,learnmachinelearning,1501863444,False, 
Skewed results for probabilistic forecasting on testing set.,0,2,False,False,False,learnmachinelearning,1501865125,True,"Hi, I am using an autoregressive recurrent network to create probabilistic forecasts. I predict 99 quantiles, and randomly sample from the resulting distribution, and then feed that forward to the next time step to generate a single trajectory. I repeat the  process 1000 times and create the probabilistic forecast from the sampled values for each time step. I divide my data set into the first 70% for training and the next 20% for validation, and last 10% for testing. 
My model performs well during the validation set up 
http://imgur.com/a/Pui9w (first image). Ideally all the bins should perfectly align with the red lines. The first and last bin size is 0.01, second and second last is 0.09 and the rest are all .1. Thisindicates how many values fall into each bin. If you see in the second image the test results are extremely skewed. 
I tried my method on two different data sets and they always perform extremely well on the validation set but the testing set has extremely poor results."
Trouble setting up a neural network with L2 regularization,1,2,False,False,False,learnmachinelearning,1501874799,True,"Hey guys! I'm fairly new to Tensorflow and machine learning and am looking for help with my python program.

I'm trying to make a neural network with one hidden layer and compare its accuracy before and after L2 reg. I'm feeding pseudo-random data into the network. The network seems to be converging slowly both with and without l2 reg. Additionally, the loss change to nan if I add a second hidden layer.

Here is my code https://github.com/BreeCat10/L2Regularizatiom/blob/master/L2Testing.py
Any idea whats happening? Thanks so much for any advice!"
Good Place to Learning Machine Learning Online,7,10,False,False,False,learnmachinelearning,1501876012,True,"I am looking to get a online degree in machine learning ?

Please advice if you know a good resource.

Thank you"
What type of NN should I be using?,10,1,False,False,False,learnmachinelearning,1501884420,True,"I am working on a bioinformatics project, involving sequence data and fitness scores. My labelled data consists of a bunch of short DNA sequences (ACCGTA... 152 letters long) and a fitness score associated with each sequence. I want to build a model that can predict the fitness score of new sequences I generate.

From some of the reading I've done it seems like I can just use a simple feed-forward network, but is there another model that would work better? 

Also, I am quite new to ML so any more ressources for beginners, espescially specific to bioinformatics, would be really appreciated.

"
"Weekly Status Check Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",1,1,False,False,False,learnmachinelearning,1501916710,True,"Let's have a  meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
How to combine CNN + RNN?,6,13,False,False,False,learnmachinelearning,1501954611,True,"I have made a convNet that plays a game called Speedrunners:
https://www.youtube.com/watch?v=-lVN5e9DS5w

It used AlexNet in the video (now inceptionV3). It takes a screenshot of the game every few milliseconds and decide. As you can see, it is pretty mediocre. My plan is to combine CNN with RNN to detect character speed for better decisions. What are the steps to combine CNN with RNN? I use TFLearn. Pseudo Code and helpful ressources would help me a lot. Do I need to pass the last 3 softmax outputs of the CNN to RNN? (To take the last 3 frames into account)
"
Learning to Read Handwritten Digits,0,1,False,False,False,learnmachinelearning,1501957798,False,[deleted]
Learn to Read Handwritten Digits!,0,8,False,False,False,learnmachinelearning,1501958469,False, 
Traffic Machine Learning Algorithm Advice,5,6,False,False,False,learnmachinelearning,1501967081,True,"I am wanting to create a Machine Learning Algorithm to decide what route would be the most efficient to get to school every morning. The variables that I would be watching, or features, are how long the roads are, frequency of stop lights and stop signs, traffic, and the total amount of times it would take to get to school on that route.

Is this problem better suited a traditional if-then program, or should I use a Machine Learning Algorithm to accomplish this?

I tried doing a quick search for a traffic dataset online that I might train my algorithm with, but found nothing. 

If you have any resources, or advice, let me know!"
Learn about variance - Part II,0,11,False,False,False,learnmachinelearning,1501967520,False, 
Best image annotation tool with polygons and multiple classes,3,2,False,False,False,learnmachinelearning,1501987203,True,"It seems like most annotation libraries are half-done or half-broken. I'm looking for one that let's you annotate images with polygons. [There are lots of alternatives](https://tensortalk.com/?cat=annotation), I usually use sloth but it's a pain to set up. What do you use?"
How do I use this trained model for prediction?,1,4,False,False,False,learnmachinelearning,1502028661,True,"I'm currently reading the e-book ""Machine Learning Cookbook from packtpub, which is a great book imo.
I'm now in the section ""Implementing RNN for Spam Prediction"".   

The code works perfectly but the book doesn't explain how to actually use the model to predict from new data after training the model. The code can be found here:

https://github.com/nfmcclure/tensorflow_cookbook/blob/master/09_Recurrent_Neural_Networks/02_Implementing_RNN_for_Spam_Prediction/02_implementing_rnn.py

How do I rewrite it so I can use the trained model for prediction? Thank you"
"Noob question: if I have many different time series for both inputs and outputs of a system, can I train a bot/program to recreate the network of neurons that produces the output",0,1,False,False,False,learnmachinelearning,1502028852,True,"And then test my simulated system with a new and random/artificial input time series that that will mimic the real life system (group of neurons in the brain)? 

How do I determine the chances that the artificial input will produce an output that's representative of the physical system?

 I realize that this is may be the very heart of predictive analysis and machine learning. But I 
feel compelled to ask haha

I feel like step 1 is training an ANN with the input/output neural data, and then step 2 is testing the ANN with my own inputs. Am I on the right track?

Please excuse my ignorance!! c:"
What ML model would be best for lottery prediction?,0,2,False,False,False,learnmachinelearning,1502033943,True,[deleted]
NOOB question: Is machine learning appropriate for my project?,7,2,False,False,False,learnmachinelearning,1502060825,True,"I want to build a program that will estimate the difference between when something will start and end. But i'm unsure if I have enough data to accurately predict the difference between the start and end times. As of now I have roughly 20,000 data sets with 15ish data points per set. If machine learning is appropriate for the amount of data what algorithm should I use for my project."
Can OpenAI Gym's BipedalWalker-v2 be solved with Deep Deterministic Policy Gradients (DDPG)?,1,5,False,False,False,learnmachinelearning,1502062923,True,[deleted]
Question about solving linear regression with gradient descent,7,2,False,False,False,learnmachinelearning,1502075221,True,"Hi all. I am currently working on a program that solve linear regression problems using gradient descent. I tried to test the program by putting in y = x as the input and observe the solution. The program finished and it outputted the y intercept as 5.506706202142354E-14 and the slope as 0.9999999999999725.

Here is where my question is. At what point can you confidently say that the slope is 1 or the y-intercept is zero (in the above scenario)? I know that gradient descent slows down as you get closer to the local optimum but what is the cut off point to say that the solution is a whole number rather than a decimal number that is just really close to being a whole number? I really hope that makes sense lol. If it wasn't clear enough, I will be happy to clarify. Here is my code: https://github.com/steven9909/example-linearregression "
Which is the best (cheap) Cloud GPU server?,4,7,False,False,False,learnmachinelearning,1502096731,True,"Hi,

I'm new to machine learning and deep learning, and I was looking to set up a server for machine learning. 

Which is the best cloud based GPU server available right now? I already looked at AWS p2 and google's GPU servers, they all seem to be pretty costly. Currently, I'm only using my p2 instance for like 2-3 hours a day, but I'm afraid if I use it 24x7 i will go bankrupt in few months. That's why I'm looking for some cheap solutions for both small scale usages and 24x7 usage.

As a beginner I might not need a very powerful GPU server, but something powerful enough to do some sort of image classification (with around 100k training data) is what I'm looking at. "
[neural nets]can you split up large data and run many epochs on just a fraction of the data?,9,4,False,False,False,learnmachinelearning,1502123502,True,"for example, lets say i have files that are 1 GB and i can only train my model on 5 at a time. Should i do one full epoch of one training cycle on 5 items at a time, or can i load 5, run 50 training cycles, and then load another 5 etc.

the latter approach is much faster, but does it break any assumptions underlying the optimization of gradient descent"
Hyperdash | Monitoring for Machine Learning,0,1,False,False,False,learnmachinelearning,1502127039,False, 
Quick Question: I'm confused about train/test split and LSTM model predictions...,1,3,False,False,False,learnmachinelearning,1502138862,True,"(be warned, I'm pretty new at machine learning!)

Quick question about performing predictions on a LSTM model: 

When I perform a train test split for a time series data (let's say in this instance, from 2012 to 2017), I split the data for training between 2012 to end of 2015, and then do a test split from the beginning of 2016 to 2017. 

So when I perform a predictions on my model, it's going to start predicting points to the 2016-2017 range, correct?

So let's say now I do want to make future predictions for data I don't have yet (present, onward), do I stop performing a train test split, and train my model with the entire series of data? 

And if that's true, can anyone provide some example code with the (keras) .predict function for future data? All the examples I found performed a train/test split for a time series, but never predicted future data points that weren't available. 

Feel free to link any resources that might clear this up. 

"
Can someone explain the policy gradient output layers for continuous & discrete action spaces?,0,3,False,False,False,learnmachinelearning,1502145427,True,"I'm building my first policy gradient learner.  There are lots of examples of parameterizing a policy for a discrete action space (usually using a softmax on the output layer).  It's not so clear to me what to do for a continuous action space (say for example if we are parameterizing the mean of a Gaussain distrubtion).  

Can anyone help me gain some intuition on what is going on for both cases?"
What do you do with the results of SVD?,1,5,False,False,False,learnmachinelearning,1502154397,True,"I recently have learned about Singular Value Decomposition as a method for dimensionality reduction, but I notice I'm a little confused. Once you've decomposed your matrix into U\*S\*V (U and V unitary, S diagonal), after you've decided on some top N entries in S to keep and replaced the rest with zeroes, what do you actually do with your matrices? 

Do you just multiply them back together and call it good? Or do you then need to do something else with the resultant matrix (e.g. remove all the zeros that will be at the bottom) "
Choosing the right technology for image processing and (later) detection,2,7,False,False,False,learnmachinelearning,1502160452,True,"Hi all,

I'm working on a personal project where I have a number of wildlife cameras that shoot an average of 3000 images per week. 75-80% of them are duplicates that due to the wind blowing foliage and other factors, the cameras sensors are tripped, and an errant picture is taken. I have no interest in messing with sensors in these cameras (I want everything to be as stock as possible), and I'd rather just process all of the photos to remove duplicates (or better yet, determine outliers).

See a sample of duplicates (taken one minute between each other):
http://imgur.com/a/956PC

Anyways, I'm looking for the right framework to not only remove duplicates or determine outliers. Once I have that working, I'd like to feed training data to one of the ML/DeepLearning frameworks to do better image recognition for certain wildlife (feral hogs).

The problem I have is that I haven't read too much on the subject, so I don't want to go down the wrong rabbit hole. After two days of looking around, I'm looking at the following topics (and some examples that name opencv as a starting point):

* euclidean distance
* cross correlation
* convolutional neural networks
* too much Nvidia marketing material

If anyone has any pointers on the best place to start, that would be appreciated. I can handle pipelining all of the images, training data, etc into a ML-type framework, but I'd just like to choose a core/framework that would support most of this.

I'd prefer something Python centric, but I'd be open to other ideas too. I probably will use GCE to handle the processing once I figure it out locally on my machine.

 "
One-class classification in Keras using Autoencoders?,2,1,False,False,False,learnmachinelearning,1502160721,True,"I am trying to develop a model for one-class classification. For example, the model should to identify if a given picture contains a cat or not. Keep in mind that my training dataset only contains pictures of cats and nothing else. Sort of like a anomaly detection problem

I have seen some suggestions on using autoencoders for unary classification but I couldn't find a concrete example on the net? Can someone nudge me in the right direction? An example using Keras will be tremendously useful! Thanks in advance."
University Machine Learning Degrees and Courses in Canada,1,7,False,False,False,learnmachinelearning,1502171510,True,"University for Machine Learning Degrees and Courses in Canada, Recommendations Please.

Thank you"
blue1,0,1,False,False,False,learnmachinelearning,1502173486,False,[deleted]
Neural Network with Input Depending on Variable,5,1,False,False,False,learnmachinelearning,1502179027,True,"Let's say we have a fully connected network with 1 hidden layer. Let's call the input to the network **X**. Suppose now that there is a variable **Z** on which the input depends, i.e. **X = f(Z,D)** where **D** is the training data available. 

In other words, the input of the network depends both on the training data and on a variable. Now, when writing the loss function in terms of **X**, clearly the optimization will also depend on the value of **Z**, therefore the network will learn that variable too. 

Does this make sense? Is this kind of model still a Neural Network in the general sense?

EDIT: **Z** is indeed a trainable variable for the model. The network runs (in tensorflow) and the variable is actually being learnt, my question is more on the architecture level/mathematical details of such a model."
Introduction to Imitation Learning,2,18,False,False,False,learnmachinelearning,1502198514,False, 
Limitations of running models on gpu,0,1,False,False,False,learnmachinelearning,1502198851,True,I'm planning to buy a PC with a gpu for machine learning. I am wondering what are the limitations of using the GPU? Obviously it's faster but I want to know can I use all types of models? Can both R and Python utilize the GPU? Does the processor matter as much?
Announcing new Deep Learning courses on Coursera,14,73,False,False,False,learnmachinelearning,1502206215,False, 
Can someone explain to me how the chainrule and backprop come together in a Neural network?,0,1,False,False,False,learnmachinelearning,1502215253,True,"My calculus is a bit weak: 
I understand that finding the derivative of a function gives you the rate of change of the function, this however gets confusing for me when there are multiple variables involved. 

I get the chain rule on a semantic level: g('f(x))* f'(x) = (g(f(x)))'

But I'm still confused on backprop, suppose my format is the following for a really simple network: 

output = Activation(input * weights)

error = Loss(output, expected)

How do I figure out what to multiply the weights by? 

weight = weight* weight_adjustment

Is weight_adjustment = Loss'(output- expected)*Activation'(input*weights) ?

How do I do it 'with respect to the weights'.
I would really appreciate it if someone could explain or perhaps guide me towards a helpful resource that would help me wrap my head around it. "
Can Tensorflow detect Doge or something like that. This video is just testing googles machine learning library for some image recognition,0,1,False,False,False,learnmachinelearning,1502216696,False, 
Keras outputs constant value no matter what input,8,2,False,False,False,learnmachinelearning,1502222030,True,"Just as the title states. Keras outputs a constant value no matter what inputs I throw in. The inputs vary in order of magnitude, and even when I scale everything to between 0 and 1, the same issue occurs. I've done this in MATLAB with and without any data preprocessing, and both have very good prediction results, so I'm at a loss for what to do. 
    
    model = Sequential()
    model.add(Dense(1, activation='tanh', input_dim=13))
    model.add(Dense(1, activation='linear'))
    
    model.summary()
    
    model.compile(loss='mean_squared_error',
        optimizer='adam')
    
    history = model.fit(x_train, y_train,
        batch_size=batch_size,
        epochs=epochs,
        verbose=1,
        validation_data=(x_test, y_test))

Anyone have any idea why the prediction is all constant values?"
Principal Components Analysis Tutorial,0,4,False,False,False,learnmachinelearning,1502230093,False, 
Heroes of Deep Learning: Andrew Ng interviews Geoffrey Hinton,0,34,False,False,False,learnmachinelearning,1502242213,False, 
Coursera deep learning course by Andrew Ng,0,1,False,False,False,learnmachinelearning,1502251118,False,[deleted]
TWIL (This Week I Learned) - Share something new that you have learned this week!,2,4,False,False,False,learnmachinelearning,1502262314,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
How I plan to become a machine learning engineer,0,1,False,False,False,learnmachinelearning,1502265168,False, 
Ml challenges on HackerEarth,1,2,False,False,False,learnmachinelearning,1502294927,True,"Hi, I am fairly new to the world of Data Science. I am stuck with the Andrew Ng course. I am also doing a boot camp course on Udemy. I have recently come across this ml challenge on HackerEarth. Is anyone here participating. If yes, can you take me in. I might be new but I am willing to learn and could use the guidance. 
Also if anyone with similar interests would like to join me please let me know.
Email id- abhijith1306@gmail.com

PS: Thanks in advance!"
"Are LSTM/GRU RNN layers comprised of multiple individual cells or just one ""big"" cell each?",0,2,False,False,False,learnmachinelearning,1502301460,True,"Or are they equivalent interpretations of the same thing?

I've seen multiple sources describe one cell, which later is supposed to go along many more in the same layer, similar to a standard NN. But other sources describe instead a ""hidden state size"" parameter that you adjust to increase the ""capacity"" of the cell.

I've been looking around, and this hidden state size seems to be pretty much the amount of *h* outputs from the cell, which in my mind is similar to having many units in the same layer, each outputting one value. Which one is a more *accurate* explanation of what is actually computed or is one just totally wrong?

#Follow up question:

Going with a 'one big cell per layer' mentality, I'm trying to figure out what are the sizes of each of this cell's parameters. I found [this Quora answer](https://www.quora.com/In-LSTM-how-do-you-figure-out-what-size-the-weights-are-supposed-to-be), but I'm still quite confused.

So if I have an input vector *x_t* of size *D* (ignoring a batch *B* = 1) and a hidden state size (aka number of units?) *H*, I understand that these parameters need to have these sizes:
   
* All *W_x*: size *H* x *D*
* All *b*: size *H*
* All gates: size *H*
* *h*: size *H*

However,  when I see that all *W_h* should have a size of *H* x *H* I wonder: does every individual unit have its own parameter vector *W_h* of size *H* to multiply the previous state vector of its **entire layer** (size *H*)?

Shouldn't each unit just multiply their own previous state and not also the ones of the rest of the layer? Is this the correct behavior?

Sorry if this question is confusing, as I'm quite confused myself."
Check out the Wrangle Conference Interview Series from TWiML & AI!,0,2,False,False,False,learnmachinelearning,1502310698,False, 
What are some interesting NLP projects that one could make a webapp out of?,2,0,False,False,False,learnmachinelearning,1502314861,True, 
Anyone have a link to exercises on random forests and gradient boosting that I could work through?,4,3,False,False,False,learnmachinelearning,1502315752,True,"I want to be able to code one from scratch. I've only seen tutorials use scikit learn's algorithms, but that's no fun :P"
A Guide to Machine Learning PhDs,1,25,False,False,False,learnmachinelearning,1502319056,False, 
Machine Learning: Inevitable but expensive path for future business | Savvycom,0,1,False,False,False,learnmachinelearning,1502349987,False, 
"I am currently in the beginning of Andrew Ng's Machine Learning course. Should I stop, and just start over with the newly released Andrew Ng classes on coursera?",19,24,False,False,False,learnmachinelearning,1502352049,True, 
Need some help.,1,2,False,False,False,learnmachinelearning,1502373017,True,"I am very interested in deep learning, and I was recommended to read eslr, but it is very hard to get into. So my question is :

How important is learning statistics and reading books like elements of statistical learning, of my end goal is learn deep learning? "
What topics should I study to complete a neural network that plays an online game?,6,19,False,False,False,learnmachinelearning,1502379007,True,"TL;DR: How do I evolve a neural network like this one here?  https://www.youtube.com/watch?v=qv6UVOQ0F44

---

Hello,

I am trying to complete a project that does the following:

- Players an online web game (html5)
    - Specifically, wanders around while dodging shapes/bullets/players

My goal is very similar to this one: https://www.youtube.com/watch?v=qv6UVOQ0F44 with one key difference -- the game I'm playing is an MMO (diep.io).

First and foremost, I'd like to know if this is *even possible*. The game I'm playing has about 4 different types of shapes scattered throughout a very large map and I want my player character to navigate without hitting them. The controls are simple wasd, no shooting or anything complicated. The only thing it would have to learn is to move away from the shapes/players/bullets and to turn around when it hits an edge. The enemy players and bullets are varying in size and shape but they are all a distinctive red color. 

I already have a vague sense of how this would be done, but the specifics are lost on me. If anyone can fill in the holes and give me some direction in what I should be studying, it would be much appreciated. Here is my basic plan:

- Use selenium to open a webpage, constantly screenshot the window using PIL and pass the image data into a CNN 

- The CNN will pool, filter, ect. and finally feed the simplified input into a fully connected layer

- The output will be `w`, `a`, `s`, or `d`.

- The fitness will be measured based on how long the bot lasts in the game. If the bot doesn't move for x seconds then it commits suicide and the cycle starts over.

--- 

**The plan above is incomplete.** I have absolutely no idea what to do with the fitness, or how to ""evolve"" the neural network. If I ran the code as I have it planned out, the bot would simply perform random actions until I shut it down with no improvement. Obviously I can't pass training data into the net, so -- what to do? "
Questions about momentum gradient descent and Nesterov accelerated gradient,0,3,False,False,False,learnmachinelearning,1502384438,True,"Hello! I plan on doing a project in which I compare Nesterov accelerated gradient to normal momentum gradient descent and plain gradient descent.

I have two questions before I dig in though.

1. My understanding is that NAG and momentum basically just speed up the convergence of gradient descent. Normal momentum makes bigger jumps than NAG and takes longer to converge than NAG, while both methods converge faster than normal gradient descent. Assuming this is correct, are there any downsides to using NAG instead of normal momentum? Also, are there any downsides to using either NAG and normal momentum vs gradient descent?

2. I was planning on doing this project using pseudo-random data sets generated with scikit learn functions like make_regression, make_classification, and make_blobs. This would allow me to easily control things like the data set size, noise, etc. Using these scikit learn functions for generating data sets, which types of data sets would be good for testing these algorithms on to show the differences?

Thank you for your help!"
Has anyone worked through a good deep reinforcement learning course/series of exercises?,5,4,False,False,False,learnmachinelearning,1502384804,True,"I just found out about Berkeley's deep RL course here:

http://rll.berkeley.edu/deeprlcourse/#lectures

and I was just wondering where, if anywhere at all, to start on this topic. I've already worked through lstm's (cs224), cnn's (cs231) and basic rl (pacman berkeley), so right now I'm looking for some introductory things to work through to get a foundation in combining them all. Any suggestions from things you've successfully worked through in the past would be appreciated!"
[HELP]Machine learning in MERN web app w/ recommendations,1,2,False,False,False,learnmachinelearning,1502395173,True,"I understand what machine learning is, I just don't understand how to integrate it with my web app.
I want the user to be able to create different types of lists and upon sign in, a set of recommendations to show up based on previous lists (just an example). These lists are saved in the database.
I've seen many examples of machine learning using python and scipy etc. but how are these programs integrated with a web app?"
"Re-writing base algorithms, learning underlying theory? (cross post from r/MachineLearning)",0,2,False,False,False,learnmachinelearning,1502396265,True,"Hello r/MachineLearning!

I'm an aspiring data scientist and I wanted some opinions on how to become thorough in machine learning. I thought about taking some time to understand the theory behind the algorithms. I also thought about trying to crudely code my own implementations of it. This summer I've been trying to get a hang of tensorflow.

Would trying to write the underlying code from the base up be a productive use of my time? What are the best resources out there to go about this?

Some background on me if it helps: I'm currently a masters student in computational statistics and I've taken two introductory courses in machine learning last semester. Both were somewhat of a mix of applied and theoretical. I've spent this summer trying to get a hang of Tensorflow, and in the fall I'll be taking another class on ML. 

"
"How can I use GANs to generate structured data, e.g. SVG/XML?",3,2,False,False,False,learnmachinelearning,1502397334,True,"Using [Generative Adversarial Nets (GANs)](https://papers.nips.cc/paper/5423-generative-adversarial-nets), how can I created data like SVG or XML that's:

1. Variable size and/or structured data, i.e. we're not dealing with fixed-dimension pixels and convolution layers; rather, hierarchical/tree data structures like HTML
2. Semantically-valid, e.g. needs to be valid markup, like matching closing tags

Anyone have any pointers or papers to read up on how to do this? I have no idea how to structure the neural net and preprocess the inputs. As some context, I'm trying to take a bunch of SVG icons downloaded from a site like [Icon Finder](https://www.iconfinder.com/) and train a model on it. Thanks!"
Statistical Inference Showdown: The Frequentists VS The Bayesians,0,5,False,False,False,learnmachinelearning,1502400513,False, 
I would like to use Feature Learning to identify animal species by sound in the wild. I have no background in machine learning. How can I get started?,0,1,False,False,False,learnmachinelearning,1502406551,True,[deleted]
"I want to do something similar to Warblr, which uses Feature Learning to identify and map multiple bird species by sound simultaneously.",2,2,False,False,False,learnmachinelearning,1502407156,True,"I have no background in machine learning. I'm more of a biologist more than anything, so this is very new to me. Where can I get started for a project like this? Are there any books or courses out there that wouldn't completely discourage me right away? This is the first project I've felt really passionate about, but the learning curve for sound physics and feature learning seems overwhelming."
easy setup for remote jupyter notebooks on your own server,0,6,False,False,False,learnmachinelearning,1502422593,False, 
Seq2Seq models that allow for variable input and output without requiring padding? Does one exist?,0,3,False,False,False,learnmachinelearning,1502431481,True,[deleted]
gradient descent error,2,3,False,False,False,learnmachinelearning,1502432779,True,"Matlab is giving me matrix inner dimensions error. i have work out the dimensions they are right according to me. I you find a mistake please let me know.

X = 47 * 3

Y = 47 *1
 
theta =  3 * 1

    theta = theta' -(((1/m) * ((theta' * X') - y') * X) * alpha);"
Machine learning bootcamp by Jose Portilla,2,6,False,False,False,learnmachinelearning,1502433032,False, 
Weekly Show-off!,1,3,False,False,False,learnmachinelearning,1502435120,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
How can I get into Machine Learning with a undergraduate degree in a non-technical discipline?,8,8,False,False,False,learnmachinelearning,1502445361,True,"Hi,

So I'm really interested in getting into machine learning. I'm in my last year of studying an undergrad degree in History and am predicted a first. I've been spending most of my free time getting my math and programming ability up to an undergraduate level. Having refreshed my college level maths, I'm now just starting Linear Algebra, Calculus and Stats at an undergraduate level using online resources such as books and MOOC's, while also doing online courses such as Dataquest and some courses on Pluralsight, Edx and Coursera (andrew ng's ones, etc). 

I'm deadset on doing this as a career and have really loved learning everything but having looked at some of the Masters in Machine Learning in the UK, most require a technical undergrad degree, such as Computing or Maths. I'm still in the process of researching universities in Europe, Canada and the UK but it doesn't look promising so far. So are there any courses any of you are aware of that don't have these prerequisites? If I can build a big enough portfolio and have enough relevant MOOC certificates, will this be useful in an application? Are bootcamps a viable alternative to a Masters? I'm going to email relevant university departments but I thought I'd ask here first

Lots of questions but I really hope you can help me answer them. Thanks in advance "
Confirmation about cost function,3,6,False,False,False,learnmachinelearning,1502446926,True,"For a learning algorithm to be considered a good algorithm, I know the cost function has to be low. 

My understanding is:

1. we have to find the point where cost function converges to the lowest possible cost.

2. we find the theta(weight) that makes gives us the lowest cost and use that as a parameter that gets plot into our hypothesis function (y = theta0 + theta1*x in linear regression)

Is my understanding correct? "
Help - Coding along the likes of HoloLens,0,4,False,False,False,learnmachinelearning,1502461697,True,"Hey guys! So I'm pretty new to machine learning as a whole with some programming experience, and just finished Andrew Ng's machine learning course, which was a fantastic introduction to machine learning. I've been wanting to learn more about machine learning and how it fits in with HoloLens, in accordance to its visual cues and how it interprets its surroundings. I'm planning on taking Andrew's new Deep Learning Specialization and a Game Development specialization (based off Unity since HoloLens uses that a lot). I was wondering if you guys had any other advice for basic or intermediate, material or courses I should start to study, for say if I theoretically wanted to build something like HoloLens and whatnot. Thanks for the help!"
Good RMSE value?,2,3,False,False,False,learnmachinelearning,1502466593,True,"I'm trying to predict a variable which has values in the range 6000 - 20000. The RMSE I'm getting is around 2400. Without any reference, how do I determine if the model is doing a fine job? Also, in those ranges, what does this rmse mean? Does it mean for each value, the prediction can be in the range of the actual value (+-)2400?"
Is it possible to get into the field with just a bs degree?,7,13,False,False,False,learnmachinelearning,1502469028,True,"Hi, at my current job i'm allowed to spend 20% of my time to do whatever I want. I'm interested in getting into the field but i only have a bachelors in computer science. Will it be hard to get a job in the field without a masters? "
I'm getting stuck with using an HMM library in Python called Pomegranate. It's giving me an error that doesn't really make sense.,4,8,False,False,False,learnmachinelearning,1502470675,True,"I'm using the [Pomegranate library](http://pomegranate.readthedocs.io/en/latest/HiddenMarkovModel.html)  for an HMM implementation. I'm following what the docs say for using the `from_samples` function which says that one of the parameters `labels` should be: 

`An array of state labels for each sequence. This is only used in ‘labeled’ training. If used this must be comprised of n lists where n is the number of sequences to train on, and each of those lists must have one label per observation. Default is None.`

My code is:

    model = HiddenMarkovModel('Gestures').from_samples(
            NormalDistribution, 3, training, labels=[0, 1, 2], algorithm='labeled')

I get the error: 

    ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()

which doesn't make sense since I'm inputing an array, but I guess it thinks I'm supposed to input a boolean?

"
Regularized Linear Regression,0,1,False,False,False,learnmachinelearning,1502478571,True,"Hi , I am learning ML , I have a few questions regarding regularized linear regression ,
 + should the features be scaled with 0 mean and unit variance ? And why ? 
 + What is the significance of lambda , is the value of lambda specifies the bound of weights ? Ie Wi < 3/root(lambda) . 
"
Best way to get deep into RL and DRL?,3,1,False,False,False,learnmachinelearning,1502480133,True,"Apparently my university only offers courses in Reinforcement Learning to PhD students, however I really wish to get my hands dirty with it as a MSc student.

What are the best books or online references/websites/materials to get into Reinforcement Learning and Deep Reinforcement Learning in particular?

I've already taken courses in Linear Algebra, Probability Theory, Statistics Theory, Univariate Analysis, Multivariate Analysis, Numerical Methods and Analysis of Differential Equations, and Discrete Mathematics in my Bachelor's degree. Haven't gotten to Optimization Theory in my MSc yet."
How do we find the best_fit_y for multivariate linear regression?,3,0,False,False,False,learnmachinelearning,1502481914,True,"Let's say I get the theta of:

-1.001562898810780470e-16
8.847649021574507389e-01
-5.317773396577776118e-02

After running my gradientDescent with some given data.

When there were only two parameters, it was easy since i just had to do:

theta[1] + theta[0] * x

to get the best_fit_line, but I am confused how to form a best_fit_y line with multi-variable.

Thanks!"
How do I determine whether my Deep Q learning algorithm is still learning or not.,1,3,False,False,False,learnmachinelearning,1502485106,True,"I have been running my R training process for a little over 3 days now and I'm trying to determine whether or not it's still learning. [Here](https://i.imgur.com/dW0xdiJ.png) is a graph of the running average of reward sums over around 90k episodes. The process just finished up and I'm wondering if I should bother running it for a longer period of time. Also, I have saved the neural networks for this run, can I just load the existing weights and pick-up training my deep Q network where I left off?"
The CS231n 2017 lecture videos are now up,0,56,False,False,False,learnmachinelearning,1502488374,False, 
Modeling a MLP with the sklearn Perceptron class?,1,2,False,False,False,learnmachinelearning,1502491201,True,"Hey guys,

I am trying to solve the XOR problem with a very simple MLP. Specifically this diagram:
http://i.imgur.com/PX1Is06.png

My code is essentially:

    X = np.array([[0, 0],[0, 1],[1, 0], [1,1]])
    y = np.array([0, 1, 1, 0])

    per_clf1 = Perceptron()
    per_clf2 = Perceptron()

    per_clf1.fit(X,y)
    pred1 = per_clf1.predict([[0, 0],[0, 1], [1, 0], [1,1]])

    per_clf2.fit(X,y)
    pred2 = per_clf2.predict([[0, 0],[0, 1], [1, 0], [1,1]])

    pred = np.array([pred1, pred2])
    pred = pred.T

    per_clf3 = Perceptron()
    per_clf3.fit(pred,y)
    pred3 = per_clf3.predict([[0, 0],[0, 1], [1, 0], [1,1]])

    pred3
array([0,0,0,0])

Which is incorrect.

I cannot seem to get it to work. Is my problem that I am trying to do the first layer then the second when they need to be calculated at the same time?"
Monthly ELI5 (Explain Like I am Five) Thread,5,5,False,False,False,learnmachinelearning,1502493609,True,"Top comments need to be in the format of: `ELI5 $CONCEPT_NAME` and the replies should provide a clear explanation in a layman's term.
Here are the relevant rules from /r/explainlikeimfive breaking down the meaning of ""ELI5"":

- E is for Explain - merely answering a question is not enough.

- LI5 means friendly, simplified and layman-accessible explanations - not responses aimed at literal five-year-olds.
"
"CNN: How to classify when you're not even sure if the item is in the image, let alone where it is?",2,4,False,False,False,learnmachinelearning,1502496063,True,"Hey,

This isn't currently a problem of mine, so I don't have any specific examples, but it's something that's interested me for a while since all of the examples of CNN's I see online are really basic. 

What would I do if I had a very large image of, say, something on a lawn... and I wanted to know if that something was a dog or a bird. I understand that it would be foolish to simply feed in the very large image, as the training would take forever with so much irrelevant data, so what would be the best strategy here? Dogs/humans can be so many different colors and shapes, I can't imagine how I could reliably pre-process without some form of AI.
"
Release history — scikit-learn 0.19.0 documentation,0,2,False,False,False,learnmachinelearning,1502496366,False, 
"Weekly Status Check Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",1,1,False,False,False,learnmachinelearning,1502521510,True,"Let's have a  meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
ML PhD doubts,3,7,False,False,False,learnmachinelearning,1502525300,True,"Hi,

I recently made a post on this sub and got some excellent responses. 

I believe that ML is an emerging field and the best way to learn it is through research and by completing a PhD. 

However, I see many comments on r/cscareerquestions that are [against doing a PhD. ](https://www.reddit.com/r/cscareerquestions/comments/6r8w9i/comment/dl3jq7x?st=J690D4A5&sh=a8c3d487). And with tools such as TensorFlow and python ML libraries, it seems you don't need a PhD. 

So, should I pursue a PhD or just learn through online content? I would love to hear from people who have done PhD's in ML. I'm planning on a PhD in Australia's top universities. A PhD takes 3-4 years in Australia. I don't want to do typical web dev work, and ML has caught my interest. 

Many comments say that it is a waste of time, and years of experience lost in doing research work. They also say there is hardly any raise in pay, hence it is not worth it. "
Listing of some of the best of Image Classification Convnet papers,0,1,False,False,False,learnmachinelearning,1502564526,False, 
Which courses I need to study to understand this paper?,5,6,False,False,False,learnmachinelearning,1502569492,True,"The paper is ""Identifying and attacking the saddle point problem inhigh-dimensional non-convex optimization"". https://arxiv.org/abs/1406.2572"
Implementing partial_fit with CalibratedClassifierCV in Python,4,5,False,False,False,learnmachinelearning,1502573038,True,"Hi guys, I've asked this same question on stack overflow and haven't gotten a response, but maybe what I'm about to ask is possible.

I need a classifier that is able to learn incrementally via scikit learns partial_fit method. I also want to calibrate the classifier before using it. One option is to use SGDClassifier. The problem is that scikit learns CalibratedClassifierCV does not return a ""corrected"" version of my original classifier, but rather wraps around it so that I cannot use partial fitting. It there a better way to do this? Why is the wrapper necessary rather than returning a calibrated version of my original classifier?"
How to standardize the data?,0,5,False,False,False,learnmachinelearning,1502580848,False, 
Scikit-Learn's metrics.log_loss vs. gridsearchcv's scoring = 'neg_log_loss',0,1,False,False,False,learnmachinelearning,1502590209,True,[deleted]
"Interested in ML, background in philosophy",5,5,False,False,False,learnmachinelearning,1502597040,True,"Hello!

I used to study Electrical Engineering but dropped it to study Philosophy, my real passion. However, with all the incredible things happening in ML, I must say that I'm fascinated by it. I'm finishing my degree in Philosophy but I'm also thinking on pursuing a career in this field. My question is: if I were able to work really hard and learn things by myself, even though I don't have a background in Computer Science, would it be possible to find a job? I live in Europe, for additional information. "
how to build a model here and what algorithms i need to study to make something out of it?,2,2,False,False,False,learnmachinelearning,1502613104,True,"hi

my first post here, so be gentle please. im trying to get my head around machine learning. 

my domain right now is stream of data that says what product pages user visits and what product user buys.

id like to get some insight from this data, for example make recommendations to users.

from what i studied to date, this is learning based on implicit ratings. 'view page X' or 'buy product Y' are my features and user is my label (is it?). problematic thing here is that let's say we got like 17k products. 

my questions:

* 17k products times two (view/buy) seem to be too much to become a feature set - it will be very sparse. what is my model here then? how am i able to reduce this space?

* does making user id a label make sense here at all? having user as label upfront make no sense from classification point of view, i could however cluster users maybe and make any sense out of it?

* is there any sense in applying classification here? are there any unsupervised classification algorithms so that i don't need to invent labels, but they will somehow be invented for me for users with similar behaviour?

please give me some advice and pointers to learning materials that may be useful in this particular case. what algorithm would be useful here? it looks like something ml could easily be applied to, but yet i cant wrap my hand around it. most of the examples/books focus on explicit 5 star ratings examples and it's not the case here."
Building simple perceptron in Python,0,25,False,False,False,learnmachinelearning,1502621273,False, 
Logistic Regression Help,0,0,False,False,False,learnmachinelearning,1502642404,True,"    function [J, grad] = costFunction(theta, X, y)
    data = load('ex2data1.txt');
 
    y = data(:, 3);
    theta = [0;1;2];
    m = length(y); 
    one = ones(m,1);
    X1 = data(:, [1, 2]);
    X =  [one X1];

    J = 0;
    grad = zeros(size(theta));
    J= 1/m *((sum(-y*log(sigmoid(X*theta)))) - (sum((1-y) * log(1 - sigmoid(X*theta)))));

    for i = 1:size(grad) 
    grad(i) = (1/m) * sum ((sigmoid(X*theta) - y')*X);
    end
    end
-------------------------------------------------------------------------
I can't figure what is wrong with my code i am just getting a vector of NaN.
-------------------------------------------------------------------------
Here is my sigmoid function :
    
    function g = sigmoid(z)
    data = load('ex2data1.txt');
    g = zeros(size(z));
    y = data(:, 3);

    theta = [0;1;2];
    m = length(y); 
    one = ones(m,1);
    X1 = data(:, [1, 2]);
    X =  [one X1];
    zz =  X * theta;
    g =  1/ (1 + exp(-zz));
    end"
NEAT using tensorflow?,1,1,False,False,False,learnmachinelearning,1502643694,True,"I've started reading a lot of papers about NEAT which uses genetic algorithms to decide the structure of a neural network. I was wondering if there are any examples online about how to implement this in tensorflow (I searched, but unfortunately nothing). If not, has anyone attempted it and succeeded? Is it possible at all?"
Teaching an AI to play a simple game using Q-learning,2,20,False,False,False,learnmachinelearning,1502653577,False, 
"Update model parameters with new data, discarding old data",0,3,False,False,False,learnmachinelearning,1502661246,True,"I have [this][1] dataset, and I am using `y = (a * x^n) / (b + x^n)` Hill function as the model, where `a` is the limit of the Hill curve, `b` is the point of inflection and `n` is the cooperativity or steepness of the curve.

Currently, I am storing all `X,y` values, computing the parameters from `scipy.optimize.curve_fit`, and plotting the curve. If new data points come along, I re-calculate the parameters with the old+new data.

Is there a way to update the parameters of the model without storing **all** of the previous old data points, once the initial parameters are obtained from the previous data points?

Example, I fit the curve to the first 1000 data points and have my parameters. Next, I discard some or all of the old data. Then, when I see the 1001st point I simply update my parameters and plot the curve again and so on for every new data point.

**EDIT**

My existing code is as follows (not super elegant).

    import matplotlib.pyplot as plt
    from scipy.optimize import curve_fit
    
    def file_stream(file_name):
        with open(file_name, 'r') as in_file:
            for line in in_file:
                yield map(float, line.strip().split('\t'))
    
    def hill_model(X, a, b, n):
        return [float((a * x**n)) / (b + x**n) for x in X]
    
    def get_params(X_all, y_all, prev_par=None, fn=hill_model):
        if prev_par is None:
            a_init, b_init, n_init = y_all[-1], y_all[0], 1.0
        else:
            a_init, b_init, n_init = prev_par
        opt_par, opt_cov = curve_fit(fn, X_all, y_all, p0=[a_init, b_init, n_init])
        a_final, b_final, n_final = opt_par
        return a_final, b_final, n_final
    
    def main():
        file_name     = 'data.tsv'
        file_streamer = file_stream(file_name)
        X_all, y_all  = [], []
    
        # Get some intial data from stream
        for _ in xrange(1000):
            X, y = file_streamer.next()
            X_all.append(X)
            y_all.append(y)
        plt.scatter(X_all, y_all)
    
        # Initialize params of model
        a, b, n = get_params(X_all, y_all)
        y_model = hill_model(X_all, a, b, n)
        plt.plot(X_all, y_model, 'r-')
        plt.show()
    
        # Rolling update
        seen_all = False # Helps stop when all data is fit
        while True:
            for _ in xrange(1000):
                try:
                    X, y = file_streamer.next()
                    X_all.append(X)
                    y_all.append(y)
                except:
                    seen_all = True
                    break
            a, b, n = get_params(X_all, y_all, prev_par=[a, b, n], fn=hill_model)
            y_model = hill_model(X_all, a, b, n)
            plt.scatter(X_all, y_all)
            plt.plot(X_all, y_model, 'r-')
            plt.show()
    
            # Nothing more to update, return
            if seen_all:
                return
    
    if __name__ == '__main__':
        main()

The code currently reads in some `X,y` values, calculates the `a`, `b`, `n` parameters and when more `X,y` values are added, the code updates `a`, `b`, and `n` params. As you can see, I need to store previous `X,y` values, which I do not **want**. I want to update the parameters as new `X,y` values are seen and from the previous `a`, `b`, and `n` values only.

  [1]: https://pastebin.com/A3s9dUKp"
Easiest (or dumbed down) online tutorial on deep Qlearning?,1,1,False,False,False,learnmachinelearning,1502664201,True,"I'm familiar with neural networks and most machine learning algorithms. I'm also familiar with the concept of Qlearning applied to simple problems. However, I have a hard time understanding how to combine Qlearning and neural networks when the state space is not either deterministic or limited. 


For example. Think of a video game. The task is to build a deep qlearning model that can learn the game from scratch. This is an example using genetic programming https://www.youtube.com/watch?v=qv6UVOQ0F44


Do you happen to know a very dumbed down tutorial on how to approach problems with deep Qlearning when the state space is not limited or it is not practical to map it?"
Tutorial “Number plate detection with Supervisely and Tensorflow”: Step-by-step guide of how to build number license plate detector with Tensorflow and Supervise.ly,3,26,False,False,False,learnmachinelearning,1502707388,False, 
Why backpropagation dimensions don't match?,3,2,False,False,False,learnmachinelearning,1502722432,True,"Consider an MLP with one hidden layer that has (4, 3, 1) activations nodes in each layer (input and hidden layers have one bias each). Weights, w_1 is of shape (3, 2) and w_2 of (3, 1).

Forward propagation works. Now you wanna do backpropagation:

    delta_3 = a3 - z3 

so far, so good. `delta_3` shape is (4, 1). Now, 

    delta_2 = np.dot(delta_3, w_2.T) * sigmoid'(z_2)

**Now we have a dimensionality problem**! The left-hand side is of shape (4, 3) and the right-hand side is (4, 1). What am I doing wrong?  
"
Come learn about the Composition a Basic Neural Network,0,2,False,False,False,learnmachinelearning,1502745618,False, 
"Ever wanted to easily experiment with generating images? Here's an easy to use DCGAN that trains on a folder of images, and the repo includes pre-trained models (on genres of art) and a wikiart scraper to help build datasets.",3,21,False,False,False,learnmachinelearning,1502774714,False, 
Questions about Tensorflow tutorials,1,6,False,False,False,learnmachinelearning,1502778969,True,"Hello, I’m just trying to understand the Tensorflow ML tutorial and I had a few questions on certain points.

https://www.tensorflow.org/get_started/mnist/beginners

I have some questions about the training. As I understand it in the beginner’s example each pixel has an associated Weight and Bias for each of the different letters. An image having a pixel there or not is weighted and then added up for the total evidence. Each W and b is initialized to some value and then through something like gradient descent they are nudged slightly in one direction based upon how well the prediction matches up. 

Wouldn’t it be simpler to just determine statistically how much a pixel appears in each spot for each letter and derive a probability model from there with no training needed? Lets say for instance Pixel 1 being occupied has an 80% chance of being A and a 20% chance of being B and Pixel 2 being occupied has a 52% chance of being A and a 48% chance of being B etc. Is this less accurate? How is that possible? 

https://www.tensorflow.org/get_started/mnist/pros

Moving further along into the ‘Expert’ tutorial I’m also a little unsure how the convolution steps are trained. Is the below explanation on the right track? 

Each convolution step consists of a grid of numbers (input matrix) which slides over the image grid and through matrix multiplication and taking the dot product and pooling generates new grids of values called features. These features are through one or more convolution steps shrunk down until you have a final feature ‘image’. 

I assume at the end the you have a similar randomly initialized weight maps for each letter like the ones you had in the beginner’s example and then use it to weight the pixels of the final feature image and add up the evidence of it being a particular letter.  You then use backpropagation to determine the amount of change each value of the weight map and all the previous input matrices contribute and adjust them accordingly? 

Also, In the first convolutional step they somehow extract 32 features at once. Is this just 32 separate grids of values they create to convolute across the image? 
"
"LDA, number of topics and hyperparameters",3,4,False,False,False,learnmachinelearning,1502789273,True,"Hello!

I am working on topic modelling project using LDA. I started with a small corpus of ~7000 documents where I could comphrehend the impact of hyperparameters and the amount of topics quite intuitively (or at least I think I could). Now I am working on far larger corpus (~100.000 documents). My goal is to extract scientifc topics, similiar to [this paper.](http://psiexp.ss.uci.edu/research/papers/sciencetopics.pdf)



Now I have problems to chose my model, i.e. the amount of topics and the hyperparameters. For the amount of topics I wanted to do something similiar like  in the aforementioned paper on page 5, calculating the log-likelihood for different topics and pick the model with the highest value. The problem is: I still do not know which hyperparameters to chose and I suspect that the calculated curve will be highly dependent on the hyperparameters. 

For the hyperparameters themselves I tried to come up with a more intuitive metric instead of using something like likelihood. I know how the hyperparameters impact the model (sparsity doc-topics / topics-words) and I want finely resolved topics which can be identified with an academic subfield, dominated by not that much words defining those topics. So I know I have to set the hyperparameters rather low. My approach was to take a model and implement some kind of threshhold (e.g. 50 percent) which has to be reached by the fractions of the y dominating topics (e.g. y=10) for each document. But also here I have to problem: how do I chose the number of topics before estimating the hyperparameters?


Somehow I do not see a way to isolate the estimations for the number of topics or hyperparameters, such that I always need one in the first place to get the other one. So I am asking if someone knows some tricks or knows a good method to solve this problem.


Edit: as a third problem, I also have to know how many iterations I will perform. I also did this using log-likelihood, but I guess the behaviour of this also alters with varying the amount of topics."
Which path should I follow to pursue my interest in Deep Learning?,4,13,False,False,False,learnmachinelearning,1502789530,True,"Hello everyone!

I am an Electrical Engineer, who recently did graduation with a final thesis research topic on image classification using deep convnets on a Kaggle challenge.

I came to know about the exciting field of Deep Learning in 2014 and since then I've been fascinated by it. In order to jump into the field, I decided that I'd do my thesis in this field. Now, I know a plenty about deep learning in sufficient detail, and want to further pursue in this field.

What I'm confused about is what path should I take now, considering I've just completed my graduation. I have the following three options in my mind:

1. Pursue a PhD in deep learning: I like this option because I think can then go for teaching in this field. But at the same time, I wonder whether spending 2-4 years doing Ph.D. is even worth it and will this even help me do exciting real-life deep learning projects?

2. Take Deep Learning Courses Online: Like the one recently launched by Andrew Ng. Do such courses really help and are they really worth the money? That's what I am wondering. Will I be acceptable in Deep Learning industry after doing so?

3. Just read and study about concepts of Deep Learning via online articles and books, do Kaggle challenges, publish papers and maybe build my own company one day.

So, what do you guys suggest?"
GPU utilization using resnet on Titan X,2,4,False,False,False,learnmachinelearning,1502798821,True,"I'm evaluating images on resnet using batches of 1 (there's a reason for that). I get ~50% GPU utilization. I believe the low utilization is because memory transfer takes too much time, but I don't know how I can find out exactly why GPU utilization is low. Can anyone give me any pointers on debugging GPUs like this? I have very little experience on this topic.

Edit: I'm also at 280% CPU utilization. I'm slightly suspicious that I'm accidentally doing some work on the CPU, which might incur additional host<->device memory transfers."
A good read to understand Unsupervised learning and Autoencoders.,0,1,False,False,False,learnmachinelearning,1502802367,True,[removed]
Logistic Regression Implementation,0,4,False,False,False,learnmachinelearning,1502804616,True,"I am having some ambiguities regarding the implementation of Logistic Regression, I want to know if i am proceeding with the steps on the right way.

* Fitst we have to find the θ to minimize our cost function. To find θ we will use this function

        θ = θ - 𝛼 x (gradient).

* The we will find the cost using :

        J= 1/m *((sum(-y*log(sigmoid(X*theta)))) - (sum((1-y) * log(1 - sigmoid(X*theta))))) +      lambda/(2*m) *sum(theta).^2;

* Then we will find the gradient 

        grad = (1/m) * sum ((sigmoid(X*theta) - y')*X);
"
Support Vector Machines tutorial from examples,0,1,False,False,False,learnmachinelearning,1502805606,False, 
Question regarding statement that the maximum entropy tends to N bits,0,4,False,False,False,learnmachinelearning,1502811680,True,"Working through Mackay's book on information theory.

> Systems with 2^1000 states are two a penny. One example is a collection of 1000 spins such as a 30x30 fragment of an Ising model [...] if we wish to evaluate this function at all states **x**, the computer time required would be 2^1000 function evaluations.

[...]

> [...] a high-dimensional distribution is often concentrated in a small region of the state space known as its typical set T, whose volume is given by |T| ~ 2^H(x) [...] The total size of the state space is 2^N states, and the typical set has the size 2^H. So each sample has a chance of 2^H / 2^N of falling in the typical set. The number of samples required to hit the typical set once is thus of order 2^(N-H).
So, what is H? At high temperatures, the prob dist of an Ising model tends to a uniform distribution and the entropy tends to H_max = N bits [...]

The problem I have with the final statement is that it seems to me it is trivially shown to be incorrect. Take any uniform distribution and calculate the entropy of it, that number will not be close N (the dimension of **x** and therefore size of the prob distribution). "
100% accuracy with Adult income dataset,9,5,False,False,False,learnmachinelearning,1502814012,True,"Hi!

I created a notebook [what you can find here](https://www.kaggle.com/gaborvecsei/accurate-predictions-with-20-test-data/) and at the end I got 100% as accuracy score with 20% test split and RandomForest.

I used Random Forest because it is robust to unbalanced datasets like this. There are 2 classes and one contains >20k samples the other around 7k.

What do you think about that and my notebook? It is strange to get 100% :D."
"Check out TWiML Talk #42 with Josh Bloom, VP of Data & Analytics at Wise.io/GE Digital.",0,3,False,False,False,learnmachinelearning,1502816389,False, 
"""Is this Food?"" - Classification Images using TensorFlow in Python",1,16,False,False,False,learnmachinelearning,1502822798,False, 
Cloud Services For Reinforcement Networks,4,2,False,False,False,learnmachinelearning,1502822973,True,"Hey guys,  
  
I'm trying to find a good online GPU service for training reinforcement networks. I looked at Google Cloud but it seems like the setup they have is more for supervised learning. I tried looking into the AWS ones but it looked like all the GPU capable ones were booked up.  
  
Does anyone know a good place to look for this kind of setup?"
teaching a model to write graphics programins,0,2,False,False,False,learnmachinelearning,1502828028,False, 
Choosing and Undergrad Degree Path,2,2,False,False,False,learnmachinelearning,1502830630,True,"I just got back to college for my 4th semester.  I am currently a Computer Science Major and recently became intensely interested in Machine Learning.  I am about to start on the Andrew Ng course, and plan to do a lot of independent studying, as my university does not have an ML program.  
  
I am really interested in furthering research in the field as a researcher, not just getting into industry and implementing others' research.  To this end, I am highly considering double majoring in Math and CS, but adding the Math major will cause my course load to increase significantly from the added Math courses as well as extra science and humanity courses that the major requires.  Due to this, I am wondering if it is worth the hassle.  
  
My school also offers minors in Math and Statistics, which I would consider in lieu of the Math major.  Finally, if having the additional degree/minors aren't incredibly important, I would consider simply taking the Math classes that would be beneficial without any formal recognition.  
  
I'll list out the courses required and available below.  I'll skip the classes I've already taken, as I can't unlearn them.
  
**Math Classes**  

Course Name | Major | Math Minor | Stats Minor
---|---|---|---
Calculus IV | Yes | Yes | Yes
Foundations of Math I | Yes | |
Linear Algebra | Yes | Yes | Yes
Differential Equations | Yes | Yes | 
Intro to Modern Algebra | Yes | |
Advanced Calculus I | Yes | |
Advanced Calculus II | Yes | |
Numerical Analysis I | Yes | |
Numerical Analysis II | Yes | |
Linear Programming | Yes | |
Intro to Probability | Yes | Yes | Yes
Nonparametric Methods OR Intro to Spatial Statistics | | | Yes
Data Analysis I | | | Yes
Data Analysis II | | | Yes
Intro to Math Statistics II | | | 
Discrete Mathematics | | | 
Graph Theory | | | 
Matrix and Linear Algebra | | |
Group Theory | | | 
Number Theory | | | 
Intro to Partial Differential Equations | | |
  
So, given the courses that are available, which courses do you think are important to take for a future in this field, and is having a degree/minor in math/statistics worth the extra hours from non-math requirements, or would the relevant coursework be enough?
  
Thanks!!"
Deep learning is not diverse enough: announcing fast.ai diversity scholarships,0,0,False,False,False,learnmachinelearning,1502835469,False, 
How do I Convert MIDI Files in CSV Format into a Machine Learnable Format? (torch-rnn) [My X-Post from /r/learnprogramming],0,8,False,False,False,learnmachinelearning,1502842104,False, 
SVM - Understanding the math - What is a vector?,0,18,False,False,False,learnmachinelearning,1502848606,False, 
Microsoft Certification - Is it worth investing time in it ?,0,6,False,False,False,learnmachinelearning,1502864262,True,"I am currently doing the Udacity nanodegree course and I also would like to prepare for the Microsoft certification. The nanodegree focuses on Python and the Microsoft certification is all about your expertise in R. I know Python much better than R so it'd take considerable effort to get familiar with R to complete the Microsoft certification. So considering this, is that certification valuable in the industry, atleast to get my foot into the ML related roles ?"
TWIL (This Week I Learned) - Share something new that you have learned this week!,0,1,False,False,False,learnmachinelearning,1502867116,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
"Looking for train, val, test example in Keras",0,1,False,False,False,learnmachinelearning,1502877418,True,"Hi there, I'm running a number of models for a college project and many guides I see just use a train and test set, which is ok in many cases but my supervisor recommended that the results would be more trustworthy by having a validation set to tune parameters on and not overfit on training data. 

My code looks similar to the code in the below example so does anyone know of any scripts which highlight how to do the train, val, test approach?

In Keras's Sequential model they have a 'validation_split' parameter but I'm not sure if this is just another paramater for train/val split where val means the same thing as test?

    fit(self, x, y, batch_size=32, epochs=10, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0)

Many thanks

https://github.com/fchollet/keras/blob/master/examples/pretrained_word_embeddings.py"
Practice English for your own good,0,0,False,False,False,learnmachinelearning,1502887712,False, 
Going to a hackathon in a month...what basic ML should I learn to integrate into cool apps?,2,14,False,False,False,learnmachinelearning,1502892975,True,"I have general thoughts of what I should learn, e.g building a basic image classifier, but I'm not sure what else would be most useful and relatively easy to learn. We will hypothetically be working with datasets of a huge amount of health records.

So what algorithms and techniques could get me off the ground quickly? Obviously this is vague and it depends on what we need, but I'm talking about what pops out as some of the most tried and tested algorithms and corresponding libraries/resources to use them

For reference, I am a 4th year CS student and mainly dabble in iOS, web, and scientific research"
Trained Deep Q Network performs seems to have random predictions on test data.,0,1,False,False,False,learnmachinelearning,1502901392,True,"After training my DQN for over 180k episodes, i've seen fairly decent performance on the training data and I decided to check it on some test data. After several test runs on the same set of data I noticed that my predictions varied wildly between runs, almost to the point of seeming random. I'm trying to figure out what are the possible issues for the randomness I'm seeing:

* Is my DQN overfitting the training data?
* Have I not given the DQN enough input data to actually make an accurate guess?
* Is my NN too small/large?
* Do I need to tune my hyper parameters? 

Below is my Keras NN setup: 

        learning_rate=0.0001
        gamma=0.99
        exploration_rate=1.0
        exploration_decay=0.995
        exploration_min=0.01

        model = Sequential()
        model.add(Dense(236, input_dim=59, activation='relu'))
        model.add(Dense(236, activation='relu'))
        model.add(Dense(3, activation='linear'))
        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate)

- [Here is my training performance after 180k episodes](https://i.imgur.com/GG9rNTf.png)

- [Here is run 1 on my test data](http://i.imgur.com/ouzqlt8.png)
- [Here is run 2 on my test data](http://i.imgur.com/rVWaoQx.png)

Any thoughts on how to help determine the root cause of the issues here would be greatly appreciated.

"
Question about deep learning word embeddings,1,4,False,False,False,learnmachinelearning,1502904174,True,"As a rule of thumb, should I limit the size of the vocabulary of my embeddings? In NLP problems, my vocabulary goes up to like 20k+ words. Is it best practice to have my embedding be that big as well or is there merit in cutting down to, say, the top 2k+ words?"
n00b question: getting oriented for text mining,1,5,False,False,False,learnmachinelearning,1502905635,True,"Hi everyone, 
I do a lot data analysis at my job at a publishing company, but I haven’t dipped my toes into machine learning at all yet. I’m pretty conversant in Python and Pandas, though. There’s a large project looming in the somewhat-near future that would be a great opportunity for me to get started in ML (and would look great on my resume!).

The project will be this:

* 1 Scan all our company’s PDF products (I have HMTL versions, and can convert to plaintext with Linux pdftotext package). There are ~70,000.

* 2 Try to match each text to a list of our taxonomy terms, based on relevance.

* 3 Audit the taxonomy terms that are already applied to these products in our metadata management system. I suspect that many of them will be irrelevant or wrong when compared to the ML-generated list of step 2. 

Because I’ve never done any ML, I would love some tips on how to orient myself. Are there good beginner examples of text mining that you could share? Which Python modules should I look into? Are there MOOCs I should sign up for (I hear Coursera has a really good ML course, would that be relevant)? Other tips? 

Thanks in advance!

"
How to Get Traffic for FREE!,0,0,False,False,False,learnmachinelearning,1502910211,False, 
Tutorial on building your first Neural Network,2,72,False,False,False,learnmachinelearning,1502917125,False, 
[Python] Handling Negation Stopwords in Sentiment Analysis,0,2,False,False,False,learnmachinelearning,1502917732,True,"Good Day,

I am working on a beginner ML project to make a sentiment classifier using Python, NLTK and SKLearn. I pre-processed my text, ran `GridSearchCV` on various estimators and found optimal parameters for `SGDClassifier` (`Multinomial Naive Bayes` was less effective; I haven't tried a Random Forest or a Decision tree yet).

My input data has 3 classes, -1 for negative, 0 for neutral and 1 for positive.

The best accuracy/F1 score I can obtain on my test/train split 81%/80%.  The baseline is 70% for the majority class.

When I look at the input the classifier predicted incorrectly a large portion of them are sentences that contains negatives which were removed as they considered a stop word (`nltk.corpus.stopwords.words('english')`).  

e.g. *""He is not bad""* -&gt; *""bad""*.  The original sentence is a *0 or 1* (neutral/positive) but it predicts as a *-1* (negative) as it losses the context of the negation.

What is the best way to handle negation stopwords for sentiment analysis?

---

Two methods off my head:

1. Find all negations that should remain and remove them from the stopword list e.g. `stopwords = set(stopwords.words('english')) - set('not')`

2. Join *not's* to the following words before pre-processing e.g. *He is not_bad* -&gt; *""not_bad""*

Is there a better way?"
Appraisal of course syllabus,0,2,False,False,False,learnmachinelearning,1502951075,True,"I intend to take Computer Vision as a course in the upcoming fall semester and I was wondering if anyone can evaluate the course syllabus to tell me if the concepts covered are relevant in today's world and if it will help me with respect to what I will learn in Machine Learning. I do have interest in object recognition, tracking, self driving etc. and I have already taken the ML course on coursera. I also intend to take a formal ML course in Spring.

So, here's the syllabus:

**Image Formation:** 

Monocular imaging system; Orthographic &amp; Perspective Projections; Camera
model and Camera calibration; Binocular imaging systems; 3D image sensing (range sensing
with laser ranging, grid coding etc.)

**Low-level Vision:** 

Basic image processing (continuous and discrete images), Edges and edge finding,
stereo vision, Regularization, Shape from X, Optic flow and it’s computation, Motion
analysis (computation of motion parameters and structure).

**Shape Segmentation &amp; Representation:** 

Simple segmentation techniques in 2D and 3D: Deformable
curves and surfaces a.k.a. “snakes” and associated numerical methods. Snakes
for tracking and Kalman snakes. Normalized Cuts and Graph Cuts. 2D (implicit and explicit
functions, boundaries: Fourier/Wavelet descriptors; regions: Texture description using
co-occurrence matrices, Medial axis, quadtrees etc.) and 3D shape representation (surface
based:implicit and explicit functions, Gauss map and its differential; and volume based: Octrees,
deformable solids etc.) techniques, Multi-resolution representations (Laplacian pyramid
and wavelet basis).

**High-level Vision:** 

Simple object recognition methods in 2D and 3D: Various criteria for imageimage
or shape-shape matching. Principal Component Analysis (PCA) and building priors
for recognition.

"
Understanding overfitting: an inaccurate meme in supervised learning,0,7,False,False,False,learnmachinelearning,1502951714,False, 
"Tutorial “Training road scene segmentation on Cityscapes with Supervisely, Tensorflow and UNet”: Step-by-step guide of how to train UNet neural network on Cityscapes dataset",0,6,False,False,False,learnmachinelearning,1502953785,False, 
"Finished with coursera ML course, whats next?",3,14,False,False,False,learnmachinelearning,1502957861,True,"I have just finished with the ML course on coursera by Prof Ng, was thinking about the follow-up series also available at coursera by Prof Ng for deep - learning specialization:
https://www.coursera.org/specializations/deep-learning

I have also come across this free google course at udacity:
https://www.udacity.com/course/deep-learning--ud730

and these nano-degrees as well at udicaty:

Machine Learning Engineer Nanodegree
https://www.udacity.com/course/machine-learning-engineer-nanodegree--nd009

Artificial Intelligence Engineer
https://www.udacity.com/ai

DEEP LEARNING NANODEGREE
https://www.udacity.com/course/deep-learning-nanodegree-foundation--nd101

Did someone here had any experience with these ? are there other better courses\speicalzation that you recommend of?

Thanks(:"
Generative Adversarial Networks (GANs): engine and applications,0,21,False,False,False,learnmachinelearning,1502976058,False, 
use cases of word2vec,0,1,False,False,False,learnmachinelearning,1502980505,True,[deleted]
can i use word2vec for this use case?,1,1,False,False,False,learnmachinelearning,1502980551,True,"I want to test out using word2vec to rewrite complex stuff in simpler terms sort of as a translator but all in English. This is not really a summarization problem. can anyone point me to any experiments where people have taken the word2vec model and sentences and rewrite the same sentence in a different natural way. For example taking the sentence ""i am from china"" and rewriting it in different ways like "" I live in the country next to india"" or "" I am from asia"" etc. It doesnt have to use word2vec, but I thought word2vec would be best for a situation like this."
What does it mean to have bias in a neural network?,2,9,False,False,False,learnmachinelearning,1502990601,True,"I understand weights. Weight is the value a neuron is adding at a given point in training. I understand bias and its role in regression. It's what happens at zero, the starting point. It's almost intuitive for a basic neural net.   
  
What about CNNs, RNNs, or GANs? What does bias mean for these neural networks?"
Finding a ML Mentor,3,1,False,False,False,learnmachinelearning,1502996303,True,"I have been working on learning ML on my own via several different platforms including Udemy, Data Camp, Lynda and Elite Data Science. I’m currently considering the ML Nano degree on Udacity. The thing that I like about the nanodegree is the structured approach and the mentor support. I’ve come to realize that mentor support is extremely important in the learning process.  Before I invest in the program, I wanted to see if anyone has been able to find a mentor in another way. Is there any type of service that matches learners with mentors? "
Looking for feedback on my side project,3,6,False,False,False,learnmachinelearning,1503007069,True,"Hi folks,
I'm gaining a bit of traction on a side project I've been building for a little while around tutorials like this one: https://www.worldlybayes.com/tutorial_sample

The problem I'm looking to solve is that I see a lot of folks entering our field who have spent time learning algorithms and apis, but are missing critical skills needed to add value in companies (critical thinking, product sense, and systems design). I think this just do to lack of exposure and an absence of good examples (eg. there are lots of tutorials on how to use tensorflow for image recognition on MNIST, but very few on how to think about building a product around a deep learning model). So I've been writing a set of tutorials with more of a product development focus in the hopes that I can help out early career folks level up. The first 4 I have planned are:

- Building basic models (linked above)

- Generating feature hypotheses and iterating on a model

- Writing reusable and shareable code to get rid of cut and paste

- Using a database to back your modeling efforts

And then I'll see where it goes from there. I'm looking for feedback around the tutorials I've written: Are they understandable? Do they make sense? Do they seem useful? I'd like to make this as good as it can be and I think this group would be very helpful.

Thanks!"
What are order statistics?,0,4,False,False,False,learnmachinelearning,1503007554,False, 
Tech Question: Apache Hive won't start up,0,3,False,False,False,learnmachinelearning,1503008995,True,"I'm in the process of learning the hadoop ecosystem, and I'm on hive. I downloaded it, but when I just try to run the executable on Ubuntu 16, I get a massive error note:

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/niklas/hadoop_files/apache-hive-2.1.1-bin/lib/log4j-slf4j-impl-2.4.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/niklas/hadoop_files/hadoop-2.7.3/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]

Logging initialized using configuration in jar:file:/home/niklas/hadoop_files/apache-hive-2.1.1-bin/lib/hive-common-2.1.1.jar!/hive-log4j2.properties Async: true
Exception in thread ""main"" java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient
	at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:591)
	at org.apache.hadoop.hive.ql.session.SessionState.beginStart(SessionState.java:531)
	at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:705)
	at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:641)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient
	at org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:226)
	at org.apache.hadoop.hive.ql.metadata.Hive.&lt;init&gt;(Hive.java:366)
	at org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:310)
	at org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:290)
	at org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:266)
	at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:558)
	... 9 more
Caused by: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient
	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1654)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&lt;init&gt;(RetryingMetaStoreClient.java:80)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:130)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:101)
	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3367)
	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3406)
	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3386)
	at org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3640)
	at org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:236)
	at org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:221)
	... 14 more
Caused by: java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1652)
	... 23 more
Caused by: MetaException(message:Version information not found in metastore. )
	at org.apache.hadoop.hive.metastore.ObjectStore.checkSchema(ObjectStore.java:7753)
	at org.apache.hadoop.hive.metastore.ObjectStore.verifySchema(ObjectStore.java:7731)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:101)
	at com.sun.proxy.$Proxy21.verifySchema(Unknown Source)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:565)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:626)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:416)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&lt;init&gt;(RetryingHMSHandler.java:78)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:84)
	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6490)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&lt;init&gt;(HiveMetaStoreClient.java:238)
	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.&lt;init&gt;(SessionHiveMetaStoreClient.java:70)
	... 28 more

I don't know how to approach this, and I can't seem to find much so far."
Weekly Show-off!,1,12,False,False,False,learnmachinelearning,1503039919,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
Unsupervised Classification problems(Clustering analysis),2,5,False,False,False,learnmachinelearning,1503045749,True,"So far, the one I know is from [scikit learn clustering](http://scikit-learn.org/stable/tutorial/statistical_inference/unsupervised_learning.html)

Is there any good resources about this kind of unsupervised clustering analysis? Mainly interested in implementing this in python but other languages are welcome."
[1708.05070] Data-driven Advice for Applying Machine Learning to Bioinformatics Problems,0,8,False,False,False,learnmachinelearning,1503077677,False, 
Guidance regarding machine learning,3,2,False,False,False,learnmachinelearning,1503083950,True,"Hey!!!
I am very enthusiastic about learning machine learning.i am very interested in doing project based machine learning courses and prospects being taught by the person who themselves are working in the field.the biggest problem I have encountered is that courses on Coursera and udacity are good but they don't help much in doing real life projects as a developer.on the other hand I am amazed by the self taught computer wizards who do everything by themselves so my question please guide me to resources to help me pursue a career in Machine learning"
Learn about t-distribution. Interactive tutorial,0,16,False,False,False,learnmachinelearning,1503124006,False, 
Resources for Learning about Quantum Computing,1,13,False,False,False,learnmachinelearning,1503124213,False, 
"Weekly Status Check Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",3,4,False,False,False,learnmachinelearning,1503126318,True,"Let's have a  meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
LSTM:quick question,0,1,False,False,False,learnmachinelearning,1503162500,True,"I am learning from:
http://colah.github.io/posts/2015-08-Understanding-LSTMs/
My question: is h(t) empty (so after h(t-1) is basicly being done in t-th unit(it alredy gave info to cell state and produced output h(t)))? That's how I assume it is, but it ins't anywhere explicitly stated?"
Machine Learning in 90 Days,1,1,False,False,False,learnmachinelearning,1503163046,False, 
A Comparison of Six Methods for Missing Data Imputation,2,10,False,False,False,learnmachinelearning,1503166060,False, 
Teaching Machines How To Spot Diseases,0,1,False,False,False,learnmachinelearning,1503168140,False, 
Playing large number games in R.,0,2,False,False,False,learnmachinelearning,1503171599,False,[deleted]
Help with deployment in tensorflow?,0,2,False,False,False,learnmachinelearning,1503175118,True,"In my case, I need to compile binaries but run into errors.

https://stackoverflow.com/questions/45775944/compiling-binary-with-tensorflow-library-for-cpu-cannot-find-cuda-library

What is your workflow?"
"Deep Learning Introduction Tutorial Series, What Next?",0,2,False,False,False,learnmachinelearning,1503177717,True,[deleted]
Building Your First Neural Network Tutorial,3,32,False,False,False,learnmachinelearning,1503179247,True,"I've been working on a [series teaching deep learning](https://youtu.be/g5n4BVNdxK8?list=PL_49VD9KwQ_NFnA6egEPs4UiM6P3pp0hS), particularly how neural networks work and how to create one on Youtube that can be found [here](https://youtu.be/g5n4BVNdxK8?list=PL_49VD9KwQ_NFnA6egEPs4UiM6P3pp0hS)

I've finished going over some basics and I can't decide on where to go next. I was thinking of going into a project, like making a Go bot, Open AI Gym projects, a StarCraft II bot or something of the sort. I could also do general concepts like reinforcement learning, ect.

Any thoughts on what would be most helpful or what you would like to see?"
"Launch a GPU-backed Google Compute Engine instance and setup Tensorflow, Keras and Jupyter",0,2,False,False,False,learnmachinelearning,1503181216,False, 
A simple example of how to use Keras on Cloud ML Engine:,0,1,False,False,False,learnmachinelearning,1503181344,False, 
How would I go about training a model to detect/outline where joints are on a picture of a hand?,0,1,False,False,False,learnmachinelearning,1503183397,True,Would a CNN be a good place to start with this? Not sure where to go really because I know I'd have to manually label a bunch of images of hands but don't know where to go after that.
Multivariate imputation and matrix completion algorithms implemented in Python,0,5,False,False,False,learnmachinelearning,1503197316,False, 
Preparing for full-time roles in deep learning/machine learning,1,1,False,False,False,learnmachinelearning,1503199056,True,"What are the good ways/resources for preparing for full-time roles in machine learning/deep learning?

I come more from a statistics background but have taken many machine learning/deep learning classes and currently doing deep learning research internship at silicon valley company. But I am not trained as software engineer/traditional CS student and thus not sure how to prepare for coding components of the interview. Should I prepare for coding as in the same way as software engineering interview? Any resource/insight/suggestion would be greatly appreciated. "
How To Become A Machine Learning Engineer: Learning Path,0,1,False,False,False,learnmachinelearning,1503219466,False, 
Large number experiments in R with full code,0,6,False,False,False,learnmachinelearning,1503219511,False, 
Newb wanting to get into ML,15,10,False,False,False,learnmachinelearning,1503229275,True,"Hey guys, first time posting here. I just recently got into ML after watching vids on YT by caryekh and sentdex. I was wondering how I should start. Until now I read a book called ""make your own neural network"" which reinforced my desire to get into ML (I wouldn't recommend it tho. It's really really basic and it didn't quite help me as much as I knew most of it already), I've been tinkering around with the MNIST dataset in python and numpy doing all multiplications with matrices and I've watched sentdex's ML playlist.

Now my question is: Where should I go from here? Read papers on ML? Get into Tensorflow? Something else?

I'd very much appreciate your help and support :)"
Towards Artificial General Intelligence: Oriol Vinyals,0,1,False,False,False,learnmachinelearning,1503229327,False, 
trying to track and recognize hand gestures,1,2,False,False,False,learnmachinelearning,1503248071,True,"Hello

I am trying to perform some sort of hand gesture recognition.
In order to do so I need to:

1) detect the hand in an image 

2) track the hand and analyze its gesture

-  In order to do step 1 I am using support vector machine. I start by computing the HOG of all my training data (5 positives and 5 negatives so far for the first tests) and use the obtained results to train my SVM-classifier.

      - my 5 positive images: http://imgur.com/a/rXK8o
      - my 5 negative images: http://imgur.com/a/BFDUR (which are supposed to represent the environment of where the people are whose hands we are going to track)

- Once I detected the hand I can try the track it. I am planning to use a particle filter to track it and an SVM to recognize which symbol is being shown by the hand

- later I'll try to recognize gestures. Maybe based on the acceleration of the hand gesture or some other kinematics. Need to do some research about what could be the best.

I am surprsed that the matrix containing the HOG's is so big: 10x22680

Could someone give some feedback on my approach?

Thanks!



"
Overview of most used algorithms in Machine learning,1,5,False,False,False,learnmachinelearning,1503248338,False, 
Prerequisites for reinforcement learning + tutorials?,2,8,False,False,False,learnmachinelearning,1503254331,True, 
Kaggle Ensembling Guide | MLWave,0,1,False,False,False,learnmachinelearning,1503279066,False, 
Where do I start with this data? Win or lose using certain players in a game,1,1,False,False,False,learnmachinelearning,1503289321,True,"I spent a few weeks learning the importance of clean data. I think the scrapper I modified is collecting data correctly. I can run it through vowpal wabbit to get the best character choices (feature selection), but I'd like to validate the results using another ML framework. What kind of algorithm should I use? Where do I start?

This is literally the first project where I'm starting from scratch instead of building on someone else's work, so I don't even know the right algorithm or framework to use. I was hoping to do something in python using TensorFlow. Thank you and god bless."
Systematic way of self learning ML from scratch?,8,16,False,False,False,learnmachinelearning,1503292519,True,"I'm a student from CS who has no introduction to ML, other that knowing the power of it, and the fact I will be left out in the competition if I don't know it. 

I wanted to learn ML. Since there are a ton of resources to learn Machine learning, I wasn't able to determine a proper method of learning it. 

Any suggestions or a mind map of how to going about learning ML on my own?"
"New to machine learning, how can I do this?",5,2,False,False,False,learnmachinelearning,1503303490,True,"So, I'm pretty new to machine learning (meaning I have no idea how anything is done) and I want to make a network(?) that can find from a ""before"" and an ""after"" inputs, if the after string was a simple typo fix or a message deletion.

If you didn't understand what i just said, here's some examples of what I'm trying to make:

before: ""Welcom"", after: ""Welcome"" -&gt; typo fix,  
before: ""How did you do"", after: ""How did you do that"" -&gt; typo fix  
before: ""I am dumb"", after: ""del"" -&gt; message deletion.  
before: ""You suck"", after: ""asdasd"" -&gt; message deletion.

So yeah, how can I do this? I'm planning to make it in Python."
I've Got a Lot of Questions,2,3,False,False,False,learnmachinelearning,1503305277,True,"•	Are there any Weights Libraries, I mean Neural Nets Are Trained on Huge Datasets and then Implemented into Products, Services and Research so, are there any libraries of Pre-Trained Neural Nets that we could use 

•	How can we tackle an ML Problem if the Data is Heterogeneous or Complex or Recursive? Like can you use a Neural Net to Solve Definite Integrals?

•	What are the ways we can prepare and feed data sets into TensorFlow?

•	Projects that involve Generating Insights or Further building on Trained Data? What are the ways we can acquire outputs?

•	Can we combine multiple Neural Nets into a Modular Pipeline to Process data? "
Machine Learning - Hands-On Python and R In Data Science,1,5,False,False,False,learnmachinelearning,1503305361,False, 
Reasoning about ML possibilities w/ our data,0,6,False,False,False,learnmachinelearning,1503315162,True,"You're a company (my company) that buys and sells big machines, called ForgePresses. The whole idea is that **you buy the machines after a decade of abuse, fix the things that need fixed, and resell them**. The average reconditioned ForgePress costs between $25,000 to $75,000 to fix up, and then sells for around $200k. Between shipping and repurposing, that means you need to buy them for $100k or so.

You have a problem. **Competitors from China and India have gotten into the game**, and competition for the used machines is fierce. The increased competition means bidding wars for used machines on the market, driving up prices to unprofitable levels.

So you start looking for machines that AREN'T on the market - pre-market, used ForgePresses. This is where machine learning comes in.

Each ForgePress has a unique serial number. You have the record for every machine owner from the manufacturer, and a record of every sale in the past six month. You also have three kinds of maintenance records indicating the machine may be having some problems.

Easy, right? Just market to every single owner, every single time there's a new maintenance record! Well, you're not the first person to think of that. Additionally, it can take months or years for these owners to finally sell their machines (or they keep fixing them and never sell). **How can ML help identify the highest-probability ForgePress owners that are about to sell their used machines?**

So that's where I am. I have data, but I don't know how to use it! My ideal scenario is that I have a self-updating predictive model, using the constant stream of sales/maintenance data into my database, that notifies me when a high-probability owner is flagged in the system. Then I can direct a marketing blitz their direction before competition arrives.

My thoughts mostly revolve around tracking purchase/sales dates vs. maintenance dates. I also have the maintenance records indicating some kind of distress with the machine, and I know if they have on-site technicians.

My biggest challenge is knowing how to pick my dependent variable/target variable, and then what information to tease out of my dataset to help predict. Any inputs?"
Come learn about the Confusion Matrix!,0,1,False,False,False,learnmachinelearning,1503330503,False, 
"Take a listen to Bonsai Co-Founder &amp; CEO Mark Hammond describe ""Machine Teaching for Better Machine Learning"", TWiML Talk #43",0,4,False,False,False,learnmachinelearning,1503335568,False, 
Lecture on How to build a recognition system (Part 1): best practices,0,12,False,False,False,learnmachinelearning,1503335593,False, 
Neural Network for Group Membership?,6,8,False,False,False,learnmachinelearning,1503338426,True,"## The Data:

Lets say I had a dataset from an online shopping platform with the following tables:

**Transactions:** each row is a purchase made on a shopping website:

| transaction_id | customer_id | product_key | price | product_name | 
|----------------|-------------|-------------|-------|--------------| 
| 00001          | 3424        | 3254325     | 19.99 | ""blue jeans"" | 
| 00002          | 3123        | 3214321     | 3.00  | ""socks""      | 
| 00003          | 9982        | 2134551     | 33.33 | ""sneakers""   | 
|...|

**Classes**: A mapping of customer_id and true class:

| customer_id | true_class          | 
|-------------|---------------------| 
| 0001        | non\_problem\_shopper | 
| 0002        | non\_provlem\_shopper | 
| 0003        | problem_shopper     | 
| 0004        | problem_shopper     | 
| 0005        | problem_shopper     | 
| ...         |                     | 

## The Goal:

My goal is to categorize specific customers as ""Problem Shopper"" (addicted to online shopping) or ""Non-Problem Shopper"".

Is there a way that I can feed my transaction data as shown above into an artificial neural net and get predictions as of ""Problem Shopper"" or ""Non-Problem Shopper"" assuming I had a list of customer_id's that were true problem shoppers for training and testing. Like so:

| customer_id | true_class          | predicted_class     | 
|-------------|---------------------|---------------------| 
| 0001        | non\_problem\_shopper | non\_problem\_shopper | 
| 0002        | non\_provlem\_shopper | problem_shopper     | 
| 0003        | problem_shopper     | problem_shopper     | 
| 0004        | problem_shopper     | non\_problem\_shopper | 
| 0005        | problem_shopper     | non\_problem\_shopper | 
| ...         |                     |                     | 

I have experience doing binary classification problems with typical training and testing sets but in this case I want to use all of the information contained in the _transactions_ table but then predict the class by just giving the algorithm a set of customer_id's.

## The Question

How can I structure the data and/or neural net to learn from the entire transactions table _but make predictions solely based on the customer\_id_?

Any suggestions, tips, resources, etc. in general would be greatly appreciated. Thanks!"
Lecture. Evolution: from vanilla RNN to GRU &amp; LSTMs,1,5,False,False,False,learnmachinelearning,1503339603,False, 
Question about vector size in word2Vec,6,1,False,False,False,learnmachinelearning,1503387563,True,"I am studying word2Vec and somewhat confused with the size of the word vector. In the explanation that I am reading, it says,

All of these words are one-hot encoded meaning they are vectors of length V(the size of the vocabulary) with a value of at the index corresponding to the word and zeros in all other indexes. 

When it says ""size of the vocab"" what exactly is the size? Is it  all possible list of vocabulary? But in this case wouldn't it be too huge? I need some clarification here. Thanks"
Free eBook: Practical Machine Learning (PDF/ePub/Mobi),0,20,False,False,False,learnmachinelearning,1503389805,False, 
Ensemble Learning to Improve Machine Learning Results,0,13,False,False,False,learnmachinelearning,1503406539,False, 
I want to learn Robotics AI !,1,0,False,False,False,learnmachinelearning,1503409009,True,"Hello everyone,

I am totally new to AI and machine learning, and i have no idea about it, but i want to learn it and know how to build applications using it.

I'm interested in AI in the robotics field, such as these Autonomous cars and Drones, self walking robots, etc.

so could someone that has a good knowledge in the field to guide me where to start and learn about it ?? books, videos, sites, anything that is useful and good to learn !

thanks."
LSTM net generating only zeroes,0,2,False,False,False,learnmachinelearning,1503423664,True,"Hello,

I am a complete beginner and I'm trying to make an LSTM neural net with keras to generate spectrograms like [this.](http://i.imgur.com/LlVMBID.png)

My model looks like this:

    model = Sequential()
    model.add(LSTM(780, batch_input_shape=(args.batch_size, args.seq_len, args.features),
        return_sequences=True,
        stateful=True,
        activation=""tanh""))
    model.add(LSTM(780, return_sequences=True, stateful=True, activation='tanh'))
    model.add(LSTM(780, stateful=True, activation='tanh'))
    model.add(Dense(args.features, activation='tanh'))
    model.compile(loss='mse', optimizer='rmsprop', metrics=['accuracy'])

For training I tried feeding it an hour long spectrogram (69x324001). I am using sequence length of 30. The features parameter is the number of frequency bands, in this case 69.

I also normalize the data to the range (0, 1).


And I'm generating from it like this:

    pred = np.zeros((1, 5050, 69))
    
    for i in range(30):
        for j in range(69):
            pred[0][i][j] = random.random()
    
    for i in range(1000):
        p = model.predict(pred[:, i:i+30, :])
        pred[0][i+30] = p
        for j in range(69):
            print('%.2f ' % p[0][j], end='')
        print('Size: %d' % p.size)
    
    pred = pred * 255
    pred.astype('uint8').tofile('test.bin')

The problem is that this is always generating only zeroes - silence.

I also notice that nets for generating text often use one hot encoding for output. Should I try to do this? Would that mean that the output would be 69 vectors of lenght 256? Is that practical? (sounds too big to me). Are even LSTM nets suitable for this type of task?

"
[Python] How do you select your classifier?,2,12,False,False,False,learnmachinelearning,1503428871,True,"What's your strategy for selecting your classifier for a problem you are working on?

Let's say I am working on a simple text classifier with 3 outcomes (70% positive, 10% neutral, 20% negative).

I use Python and Scikit-Learn.  First thing I do is look at my handy [scikit-learn chart](http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) and see NaiveBayes is what's recommended for text and apply Multinomial Naive Bayes with default parameters and receive an F1 score of 72% (on my test set).  I plug into my pipeline an SVM (SGD Classifier), Random Forest and Decision tree Classifier and they all yield F1 scores of 0.79-.81 so they initially seem better choices.

So I take the top 1-3 classifiers from this broad scoping and run a Cross Validated Grid Search and see which yields the best results.

The best of those is what I then use on my newly trained model for all future data.

---

Is there a better way to select your classifier?"
TWIL (This Week I Learned) - Share something new that you have learned this week!,4,3,False,False,False,learnmachinelearning,1503471914,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
"In Keras, how can i pass additional data that i can access in the loss function?",3,4,False,False,False,learnmachinelearning,1503490382,True,"I need my loss function to behave differently for some samples, so my plan was to pass a few variables along with each sample and then reference them in the loss function. 

i modified my model to have two inputs, the first takes the training data and the second takes the extra variables, and reference the second input by name in my loss function:
vars=Input(shape=(10,1))
model2=Model(inputs=[model.input, vars], outputs=model.output)

1. Is this a reasonable way of passing information to the loss function?
2. Will keras actually update ""vars"" for each sample when training in batches?(i.e. in the loss function, will vars refer to a tensor of size (10,1) or (batch_size,10,1)?

The loss returned  is unusually high and I'm not sure where I'm going wrong."
Coursera Deep Learning Specialization,33,20,False,False,False,learnmachinelearning,1503493485,True,"How are people liking the new Andrew Ng specialization?

I just finished the first assignment and am finding it way more polished than past courses."
DNN: Fixed length string to fixed length string mapping,0,8,False,False,False,learnmachinelearning,1503495236,True,"I have a situation where I'd like a DNN to learn the [unknown] mapping between two fixed-length strings. For example:

    ""-+--++-++-"" -&gt; ""968""
    ""+-+-+-+-+-"" -&gt; ""185""
    ""-+-+-+++--"" -&gt; ""766""

I can take the input string and convert it into the numerical inputs required by the DNN but I'm not sure how to structure the output layer (I'm using Keras).

Assuming the output string is 3 characters long:

    model = models.Sequential()
    model.add(layers.Dense(x1, activation='relu', input_shape=(N,)))
    model.add(layers.Dense(x2, activation='relu'))
    ...
    model.add(layers.Dense(3, activation='???'))
    
1. I'll need a way to convert the 3 outputs back into characters.
2. I can't seem to figure out which activation function I should use.    
3. I'll also need to choose appropriate optimizer and loss functions

 --

        model.compile(optimizer='???', loss='???')
    "
Image spatial relationships in ML classifiers,4,8,False,False,False,learnmachinelearning,1503496322,True,"I use classifiers such as Random Forests and SVM to classify aerial imagery and other similar spatial data. I use R, and my primary approach is to vectorize my raster data prior to running it through the classifier. This approach obliterates any spatial relationship between cells. To account for this, I typically include some derivative grids that use different focal statistics or GLCM data (with different neighborhood sizes) that can recapture some of the neighborhood spatial variance for each cell.

I'm interested in learning more about ML classifiers that inherently capture/consider the spatial relationship of the data so I can retire my vectorized approach. I'm assuming that computer vision / NN algorithms do capture the spatial component, but I have not yet found good resources that discuss this in a way that helps me plan for feature engineering and workflow implementation.

I'm looking for some recommendations on reading that can help me get up to speed in this arena. Thanks."
What are some practical reinforcement learning tutorials for people familiar with ML?,2,11,False,False,False,learnmachinelearning,1503499476,True,"A lot of courses I've come across seem too rigorous in that they delve quite a bit into the theoretical aspects of RL (not that that's a bad thing -- it's great to take deep dive into the mechanic of it all). 

I'm looking for a course/tutorial that's light on theory and big on the implementation. I realize this isn't quite ideal, but I'm really just trying to just have fun and gain an intuition for RL algorithms before taking the dive. What are your suggestions?"
Histograms - how to build them.,0,7,False,False,False,learnmachinelearning,1503513645,False, 
Any good tutorials out there for Twitter bots?,0,7,False,False,False,learnmachinelearning,1503521561,True,"I want to start with one, then go ten, one hundred etc. See how they work in the real world, etc. 

Thanks!"
Question on how to organize nodes in my maze running AI.,0,2,False,False,False,learnmachinelearning,1503525502,True,"Im trying to make a network of nodes so I can experiment. 

Im using javascript. I have created a maze generator, the maze is represented by an array like :

    maze = [0,0,0,1,0,0,1,1,1,0,1,... etc]

Then I have a few functions that build up a network

    buildNode() {} //returns an object {weight:random, value:random, threshhold:random}
    buildLayer(nodes=6) {} //returns an array of nodes
    buildNetwork(layers=3) {} //returns an array of layers

So the NN looks like a matrix :

    [
        [
            [{initial layer, node 0}, {initial layer, node 1}, {initial layer, node 2}, etc...]
        ],
        [
            [{2nd layer, node 0}, {2nd layer, node 1}, {2nd layer, node 2}, etc...]
        ],
        [
            [{nth layer, node 0}, {nth layer, node 1}, {nth layer, node 2}, etc...]
        ],
        [
            [{output1},{output2},{output3},{output4}]
        ]
    ]

So, finally, my questions :

1) Should the maze array be the initial layer?

2) Should the position (maze index) of the AI be in its own layer, be in the initial layer alongside the maze data, or what?

3) Same question, but for the goal position.

4) Im thinking structure it like this :

    [ initial layer = maze data {},{},{}...(thousands of these) ] -&gt; 
    [ { 1 node representing current position }, { 1 node representing goal } ] -&gt;
    [ hidden layers {},{},{}... ] -&gt;
    [ output layers {},{},{},{} ]   //up, down, left, right... Highest value wins.

Thoughts?
"
[Java/Naive Bayes]Training a Naive Bayes model for text classification,3,3,False,False,False,learnmachinelearning,1503532140,True,"Hello,
I wanted to create a simple text classification program with Naive Bayes so I searched around on github and found a Java implementation.Now my question is this,do I have to train the model every time I compile/run the program or is there a way for the model to remember what it has been taught even after exiting?
Can it even been done that way?
Here is the code:
https://pastebin.com/6SiUaB1Q

Thanks"
Machine Learning project advice (OpenAI Universe or Adverserial Attacks),1,2,False,False,False,learnmachinelearning,1503536262,True,"I have a taken machine learning course and it has a pretty significant Project component. Me and my team are exploring options and we are mostly beginners in the field but have some basic knowledge about DL, RL, GANs etc.

We have found a couple of things that interest us. One is the [OpenAI Universe](https://universe.openai.com/). It seems like a good idea which gives us scope to explore but not work on something completely new that we might not be able to handle. However [this](https://blog.aqnichol.com/2017/06/11/why-im-remaking-openai-universe/) post seems to suggest it's abandoned now.

Another option was the NIPS competitions on [Kaggle](https://www.kaggle.com/competitions) regarding adverserial attacks. 

Any advice about these topics or any new suggestions are appreciated."
Viability of using survival analysis / anomaly detection results as inputs in a binary classification model,0,1,False,False,False,learnmachinelearning,1503558276,True,"Hi everyone, long time lurker, first time poster so please provide gentle feedback if this posts doesn't fit the criteria or belongs elsewhere.

Is there any benefit to creating different models that attempt to detect anomalies or ""time to event"" (using the same raw data that is available for a classification model) and then use the resulting values as inputs for the  classification model? That could be one (or more) categorical variables for anomalies (per-variable anomaly detection as simple as three-sigma or something more elaborate for a whole record) and a numerical variable for the time-to-event prediction.

Can you point me towards any blog posts or papers that have implemented something like this? Or is that kind of feature engineering pointless due to ""double-dipping"" in the same source data? 

I am going to just to try this out to see if it helps in practice, but would love to hear opinions and find theoretical background information and experience reports on this. 

Whenever I try to search for something with both classification and a different kind of tasks in the query I just seem to find ""what is ML"" overviews or guides that help you select the right model for a task, but nothing on combining them or using one as input for the other. I think this is also distinct from ensemble learning since this is not about aggregation of multiple models for the same task.



"
Floydhub Documentation- A cloud platform to run various ML models,1,7,False,False,False,learnmachinelearning,1503576674,False, 
Which conclusion can be drawn from this error curve?,6,1,False,False,False,learnmachinelearning,1503601205,True,"Is there anything you can conclude from my [error curve!](http://imgur.com/a/ua7En)
or 
[network!](http://imgur.com/a/gD3Bf)
what I can do do reduce the error further? Training is really sensitiv, e.g. changing the momentum from 0.925 to 0.95 produces only NaNs. Therefore it is a nasty training, so improving further is hard, but maybe somebody has an idea or something is ""wrong"". If it is helpful, I am training my Autoencoder with sparse input vectors. Error drops heavily, because I implemented a scheduler which drops the learning rate if the training performance does not improve within ten steps. Some parameters:
Batchsize: 128,
LR: 0.001 (SGD),
Size Trainingset/Testset: 25k/5k,
momentum: 0.925,
Weight Decay: 1e-6

Edit: I am training an Autoencoder to reproduce sparse input data (~30% of values are non zero), which fallow a specific (gaussian) distribution.
It is quite confusion that my error does not increase on my testset?! Is this sometimes usual?

"
Data Analysis Course Help,0,1,False,False,False,learnmachinelearning,1503601984,True,"Do you guys think this course is worth the money?

https://www.ucsc-extension.edu/certificate-programs/offering?offering_id=5594497&amp;offering_name=Data%20Analysis%2C%20Introduction"
Python for Data Science and Machine Learning Bootcamp,0,25,False,False,False,learnmachinelearning,1503603387,False, 
Detailed derivation of mean field variational inference?,0,2,False,False,False,learnmachinelearning,1503606932,True,"Hey all,

Is there a detailed introduction to mean field variational inference that goes through all the steps? This one I'm reading focuses on the Gaussian clusters model but skips a lot of steps in getting the equations. Thanks!"
How is it possible for the loss to converge but the gradient norm of the parameters to increase during training in Deep Learning?,0,2,False,False,False,learnmachinelearning,1503611687,False, 
Machine Learning Playground - visualize ML algorithms on a toy canvas,0,1,False,False,False,learnmachinelearning,1503629205,False, 
Weekly Show-off!,0,6,False,False,False,learnmachinelearning,1503644720,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
Operating system principles,0,2,False,False,False,learnmachinelearning,1503685570,True,[deleted]
Need help with reading subtree assessment plots,0,1,False,False,False,learnmachinelearning,1503685641,True,"I have used a decision tree model on my data set using SAS Enterprise Miner. Upon examining Misclassification error and Average Square Error, I see the following.

Not sure where the optimal number of leaves would be. Sometimes I feel it would be at 4 leaves or 14 leaves. http://imgur.com/a/QAYah

How does one determine optimal number of decision tree leaves in a smooth curve like this http://imgur.com/a/lxRah"
"How to classify neural networks (Supervised, Unsupervised, Reinforcement)",5,5,False,False,False,learnmachinelearning,1503685763,True,"We have various neural networks and various styles of machine learning. Is the following table correct?

Are ANNs, CNNs, RNNs, and GANs forms of supervised neural networks? Can those NNs be used in an unsupervised manner?"
My ML journey and resources so far,2,13,False,False,False,learnmachinelearning,1503695360,False, 
How skilled you must be in Machine Learning to find a job ?,6,1,False,False,False,learnmachinelearning,1503695817,True,"Hello everybody,

the title might be enough I think, but I would like to know what are the required skills to find a job in Machine Learning's field. I am majoring in applied maths and maths applied to finance, and I have : - basic skills in Python and C++ - basic knowledge of optimisation (convex optimisation, KKT's conditions...) and operations research - numerical integration of ODE and PDE - strong background in probabilities and stochastic process - knowledges in Machine Learning. I had a 6 months class this year, and I am refreshing my memory with the Stanford's MOOC (but it is far too slow even for a non native english speaker). It is less difficult than the classes I had. -Oh, and statistics too.

For the redditors who managed to get a job in Machine Learning or Machine Learning/applied maths field : I had a class, but I have absolutely no idea what kind of skills a compagny need. What kind of skills do you have ? I am a little bit affraid, what if everything I learnt is useless, to superficial ? Would have been better to learn only C++ and MALAP instead of a mix between Maths and CS ?

Thank you very much for you answers.
"
Awesome Deep Learning Resources,1,42,False,False,False,learnmachinelearning,1503718814,False, 
"Weekly Status Check Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",0,2,False,False,False,learnmachinelearning,1503731115,True,"Let's have a  meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
Implementation of NEAT using tensorflow,1,3,False,False,False,learnmachinelearning,1503732066,False, 
Summarizing text with Case Based Reasoning,0,1,False,False,False,learnmachinelearning,1503754373,True,[deleted]
"I want to build a deep learning MOOC on visual recognition, and I want to see if there's interest.",0,1,False,False,False,learnmachinelearning,1503767050,True,[removed]
Classification with multiple sub classes,2,3,False,False,False,learnmachinelearning,1503767085,True,"Hi,

I am currently trying to think of a way to create a CNN or multiple to help me with classification of items. The problem I currently have is that every CNN I have seen so far has classification but not on sub-classes. To give you an example here is what my classes look like.

-Class1 

--Sub-class1

---Subsubclass1

---Subsubclass2

--Sub-class2

---Subsubclass1

---Subsubclass2

---Subsubclass3

--Sub-class3

---Subsubclass1

---Subsubclass2


-Class2

--Sub-class1

---Subsubclass1

---Subsubclass2

---Subsubclass3

--Sub-class2

---Subsubclass1

---Subsubclass2

---Subsubclass3

--Sub-class3

---Subsubclass1

---Subsubclass2

---Subsubclass3

---Subsubclass4

And this list has about 15 classes which almost all have sub-classes and subsubclasses. The problem is that for every set of subclasses a class has and for every set of subsubclasses a subclass has I have to create another CNN to identify those. Also making classes of all the subclasses makes it too close together I think. What are some common solutions to this? or what options can I try?

Thanks"
"Would you be interested in a deep learning MOOC focused on theory and turning research papers into real, working code?",26,109,False,False,False,learnmachinelearning,1503768465,True,"Edit: Thanks for all the interest! If you want to get an email link to the course when it's ready, please sign up on this Google Form: https://docs.google.com/forms/d/e/1FAIpQLScFol5PqDV4y3Z0-pAqP5OoxXbH5BS2OSTpdMdSnqdWSrAG0g/viewform. Thanks! No spam I promise. Just the best content I can possibly produce to help you learn :)

Feedback I've gotten from Reddit so far:
* Make the math intuitive and fun. Don't gloss over it.
* Introduce topics like Deep Reinforcement Learning. This is something I probably won't do in the course because my focus is on depth, not breadth. I feel like if students complete my course, they'll be prepared to read research papers to tackle deep reinforcement learning on their own and produce working projects. I want to focus on making students strong fundamental practitioners of visual recognition with convolutional neural networks.

Hi Redditors! First off, I love this community where we share great resources to learn deep learning. I've been doing deep learning for 2 years now, and I work on an AI team that uses the latest deep learning research. Acquiring this knowledge and experience required going down lots of rabbit holes, and after talking to my colleagues, I realized this is a common problem that many deep learning enthusiasts face.
I'm thinking of creating a deep learning MOOC on one of the online learning platforms (e.g., Udemy, Teachable, etc.), and I wanted to get feedback on whether or not engineers, data scientists, product managers, and people generally interested in AI would want a course with the curriculum below. While there are plenty of great deep learning MOOCs on Coursera, Udacity, university websites, and others, I find that most, if not all, of them either focus heavily on theory without a lot of guidance on practical coding or focus heavily on coding without a lot of theory. Thus, upon completion of the course, students are either clueless as to how to translate the latest deep learning research into real code or have simply learned how to call a bunch of functions in Tensorflow without a true understanding of how to train a good deep learning model.

In essence, I want to build the MOOC that I would have wanted to obtain a fundamental grasp of knowledge and experience equivalent to those obtained by masters students at CMU, Stanford, and Berkeley were they to take a course in visual recognition with deep learning. Another differentiating factor is I've already been teaching those around me about deep learning, and I often get feedback that I make seemingly complex concepts appear simple and intuitive. I want to do this on a wider scale so that everyone can get into deep learning without the false notion that you can create something cool only after completing a masters or PhD in artificial intelligence. Creating a really good course will take hundreds of hours, so I want to make sure there's demand for this before I pursue it. What do you think?

Note: The curriculum below is a rough draft.

1. The Essence of Computer Vision
* What is computer vision?
* Introduction to pixels
* 2D Images as 2D Math Functions
* Color Spaces
* Image Filters
* Lab: Create your own Photoshop-like image filters (Gaussian blur, sharpening

2. Neural Networks
* Linear Regression
* Logistic Regression
* SVM, Softmax, and Information Theory
* Gradient Descent
* Deep Neural Networks
* Backpropagation
* Universal approximation theorem
* Regularization with L2 regularization and Dropout
* Lab: Implement an image compression algorithm with a deep neural network

3. Convolutional Neural Networks
* Convolutional Layers
* Pooling Layers
* Lab: Implement LeNet with Tensorflow and run on MNIST
* Visualizing convolutional layers
* Lab: Implement AlexNet with Tensorflow and run on CIFAR10
* Batch Normalization
* Lab: Feature extraction with VGGNet, ResNets

4. Object Detection and Image Segmentation
* Lab: Work through paper on R-CNN and implement it in Tensorflow
* Lab: Work through paper on Fast R-CNN and implement it in Tensorflow
* Lab: Work through paper on Faster R-CNN and implement it in Tensorflow
* Lab: Work through paper on Mask R-CNN and implement it in Tensorflow"
Data Analysis Classroom — A free online platform to learn data analysis,0,10,False,False,False,learnmachinelearning,1503769059,False, 
Why is experience replay supposed to be better in reinforcement learning?,6,2,False,False,False,learnmachinelearning,1503769912,True,"I don't get why feeding experiences to the NN training in a non-ordered way is supposed to be better in Q-learning.

Intuitively I feel like Last In First Out would be the best order. If we train first with the terminal states the network will be better at estimating future rewards for the states that led to them, which will make the loss converge faster.

Why is it better to use experience replay?"
Cost's not decreasing much when i apply Batch Normalization to Negative values in dataset,0,1,False,False,False,learnmachinelearning,1503776173,True,"First of all here's the code , i've been playing with siraj ravaal's CNN MNIST Code :
https://gist.github.com/omdano/d0700c3fe868c7e4b70f0f822210db96

So basically , i'm using an input of numbers ranging from -1000 to 1000 and predicting x+1 = y , simple , right ? 

Well that alone was fine . However when i apply Batch Normalization (line 85) to the Convolution layers , the whole thing starts crumbling and my cost function isn't getting minimized at all . 

This is what i get when i use batch normalization on -3653 , 143  
[ 4113.74267578]
[ 229.4508667]

however , without batch normalization i get normal outputs .
What am i doing wrong here ? "
Help Generating a Random Cubic Dataset for Neural Networks,2,1,False,False,False,learnmachinelearning,1503782314,True,"Hello! I'm trying to make a custom, random cubic dataset for a neural network. However, I'm having trouble figuring out how.

I could generate random numbers along x^3, but how would i generate noise? If I added a random number from range 0 to 1 to each data point, then wouldn't it just fit x^3 + .5?

Thanks!"
What kind of relationships can (and will) an artificial neural network learn?,4,1,False,False,False,learnmachinelearning,1503819783,True,"I have a basic understanding of neural networks but I can't find a good answer to this. I know that if an input is high then the network can make an output high, but what about a low input (zero)? I'm thinking a bias node can make it high and then when the input goes high a negative weight can make the output low. Maybe the inputs should be between -1 and +1 instead of 0 and 1? What's the best input range is also something I lack a good answer to.

But my main question is about combinations of inputs. Two high inputs may contribute independently to one high output, but what about only when both are high, like an AND gate? Or only when one of them, like XOR? What about an high output when two inputs are close in value?

I'm wondering if an artificial neural network can, and do, learn such relationships, and/or if you should work out such features first and then make them inputs? But what if you don't know them - the point is for the network to learn such things?"
Softmax Layer supporting several classes?,0,1,False,False,False,learnmachinelearning,1503821247,True,"I am looking for a layer which is similar to a softmax layer, but instead ""support"" always a fixed number of classes greater than one.
Let us say I want to determine the position of exactly 4 objects in a vector of size 20. So the most weight of the layers output should be moved to those four positions.
Are there any ways to exploit a softmax layer or other ideas?"
Help with figuring out test cases for a neural networks assignment,4,2,False,False,False,learnmachinelearning,1503849514,True,"I have taken a neural networks course and have been given an assignment to take some sample code, try to figure it out and write a report on it. 

My searching led me to www.neuralnetworksanddeeplearning.com and the written digit recognition code on it. The code in concern can be found [here](https://notepad.pw/neuralnetworkscode) and the code to load the data can be found [at this address](https://notepad.pw/dataload). 
I do not understand the test data is related to the code, or even what format the data is in. Is it a data structure? Because the training data is supposed to be a set of images.

I haven't worked with neural nets before so it'd be great if it could be simplified for my understanding."
Looking for resources for a specific kind of ML learner,6,6,False,False,False,learnmachinelearning,1503858200,True,"I'm trying to learn ML, specifically as it relates to AI ethics, and I've heard that the best way to start is to start implementing models in TensorFlow. However, I'm confused as to how to go about this:

* Where are the best intuitive explanations of the basic components of ML? (e.g., terms I keep seeing everywhere, like hyperparameter and 
* What math background do I *need* (or would find so useful that it's basically a need) going in? How much calculus, how much linear algebra, etc? I'm coming at this partway through high school calculus, but I'm trying to work ahead using Brilliant.org. Any good exercises and explanations are appreciated.
* Online books and exercises (I'd prefer non-MOOC courses and free resources) that mix theory and practice in a useful way.
* Hardware: would an NVIDIA GTX 970 suffice? Or do I need something higher-end? How would I connect to/use a higher-end one?

I'm looking particularly for resources specific to my level. Too much explanation would be preferable to too little explanation.

**TL,DR: what does a high-school calculus student need to do upfront to start building and playing with ML models at home?**"
Book for beginner,2,2,False,False,False,learnmachinelearning,1503882222,True,"Hi, I know absolutely nothing of ML but would like to learn (self taught). I just started with this book ""A. C. Muller and S. Guido - Introduction to Machine Learning with Python - 2017"".

I would like to know your opinion of it. Is it a good book for beginners?

Some other information about me: Math, unless is awfully specific, wouldn't be a problem, I did an engineering degree so that should cover it. Also, I am not a programmer, but I have experience programming with Python before."
"Is CTC just training an RNN on existing alignments, and then having a step that readjusts the alignments based on the predictions it then gives?",0,5,False,False,False,learnmachinelearning,1503883876,True,"So just normal EM?

Am I correct in that the main contribution is the idea of doing so with RNNs plus backpropagating across several frames (from the best path)?

Also they compare to results to just an HMM, shouldn't it be an HMM/GMM?"
Path to Learning Machine Learning,2,7,False,False,False,learnmachinelearning,1503889820,True,"Hey, I'm sure this has been discussed before, but I couldn't find anything specific, so I apologize in advance.

I am about to enter my second year in Computer Engineering in university, but would like to focus more on ML (which I believe is covered more in Computer Science). Thus, I'll have to do a lot of independent work/study.

My current experience in programming was an introductory course in C and a bit of Java I taught myself (which I'm currently pursuing). Also, my current mathematical background is up to Calculus II and Linear Algebra. However, I'm not quite sure what to do now other than learning more of Java. What is a sequential path I can take towards learning ML? "
Help with IMDb sentiment analysis,0,3,False,False,False,learnmachinelearning,1503898451,True,"So I was trying out a [sentiment analysis tutorial](https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words) from Kaggle. Thing is I am getting absolutely terrible results for my submissions. (53-56%) Could someone point out where I am messing up? In fact not only the Random Forest approach suggested in the article, but also an ANN approach I tried on my own seems to give me results in the same range (~0.54). [GitHub](https://github.com/abnan/IMDb-Sentiment-Analysis/blob/master/2.%20Bag%20of%20words/Sentiment_analysis_bag_of_words.ipynb)"
Docker Compose + GPU + TensorFlow = ❤️,0,3,False,False,False,learnmachinelearning,1503928839,False, 
Any docker-image for deep learning?,0,0,False,False,False,learnmachinelearning,1503933713,True,"Is there any docker image that consists of all deep learning and computer vision tools such as opencv, keras, tensorflow, theano, etc??"
Text Classification: how to constantly train,4,13,False,False,False,learnmachinelearning,1503942740,True,"I'm just trying to learn how to classify text and been through several tutorials. but I just been googling for some time and found no answer to how to keep feeding the model with data so the classification can get more and more precise. 


My goal is to use it to pre-fill a form where it should pre-select a category for the input text then, when the user submit the form, I would check if he changed the category or not so I could ""teach"" the right answer/reinforce that the current classification was right or not.

Most recent tutorial I tried was [this one](https://medium.com/towards-data-science/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a).

Well, is that a thing or am I mistaken? Does it need constant inputting of data? "
Pulling data from receipts,5,2,False,False,False,learnmachinelearning,1503942871,True,"I am completely inexperienced in machine learning and would like to gain some experience in the field with a personal project. I was hoping for some advice on common tools, approaches and or guides that might help me accomplish this project idea:
Using machine learning to pull data on purchases from receipts stored as text documents. These receipts may differ in format.
Any help or direction would be greatly appreciated. I've tried googling this problem without much success. I have a few years of software development experience mainly in .NET and NodeJS."
Smallest Cross-Validation Code :,0,4,False,False,False,learnmachinelearning,1503945424,False, 
Best tools for machine learning coding?,0,1,False,False,False,learnmachinelearning,1503955644,False, 
PCA: clarification question about extracting eigenvectors from svd function.,3,0,False,False,False,learnmachinelearning,1503967068,True,"    [U,S,V] = svd(A);

I've seen different texts/implementations use the matrix U as the eigenvector matrix, and some use matrix V. From what I understand (which is relatively little, so please correct me if I'm wrong about any of this), S[ i,i ] is the corresponding eigenvalue for the ith column of the eigenvector matrix. Whether that index is U[ i ] or V[ i ] I am unclear on, but in most examples I've seen U and V are nearly identical matrices. So does it really matter? Is there an incorrect choice of matrix?"
Attention Mechanisms in Recurrent Neural Networks (RNNs) - IGGG,0,10,False,False,False,learnmachinelearning,1503983992,False, 
How neural network's avoid local minima problem ?,10,13,False,False,False,learnmachinelearning,1504003888,True,Neural networks uses backpropagation to learn and for this purpose employs gradient descent. While using loss function algorithm how latest neural network avoids local minimum and finds the global minimum for a problem?
Training/dev sets which one to use after tuning.,2,4,False,False,False,learnmachinelearning,1504005487,True,In deep learning lets say I trained my NN with training set and i wanted to tune my hyperparameters.After looking results of dev set i decided to change learning rate.After the change am i going to train my NN with training set or dev set to tune NN ?
Getting Started,3,0,False,False,False,learnmachinelearning,1504009962,True,"I recently came up with an idea to implement machine learning because I've grown a fond interest of it. It has to do with machine learning a video game like Sethbling did with Mario. What programming language should I learn for this? Sethbling used Lua. How useful would Lua be? 
(My first time on Reddit. Please excuse my inexperience and bad Reddiquette)"
"Check out the recap of the 1st TWiML Online Meetup, where we discuss the CVPR Best Paper Winner ""Learning From Simulated and and Unsupervised Images through Adversarial Training""",0,8,False,False,False,learnmachinelearning,1504023853,False, 
"This week we have a very special interview to share with you! Sam is joined by Jürgen Schmidhuber, Scientific Director of IDSIA. We covered a lot of very interesting ground in the discussion, including his work on neural networks, especially LSTM’s, general purpose AI &amp; Fizzbuzz in TensorFlow.",0,2,False,False,False,learnmachinelearning,1504035204,False, 
Learning Repetitive Features?,0,3,False,False,False,learnmachinelearning,1504038341,True,"I'm new to this field, and I'm trying to figure out the best way to learn regularly spaced features from data where the entries which are relatively large. Think of each entry as a stock ticker, with ~3000 timestamps, and a uniquely shaped peak appearing every 500 +/- 100 timestamps (note: the data isn't stock ticker data, but I hope this provides an idea of what it looks like.)

My initial thought is to use CNN's, where the kernel size is on the order of 200 - 500, but I'm not as familiar with neural nets as I am with other areas of ML. PCA with clustering is another option, but it seems to work very poorly for any small number of clusters (probably because of the +/-
 100 variation in the underlying data).

Any suggestions are welcome."
Is there an easy way to learn how to create a neural networks with inputs and outputs other than 0's and 1's?,7,9,False,False,False,learnmachinelearning,1504056279,True,"I'm trying to learn from what I can scratch from the internet how to program simple Neural Networks. As for now, I have managed to learn how to do them with hidden layers and how to increase/decrease the nodes using python. The webpages where [this one](https://medium.com/technology-invention-and-more/how-to-build-a-simple-neural-network-in-9-lines-of-python-code-cc8f23647ca1) for the base work and later on [this page](https://iamtrask.github.io/2015/07/12/basic-python-network/).     
Although both very helpfull, I am still stuck at the input/output limitation to just 0's and 1's. Is there any simple beginner-level tutorials/method to implement other numbers or letters into the inputs and that it still makes sense?

More information on my project, if it helps with explaining what I want to do:    
I was thinking of creating a neural network which would predict the human's input at rock-paper-scissors. I thougt of making the different inputs be the ""previously chosen"" options. As you can see, there would be at least 3 different input values necessary or completely reprogram the whole network"
TWIL (This Week I Learned) - Share something new that you have learned this week!,0,3,False,False,False,learnmachinelearning,1504076722,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
Is my SARSA correct?,0,5,False,False,False,learnmachinelearning,1504079260,True,"Thank you for reading this post!  
  
I'm getting into Reinforcement learning, so I wanted to implement some algorithms.  
I found a DeepSarsa implementation along with DeepQ with replay, so I wanted to mix the two so as to get DeepSarsa with experience replay.  
  
However, I'm not sure whether I did this correctly, so I'd be very grateful if anyone could check it out and leave a comment below!  
  
Links:  
1) **DeepSARSA with Replay**: https://github.com/PetarKing/RL/blob/Gym/DeepSARSA_OpenAI-Gym.py  
  
2) DeepQ with Replay:  https://github.com/rlcode/reinforcement-learning/blob/master/4-gym/1-mountaincar/mountaincar_dqn.py  
  
3) DeepSARSA: https://github.com/kengz/openai_lab/blob/master/rl/agent/deep_sarsa.py"
"As a beginner, Here is how I understood tensorflow Linear Regression example better through LibreOffice Calc Spreadsheet application in Linux/Windows",7,11,False,False,False,learnmachinelearning,1504091674,False, 
Data Science and Machine Learning with Python and Spark,0,23,False,False,False,learnmachinelearning,1504099602,False, 
Help resolving a dataframe error for logistic regression,2,3,False,False,False,learnmachinelearning,1504101754,True,"I was attempting to use one hot vectors to make my dataframe useful to pass in specific columns but as you can see it still returns an error: 

Would anyone be able to tell me what i'm overlooking? Test code is [here] (https://github.com/Jsauc/LR/blob/master/Optimize%20Analysis.ipynb)"
Starting to use Pylearn2,1,4,False,False,False,learnmachinelearning,1504104941,True,"I'm trying to create a neural network for the first time. My project plan is to use Pylearn2 but I'm having issues even setuping Pylearn2 after downloading it.
 I am using anaconda on windows at the moment but am not dead set on anaconda.
Any guides or suggestions would be appreciated!"
How a robot finds its location based on what it ‘sees’,1,1,False,False,False,learnmachinelearning,1504176972,False, 
Taking Andrew Ng's Deep Learning course - limited knowledge of ML to begin with... steps?,10,21,False,False,False,learnmachinelearning,1504184128,True,"Hey guys,

I'm taking Andrew Ng's DL course on Coursera right now - seemed like the time was right (although I might have just gone for Fast.ai's version.

One thing I can't seem to find many places is - when it comes to supervised learning - when/where deep learning algorithms best traditional ML techniques.

Do I need to hold my horses and get a better ML overview first?

Familiarity with ML to the extent of deploying SVM models for NLP classification, but not much more."
Understand Classification in Machine Learning,1,4,False,False,False,learnmachinelearning,1504215203,False, 
Weekly Show-off!,3,2,False,False,False,learnmachinelearning,1504249520,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
Thesis About Identification of Rice plant Diseases on Mobile,2,9,False,False,False,learnmachinelearning,1504261716,True,"I'm currently in third year college and just started my thesis 2, and for my suggested title I went with ""Rice plant Disease analyzer"" i was originally planning on building the application on desktop, however upon interviewing farmers( who are the target of my app ) they told me that they prefer a mobile application instead of a desktop app.

upon learning this, my team and I are now tweaking our documentation and are now planning on developing a mobile application on android instead.


Now my problem here is I have zero knowledge of image processing, although I found a related literature stating techniques and algorithms I can use, I don't know where to start actually learning image processing on mobile, I tried searching online but I can't find a decent tutorial on it. we also are also severely lacking time i don't even know if all of these is possible in a month.


if you guys and point me in the right direction, it would be very helpful. Thank you very much


target language: Xamarin ( just starting to learn it too, not comfortable with android studio )


"
The Axioms of Probability,1,11,False,False,False,learnmachinelearning,1504262565,False, 
Learn Python For Data Science And Machine Learning With Jose Portilla,3,9,False,False,False,learnmachinelearning,1504267891,False, 
Machine Learning and Human Bias,0,1,False,False,False,learnmachinelearning,1504296122,False, 
Why Netflix Never Implemented The Algorithm That Won The Netflix $1 Million Challenge,0,11,False,False,False,learnmachinelearning,1504315222,False, 
How to interpret weights of a simple Multilayer Perceptron?,3,3,False,False,False,learnmachinelearning,1504328550,True,"It seems to be commonly shared that neural networks function somewhat as a ""black box"" in terms of classifiers. I am curious if anyone has had any success in the way of analyzing the weights of an MLP to reveal information about the data. I have had trouble finding literature on the topic.

My simplistic approach so far has been to work backwards through the layers, and keep track of nodes with weights in the 80th percentile (or some other threshold). Ultimately the end result is a group of the features that passed the ""filter"" for the nodes in the last hidden layer, or stated another way, a group of features that significantly influence that activity each node in the ultimate hidden layer

This is somewhat of a quick and dirty approach so any advice on the topic, and/or any constructive criticism on my approach so far would be much appreciated!
"
Can I use an algorithm to generate an outline for a given essay?,4,1,False,False,False,learnmachinelearning,1504334601,True,It woukd be cool to apply not just in simple 5 paragraph essays but also in more complex essay strucures. 
"Weekly Status Check Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",0,3,False,False,False,learnmachinelearning,1504335910,True,"Let's have a  meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
Linear Algebra Project,2,20,False,False,False,learnmachinelearning,1504339361,True,"I am taking a linear algebra course this semester and understand that it is an important area of math for machine learning. Do you guys have any suggestions on things I can make so I can practice the math concepts with regard to ML. I was thinking of making a my own library to do matrix operations, but that seems kind of boring. Are they any simple algorithms I can implement from scratch that require Linear Algebra? "
Interesting applications of Markov Models?,0,3,False,False,False,learnmachinelearning,1504347761,True,I've just recently started out learning about markov models and I'm looking for some doable projects to put my knowledge to use.
Anyone knows when parts 4 and 5 of Andrew Ng DL course will be available?,1,7,False,False,False,learnmachinelearning,1504358206,True,I've just finished first 3 courses and loved every second of them. Sadly courses on CNN and RNN are not avaiable yet and I can't find any info on when they will come online. Are there some other good courses on more advanced NN architectures to finish in the meantime?
Implementing my first unsupervised model but having some difficulty with the loss function,1,4,False,False,False,learnmachinelearning,1504365643,True,"Hi, I'm trying to implement my first unsupervised model from this paper:

[Learning Temporal Embeddings for Complex Video Analysis](https://arxiv.org/pdf/1505.00315.pdf)

The idea in the paper is kinda like word2vec but they are trying to encode temporal information into video frame embeddings. Anyway it was all going fine until I started training it. My loss function would nose-dive to zero after only a couple of batches. And it stays there right at exactly 0.0 - presumably learning nothing about projecting the embeddings. The loss going down is great but the speed at which it reaches absolute zero is way too good to be true.
 

[So here's the loss function from the paper - it's quite straightforward I think:](https://imgur.com/GCiCiZf)

And here's my implementation with the keras backend: 

    def loss_function (y_true, y_pred) :
        target   = y_pred[:, 0,  :, :]
        negative = y_pred[:, 1,  :, :]
        context  = y_pred[:, 2:, :, :]
        mean_context = K.reshape (K.mean (context, axis=1), (batch_size, embed_dims, 1))
        return K.sum (K.relu (1.0 - K.batch_dot ((target - negative), mean_context)))
    
    model.compile ('Adam', loss=loss_function) 

[And here's what my loss looks like when I train it:](https://imgur.com/RHRTuXf) 

There is a [caffe implementation](https://github.com/eevignesh/videovector) that the authors have kindly provided but I'm not implementing the multi-resolution data augmentation just yet. Also I was having a lot of trouble understanding their code as I've zero knowledge of caffe as of now unfortunately. 

Hopefully I just made some rookie mistake that's obvious. Any help would be greatly appreciated!"
Determining the language of a word,3,2,False,False,False,learnmachinelearning,1504367388,True,"Hello I wanted to ask how should I approach a task which Involves guessing the language of a word?  


I currently have a 37k list of words that I know are certain to be o a specific language eg. `Esperanto`.  Lets assume these 37k of words can be used as my training data.  And now lets assume I have a list of words that contains multiple languages Esperanto, English, Dutch, Spanish. and is of length of 400k


Given the fact that I have 37k Esperanto words  what could be the best algorithm to decide whether the word from the mixed 400k word list is of language `Esperanto` ? "
How to learn to code deep learning from scratch (not using any framework)?,12,25,False,False,False,learnmachinelearning,1504377448,True,"I want to learn to code Deep learning models entirely in numpy and not use any frameworks. Is there any tutorial which can help me?

Thanks"
"If train 1 RBM on random pairs from 2 datasets, so the first half of visibleNodes are statistically independent of the second half, what can we know about comparing the weights of those halfs?",0,1,False,False,False,learnmachinelearning,1504382790,True,"Example: 100 visibleNodes. 2 sets (X and Y) of 50 dimensional vectors. Each trainingVector is concat(anyOf(X),anyOf(Y)). The first 50 visibleNodes learn to be statistically independent of the second 50, even though they start with random weights sharing all hiddenNodes (and deeper). If we view each node as a vector of its weights to/from adjacent layer, what can we say about comparing the first 50 vectors to the second 50? Or we might consider deeper recursions like the zigzagging that happens during contrastiveDivergence training. Should we expect those 2 groups of vectors to be mostly perpendicular to eachother? Even more extreme, should we expect them to split the hiddenNodes into 2 groups and have near 0 weight to the other side? What can we know in advance about what weights form?"
A Neural Network in 10 lines of CUDA C++ Code,0,6,False,False,False,learnmachinelearning,1504397378,False, 
Framework/course suggestions for a recommendation engine please :) back end developer,3,9,False,False,False,learnmachinelearning,1504407777,True,"Hi there :) I'm a back end developer and keen on picking up some machine learning skills - ultimately I want to look into recommendation engines for products, songs etc.

My question is **what are some good frameworks** to pursue, and are there any courses you guys have done that really paid off? 

* I currently work with PHP quite a bit
* I've seen that Java or Scala would be good options, keen on keeping away from R or Matlab
* I'll want to eventually learn to pipeline data from the likes of BigQuery, Hadoop, Scio, Spark, Cassandra or Kafka.

Any and all suggestions would be super appreciated!
Jake."
Correlation between observed and predicted values,0,1,False,False,False,learnmachinelearning,1504451567,True,[deleted]
NLG tutorial?,0,1,False,False,False,learnmachinelearning,1504473084,True,I found out recently that there are several plugins for Tableau that allow you to add natural language generation to your reports and dashboards. All of the vendors have a monthly fee. Are there any  tutorials for creating your own NLG platforms? 
Does anyone know of an in depth linear algebra course with exercises (NOT FROM MIT),7,33,False,False,False,learnmachinelearning,1504494393,True,"I'm having a *hard* time finding a decent linear algebra course that at least ramps me up to the point where I can read the derivations and proofs for PCA and least squares (BOTH NOT EITHER OR) and that has exercises w/ solns (I pretty much am incapable at my age of learning without interactive exercises eg programming).


It seems strange to me that there isn't a good one out there. I can find a plethora of resources on statistics, ML, DL, calculus, and RL, with rich interactive exercises and visualizations, yet, perhaps the most foundational thing to learn, only has MIT courseware that was last provided 7 years ago... Is this going to be the comcast internet of education?


places I've searched:

Khan academy has scant exercises on this subject. 

youtube video playlists and the most recent textbooks either have no exercises, or no solutions provided

a ton of school websites

the datacamp type websites just provide a joke of an overview, nothing which would allow me to actually understand things if I wanted to read into them (PCA least squares etc.)

Udacity's doesn't go beyond solving a system of linear equations (basically the course is just vector geometry)

Coursera took down their's and what was left over from that is sketch as hell.

An ideal example would be:

https://web.stanford.edu/~boyd/vmls/

if it actually had solutions (yes im aware it doesn't have PCA, but it's not much of a stretch if you have a solid foundation)"
Free eBook: Python Machine Learning (PDF/ePub/Mobi),1,19,False,False,False,learnmachinelearning,1504511325,False, 
Are there any neural network tutorials out there that aren't very math-heavy?,3,1,False,False,False,learnmachinelearning,1504553865,True, 
Just finished Andrew Ng's course... where to go now?,14,14,False,False,False,learnmachinelearning,1504556812,True,"So I just finished Andrew Ng's ML course on Coursera - great course for an introduction - and am looking for where to go next. I think I'm most interested in neural networks and deep learning. Also currently reading through Goodfellow's deep learning text.

Just some background about myself: I'm a theoretical physics PhD student, probably going to graduate at the end of the 2017-2018 academic year (and I'm looking to get out of academia). So math does not scare me one bit; if there's anything out there that doesn't hold back on the mathematical background that would be great.

I've found comments here and there that say Stanford's CS231n and fast.ai are pretty good next steps, but I want to see what the reddit hivemind thinks."
How to Escape Saddle Points Efficiently,0,3,False,False,False,learnmachinelearning,1504562112,False, 
"Learning ML functions with C++, need help for library.",3,3,False,False,False,learnmachinelearning,1504568984,True,"I recently decided I wanted to implement basic ML functions myself in C++, but I wanted to use an existing library for the matrices/vectors part.

I was thinking of using something like Armadillo or OpenCV, but I really wasn't sure which one would be more fit for ML, or be more practical to learn in the long run. 

Does anyone has suggestions on libraries to use for C++ for implementing the algorithms yourself?"
Linear regression problems examples?,5,1,False,False,False,learnmachinelearning,1504573688,True,"Hi, I'm week 2 into Andrew Ng's course. Besides house prices in a region, do you have good examples where linear regression could be applied? I know it's about scalars as input giving a scalar as output, but every time I think of a problem, I see it as a classification problem or I fail to see how can I use linear regression to solve it. Roughly, is it often used?"
xkcd: Ensemble Model,0,34,False,False,False,learnmachinelearning,1504584080,False, 
How long did you take to finish ML book?,4,5,False,False,False,learnmachinelearning,1504586075,True,"I'm curious for those who learn from the book, how long did you take to finish the book like from cover to cover? Please say your book title and number of days/months.

I'm looking forward to these books:

1. Pattern Recognition and Machine Learning by Bishop

2. The Elements of Statistical Learning by Hastie and Tibshirani

3. Deep Learning by Goodfellow and Bengio"
How much ML coursework/experience is needed to actually be able to work in the industry?,15,20,False,False,False,learnmachinelearning,1504593052,True,"I know most ML job postings typically require a phd, but I recall Andrew Ng mentioning in one of his earlier lectures (~week 3 ish) in his intro course that we had already acquired enough knowledge of ML to perform most of the tasks that are being done professionally in silicon valley today. 

 I know that was a huge generalization but wanted to see what you guys think about how much experience it takes to really be qualified?
"
"Just started my first Kaggle competition, and I have several questions",5,12,False,False,False,learnmachinelearning,1504596036,True,"After reading as theory, I attempted my first [Kaggle dataset](https://www.kaggle.com/c/house-prices-advanced-regression-techniques) and it raised several question for me:


1. There are many things I can do that give relatively small improvement, such as changing several feature with class to continues numeric values. Or some other changes such as feature engineering and so on. The problem with these changes is that their improvement is so small, I can't judge using my own train data whether they contributed or not (the randomness in algorithm alone has a larger noise). So how do I approach these things? Do I just guess they would help? Or maybe there's another method?
1. I'm using XGBOOST. In some guide I read it was recommended to not use more than 1000 trees. I was wondering - why is that? Is it to prevent overfitting or to save on runtime?
1. There's this basic idea of picking the model not with the best validation score, but with a high validation score is high but not so much that the training score is much higher than it. So I just need to clarify to myself this concept:
  1. Did I understand it correctly?
  2. The reason for that is to prevent a case of overfitting - that is, that the model would work well on unseen data, right?

Thanks!"
[Computer Vision] Estimation Camera Matrix P from 28 points of Correspondences.,0,1,False,False,False,learnmachinelearning,1504596192,True,So as the title suggest I am trying to get a Camera Matrix P and its components K R c from 28 points. I want to implement without any toolbox or stuff like that. I know that I have to use this [Equation](https://i.imgur.com/3vIRZTz.png) but I am not sure how. Any help would be great!
5 Ways to Get Started with Reinforcement Learning – buZZrobot,0,3,False,False,False,learnmachinelearning,1504616894,False, 
Automatic Feature Engineering - Great Feat Eng tips from Kaggle master,0,34,False,False,False,learnmachinelearning,1504623692,False, 
"Is ""Sign Accuracy"" worth considering in a regression model? Further explanation in details.",0,2,False,False,False,learnmachinelearning,1504624592,True,"This may be a weird question, but let me do my best to try and explain myself:

Say I'm working on a regression problem that is trying to fit a target that has both positive and negative values. Mathematically speaking, and assuming that there is ""class balance"" (equal amount of positive and negative target values), is there any value in optimizing towards models which are more effective in predicting the correct sign (ie positive / negative)? Or should I focus exclusively on RMSE or MAE or other cost functions (because any variance in ""sign accuracy"" is by chance)?

I'm asking because the sign of the prediction is equally (if not more) important than error. And before you suggest focusing on classification, I am doing that as well, but I am using both in an ensemble.

Hope that makes sense -- thanks in advance for any insight / help!"
Teaching a Neural Network to play a game using Q-learning,0,6,False,False,False,learnmachinelearning,1504631201,False, 
Rule of thumb on minimum number of training examples for text classification?,1,5,False,False,False,learnmachinelearning,1504631207,True,"Ideally the more text the better.

But **is there a rule of thumb on the minimum number of training examples for text classification?**

---

e.g. If I am trying to predict short sentences of text against 16 labels, and post-preprocessing my input vector is a TF-IDF vector of ~530 words, what's the minimum number of samples I should aim for before testing?  "
What is Inductive Logic Programming (ILP),3,3,False,False,False,learnmachinelearning,1504631777,True,"I recently came across ILP on wikipedia. I tried to understand the topic but couldn't.

[Inductive Logic Programming ](https://en.m.wikipedia.org/wiki/Inductive_logic_programming)"
The 7 Steps of Machine Learning,0,1,False,False,False,learnmachinelearning,1504642803,False, 
[Poll]Data Analytics vs Parallel and Distributed Computing for MS degree focus,0,1,False,False,False,learnmachinelearning,1504654922,True,"[Here are the classes I'm debating between.](https://i.imgur.com/9d8TGcP.png) In your opinion, which 10 classes would lead to the better career in the long term? I feel like the data analytics track would be good for theory, but I think the parallel computing track would be good for implementing the theory. Should I take a mix of both? Should I only do one or the other? Which would you do if you were going to apply for a job in 2 years?

Strawpoll: http://www.strawpoll.me/13870355"
What are modern options for sharing machine learning datasets?,0,1,False,False,False,learnmachinelearning,1504655876,False,[deleted]
What are modern options for sharing machine learning datasets?,0,2,False,False,False,learnmachinelearning,1504656718,False, 
Pytorch/Tensorflow vs Scikitlearn/statsmodels for Machine learning,3,1,False,False,False,learnmachinelearning,1504659378,True,"Is there a difference when I use DL focused packages like pytorch or tensorflow to do basic machine learning/computational statistics?

Should I use pytorch/tensorflow over scikitlearn, etc?
"
Multi dimensional feature set in SVM (python),2,3,False,False,False,learnmachinelearning,1504662384,True,"I am trying do an Image Classification where each sample of training data contains data of the current pixel with the 8 surrounding ones.

Where can I find examples of SVM, in python, that use 5 or more features in training?"
"What are some simple, but interesting, applications based on Vitebri algorithm?",0,1,False,False,False,learnmachinelearning,1504681020,True,[deleted]
"What are some simple, but interesting, applications of the Viterbi algorithm?",6,1,False,False,False,learnmachinelearning,1504681349,True,I know about POS tagging but that's a standard example and I'm looking to apply the algorithm to something different. What are your suggestions?
TWIL (This Week I Learned) - Share something new that you have learned this week!,0,0,False,False,False,learnmachinelearning,1504681514,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
"Dataset containing Numeric, Categorical and Free Text Data. How to use all features for Machine Learning?",1,7,False,False,False,learnmachinelearning,1504682443,True,"For supervised/unsupervised learning problems, both regression and classification, most tutorials I come across focus on:

- Numeric and Categorical Data 

OR


- Text Data (e.g. free text on a form, tweets, documents, books etc.)

But I have not seen many tutorials that focus on datasets where we have data that is numeric, categorical, and text as part of the same dataset.

What tactics, techniques and advice is available to apply machine learning algorithms to data that has all three? Do we train on the free text and other data separately? 
Or do we feed in all features (extracted text features, say bag-of-words or TF-IDF say) to an ML algorithm? How do we do this?

How would we go about:
Data Cleansing, Feature Extraction and ML?

Looking for advice, tutorials, books etc.?"
Another Free eBook: TensorFlow Machine Learning Cookbook (PDF/ePub/Mobi),14,40,False,False,False,learnmachinelearning,1504687826,False, 
Python for Data Science and Machine Learning Bootcamp,0,10,False,False,False,learnmachinelearning,1504703468,False, 
"This week we talk to Jennifer Prendki of Atlassian about the practices she helped develop at WalmartLabs, including the measurement and management of machine learning models in production and more generally, building agile processes and teams from machine learning.",0,3,False,False,False,learnmachinelearning,1504709481,False, 
CMU Neural Nets for NLP video lectures (ongoing),0,11,False,False,False,learnmachinelearning,1504710754,False, 
ML hobbyist who Just finished Andrew Ng Stanford course on Machine Learning. Where to go from here?,3,9,False,False,False,learnmachinelearning,1504748769,True,"Is there a general advanced ML course that is typically recommended? 

Is it more like you need to study whatever particular topic you want to further study?

I have a good math background (differential equations, linear algebra, stats, etc.), and a bit of a ML hobbyist already  (just using NN to make models and classifiers here and there). "
Computational requirement for Andrew Ngs Deep learning coursera course,1,5,False,False,False,learnmachinelearning,1504757981,True,I am thinking of enrolling for Andrew Ng's deep learning course from Coursera but I am not sure i will be able to submit the assignment using my laptop.My laptop is a 32 bit windows 7 machine with 2 GB of ram. I had completed Andrew Ng's ML course from Coursera using the same laptop. Please help
Why didn't word2vec use simple binary classification to learn the embeddings?,0,3,False,False,False,learnmachinelearning,1504783286,True,"I can't help but wonder that if you trained the model with a 'does this word belong in the middle of this sentence? yes or no?' type of classification, then surely you would learn something useful in the embeddings?

Perhaps if you had two inputs, one containing the target (positive or negative) vector and another with the context vectors. Then connect both to a couple of hidden layers and backprop back from a binary cross-entropy loss on the output. Wouldn't the later hidden layers automatically backpropegate similarity between the positive vectors and the opposite on the negative examples? Or am I making too many assumptions here? 

Or perhaps this type of model would have been too expensive to compute on the large corpus they used? "
Forecasting future currency exchange rates with recurrent neural networks,0,22,False,False,False,learnmachinelearning,1504787820,False, 
What do you think about the Neural Network Design book? (link included),0,1,False,False,False,learnmachinelearning,1504792213,True,"I came across the [Neural Network Design](http://hagan.okstate.edu/NNDesign.pdf) book, of the authors who implemented the neural net packages in Matlab. People [on Amazon](https://www.amazon.com/Neural-Network-Design-Martin-Hagan/product-reviews/0971732116/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&amp;reviewerType=avp_only_reviews&amp;sortBy=recent) give it good reviews, generally saying it's a good introduction to the topic. However the fact that most articles in the bibliography are from the 70s and 80s, the absolute lack of convolutional networks and generative models, LSTMs etc. make me wonder if the book is not completely outdated. 
Moreover, in chapter 2, we find: 

&gt; As for the number of layers, most practical neural networks have just two 
or three layers. Four or more layers are used rarely

Wtf ??? 

So bottom line, is this book worth the time investment, just for the math details, or is it so obsolete that I should search elsewhere? "
Learn how to make a neural network,7,3,False,False,False,learnmachinelearning,1504797022,True,"Hi All,

I've just spent the last year putting together a small introductory guide on neural networks and how to build them in python.

This community has been very supportive through the process and I first off wanted to say a BIG thank you to everyone that has helped.

Secondly, I'm giving away free digital copies today and would appreciate any honest feedback after you finish reading it.

Link: getBook.at/Neural-Networks
"
Training a Convolutional Neural Network with mostly zeros?,1,5,False,False,False,learnmachinelearning,1504812511,True,"Hello!

I'm trying to train a convolutional neural network to scan LiDAR point clouds. I've converted the point clouds into voxels, and each voxel has a value referring to the number of points inside. 

Now being voluminous space and all, most voxels are empty (0). Those that aren't usually only have values of 1 or 2. Should I attempt to normalize these values to get better results? Subtracting the mean would just result in a lot of -.00x values. Dividing by standard deviation would result in a lot of large values. Are there methods for dealing with zero inflated data in a CNN? Have people trained CNNs on binary images? Perhaps my weights shouldn't be values derived from a truncated normal distribution?

Thanks for any input!"
"Activation Functions: Neural Networks Sigmoid, tanh, softmax, ReLU, Leaky ReLU, EXPLAINED !!!",5,8,False,False,False,learnmachinelearning,1504849378,False, 
Weekly Show-off!,0,3,False,False,False,learnmachinelearning,1504854320,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
Any advice to improve LSTM,0,6,False,False,False,learnmachinelearning,1504859251,True,"Hey, I was following along with [Machine Learning Mastery](https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/) showing how to use LSTM for sequential data. 

I'd noticed, however, that he was still feeding real data to the model (in essence, it only ever had to guess one step forward)

so I modified it to slowly replace the values it uses as input with the values it has previously predicted... and it does not work at all. It basically tends towards a certain value and then stays there.

I've tried: changing optimization methods, training for many many cycles, changing look_back to up to 200, adding an exit activation function... nothing seems to change it.

The part that bothers me is that the model instantly shoots off either up or down, were it valid for a few steps at least I could work with that, but as is I feel that there's gotta be a serious flaw somewhere in my methodology.

Any advice? my dataset is 8000, separated into 6k train/ 2k test

edit: my issue is well summarized in the stock portion of [this article](http://www.jakob-aungiers.com/articles/a/LSTM-Neural-Network-for-Time-Series-Prediction) which also goes off the rails and stays at some equilibrium quickly."
Grad School(?) for Start Up,1,9,False,False,False,learnmachinelearning,1504864423,True,"Hi,

I'm a current undergrad majoring in Math with a focus on applied statistics and modeling. My friends (mentioned later) are of CS undergrad backgrounds going into ML.

After learning data analytics in school and basic machine learning through MOOC lectures and independent projects, I recently started my first freelance ML job (feature estimation using neural nets). I plan on working full time as a machine learner for industry soon, while gaining more practice by continuing freelance.

I also have hopes and plans to start my own ML company by making a ""freelance/ contracting"" team with friends, doing analysis or modeling for other smaller or less ML involved companies, and expanding it as we get better to becoming a real company ourselves.

So question: how worth is graduate school (in ML/ related degree) for this? Is industry experience enough, with extra self study, or is formal education vital for me to reach a level where I can compete with ML start up companies?"
Order of taking fast.ai courses?,2,2,False,False,False,learnmachinelearning,1504865569,True,"Hi, I'm gonna start taking the fast.ai deep learning course this weekend. I was wondering whether the computational linear algebra course is required before taking the first course in deep learning?

Thanks!"
Free Intel Nervana AI DevJam event for AI developers is coming to San Francisco on September 18th!,0,10,False,False,False,learnmachinelearning,1504885226,False, 
Questions about course.fast.ai,9,15,False,False,False,learnmachinelearning,1504918589,True,"I'm completely new to machine learning, and I stumbled upon course.fast.ai by Jeremy Howard. I was wondering if anyone has taken this before and how they felt about it? Are there any other better recommened places to start?"
"Weekly Status Check Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",0,3,False,False,False,learnmachinelearning,1504940710,True,"Let's have a  meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
Data Science and Machine Learning Courses For Learners Online,0,1,False,False,False,learnmachinelearning,1504952532,False, 
Explain the need for seperate validation and test sets,3,1,False,False,False,learnmachinelearning,1504967472,True,"My understanding is as follows, you have a set of models where you are differing some parameter (lets say for example L2 regularisation parameter) you train each of these models on the training set, you then test these on the validation set to see which L2 reg parameter gives the best result, then you test this on the test set to get an accurate idea of how well the model works.

Now what I don't understand is why is there a need to have a different validation and test set, after all - all these models are trained on the training set. Its not like they are all trained on the training data, then all further trained on the validation data, so the validation set also gives you the TEST accuracy of the model for that specific L2 reg parameter because it was not trained on any of that validation data.

Not sure how well I have explained this. For example, can anyone show an example of data where this train val test data was not used, only train and val data were used to choose the best model, and the validation accuracy was just used as the test accuracy, which turned out to be completely wrong. "
Determining the number of cluster centers,3,7,False,False,False,learnmachinelearning,1504970968,True,"Hi,

I have applied Expectation Maximization to my data set (9.8Mx20) with varying number of clusters. 

When I went to evaluate my different EM-cluster-sets using their silhouette scores, I ran out of memory. That barrier proved consistent whether I was evaluating my 5-clusters-set (the lowest I've done so far), or the 10-clusters-set (the highest I've done so far). (By some trial and error, I found that with my amount of RAM, I can get the silhouette_score of 25000 data points at a time; however, that seems pretty useless to me.) Do you have any advice on how to evaluate the different clusterings to determine how many centers to move forward with? 

I have taken a bit of time to look at some of the different cluster centers, and the variations between the different clusters did seem somewhat pronounced -- meaning just by looking at the at the feature values of each cluster center, I was able to make out some substantial difference between clusters inside the same EM-run.
    
    from sklearn.mixture import GMM
    from sklearn.metrics import silhouette_score
    
    # TODO: Apply your clustering algorithm of choice to the reduced data 
    clusterer = GMM(n_components=5, random_state=83, n_iter=100, n_init=25).fit(df1)
    
    # TODO: Predict the cluster for each data point
    preds = clusterer.predict(df1)
    
    # TODO: Find the cluster centers
    centers = clusterer.means_
    print(centers)

    # TODO: Calculate the mean silhouette coefficient for the number of clusters chosen
    score = silhouette_score(df1, preds, metric=""euclidean"", random_state=134)

One solution I have come across is running an f-test for each clustering, and then plotting the f-values as a function of the number of clusters creating an [elbow-plot](https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set#The_elbow_method); however, I am unsure about how to run that since I am in a 20-dimensional space.

The other solution which has been mentioned to me, but I can find no literature about, are shadow-plots. I'm assuming that just takes the data set and projects down into two dimensions, but I am not sure. 

Thank you for your time. 

Edit: As mentioned in the wikipedia page, another method would be using AIC and BIC. If someone could expand on that a bit, that would also be great since those I can calculate, I just don't know how to interpret them. 

    print(clusterer.aic(df1))
    719541822.637

    print(clusterer.bic(df1))
    719544699.261"
1x1 convolution kernel,7,2,False,False,False,learnmachinelearning,1504974078,True,"What is the purpose of having 1x1 convolution kernel ?
How does it increase and reduce dimension ?
How does it reduce number of parameter ?
How does it increase non-linearity ?
"
Bernoulli trials. The essential things to know.,0,8,False,False,False,learnmachinelearning,1504977679,False, 
[Question] will NLP help me solve this issue?,2,3,False,False,False,learnmachinelearning,1505006032,True,"**Problem statement:**
I have a data set containing email responses from customers. Basically email_id | text_response. I need to find the amount of emails that were written with the sole purpose of saying ""thanks"" (or related wording). A customer simply showing appreciation.

**Question:** Can this be solved through NLP?

I do most of my data manipulation in Python, so naturally I would like to use a library like NLTK. However it's unclear to me the power of NLP and what falls under its umbrella and what doesn't. Most introductory tutorials I skimmed focus on word counting, word labeling or sentiment analysis."
Best approach to recognize car license plates,3,2,False,False,False,learnmachinelearning,1505010192,True,"I'm building my first Tensorflow project. My goal is to recognize license plates and convert them to text (OCR). I was wondering if I should build a single neural network for a one step process, or if it would it be faster and more precise to do it hierarchically: first recognize cars (in low resolution), then search for the license plate and finally the letters/digits (and analyse the plate in a higher resolution)? Any insights are welcome :-)

I want this to run on mobile (ios and android) directly on the device (offline) in realtime capturing video from the camera. Do you guys think this is doable with Tensorflow or should I be looking at other ML engines (such as Darknet + YOLO)?"
[Question] Comparison of Supervised Classification Algorithms,6,4,False,False,False,learnmachinelearning,1505025537,True,"I want to create a document to compare 5 different supervised classification algorithms over the same dataset (decision trees, knn, svm, neural networks and boosted decision trees).
 
I'd like to read some examples to see which analysis I can include to make the analysis more complete.
The only metric I can think of to compare the algorithms is accuracy but I feel my report is not very interesting and complete.
I would appreciate any guidance"
Need some idea/direction for writing a literature review,1,1,False,False,False,learnmachinelearning,1505028607,True,"Hi, I'm not sure if this is the right sub for asking this but i'm currently working on quasi-similarity and would like to write a literature review that is somehow relevant to it but the research is taking some time so in the meantime i thought i'd do a literature review which could be relevant but i'm not able to think of what relevant stuff can i review so a bit of help would be really appreciated :D Thanks
"
I noticed some Kaggle competition entries have teams of multiple people (2-5). I was wondering what each person on the team does typically?,4,11,False,False,False,learnmachinelearning,1505043465,True,"If a team has 2-5 people, how is work distributed among them?"
What the hell is Perceptron? The Fundamentals of Neural Networks,2,3,False,False,False,learnmachinelearning,1505057449,False, 
How does the Supervised Discretization filter work on Weka?,0,5,False,False,False,learnmachinelearning,1505065920,True, 
Best way to learn tensorflow?,13,38,False,False,False,learnmachinelearning,1505078253,True,"I'm currently taking the Andrew NG Coursera course on deep learning. Unfortunately, it's not very detailed on tensorflow. How did you learn how to use tensorflow and how do you recommend learning it?"
"From a research perspective, can data from a well controlled experiment eliminate the need for a very large sample size?",0,1,False,False,False,learnmachinelearning,1505079754,True,"I am currently applying a variety of ML algorithms to high dimensional biological data (~70 parameters). This is more of a theory question, but would the reduction of noise (provided by controlled experimental conditions) allow you to use a smaller sample size? "
CS231n 2017 vs 2016 lecture videos,2,11,False,False,False,learnmachinelearning,1505081602,True,"I had started watching the CS231n lecture videos (up to around lecture 7) from Andrej Karpathy and I just realized that the lecture videos for the 2017 course had been uploaded -- Is it worthwhile for me to finish the 2016 lectures or should I start watching the ones for 2017 instead, and if so, are there major differences in the way the content is delivered or structured that I should be aware of?"
Statistics books for a Beginner?,2,3,False,False,False,learnmachinelearning,1505085386,True,"Hey guys, I'm interested in learning Machine Learning. I've already read a book on the topic however my stats background is lacking. Can you guys recommend me some good books to get caught up with the statistics side of ML? I'm an Engineer by day so I can handle pretty much any kind of book you recommend. I was thinking about starting with E.T. Jaynes book on Statistics. What do you guys think?

Thanks."
Where can I find a really excellent naive bayes exercise/code tutorial? POST IF YOU DID ONE!,1,3,False,False,False,learnmachinelearning,1505108676,True,"I'm actually not entirely interested in naive bayes, moreso interested in getting my feet wet (code wise) for generative models, so that I can use the experience to code a GAN. Would really appreciate any 
 and all help for this fascinating technique!

thanks!"
Replace phrases in a document with some other phrases and correcting the grammer of the final sentence accordingly.#Machine Learning,0,1,False,False,False,learnmachinelearning,1505134061,True,I am new to machine learning. I have come up with the above mentioned problem. What should I look into. I would really appreciate if someone could help. Thanks in Advance.
Build and Visualize Word2Vec Model on Amazon Reviews,0,1,False,False,False,learnmachinelearning,1505138420,False,[deleted]
What the Hell is “Tensor” in “TensorFlow”? – Hacker Noon,20,29,False,False,False,learnmachinelearning,1505139136,False, 
Tensorflow OpenCl any good?,1,2,False,False,False,learnmachinelearning,1505142665,True,"If you guys are on non-nvidia GPU, there's an alternative: https://github.com/benoitsteiner/tensorflow-opencl 

But i wanted to ask the community.. are there any known issues when training / running models?"
Executing a trained model on a different machine,2,3,False,False,False,learnmachinelearning,1505148753,True,"Hello people,
I am trying to train a large CNN, and want to train it on a GPU I have at my disposal. However, in practice I would need to implement it on a completely separate system with only a CPU and memory.

What is the best way of going about this? I've searched a bit and found that pickling might be an answer, but I'm unsure if that's the best way, or if it's even possible. All help will be deeply appreciated! "
The Future of Machine Learning in a Connected World,0,1,False,False,False,learnmachinelearning,1505150838,False, 
Monthly ELI5 (Explain Like I am Five) Thread,1,7,False,False,False,learnmachinelearning,1505172010,True,"Top comments need to be in the format of: `ELI5 $CONCEPT_NAME` and the replies should provide a clear explanation in a layman's term.
Here are the relevant rules from /r/explainlikeimfive breaking down the meaning of ""ELI5"":

- E is for Explain - merely answering a question is not enough.

- LI5 means friendly, simplified and layman-accessible explanations - not responses aimed at literal five-year-olds.
"
I might be late to the machine learning train but..,2,1,False,False,False,learnmachinelearning,1505199347,True,"So i've been playing around with SethBling's MarI/O and it's been pretty astonishing how AI works to me and I would like to dive deeper into this field ( I know the NEAT technology is outdated). I was wondering if when shutting off the BizHawk emulator, if there's any way to start a new session with the same data as before? If anyone could help that'd be much appreciated and if there's any more video game AI's that I could learn with that would also be much appreciated. Thanks for this community."
How to automate creating high end virtual machines on AWS for data science projects using the Terraform orchestration tool,0,4,False,False,False,learnmachinelearning,1505208022,False, 
Guide on building your own neural conversational agent,0,1,False,False,False,learnmachinelearning,1505223681,False, 
DataQuest Plus reviews,0,7,False,False,False,learnmachinelearning,1505226625,True,"Has anyone enrolled in the DataQuest Plus program? If so, would you recommend? How does the mentor portion work? "
Suggested starting points for beginner with this (simple) problem,3,2,False,False,False,learnmachinelearning,1505230367,True,"I am a programmer and I don't know very much about ML or AI but I think the following problem should be at the easy end the problems I see here. I would like to know some good starting points to solve it. Maybe there are some easy to use blackbox/cloud solutions already.

The problem:
Currently there is a manual process where invoicing personnel select few correct price parameters from the contract based on something like 50 different fields they see on the screen. I would like to automate this. So basically it is a problem of taking about 50 database fields and use them to predict couple of fields or to be precise make a correct selection from the other set. (I know that those source fields must be well prepared first.)  I have about 20 years of data in the database for training the model. I think there should be some good ready-to-use libraries or solutions for this kind of basic problem?

Thanks.

"
Guide on building your own neural conversational agent,0,16,False,False,False,learnmachinelearning,1505232446,False, 
"Implementation of Gaussian Processes Classifier, MLP, k-NN, PCA, RBM, LogReg from scratch in python and examples on MNIST",0,3,False,False,False,learnmachinelearning,1505239634,False, 
Transfer Learning with Keras and SqeezeNet?,1,8,False,False,False,learnmachinelearning,1505245466,True,"Hi,
Is there any tutorial about SqeezeNet transfer learning with keras?

How can I train it on my own data?"
Photo organizer app using CNNs,0,3,False,False,False,learnmachinelearning,1505247937,False, 
Pursuing Computer Vision as A Career,2,12,False,False,False,learnmachinelearning,1505256930,True,"I'm doing some studying for an interview coming up and I was wondering what are the things you NEED to know as a CV developer. CV is a fairly broad discipline. What knowledge is common across the different sub-domains, e.g. recognition, tracking, etc? "
How to approach this problem on how to identify accident's root-cause.,6,1,False,False,False,learnmachinelearning,1505265483,True,"Hello!

So my thesis is based around identifying what are the possible root-causes related to an accident based on an already established set of characteristics. It is said that an specific accident will be tied to an specific root-cause through a bunch of characteristics. What I need is for my system to automatically know, given these characteristics, what the root-cause is based on what it has learnt so far.

I don't know if I should approach this as classification problem. 

Also, any advice is really appreciated.

Cheers!"
Question about Caffe's ReLU implementation,4,2,False,False,False,learnmachinelearning,1505266207,True,"So, I started writing my own copy of a deep learning library using the forward/backward pass API today, and I am confused about the ReLU gate.

As an example of what my code looks like so far: 

    class ScalerMultGate(Node_Operations):
    
        def forward(self, x, y):
            """"""
            :param x: input variable x
            :param y: input variable y
            :return: x*y
            """"""
    
            z = x*y
            self.x = x # = dz/dy
            self.y = y # = dz/dx
    
            return z
    
        def backward(self, dz):
            """"""
    
            :param dz: dL/dz
            :return: [dL/dx, dL/dy]
            """"""
    
            #dx = dL/dx = dz/dx * dL/dz
            dx = self.y * dz
            #dy = dL/dy = dz/dy * dL/dz
            dy = self.x * dz
    
            return [dx, dy]

For the most part, so far, implementing the different gates has been pretty straight forward. 

1) Write out the forward operation

2) Save relevant pieces to self

3) Write out chain rule to get the missing parts of the gradient. 

4) Push backward the correct pieces.

I'd think that the forward pass of ReLU gate would be like this: 

    class ReLUGate(Node_Operations):

        def forward(self, x):
            """"""
    
            :param x: input variable x
            :return:
            """"""
            self.z = x
            for each_element in range(x):
                self.z[each_element] = max(0, x[each_element])
    
            #self.z = max(0, x)
    
            return self.z

But according to [how they implemented it in Caffe](https://github.com/BVLC/caffe/blob/master/src/caffe/layers/relu_layer.cpp), that's not right. Therefore, I was hoping someone could walk me through how to do that gate.

I am not understanding why on their forward pass they have: 

    ... + negative_slope * std::min(bottom_data[i], Dtype(0));

and on the backward pass: 

    ... + negative_slope * (bottom_data[i] &lt;= 0));

----

To make sure that I'm understanding the backward pass correctly: 
in pseudocode:

    for each_element in dz:
        if dz[element] == 0:
            send 0 backwards/kill the gradient for that element

        else: #dz[element] &gt; 0:
            send 1 backwards for that element of dz

Thank you."
TWIL (This Week I Learned) - Share something new that you have learned this week!,4,13,False,False,False,learnmachinelearning,1505286315,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
Another Keras Tutorial For Neural Network Beginners,1,27,False,False,False,learnmachinelearning,1505321233,False, 
"This week we spoke to Sentient Technologies VP of Research, Risto Miikkulainen about Machine Learning in E-Commerce &amp; Evolutionary Algorithms! Check it out now!!",0,5,False,False,False,learnmachinelearning,1505321993,False, 
Resources to learn about recommendation systems,1,4,False,False,False,learnmachinelearning,1505341249,True,"I thought a fun side project with machine learning would be to train a neural network on people's anime ratings (scores people have given anime they have watched) to predict animes that a new person may enjoy based on their scores. I was able to find a nice data set for this

I have done some personal projects with neural networks before (I'm just self studying because I find this stuff super cool) and for those I've been able to just Google and find good blog posts and research papers for stuff I want to do, but I'm somehow unable to find a good resource for neural recommendation systems

**If someone could link me to a good resource for this or even just put a name on the technique I'm trying to use (if I remember correctly there are two different main types of recommendation systems) I would greatly appreciate it**

I have an idea of how one could work:
The normalized rating of half of the person's rated anime as the input and the other half of the normalized ratings are the output it's trained on, but that would obviously not train the network on half of the data. I could then use the output as the input and input as the output and train it again to train it on all of the data, but it still wouldn't be able to make all of the connections by splitting the input like that, and I'm not sure how to fix that. Training it on all of the data as both input and output would just create one to one mappings between the inputs and outputs"
Python: Implementing a Logistic Regression Algorithm with Sklearn,1,1,False,False,False,learnmachinelearning,1505345853,False,[deleted]
ensembling/stacking machine learning models,0,1,False,False,False,learnmachinelearning,1505346360,True,"Hi guys, I'm working on a problem and was wondering if anyone could help. If I'm given a piece of text, I have three models:

    model 1: Flag the text if it contains political content
    model 2: Flag the text if it contains a personal attack
    model 3: Flag the text if it contains vulgar language

All three are different logistic regression models trained on different appropriate datasets. We pass the text through the three models, and if any one flags the text, then the text is considered flagged.

However, each of these models is imperfect, and for any given case, it's likely that at least one model will accidentally flag (false positive).

How would one ensemble/stack the outputs of these three models into a fourth to maybe better predict the true class of the text?"
Is TRPO/PPO an online only algorithm?,0,2,False,False,False,learnmachinelearning,1505378577,True,"Is it possible to train these offline?

https://github.com/reinforceio/tensorforce/issues/83 this thread seems to indicate this is not the case"
I was thinking in applying to a degree in Computer Science but seeing job openings for Software Engineers confused me a bit.,8,0,False,False,False,learnmachinelearning,1505393939,True,"I'm heading into the ML direction. I have no experience at all on this so I'm sorry if this is a dumb question.

I've been studying for the past month everyday and I'm starting to feel the urge to start a degree next year. I was really considering Computer Science but I started to wonder what Software Engineering does differently and what they have in common.

DeepLearning.ai just opened job positions as ""Software Engineers, Machine Learning"" and that made me think if Softare Engineering is the actual way to go.

Help, please?"
How to train on a GPU without having one,0,1,False,False,False,learnmachinelearning,1505395210,False,[deleted]
How to train on a GPU in the cloud,0,1,False,False,False,learnmachinelearning,1505395821,False, 
Keras Tutorial: Content Based Image Retrieval Using a Convolutional Denoising Autoencoder,0,2,False,False,False,learnmachinelearning,1505396101,False,[deleted]
Keras Tutorial: Content Based Image Retrieval Using a Convolutional Denoising Autoencoder,0,3,False,False,False,learnmachinelearning,1505399328,False, 
"PROBLEM: Given a person's name (2+ words), which is the given name so I can say hello.",1,0,False,False,False,learnmachinelearning,1505402216,True,"I hope this is not too open ended to post but I was hoping for some direction as to how to solve this problem for a complete noob. 

I deal with a lot of emails froim Uni/College students with diverse backgrounds and it is pretty common that someone writes their full name (I.e. Given Surname OR Surname Givenname). I want to be able to reply to their email and address them by their first name. I know that in east Asian countries like Korea the name order convention are reversed/different but when I see a Korean looking name in a western context I don't know which convention they are following. I feel like a native speaker would be able to tell the difference pretty quickly and given what I have seen about language identification in ML it seems like it could be done pretty simply. 

The training data should be pretty easy to come by from any phone book or online list of common names as long as they all follow the same name order conventions.

Is this a hard problem to solve? What is the shortest path to getting a reasonably accurate solution for a beginner? I am hoping this will help motivate me to learn more python and basic ML tools. 

If you feel like stealing my idea and making a web widget or iphone app I would be happy it exists! Just tell me how you did it so I can figure it out too.
"
Oxford Course on Deep Learning for Natural Language Processing,0,1,False,False,False,learnmachinelearning,1505408870,False, 
Self-study: learn Machine Learning and implement algorithms from scratch,17,9,False,False,False,learnmachinelearning,1505412875,True,"Hi all. I am about to start studying (seriously) machine learning and I am looking for a textbook. I spent a lot of time here on Reddit and searching with Google but I am more confused than before. I do NOT want a cookbook, or an ML book that uses a library (I would not understand the implementation of the different algorithms) or a pure theoretical book. But I am not able to find the right combination: theory and implementation, using for instance Python (not more than SciPy), of the important algorithms.

Many suggest to buy a standard ML book and then implement the algorithms by myself. The problem would be that I should then spend time trying to understand if they are correct by, for instance, comparing the result with that of a standard library. And since I am a beginner, I need to follow a path. Any suggestion? Thanks."
Basic cost function contour plot question,4,2,False,False,False,learnmachinelearning,1505420792,True,"Hey guys, so I'm taking the famous Andrew Ng course, and I've run into a small but incredibly annoying issue in my understanding. I've googled left and right for it, so now I'm turning to y'all.

So I know how contour plots work. I least I thought I did. If lines are close together, it implies a sharp rise or fall, and if lines are far apart, the slope/gradient become much smaller and the 3d figure flattens. It seems that this is consistent with the teaching of contour plots everywhere else.

In professor Ng's course, however, and it seems like in some other linear regression texts, that's not how contour plots are used, at least to my understanding. Check this out:
https://imgur.com/a/OKLnQ

The bowl clearly is flatter at the center, and get steep around the edges. So why does the contour plot, with the lines getting closer to each other towards the middle, imply a funnel shape?

The lines getting closer mean that for a change in theta 1, theta 2, you get a sharper change in J(theta1, theta2). So why is it that the contour plot and the 3d graph contradict each other according to the classical understanding of contour plots?

Since an entire field can't be wrong, and google searches have yielded me nothing of value, I'm hoping someone here can shed a light on my ignorance.

EDIT: Here is a link to what a normal bowl shape contour plot would be like, according to UMD:
http://www.astro.umd.edu/~cychen/MATLAB/ContourPlots.html"
Weekly Show-off!,1,16,False,False,False,learnmachinelearning,1505459119,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
[Audio models] when training with stft and mel-spectrograms - aren't you just throwing away important information (phase) if you only use the magnitude?,0,0,False,False,False,learnmachinelearning,1505475881,True,"This is something that's been bothering me lately. I'm mainly interested in audio models and in almost every research paper I read they are just throwing away the phase information from the fourier transform like it's nothing. Surely this is a terrible idea? 

I did an experiment - if you do an stft, throw away the phase and then reconstruct (even with a fancy algorithm) - it sounds terrible - truly awful. There's clearly a lot of information in the phase angle.

Are any of you also working on audio models? What are you're thoughts on this? "
Has anyone figured out how to deal with satellite image time-series?,6,1,False,False,False,learnmachinelearning,1505478294,True,"There's tons and tons of time-stamped satellite images of earth coming out of the big ESA missions (Sentinel 1 SAR, Sentinel 2 hyperspectral imaging, etc.) that are really useful for observing/predicting time-varying phenomena. However the imaging satellites are all blocked by cloud cover, meaning that for any one spot you'd like to observe, samples will be randomly missing in time. 

Additionally, a lot of other, lower-dimensional data is available at a much higher frequency, like climate measurements. Has anyone figured out how to combine these kinds of data? 

There's quite a lot of work on semantic segmentation of single images, but that's not quite enough. "
"Going from nothing to advanced neural nets, where do I start?",2,0,False,False,False,learnmachinelearning,1505491931,True,"I've recently become very interested in machine learning.

I'm 16 and I have quite a bit of time.  I've got very little experience with programming and coding, but I know basic to intermediate python.  I have full knowledge of precalculus and am learning BC calculus.  How long would it take to become adept at machine learning, and where do I start?"
What is the ideal use case for a feed forward neural network,1,4,False,False,False,learnmachinelearning,1505499065,True, 
"Weekly Status Check Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",2,5,False,False,False,learnmachinelearning,1505545510,True,"Let's have a  meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
VGG16 extract 4096 feature vector,0,5,False,False,False,learnmachinelearning,1505565484,True,"Hi,

I am trying to extract the 4096 dense activations from the VGG16 model, my current understanding of what I would get is a 4096 characters long string but I can't really find any info on this. What I tried is this code: https://gist.github.com/GertjanBrouwer/67fcf1747d0860fedf9be2cd563bc688

What I tried is: 
1. Add the VGG16 weights to the model and use Top=False
2. Add the VGG16 weights to the model and use Top=False and add model.layers.pop 2x to the model. 
3. Add the VGG16 weights to the model and use Top=True and add model.layers.pop 2x to the model. 

Which gave these results:

1. https://gist.github.com/GertjanBrouwer/6b59939593673dac85e313bf9fc72b34
2. https://gist.github.com/GertjanBrouwer/32a840247024d25b366a42b3a4dcaaf0
3. https://gist.github.com/GertjanBrouwer/b62ce0436e2aec541169e01835d2224d

The 3rd results looked the best to me because it looks like it 1 long string, but it still has spaces in it which look a lot like the output you would get if you just used VGG16 output as is which I have here: https://gist.github.com/GertjanBrouwer/9f3cc08f09174dee3cb2968350db9d43

Can anyone help me get the correct 4096 feature?

Note: I used 1 image to get these features and it was the same image.

Thank you !"
Theano won't use GPU on win10 to generate neural network,4,3,False,False,False,learnmachinelearning,1505574424,True,"I've installed the Nvidia cuda drivers, CUDnn and tried to follow [these intructions](http://deeplearning.net/software/theano/install_windows.html). I also changed the device to GPU in the *.theanorc*-file, but it still uses the CPU to generate neural networks.

Is there anything I could've missed? I'm using Python 3 and Geany on Windows 10.

I've been trying to get this to work for weeks now, any help would be greatly appreciated."
What are the subfields of ml?,0,1,False,False,False,learnmachinelearning,1505574726,True,[deleted]
Binomial distribution explained in a simple and intuitive way.,0,19,False,False,False,learnmachinelearning,1505598341,False, 
Any advice for a time-series problem,6,2,False,False,False,learnmachinelearning,1505603405,True,"Hey, I'm modeling some time-series data, and I know what I want to do, but can't figure out how to do it.

Basically, I set up a model using keras that would train using a sliding window of n days and predict the next day. Once trained, it'd predict for n days ahead, manually switching out the values in the sliding window for predicted values.

It was able to predict long-term trends, but had no understanding of amplitude, axis, frequency... and I had no way to teach it those things as this was post training.

I can't train it to do the same thing (when I just take, say, 8 days, and try to get the model to predict 8 days ahead, the results are trash, I need the sliding window to move forward)

Currently using keras and tensorflow, is there a model that'll feed output as input for n iterations **before** updating the weights?

I'm looking at timedistributed, but I don't think that's actually what I wanted (still not sure what exactly it is)

Sorry for wall of text. Tl;DR version: any way to have output fed back in as input for a few cycles, and only after have the weights updated?"
Is this a ML problem?,0,1,False,False,False,learnmachinelearning,1505612513,True,[deleted]
Setting up Jupyter Notebooks with Anaconda,2,7,False,False,False,learnmachinelearning,1505621746,True,"http://joshlawman.com/getting-set-up-in-jupyter-notebooks-using-anaconda-to-install-the-jupyter-pandas-sklearn-etc/

I'm learning data science and machine learning. I decided to create a brief tutorial for anyone who is also starting off and needs to install Jupyter Notebooks.

More posts coming soon. Thanks for checking it out!"
Best way to implement a string classifier?,8,1,False,False,False,learnmachinelearning,1505622432,True,"Hi, I have a bunch of strings in three categories. There is no other outside information other than what categories they are in. What would be the ideal method/methods for making a classifier to put other strings into the 3 categories? RNNs or something simpler? If there are several what would be the drawbacks and advantages of each?  "
Setting up Jupyter Notebooks with Anaconda,0,1,False,False,False,learnmachinelearning,1505623700,False,[deleted]
Where to start for learning machine learning?,12,21,False,False,False,learnmachinelearning,1505630692,True,"Hello everyone, I know the above question is something which everyone who is experienced in machine learning must have come across from a newb in ML. I am a graduate in Computer Science and have some experience in python and data science (a bit only). Now I want to make my career in data science and machine learning. I have done few online courses, but I feel somewhere I am not good with basics of machine learning. I have also tried Kaggle, but there also I am not doing good. For now I am not thinking of doing Masters in these fields.
I want some suggestions for where to start. I want to know from you people that where did you start and what did you do on this path. Any book, online courses, practices to do? 
PS - I have made my hands dirty with few things in python, data science and machine learning but hasn't been successful. Guide me. Thanks."
neural nets - Does bias shift the input or the activation function?,3,2,False,False,False,learnmachinelearning,1505658877,True,"Hi

The input to the activation function inside a neuron should be: linear combination of the neuron's inputs and weights + bias and its corresponding weight. You then take that calue and squash it through the activation function. 

Based on this, it seems obvious to me that it is the input to the activatioj function that is shifted and not the activation function itself.

Yet, i kee seeing explanatory graphs like those: https://imgur.com/gallery/6TDtk showing how the activation function itself is being shifted.

Could someone explain this?

Thanks"
Best course to get started with deep learning in 2017?,14,20,False,False,False,learnmachinelearning,1505670129,True,"I'm currently looking for some good (and up-to-date) resources to get into neural networks (or as most people call it nowadays ""deep learning""). Preferably some course with lectures, assignments and stuff available on the web. Although the theory part is important, I'm more interested in applying these things.

I have a solid programming background and know some machine learning stuff. I don't need someone to tell me the difference between supervised and unsupervised methods..

Does anyone have experience with the new course by Andrew Ng [1] or the Fast AI [2] course? 

[1] https://www.deeplearning.ai/

[2] http://course.fast.ai/
"
Need some help with keras implementation for lstm RNN,0,1,False,False,False,learnmachinelearning,1505673826,True,"Hey! I'm trying to create a RNN for modeling api sequences  of varying length, Code: https://pastebin.com/DDDedMcB, this implementation works for a small data set, but gets killed automatically for a larger dataset. I believe the issue is something to do with the fit_generator function, in particular, the generator function I have defined. Could someone point out what I might've assumed wrongly or if I'm missing something.
The output I get while running the larger dataset is : std::bad_alloc

and some other times just ""Killed""

I believe the issue is something to do with the padding blowing up the size of the input to massive sizes. My larger dataset contains about 1000 samples with some samples having lengths of about 878,780 api calls.

Thanks in advance."
"What are ""valid"" ways to evaluate the numerical vs calculated gradient?",0,1,False,False,False,learnmachinelearning,1505677403,True,"I have been implementing all of Andrew Ng's original ML course in Python. I am up to exercise 4 and working on a backpropagation for a small 3 layer neural network. To evaluate it, I use scipy's check_grad &amp; approx_fprime. With an epsilon of .0001, I have been getting a relative difference of 2.47e-05.

I am not sure if this is close enough and if I need to work further on my implementation of backpropagation. 

But more importantly, I am wondering if there is a rule of thumb or some logical reasoning for evaluating the results of check_grad based on the epsilon chosen.

Depending on epsilon, what threshold would be acceptable when checking the gradient of an algorithm?"
How comfortable with programming should I be before starting to learn machine learning?,7,4,False,False,False,learnmachinelearning,1505683531,True,"Hi, I am a math major in college that is minoring in computer science. I have taken beginning c++, intermediate c++, and a data structures and algorithms course.

I am fairly comfortable with writing simple code, and never struggled too much with the homework assignments in these classes. But to be fair, I did not put the time into my algorithm course as much as I should have and do not feel I retained much. 

My major leaves me with little free time, but with what free time I have I am working through coding books in both c++ and python. 

I am looking for a book whose target audience is someone familiar with coding, and whose coding projects have been on the smaller side. "
Neural Network to predict Gender from First name,7,4,False,False,False,learnmachinelearning,1505713370,True,"I am working through the online Machine Learning course by Andrew Ng. Just finished the exercise where I got to train a neural network to recognize hand written digits. Wanted to see what else I can do with the code. Predicting a person's Gender based on the First Name sounded like a doable idea. 

Was able to whip something out using public data from the City of NY. With some experimentation I was able to get to 97% accuracy rate on the training set. Would appreciate any suggestions, tips, corrections, feedback. Thanks.

My Octave project is here: https://github.com/leophagus/Machine-Learning-Gender-from-Name"
I'm sorry if this isn't the right place for this but how do you help yourself when you get overwhelmed?,16,17,False,False,False,learnmachinelearning,1505736605,True,"Or how not to get overwhelmed? 

I'm going through the Hands–On Machine Learning with Scikit–Learn and TensorFlow textbook and it is really interesting but quite a bit overwhelming. I keep thinking how I have to learn all this code but also that I still have linear algebra calculus and statistics a head of me with only a few hours a day to study, and this scares me a lot.

I guess I'm anxious to be able to survive on this skill I don't have yet and the things that would help me, like a BS in CS, might restrict my study time by a lot.

 "
How we Hacked GTA V for Carvana Kaggle Challenge,3,18,False,False,False,learnmachinelearning,1505738052,False, 
Verifying audio recordings,7,6,False,False,False,learnmachinelearning,1505742031,True,"Hey all.

I'm a part of a project where we collect voice recordings of people reading a sentence aloud. The data therefore consists of the audio recording (typically shorter than 20 seconds) and a transcription text, which is what the participants are supposed to read aloud.

I wanna create an ML-solution to classify whether or not the solutions are usable or non-usable. I'm still undecided whether or not this be binary or not. Examples of recordings can be people with a heavy accent (this is usable), too much ambient noise or people just rambling random words.

Do you have any ideas or pointers for how I could start out? Maybe a similar project or ideas on how to analyse the audio? I thought about doing some kind of MFCC for the audio and maybe some voice recognition. This would then compare the result of the voice recognition with the transcription text.

I'd like to do this in python, but I am up for anything. Thanks!"
Machine Learning and Human Bias,0,3,False,False,False,learnmachinelearning,1505745858,False, 
Is there any connection between Multinomial Bayes Classifier and Multinomial distribution ?,0,2,False,False,False,learnmachinelearning,1505752605,True,"May be this is a very silly question(sorry), but for a beginner like me it is super confusing. 

My understanding:

We have x = [x1, x2, ..., xk] and its y(assume binary 0/1). x is my data vector with k features in it. All xi's take values in [0,t] (both are included). 

Now if t=1, then its multivariate-bernoulli naive bayes classifier.

if t&gt;1, then we call it ""multinomial"" naive bayes. So here our parameters will be

p(xi=s|y=0/1) := theta(s,0/1) (same for all i) where s belongs to [0,t].
There will be total of 2*(t+1) parameters. So MLE+Laplace correction we will estimate these 2*(t+1) parameters. 

And while predicting something like x_test = [xt1, xt2,  ... , xtk] we will use theta(s,0/1)
and report the class which gives max(p(y|x_test)) as our answer.

Is my understanding of multinomial naive bayes correct ?

What is the distribution of p(xi=s|y=0/1) ?Is it multinomial with probabilities of each xi=s|y=0/1 is theta(s,0/1) ? If so, what is the number of trials parameter here?

So my question is where are we using ""MULTINOMIAL DISTRIBUTION"" , I mean its pmf or something like that ?

Thanks for reading till here.
"
Learning to Act by Predicting the Future (Alex Lamb and Sherjil Ozair),0,2,False,False,False,learnmachinelearning,1505767749,False, 
Can anyone help me solve a mystery? See comments,4,1,False,False,False,learnmachinelearning,1505769063,False, 
4790k and PCIe Lanes -&gt; Two 1080ti's too much?,3,3,False,False,False,learnmachinelearning,1505771980,True,"Hello everyone,

Tired of waiting for AMD's libraries to come out, I invested in a 1080ti and was thinking about potentially adding another (when the prices drop). Unfortunately, it came to my attention that the 4790k only has 16 PCIe lanes (argh). 

Is this a deal breaker? How much of a performance hit would I see if I had the cards running at 8x each?

My current setup:
- i7 4790k
- 32gb DDR3 Memory
- 950 EVO
- 1080ti

Edit: If the 4790k is a deal-breaker, what would you recommend (the cheapest alternative)

Thanks!"
Walkthrough: Implementing the Random Forest Classifier from sci-kit learn,0,1,False,False,False,learnmachinelearning,1505772992,False,[deleted]
Tutorial: Implementing sci-kit learn’s Random Forest Classifier for the first time,3,1,False,False,False,learnmachinelearning,1505773594,False, 
The Ten Fallacies of Data Science – Towards Data Science – Medium,0,19,False,False,False,learnmachinelearning,1505791668,False, 
I am sorry if this is not the right place but when do you people code?,2,0,False,False,False,learnmachinelearning,1505803262,True,"Morning? Eveing? Night?
Do you listen to music when you code?
Do you sit on a chair or sofa?
Do you use a latpop or a PC? "
Pattern matching recommendation?,0,1,False,False,False,learnmachinelearning,1505810283,True,I'm looking to match hash patterns and wanted to know if there is any approach within machine learning that has benefits over using the standard storing strings to match approach. Is there any method that can be optimized to say read from an incoming data stream? 
"This week we are joined by Bruno Gonçalves of the NYU Center for Data Science to discuss word2vec, &amp; related NLP concepts such as Skip Gram, Continuous Bag of Words, Node2Vec and TFIDF.",0,10,False,False,False,learnmachinelearning,1505859166,False, 
Quandl,0,1,False,False,False,learnmachinelearning,1505864035,False,[deleted]
Free ebook - Python machine learning blueprints https://www.packtpub.com/packt/offers/free-learning,0,1,False,False,False,learnmachinelearning,1505865989,True,[deleted]
Webinar: How to Commercialize Your Data [Video],0,1,False,False,False,learnmachinelearning,1505873364,False,[deleted]
TWIL (This Week I Learned) - Share something new that you have learned this week!,0,8,False,False,False,learnmachinelearning,1505891117,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
Understanding Machine Learning - free book,0,0,False,False,False,learnmachinelearning,1505891457,False, 
New to AI,5,0,False,False,False,learnmachinelearning,1505898669,True,Is there a glossary of AI terms available anywhere? I see so many nouns I can not understand. please help. 
Learn about the most cited and influential models and research papers for Named Entity Recognition,0,1,False,False,False,learnmachinelearning,1505899821,False, 
Researchers use Wikipedia to give Artificial Intelligence Common Sense Knowledge,0,2,False,False,False,learnmachinelearning,1505902860,False, 
What is meta-learning and meta-labeling?,0,3,False,False,False,learnmachinelearning,1505917421,True,"Hi all - I have a vague understanding of meta learning from the wikipedia page but I think I need an example or two to really understand. Also, what are meta labels and are they related to meta learning?
Thanks!"
What classifier to classify: object 1 - object 2 - object 3 - none of those 3?,3,2,False,False,False,learnmachinelearning,1505930923,True,"I am working on a project based on object recognition. I have 3 types of objects. I am always able to detect them but unable to correctly classify the using an SVM. Very often an ""unknown"" object is classified as eg object 1 with a very high certitude. My svm only contains 3 classes actually: object 1,2 and 3 I need 3 classes. I dont have any data about the ""unknown"" object when training. When the object s features don t correspond to any of the 3 objects, it should be classified as ""unknown"". What classifier would be the most suited for this?

I was eventually thinking about random forest, but not sure.

Thanks


**EDIT:**

My software contains an option ""disable object 2 and 3"", which means that in that case the classifie should be able to classify the object as object 1 or unknown.


**EDIT:**

Could it be that the incorrect classification happens because object 1 has 4x more training data than eg object 2?"
Snapshot Ensemble extension in CNTK?,0,2,False,False,False,learnmachinelearning,1505933290,True,"I'm asking if someone here has extended CNTK before and if I were to implement Snapshot-Ensemble (https://github.com/titu1994/Snapshot-Ensembles), how would one do that? By extending the learner or directly in CNTK source code?"
My First Weekend of Deep Learning,14,9,False,False,False,learnmachinelearning,1505937265,False, 
Is there a 'progressive' ML/DL course out there? One that starts with a 'hello world' example and works up from there?,4,1,False,False,False,learnmachinelearning,1505951895,True,"I am an experienced engineer, know python.  Done the ML boot camp with Python on udemy.  Feel like I have a shiny set of tools that I'm barely familiar with, and I kinda want to do some applied learning.  Break stuff, fix it, solve some real problems.

I'm looking for some series of practical ML/DL challenges, that start off very easy and then get progressively more challenging.  Perhaps with some potential solutions if you get stuck.

Anything like that out there?   Thanks.

"
AlphaGo Movie,1,13,False,False,False,learnmachinelearning,1505954945,False, 
Does anyone know any good free or cheap courses to learn machine learning and artificial intelligence?,6,1,False,False,False,learnmachinelearning,1505956121,True, 
Coding the History of Deep Learning,0,11,False,False,False,learnmachinelearning,1505975418,False, 
Tutorial for text prediction (tensorflow),3,3,False,False,False,learnmachinelearning,1505978706,True,"I am reading the tutorials in Tensorflow website and also watching courses in Pluralsight and uDemy. I was thinking to create something related to text than number predictions, using linear regression. For example, something like Census data https://www.tensorflow.org/tutorials/wide. 

Do you guys have any tutorial to suggest that you used when you were learning something similar ? All I find in github and google are related to numbers. "
Apparently ML is also used for creating spam emails now?,0,0,False,False,False,learnmachinelearning,1505983439,False, 
"Why do people say ""training"" an SVM while it is only a 1-time computation to know the hyperplane?",12,8,False,False,False,learnmachinelearning,1505988310,True,"Hi

AFAIK SVM doesn't use a real training like neural nets, where you go back and forth through the net in order to find the optimal weights. SVM only uses a 1 time computation to find the hyperplane which gives the largest margin.

Could someone explain or correct me in case I misunderstood something?

Thanks!

EDIT: seems like I tremendously disagree with this poor wording (not that I can change anything about it, but still...). It is not an iterative/recursive computation and I therefor despice this wording with an astronomical passion. Does participating to a basketball training 1 time mean you effectively trained? I rather see it as a one time event or initiation to some extent. IMO it is the fact that you keep doing it over again that makes it a training. 

It is because you want to improve the obtained results that you train it. A one time computation shouldn't be considered as a training IMO.
"
Any suggestions for tutorial on Keras/ RNN/ LSTM? (video or text),1,7,False,False,False,learnmachinelearning,1505994754,True, 
Can I use Tensorflow to do some form of string matching?,1,5,False,False,False,learnmachinelearning,1506002924,True,"Hi,

Sorry I'm new to machine learning and ave been looking around for a solution or example of how do to the following.

In essence for the training data, I've got a list of questions (think of them as possible support ticket titles) and then the matching support articles which they work for.

I would like to train the machine to read the strings and then output a list of articles they match by confidence. I've not used it but I suppose it's alot like [Answer Bot](https://www.zendesk.com/answer-bot/).

Following te diagram from [Scitkit](http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) it looks like I need to use Naive Bayes possibly but I'm not sure if that is the correct one?

Has anyone got any experience or seen something / a tutorial which could help me out? Thank you."
Rise with Trend in Automation,0,1,False,False,False,learnmachinelearning,1506005855,False, 
Beginner’s guide to text vectorization,0,1,False,False,False,learnmachinelearning,1506009882,False, 
"Lets Talk about Precision, Recall &amp; F-Measure in Machine Learning.",0,6,False,False,False,learnmachinelearning,1506015559,False, 
Need resources for tackling Reinforcement Learning through StarCraft II,1,1,False,False,False,learnmachinelearning,1506018164,True,So I decided to finally dive into Reinforcement Learning. I know that Google Deepmind had released a Starcraft II python library https://github.com/deepmind/pysc2. I've also looked into the Udacty Reinforcement Learning program https://www.udacity.com/course/reinforcement-learning--ud600. It seems like a good course to look into but I would like more hands-on resources that go into the code. Any recommendations (videos or text)?
Learn how to build and train a machine learning model from scratch! - Vivint's Game of Codes,1,0,False,False,False,learnmachinelearning,1506023377,False, 
Comparison of various classifiers from Scikit-Learn,9,84,False,False,False,learnmachinelearning,1506026257,False, 
Don't know how to choose:Panda vs Numpy,6,2,False,False,False,learnmachinelearning,1506036423,True,"First time posting here, I'm doing the andrew ng machine learning on coursera, almost finishing (week 9 of 11), there we use octave/matlab for the programming exercises. Now i'm trying to apply the recently learned algorithms aside the course problems. 
I have a telegram bot that send info to the users about their stats in rocket league. I started saving these data in db and now I have 7k rows but I don't know which one is the best library to load/analyze this data and build some algorithms. 
I started to build more simple algorithm to learn python(I come from a ruby background) using numpy and the classic iris dataset, but i had many problems in having more than one data type in the array(float,string), I endend considering everything as string and then use casting to turn string into float.
 I never used Panda dataframe so I don't know if cover my problem of multiple data types, I also know thinking in change my string data in class represented by numbers, is this what you guys do? Any thoughts or personal experience would be great. Thanks."
[1709.04396] A Tutorial on Deep Learning for Music Information Retrieval,1,1,False,False,False,learnmachinelearning,1506043510,False, 
Can anyone help explain this line from the TF MNIST tutorial?,2,1,False,False,False,learnmachinelearning,1506061563,True,"In the MNIST tutorial for Experts, they use CNN:

https://www.tensorflow.org/get_started/mnist/pros

What I'm having trouble understanding is this line:

W_fc1 = weight_variable([7 * 7 * 64, 1024])

I understand that the 64 comes from the previous convolution:
W_conv2 = weight_variable([5, 5, 32, 64])

But how do they know the image is now a 7 by 7? Was that just arbitrarily chosen?"
Weekly Show-off!,1,1,False,False,False,learnmachinelearning,1506063928,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
How do I model a pixel-wise regression convnet?,0,7,False,False,False,learnmachinelearning,1506076683,True,"I'll try to be concise.
I have 2 inputs:

* input_image of size (HxWx3)
* input_map of size (HxWx1), that was generated by a vision algorithm with ""input_image"" as its input.

The algorithm that generates input_map from input_image is not very precise (some values are wrong).
The purpose of the network is to assign to each input_map pixel a confidence value, meaning that for each pixel of input_map I want to output the probability of it being calculated correctly or not.

At training time I have a groundtruth_confidence_map:

For groundtruth_confidence_map (HxWx1), where each pixel can assume the value:

* 0 (corresponding input_map pixel is wrong)
* 1 (corresponding input_map pixel is right)
* -1 (data for that pixel is unavailable) , which could be used as a mask when calculating the loss.


I want as an output:
output_confidence of size (HxWx1)
where each pixel is a value [0,1] corresponding to a probability.

My questions are:
How do i structure the network in order to output a matrix of continuous values (not prediction classes)?
How do I model the loss function to ignore the unknown pixels?

Thank you in advance."
Could anyone please help me with Gym error?,0,1,False,False,False,learnmachinelearning,1506086814,True,"I'm using Linux Mint (fairly new to linux) 

I have installed gym but for whatever reason it isn't being found. 
I used this sample script from OpenAI's website to test if gym was working:

    import gym
    env = gym.make('SpaceInvaders-v0')
    env.reset()
    env.render()

I received this as an error when I tried to launch this in IDLE

    Traceback (most recent call last):
      File ""/home/bok/asdfjkl;.py"", line 2, in &lt;module&gt;
        env = gym.make('SpaceInvaders-v0')
    AttributeError: module 'gym' has no attribute 'make'


any help is greatly appreciated. I've googled for hours and cannot find any solutions. 

I installed using

    git clone https://github.com/openai/gym
    cd gym
    pip install -e .

"
Subtracting residual to improve regression?,0,1,False,False,False,learnmachinelearning,1506087364,True,"If I have a regression problem, is it okay to apply the regression model to a validation dataset first and use the residuals to ""correct"" the model before finally applying it to the test dataset?"
On-Site Training Recommendations?,2,0,False,False,False,learnmachinelearning,1506090240,True,"My company is willing to pay for me to attend on-site training.  Can anyone recommend a good 1 week on-site ML course?  I've taken quite a few IT courses in the past and have found it difficult to find quality training. 

I've taken this online course and thought it was really good: https://www.edx.org/course/programming-python-data-science-microsoft-dat210x-5"
The math of machine learning,10,32,False,False,False,learnmachinelearning,1506093652,True,"So actually I have seen some theory courses and videos of about machine learning but i havent seen any math, so where should I start for linear algebra, calculus and statistics?"
Questions about machine learning based face recognition project,0,1,False,False,False,learnmachinelearning,1506109998,True,"Hi

I don't have many years of experiences when it comes to machine learning so was hoping some people here could tell me what I may be doing wrong. I have tried multiple different approaches, the one I explain below gave the best results, but still...

#The situation:

I am trying to implement a login system using face recognition. My system contains 5 authorized users and any other person showing their face, who are not part of the autorized users, should be classified as unauthorized and therefor unable to login.
My system contains: Elon Musk, Jason Statham, Angelina Jolie, Bill Gates  [and this user which we will call John](https://imgur.com/a/4iXFF) (this link contains all the pictures I use for this person)

I am using [this framework](https://cmusatyalab.github.io/openface/), which allows me to align every face using facial landmarks and afterwards using a pretrained deep neural network to extract 128 features of the face it sees in order to compare it with the features of the faces which are allowed. 
For the actual comparison I implemented a one-vs-rest architecture of non-linear SVM's (with an rbf kernel) in python.
A code snippet showing how I set up the classifier:

    fname = ""/home/technicalQuestion22/openface/demos/featuresDir/labels.csv""
    labels = pd.read_csv(fname, header=None).as_matrix()[:, 1]
    labels = map(itemgetter(1),
                 map(os.path.split,
                     map(os.path.dirname, labels)))  # Get the directory.
 
    fname = ""/home/technicalQuestion22/openface/demos/featuresDir/reps.csv"" #contains 128 datapoints for every picture
    embeddings = pd.read_csv(fname, header=None).as_matrix()
    le = LabelEncoder().fit(labels)
    labelsNum = le.transform(labels)
    nClasses = len(le.classes_)
 
    svcClassifier = SVC(kernel='rbf', probability=True)
    classifier = OneVsRestClassifier(svcClassifier).fit(embeddings, labelsNum)


Every authorized user has 12 pictures. From each pictures those 128 features are extracted.

Now, all of this works perfectly fine: when I show a new picture of eg Elon Musk it is correctly recognized with an average certitude of 87%, same with all the other user. When I show a picture of a face that the system has never seen before and which therefor should be unauthorized, the system classifies it eg as Bill gates with a certitude 2% (highest certitude); which is OK as well, because with such a low certitude we know that this user is not allowed.

#The issue:

Everything seems to work fine so far... except when I show this unauthorized person's face (see 2 pictures below). Let's call him criminal Michael:

For some dark unknown reason, Michael is being classified as John with a certitude of up to 82%! 
The certitude fluctuates a lot, jumping from 20% straight to 82%, back to 55, etc...

79% certitude as being John: https://imgur.com/a/9zLIP

85%  certitude as being John: https://imgur.com/a/Fn0yx

#My questions:

1)  Why is Michael classified as being John with such a high certitude?

2) What can I do so that Michael is not classified as being John with such a high certitude?


#Remark:

It is not possible for me to take 1000 picture of every user. 

Thank you very much for your input
"
Can Specific boundary during candidate Elimination algorithm have more than one hypothesis in it?,0,1,False,False,False,learnmachinelearning,1506110798,True,"I think it's obvious from the question, but I am just starting to learn Machine Learning. I have been following Tom Mitchell's machine learning book and I'm reading the Candidate Elimination part. While I understand the logic behind the algorithm, I can't seem to find any case where Specific boundary can have multiple hypothesis.
So, is it possible for Specific Boundary to have more than one hypothesis? If yes, can you guys give me an example and help me out?

I am really sorry if this is a dumb question, but I really am wondering. Thank you very much :) "
Does having a GPU matter when running a CNN?,4,9,False,False,False,learnmachinelearning,1506121244,True,"I know that having a GPU really helps you speed up CNNs when training. But does it matter after training, and you're running the predictions? It seems like it might, since you can do a lot of the computations in parallel, but is the different noticable at all?"
"Check out the latest TWiML Online Meetup Recap! This month, we talk ""Learning Long-Term Dependencies with Gradient Descent is Difficult"" by Yoshua Bengio &amp; company. Subscribe Now!",0,1,False,False,False,learnmachinelearning,1506136066,False, 
"Weekly Status Check Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",0,3,False,False,False,learnmachinelearning,1506150312,True,"Let's have a  meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
A doubt in object detection,1,7,False,False,False,learnmachinelearning,1506166586,True,"I was reading this article on detecting rectangles in an image, [here](https://medium.com/towards-data-science/object-detection-with-neural-networks-a4e2c46b4491). My doubt is in the part where the model works fine with detecting a single object, but struggles with two rectangles detection.

The author reasons this as follows:

    We train our network on the leftmost image in the plot above. Let’s say 
    that the expected bounding box of the left rectangle is at position 1 in the 
    target vector (x1, y1, w1, h1), and the expected bounding box of the 
    right rectangle is at position 2 in the vector (x2, y2, w2, h2). Apparently, 
    our optimizer will change the parameters of the network so that the first 
    predictor moves to the left, and the second predictor moves to the right. 
    Imagine now that a bit later we come across a similar image, but this 
    time the positions in the target vector are swapped (i.e. left rectangle at 
    position 2, right rectangle at position 1). Now, our optimizer will pull 
    predictor 1 to the right and predictor 2 to the left — exactly the opposite 
    of the previous update step! In effect, the predicted bounding boxes stay 
    in the center.

I don't understand how this reasoning is correct, apart from the fact that when they try to flip the rectangles to mitigate this error, accuracy actually improves (so there's experimental observation, but not much theoretical reasoning).

The reason I think so is because in case of single rectangle also the network has to learn for all differently placed objects just as in the two-rectangle-case, so there too, it should predict boxes in the somewhat the center only. I have to concede I am only a noob in this, so I would love to find out where I am wrong in my reasoning, because experimentally I am wrong (i.e. accuracy does improve when rectangles are flipped).

Thoughts? Also if this is not the correct sub/forum for these type of questions, please feel free to guide me towards those that better suit the content.
And finally thank you for reading :)
"
Regression metrics and cross_val_score in numpy,0,2,False,False,False,learnmachinelearning,1506169141,True,"Hello,

I'm training a simple regression classifier and I have some problems with score function.

I use R2 score function to see if the regression goes well, and when I use code like that

    x_train, x_tmp, y_train, y_tmp = train_test_split(x_data, 
    y_data, test_size=0.5)
    clf = RandomForestRegressor()
    clf.fit(x_train,y_train) 
    y_pred = clf.predict(x_tmp)
    print(r2_score(y_tmp,y_pred))
    clf = RandomForestRegressor()
    clf.fit(x_tmp,y_tmp) 
    y_pred = clf.predict(x_train)
    print(r2_score(y_train,y_pred))

The scores are 0.997850397631, 0.997832787628 for each.
But when I try to use cross_val_score

    clf = RandomForestRegressor()  
    scores =cross_val_score(clf,x_data,y_data,cv=2,scoring='r2')
    print(np.mean(scores))
The scores I get are [-0.35056264 -0.62069969].

As far as I understand these two blocks of code should do the same thing, so why the scores are so different? I plotted the predicted and test values on the same graph, and it seems that scores from the first block should be correct. So what am I doing wrong?"
Generative Learning as p(y|x)p(x)?,3,6,False,False,False,learnmachinelearning,1506180130,True,"So generative learning tries to learn the distribution of p(x,y) by learning p(x|y) and p(y). My question is what's the difference between learning p(x|y) and p(y) vs. p(y|x) and p(x)?"
What are your top recommended books for Machine Learning?,9,22,False,False,False,learnmachinelearning,1506181382,True,"Hi Reddit!

I'm looking for recommendations from people that have read a few machine learning books and have found a few they highly recommend because I want to add them to my [resource library](https://eatsleepdata.com/pages/library) on my blog for others to find. Right now I have a few that my friends or I have read.

Also please let me know if you have any ideas for something you want to see or ways to make the library better. :)
"
Epoch vs Batch Size vs Iterations,0,1,False,False,False,learnmachinelearning,1506188679,False,[deleted]
Epoch vs Batch Size vs Iterations: Machine Learning,0,5,False,False,False,learnmachinelearning,1506188737,False, 
Geometric distribution and its basics.,0,5,False,False,False,learnmachinelearning,1506193383,False, 
Anyone know of a good resource to learn the matrix algebra involved in least squares?,1,6,False,False,False,learnmachinelearning,1506197300,True,"I took a linear algebra course a long time ago, and I'm looking to specifically brush up on anything involved (likewise for analytical PCA, but moreso for least squares regression)

I guess I'm wondering if there's a cheat sheet or quick tutorial for the simpler matrix factorizations/algebraic operations

any help appreciated!"
How can I create a feed-forward with multiple outputs in MATLAB?,0,2,False,False,False,learnmachinelearning,1506211642,True,"Hey, I was wondering is it possible that in MATLAB, my network outputs n number of outputs instead of one? "
"I've been out the loop since January, can you fill me in on whats been going on since then?",7,34,False,False,False,learnmachinelearning,1506220329,False, 
Ethereum Price Predictor Project,2,6,False,False,False,learnmachinelearning,1506225783,True,"So my project is using the current opening price for ETH according to GDAX's API to make a prediction for what the price will be in an hour. I wish I had a better understanding of theory, but I don't (I'm working on it though). Currently I have a super vanilla RNN that just takes opening price into account but I eventually want to incorporate other information that GDAX's API provides (volume, high, low, etc). My current issue right now it that although I get a prediction, sometimes the prediction is significantly off. How can I figure out how good my model is (accuracy, etc) besides maybe cross validation? Also any advice more making the RNN more custom or if I should be modeling the problem in another way?"
Backprop gradient checking,5,2,False,False,False,learnmachinelearning,1506232466,True,"Hello,

I'm implementing gradient checking on a toy neural network. My gradients check out when I use only a single example to calculate the gradients (computed gradient == my backprop gradient), but if I use multiple samples, the computed / estimated gradient is greater than my backprop gradient by a factor of `(1 / m)` (where `m` is the number of samples).

I think this is because I am comparing the computed gradient:

    ((theta + epsilon) - (theta - epsilon)) / (2  * epsilon)

with the *weight update* [as shown here](http://deeplearning.stanford.edu/wiki/index.php/Gradient_checking_and_advanced_optimization), which includes a `(1 / m)` term.

When I use gradient checking, am I supposed to be comparing to my weight update (e.g. the `w - ((1 / m) * LR * deltaW)` part of `w := w - ((1 / m) * LR * deltaW)`), or just the `deltaW`?

I presume just the `deltaW`, based on my results above, but then why do we divide by `m` for the update?

Thanks for any insight you can provide."
simple question about ml,2,1,False,False,False,learnmachinelearning,1506245092,True,"hey im not really learning ml per se but haven to agree it has caught my mind.

how do you guys generate/gather large amounts of data for research and all? 

how do you guys know if the data is authentic?

if theres a case where you cant find any data to do your research/analysis on, howd you go about collecting it or even generating it?"
Super embarrassed to ask about this but why is the slope intercept form flipped for these graphs?,7,1,False,False,False,learnmachinelearning,1506258824,True,"I know I can't figure this out and I'm learning machine learning. 

https://i.imgur.com/MJuVHtU.png?1

Screenshot is from andrew ng's machine learning course.

So I kept thinking this in slope intercept form. y = mx + b
and it seems the formula he uses is y = b + mx? 
For the 3rd example when you plugin 1 for x you would get 
h(1) = 1 + 0.5 now if we use normal slope intercept 1/1 is the slope and 0.5 is the intercept , but the graph he did was completely opposite. It starts at 1 on the y axis and increases the slope by 1/2 every time. I'm confused can some one give me some pointers?"
Could I group similar realty from a dataset using clustering,2,0,False,False,False,learnmachinelearning,1506266527,True,"I would like to know if I can group similar realty using clustering, with a fixed cluster size of 10 for example.

And if I got a new realty could I define to which cluster he would belong?

If I can't do that with clustering, there is any other way to achieve a similar results using machine learning?

Edit: for clarity"
Facial recognition and swapping project,2,3,False,False,False,learnmachinelearning,1506279227,True,"Hello all,

I have set out to start a face swap video project. Specifically I am interested in taking a video (2hours or longer in length), and using facial recognition to replace particular faces in the video with other faces.

This seems like it would be a fairly formidable task, and from what I've seen online I guess the best route would be to use opencv. 

Unfortunately I have minimal knowledge of ML, and a bit of newbie programmer interested in this project as a creative endeavor.
I have tried to scour for tutorials that would be easy for a beginner like me to use and it seems like these two links would be a good place to start;

(https://www.superdatascience.com/opencv-face-detection/#disqus_thread)
(http://www.kpkaiser.com/programming/the-mostly-newbies-guide-to-automatically-swapping-faces-in-video/)

Again, since I'm mostly a beginner I'm really looking for the easiest possible way to do this and would prefer to use things others have already built.

Thank you for your time, and help!"
Back-propagation algorithm in simple 3-layer sigmoid Neural Network -- still confused.,0,3,False,False,False,learnmachinelearning,1506283010,True,"Alright, here is the code I'm using:

    def train(self, inputs_list, targets_list):
        #Convert inputs and targets to 2D matrices 
        inputs = np.array(inputs_list, ndmin=2).T
        targets = np.array(targets_list, ndmin=2).T 

        #calculate final output from querying the network 
        hidden_outputs = self.activation_function(np.dot(self.wih, inputs))
        final_outputs = self.activation_function(np.dot(self.who, hidden_outputs))

        #error is the target outputs minus the actual ones 
        output_errors = targets - final_outputs #derivative of SUMMATION( (target-actual)^2  ) with no regard for the -2 that results from the math 
        hidden_errors = np.dot(self.who.T, output_errors)

        self.who +=  self.lrate * np.dot((output_errors * final_outputs * (1.0 - final_outputs)), np.transpose(hidden_outputs))
        self.wih += self.lrate * np.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), np.transpose(inputs)) 


The forward pass makes perfect sense to me; so does the derivative being calculated for the weights between the hidden layer and final layer. What I do not understand is how the same formula used for *those* derivatives can be used for the derivatives for the first layer weights.

I understand that we back-propagate the error so that the hidden layer nodes now have their own errors.... but how can we just plug those into the original derivative function that expects to ""undo"" the error function **when there is no error function for the hidden layer**?  Is the error function carried back with the back-propagation?"
Is it possible to create an architecture where a sentence can be processed by a character lstm and a word lstm in one static compute graph?,1,8,False,False,False,learnmachinelearning,1506310418,True,"I'm currently playing with Char-RNN's and Word-LSTM's for a spam detection dataset to learn more about using RNN's and tensorflow (that's the actual goal, not so much the problem itself). 

Right now I'd like to feed in the many-to-one output of a CharRNN and the many-to-one output of a WordRNN into a classification layer to see some preliminary results. I'm currently doing the word vectorization and character vectorization separately and inputting them as two variables into the graph. However, because of variable length words/sentences I'm having difficulty concatenating the final feature vector symbolically - I know frameworks like PyTorch would make this simpler, but is there any way to emulate this in TF?

My final goal is to build a web service in Go using the trained model, so outputting a graph that's generalizable is a must. "
Hypothesis space,2,2,False,False,False,learnmachinelearning,1506315112,True,"I understand that this is a basic question.

I've spent a bit of time trying to understand what a hypothesis space.

So far, I got that it is the set of all possible function that you can learn.

In practice, where does that come in? 

A lot of machine learning concept (feature engineering, tuning, etc) have a direct mapping to an action a data scientist/analyst would do as a job but I can't seem to find one for finding a good hypothesis.

Is it something that a DS has to actively ""come up with""? Or is it something that the algorithm does in the back end while learning from the data?

And if yes that it's something you actively look for, how would one go about finding that approximation?"
Free ebook(TODAY only) python machine learning blueprints,0,1,False,False,False,learnmachinelearning,1506326470,False,[deleted]
Splitting decision trees - why do we want the tree to be as shallow as possible?,1,3,False,False,False,learnmachinelearning,1506328119,True,"When constructing a decision tree, we use a measure such as the Gini Impurity or Information Gain to decide which split is best. IIUC, we want to have as shallow as tree as possible.

But why do we care? What difference would it make if we would construct a larger decision tree splitting on some non essential parameter first?

Is it because we ideally don't want to rely on those features that do not seem to carry much information as there is a higher chance we would be fitting the noise and thus limiting our ability to generalize?"
Deep learning model that outputs a set instead of a tensor?,1,1,False,False,False,learnmachinelearning,1506339066,True,"I have an ANN that maps sequences to sequences. However, for my particular data there are inputs that should match several outputs because ordering of the output ""sequence"" doesn't always matter. I'd essentially like to output a set instead, but the cardinality varies for the same size input (think ""event detection"" from some hardware sensors).

I'm currently thinking of achieving this invariance by just augmenting my training data with the relevant permutations, but it would produce a __huge__ amount of samples. Are there obvious ways of modelling outputs that are essentially sets of tokens for ConvNets?"
Backpropagation algorithm derivation,3,25,False,False,False,learnmachinelearning,1506342135,False, 
[Noob] Trying to understand how to approach KNN algorithm on the MNIST data set?,2,1,False,False,False,learnmachinelearning,1506343745,True,"Hello! I am extremely new to machine learning and hoping someone can help explain this to me :)

I watched this fantastic video that explained the basic idea to me: https://www.youtube.com/watch?v=MDniRwXizWo

But I'm confused and feel a bit disjoint when I look to implement this on my own.

Trying to follow this page: https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm

_I understand:_

1: I need to get a distance function. Such as Euclidian distance.

2: Get the ""k"" nearest neighbours and average their weight to perform regression. And whatever class is the dominant class of the nearest neighbours is the classification task.


_What I am confused on:_

1: What are my feature vectors? Say it is the MNIST data set (pretty classic data set from what I understand?) so I have a 28*28 image, is it going to be all pixels? So vectors are going to be 784 dimensions each?

2: And for these vectors, what does it really mean to have a class label... and where are we storing these? In some matrix? I am really confused on this point. Like, I have no sense of where I am storing these or how I can compare these. Especially since a 28*28 image is 784 dimension feature vector.

""The training examples are vectors in a multidimensional feature space, each with a class label. The training phase of the algorithm consists only of storing the feature vectors and class labels of the training samples.""

3: When calculating distance should I be calculating it for all 784 points? I'm not sure what the ""distance"" I am meant to be calculating is exactly. I know the distance formulas well enough, those are easy. But where to apply it feels foggy.

4: When calculating the distance I need two points.

Since KNN is not trained... how am I getting the points to compare the new point's distance to?"
Do join this free event at Google Quad Campus. Limited seats available!!,0,0,False,False,False,learnmachinelearning,1506345154,False, 
A push in the right direction,0,1,False,False,False,learnmachinelearning,1506357703,True,I have a bunch of invoices on pdf and the computer to be able to guess which supplier an invoice belongs to. I know this is super basic stuff but I just need a nudge in the right direction regarding technology and tools. Thanx a bunch!
Adaptive Gamma in Q-Learning,0,2,False,False,False,learnmachinelearning,1506357833,True,"Question for those of you who are more adept at Q-Learning scenarios.  
  
Normally γ(gamma) in the Q-Learning scenario is used to discount future rewards based on inherit risk of the situation ending prematurely. If you have sufficient data to be able to know when risk is higher, would using an adaptive γ(gamma) be a worthwhile approach to solving problems, or is this something that the model already accounts for when learning?"
"Is ""negatively correlated learning"" of neural net ensembles still used?",1,1,False,False,False,learnmachinelearning,1506376006,True,"I've been experimenting with creating ensembles of neural networks. In most cases, their errors have ended up having a very positive correlation.

So I looked for ideas, and it seems there is/was a method of training the entire ensemble together and introducing an explicit penalty in each ensemble member's error for correlation with the rest of the ensemble's error. I see it called NCL (negatively correlated learning).

Most papers on this seem to be 5 to 15 years old though. Is this method still used? Are there better methods for creating negative correlation between an ensemble of learners? (I'm familiar with random forest, but need to create an ensemble of neural nets.)

(X-post from /r/MachineLearning, but this seems like a better place to ask.)"
Question on Weighting in Convolutional Neural Networks - effect of data repetition.,1,3,False,False,False,learnmachinelearning,1506392696,True,"Away from my DL rig and this came up at a group discussion tonight.  If you take a standard CNN (think Alexnet or VGG) and train the CNN with 100 unique images from imagenet, what would happen to the CNN's internal weights if:
You fed the same image through the CNN twice?  Would internal weights of that image double, increase by some other amount (how to calculate?) or is it dependent upon WHEN in the sequence that duplicate image is applied?
2.  What about same duplicate image but now using a RESNET approach?

Any opinions?  Thanks
"
"Just starting machine learning and the amount of python shell programming is surprising, is this how it's done?",23,24,False,False,False,learnmachinelearning,1506405953,True,"I'm going through a bunch of tutorials on matplotlib, pandas, numpy, sklearn etc., and a lot of them are based on Jupyter notebooks, which seem to be pretty cool.  But for me, following along, I want  to write my code in a file so that it's easy to review.  While writing the shell scripts in a file I I have run into some small, but disruptive, diferences.  Should I start gettting used to doing data science in the shell?  Or should I continue to find work arounds?"
"Noob question: finding a mathematical model to predict vapor pressure of water (2 features, less than 10^4 training samples)",0,1,False,False,False,learnmachinelearning,1506409797,True,[removed]
Design guidelines for RNNs,2,6,False,False,False,learnmachinelearning,1506413509,True,"I'm rather familiar with CNNs and how to change the architecture when certain problems or limitations emerge. However, RNNs are still a little new to me.

What are some rules of thumb for managing the width and depth of a RNN architecture? When would I change one but not the other? I'm mostly talking about LSTM and GRU. Where would I usually try to position dropout and is it common to finish of with multiple dense layers? Any general rules would help me a lot. 

Thanks for your time. "
How do we calculate the growth function for the learning model made up of two concentric circles in R^2?,0,1,False,False,False,learnmachinelearning,1506424791,True,"Compute the growth function mH(N) for the learning model made up of two concentric circles in R^2. Specifically, H contains the functions, which are +1 for (a)^(2)≤(x1)^(2)+(x2)^(2)≤(b)^2 and −1 otherwise."
Best Loss+Activation layer setup for multi-class problem?,2,1,False,False,False,learnmachinelearning,1506432033,True,"I amtraining a network, which should generate an output vector only consisting of 0 and 1, e.g. [0,1,0,0,1,0,0,0,1,1].  

Currently I use a Sigmoid Layer as my last non-linear activation function (because it limits the output into the range [0,1]) and compute the MSE Error.  

I would be interested if there are better non-linear activation functions or losses to use for this purpose of training?

Thanks in advance!"
Which techniques are common practice when training ANNs?,1,1,False,False,False,learnmachinelearning,1506432391,True,What are the current state of the art techniques? Does everybody actually use Batch Norm or a specific learning rate policy? Mostly RELU und Dropout?
"What is the best type of machine learning algorithm to solve this type of supervised problem?: 'Fill in the blank with ""a"" or ""an"": ""I have * dog"", ""This is * atrocity"", ""You're acting like * animal."", ""What * day."" ' And where is a good place to start learning how to implement it?",8,1,False,False,False,learnmachinelearning,1506432995,True,"Edit: My actual program will need to differentiate between other pairs of words than ""a"" and ""an""."
Bayesian learning for statistical classification to improve your model,0,18,False,False,False,learnmachinelearning,1506433499,False, 
Need help implementing an LSTM,8,3,False,False,False,learnmachinelearning,1506436068,True,"I don't have much practical experience, just recently finished Andrew Ng's Machine Learning on Coursera.

I have a set of sports data which I want to run through an LSTM to analyse player performance.

I have a 3 dimensional array of feature values - x_array3d, dimensions (x,y,z) where x denotes different players, y denotes the features for each player, and z denotes different matches for which the features were recorded.

I have another vector array, y_array3d (which is actually 2d but whatevs) of dimensions (x,z) where x is the player and z is a score they achieved in the match they are being predicted for.

Is my data formatted correctly to run through an LSTM, and how would I do it? I am using TensorFlow."
Question - Getting started with Machine Learning,16,10,False,False,False,learnmachinelearning,1506441750,True,"Hey guys.
I'm really thinking about going for Machine Learning on my master's thesis. My background is frontend developer, working on JS frameworks.

My knowledge about Machine Learning is really small as I've never tried or got classes about it before.

This being said, need an answer to 3 questions:

- 1. Whats the best language to go for? (Python seems a good choice)
- 2. Any online course that is a 'must watch' / book that is a 'must read' to go forward on this topic?
- 3. Any suggestions about a theme for the thesis? I would like to work a real-time stuff or prediction/pattern finding using machine learning when receiving a big amount of data from an API for example.

Thanks in advance &lt;3
"
"This week we are back with another NLP discussion, this time with Jonathan Mugan of DeepGrammar. We talk Symbolic &amp; Subsymbolic NLP, WordNet, FrameNet, Synsets and more!",0,8,False,False,False,learnmachinelearning,1506443747,False, 
The graph I made to represent this last week when I got sick and lost all faith in my ability to understand data science and machine learning.,5,27,False,False,False,learnmachinelearning,1506453766,False, 
Learning the maths behind ML?,6,3,False,False,False,learnmachinelearning,1506456344,True,"Hello,

I'm a software engineer, I'm quick at picking concepts up - but I'd love a resource that covered all the maths I needed to know to understand ML without assuming ANY previous knowledge.

Does anything like this exist? "
Is it incorrect to run clustering on the output of t-sne?,1,5,False,False,False,learnmachinelearning,1506483460,True,"There seems to be conflicting information on the internet or perhaps I'm not interpreting it correctly, but is it incorrect to run clustering on the output of t-sne? 

These answers \[[1](https://stats.stackexchange.com/questions/263539/k-means-clustering-on-the-output-of-t-sne/264647#264647), [2](https://datascience.stackexchange.com/questions/10802/can-closer-points-be-considered-more-similar-in-t-sne-visualization/10820#10820)\] seems to suggest that t-sne should only be used for visualization, but I see implied clustering after t-sne from other examples \[[1](https://blog.datascienceheroes.com/playing-with-dimensions-from-clustering-pca-t-sne-to-carl-sagan/), [2](https://medium.com/@luckylwk/visualising-high-dimensional-datasets-using-pca-and-t-sne-in-python-8ef87e7915b), [3](http://www.cellaccense.com/)\] . Who's right?"
What algorithm should I be using to predict an output based on sets of binary data over time with a result?,4,1,False,False,False,learnmachinelearning,1506488906,True,"I have a set of data sets which are binary data mapped to time. Each data set has a final output value float. I 
want train an algorithm to predict based on these past data sets what the current set of data will likely output.

I've been reading about Machine learning algorithms, and I'm having difficulty finding the right algorithm. I feel like this is a very simple problem.

Back-story: I created automated cat feeders that use an auger to output cat food. I have an imperfect whisker switch which reads on or off when food randomly hits it in the right way. The readings are pretty consistent and I have it's binary on/off value saved over a given duration (between 200 - 400 readings for 20 seconds varying lengths of ""on"". Pretty accurate too from what I can tell, but definitely imperfect), then I measure the final weight of the food. I want to train an algorithm so as it's feeding I can estimate the current amount of food that has been dispensed based on the current set of data. It would really only need to run the prediction every .25 seconds, so I imagine this would be manageable by the cpu.

Originally I thought the alogrithm might be a simple linear regression, but I feel like that's missing actually learning from the fact that I have essentially an ""image"" of the data and then an output. It might be better to consider this a classification problem? E.g. I classify my current image of the output and estimate what the classified output weight of the food would be for the current state of the data.

I'm also considering adding a scale to the raspberry pi to continuously weigh the output (or at key points) to help train the algorithm, but this can't be used while in use since the cats eat the food as it's feeding them. It would just help with the training of the algorithm.

My goal is to feed them more exact weights of food.

Maybe I'm making this way too complicated and I just need to get a scale, measure it based on time, and find the likelihood of a given weight per amount of time with the whisker switch high."
"[Q-Learning] Is it ""cheating"" to let the agent see predefined rewards?",3,7,False,False,False,learnmachinelearning,1506495489,True,"So I'm starting into machine learning with Q-Learning and this question came up while searching for good examples.
A lot of them seem to be using the rewards table to decide if an action is possible or not
By definition however, Q-Learning should be used in an *unknown* environment. So I'm thinking, by telling the agent which actions are good without it having to actually do them, you're essentially showing it the environment."
TWIL (This Week I Learned) - Share something new that you have learned this week!,6,9,False,False,False,learnmachinelearning,1506495914,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
do any tools exist for building our own image recognition test/validation datasets? [x-post /r/MLQuestions],0,2,False,False,False,learnmachinelearning,1506534189,True,"So for example, the cats &amp; dogs kaggle dataset. I would like to create my own dataset(s) for other types of objects, perhaps using google images or another source. However, google images isn't always accurate, so I would think I could take a small set of manually curated validation images (say, 100) and use those with keras to parse google image results just like cats &amp; dogs. Then, use images that make the cut for a larger testing/validation set.
Before I try to cobble something together myself, are there any tools that do this already?"
Understanding Active Preference Learning with Discrete Choice Data,0,4,False,False,False,learnmachinelearning,1506545199,True,"Understanding Active Preference Learning with Discrete Choice Data

Hi guys, have any of you have any coding that shows an example of the application described in this [paper](http://machinelearning.wustl.edu/mlpapers/paper_files/NIPS2007_902.pdf)?

On this scenario, where you give an user 2 options and he chooses the one he prefer the most, having the options as x and the preference as f(x), how are this represented?, is f(x) between -1,1? whenever a higher preference comes I just go beyond the last limit (eg: 1.1) ?

Thanks :)"
A number of multiplayer AI questions,0,1,False,False,False,learnmachinelearning,1506553956,True,"I've always wanted to make an intelligent AI opponent that could quickly adapt to your actions and outsmart you, and I have always wanted to go with the min-max algorithm that chess AI follows, but apply it to 3D games and platformers. 

This could get tricky, but I wanted to know if it was possible on the following:

- In which programming language is this feasible? 

- In what game development environment can this be done?

- combining the two, how much coding and scripting would be required for at least a platformer game? "
Problems with first neural network,8,1,False,False,False,learnmachinelearning,1506557716,True,"I am having trouble with my first neural network.  I've used this post as a reference to how to handle the network as a series of matrices as I think that would be better than tracking individual neurons.  
http://briandolhansky.com/blog/2014/10/30/artificial-neural-networks-matrix-form-part-5  
  
I coded the program in python using numpy and a psuedo functional style where I compose each step and pass the data forward and then the error backward through the network.  It has some side effects where it stores data needed for later, but, at least I can declaratively write forward and backward propagation.  
  
This is for a class and the task is to represent the XOR function. 
 I have to manually code the network without using any frameworks.  Every neuron in the network uses the sigmoid activation function and I am tracking error with half mean square error.  The network shows only very slight error improvement over many epochs, but it seems to be adjusting the weights uniformly, as the global output for all 4 instances of the XOR problem trend the same direction during training.  
  
I plan to do the mathematics by hand tomorrow when I get some time to see if I can find out where it is going wrong, but if anyone here can spot the error from the code, I would greatly appreciate it.  In the github repo, NN_Lib are most of the individual functions that get composed, NN is the actual neural net class, and NN_Driver is code to try to train a network.  Also attached are diagrams I made of what should happen with all of the matrices throughout each step as well as the xml file to open it in http://draw.io.  Green arrows represent forward propagation and red arrows represent backward propagation.  Also, the ""+ 1""'s throughout represent bias weights or outputs, and the starting X matrix is the training data after stripping the answers, which are stored in Y.
  
Here is the github repo: https://github.com/ZDTaylor/NeuralNets  
  
TL;DR:  Self-implemented binary classification neural network won't learn.  Would appreciate help determining why."
Sudden explosions in loss in my first written fully connected layer .,4,4,False,False,False,learnmachinelearning,1506558493,True,"Here's the code first : 
https://gist.github.com/omdano/de5f8361b0f3610a02215af42f4393d0


So basically i'm trying to predict a certain function Y = (2*(X)^2 ) using a single fully connected layer which i know is 100% doable since i've ran another single fully connected layer using tensorflow's library .



however explosions in loss are occurring periodically such as :

https://imgur.com/a/a8woB

(the values between brackets are losses and the one marked is one of the explosions)


what's going on here ? 

I've been trying and playing with optimization methods as visible on the code .. 

the code runs perfectly on linear functions .."
"Where can I get medical dataset for research purposes? Specifically bone images (DICOM, jpg..)",2,2,False,False,False,learnmachinelearning,1506571410,True, 
Free eBook: Machine Learning for the Web (PDF/ePub/Mobi),0,16,False,False,False,learnmachinelearning,1506587504,False, 
Find missing/superfluous item in group. Need some pointers where to start,0,2,False,False,False,learnmachinelearning,1506612862,True,"I need some pointer where to start. My data has individual groups, each containing one or more items (up to ~ hundred). When a new group is added with a couple of items, I want to identify which item(s) are missing/superfluous in this new group.

What should I read, where can I start?"
Linear Regression from Scratch in Python,3,17,False,False,False,learnmachinelearning,1506617475,False, 
RNN predicts average input,3,2,False,False,False,learnmachinelearning,1506622744,True,"Every time I play with RNNs and make my own, it converges to the average of expected output. I feed n time steps of input and try to predict next n steps, but my network returns a (near) constant output that converges to the average of the input as training progresses.


What am I doing wrong? Too many hidden parameters? To layers? How can I determine what the problem is?"
I need help understanding the second part of the Gradient Descent formula from andrew ng's ML course.,5,1,False,False,False,learnmachinelearning,1506627199,True,"https://i.imgur.com/dWDdZ8M.png

In the second part of the picture it shows I need to multiply everything by x^(i) or the i th element in x. Why? I went back to week 1 and watched the gradient descent video again I didn't see him mention any of this I did see him write x^i but he didn't talk about it at all. I understand the concept of gradient descent, I need to find the first slope from function J, then use the original theta minus or plus (depends on slope direction) the derivative that we just found, . To slowly stepping towards zero which is where the global optimum sits. I don't understand how we just went from this to needing to multiply the i th element of x?
Unless x^i is the step size?"
What are beginners projects using neural networks?,2,3,False,False,False,learnmachinelearning,1506632397,True,"Hi

I started learning about neural networks. I have a mathematical understanding of how a fully connected neural network and a convolutional one work. 

It is pretty easy to just go through a tutorial, copy paste the code and see the results you obtain with your copied neural nets (although you understand the maths behind it).

So I'd like to know what little projects (that don't contain too many pitfals) I could make to start having hands-on experience with neural nets.

The endgoal (after a few projects?) would be to be able to tell my employer: ""Yes, I have experience with fully connected NN's and convolutional ones I can work on a real project that requires one of those.... (Now raise my salary plz)""."
"Computer Vision, Machine Learning, and Control Theory",1,10,False,False,False,learnmachinelearning,1506646113,True,"Hello,
I currently have a computer vision app on my RPi that takes images of a target and receives a few data points including the height, width, x, and y of the image. I would like to train a model(in Python) so that my robot can take the optimal path to the target. What are the libraries/concepts I should look into for this? I read somewhere that neural networks might work but I'm not really sure how they are better or worse than regression or anything else. 
Thanks"
How difficult to group images by similarity,1,1,False,False,False,learnmachinelearning,1506646984,True,"I'm a beginner (but experienced dev).

I'll be honest I have a massive collection of pr0n (images and videos, but let's start with images for now, 100GB). They depict different scenes or positions.

I would like to group them by theme or ""similarity"". E.g. same position, same angle of body shot, etc. but there's too many to do manually.

I have a couple questions...

1. Do I need to set up the categories and train or is there some automagic way to group by similarity without training?

2. Is it feasible to do this locally (SSD, fast processor, don't mind if it runs for a few days)?

3. On a high level what is the process of doing this (which techniques should I research more)?"
Learning algorithms practice,2,2,False,False,False,learnmachinelearning,1506651153,True,"Hi:

Is there a list of learning algorithms or search optimization algorithms that I can practice implementing? I've done gradient descent and would like to move on to some others.

"
Deep learning with Keras - YouTube Playlist,2,43,False,False,False,learnmachinelearning,1506657308,True,"[Deep Learning with Keras - YouTube Playlist](https://www.youtube.com/playlist?list=PL_SSujepRkqyjjbWnXQBzKXXm86UQ53Ic)  

This playlist gives step-by-step tutorials for getting started with deep learning using Python and Keras. 

Some topics include:

- What prerequisites need to be met to start working with Keras
- Keras configurations
- Preprocessing data 
- Creating a neural net
- Training a neural net
- Using a neural net to predict on data
- Creating a convolutional neural net
- Using pre-trained models
- Fine tuning models
- Saving and loading model weights


[@blkHoleDetector](https://twitter.com/blkholedetector) | [YouTube](https://www.youtube.com/channel/UC4Huog4qcFfGrq_y7vKMJvg) | [Steemit](https://steemit.com/@blkholedetector)"
Weekly Show-off!,0,8,False,False,False,learnmachinelearning,1506668719,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
are the different types of general ML/DL problem categories listed anywhere?[xpost /r/deeplearners],2,2,False,False,False,learnmachinelearning,1506688075,True,"if kaggle 'dogs vs. cats' is an 'image classification' problem, then what kind of problem is kaggle 'Titanic: Machine Learning from Disaster' problem?
are the different types of general ML/DL problem categories like these listed anywhere?"
Machine learning courses covering clustering algorithms,1,9,False,False,False,learnmachinelearning,1506704479,True,"Greetings all. I finished Andrew's Machine Learning Coursera course this week. My interest in machine learning is directly related to a project I will be conducting which involves clsutering of MRI images among other types of data. I was wondering if there is any particular course or book you would recommend for the to learn about this stuff, preferably one that is up to date.

I was able to find the following, but really can't tell which is the best:

Coursera  - Cluster Analysis in Data Mining
https://www.coursera.org/learn/cluster-analysis

Udemy - Cluster Analysis and Unsupervised Machine Learning in Python
https://www.udemy.com/cluster-analysis-unsupervised-machine-learning-python/

Udemy - Cluster Analysis- Theory &amp; workout using SAS and R
https://www.udemy.com/cluster-analysis-motivation-theory-practical-application/

Udacity - Segmentation and clustering
https://www.udacity.com/course/segmentation-and-clustering--ud981

eDx - Cluster analysis
https://www.edx.org/course/cluster-analysis-utarlingtonx-link-la-cax#!"
Tutorial: Accessing scikit-learn's preload datasets (as I've been learning ML it took me a while to figure out how to access these preloaded datasets so I made a tutorial for other beginners),0,10,False,False,False,learnmachinelearning,1506733597,False, 
"Weekly Status Check Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",3,1,False,False,False,learnmachinelearning,1506755111,True,"Let's have a  meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
How to do one class classification with a neural net?,28,10,False,False,False,learnmachinelearning,1506761514,True,"Hello

I have a mathematical understanding of fully connected neural networks, but have no real idea about how to start the project I have in mind: one class classification using neural nets

I have a set of 128 keypoints describing an object (object A). I'd like to train a neural net to be able to tell me whether yes or no based on the keypoints I passed to it, it is object A.

In other words it is a one class classification problem.

I mainly use sklearn in Python or eventually tensorflow if that's more suited.

so far I have the dataset, ie 200 matrices (containing the 128 keypoints each) I extracted from 200 pictures.

Could some people help me on how to get started? I haven't found anything in sklearn about one class classification with neural nets.

So far I was thinking about having an input layer of 128 neurons, 1 hidden layer of 128 neurons as well and 1 neuron in the output neuron which uses an activation function telling me how sure it is about whether the keypoints I passed to it describe object A.

what I have in mind: https://imgur.com/hoOCzF0

**EDIT:** another approach I was thinking about was trying to detect whether the keypoints I pass to the net are outliers or not. Some sort of RANSAC approach."
How I can move forward with machine learning?,4,4,False,False,False,learnmachinelearning,1506767782,True,"Hi,

I feel I'm stuck with moving forward on machine learning. I have a software development background. I did the ML course from coursera too and I try to be updated in every major step on this world. But I don't see myself in the next step.

An example will clarify things: I'm always looking for new ideas to apply machine learning so I can build something. Either I find a good idea or a good dataset and I say to myself 'All right, let's do this'. For example, I just read the paper from Google about Smart Reply: https://arxiv.org/abs/1606.04870 so I want to build something similar just for testing but just looking at it I can't even imagine how to reproduce it.

You can say that I'm trying to do something that only people with that background and with that dedicated job can do at Google. So here there is another example. I saw a dataset of online food orders in a supermarket. How can I predict who buys what depending of previous order? Looks like a simple seq2seq problem but then I have to build the neural network in between I don't even know how to start.

I want to use Keras as I read is easier than Tensorflow but I think I need to build like 20 neural networks following steps before starting with something on my own. Where I can get that?"
Reinforcement (R) vs Online Supervised (S) Learning,4,2,False,False,False,learnmachinelearning,1506784607,True,"I'm having trouble distinguishing the two. So far what I have found are:

(R) - Feedback is delayed, not instantaneous. Time really matters (sequential, non i.i.d data). Agent’s actions affect the subsequent data it receives.

(S) - We can perform supervised learning, where the inputs are **sequences** of states and outputs are actions. 

(R) - There is no supervisor, only a reward signal

(S) - But isn't loss value a negative reward?

(R) - Trial and error learning (on past experiences=exploitation and also new choices=exploitation)

(S) - We can create an algorithm that makes random decisions with a certain probability.

What am I missing here?
"
supervised reinforcement learning?,3,4,False,False,False,learnmachinelearning,1506799281,True,"Has anyone seen any examples of reinforcement learning used for classification?
I have made a simple simulation  environment with an agent inside and I want the agent to explore the environment. Each environment is a little different and I want the agent to be able to tell me which environment it is in. Normally RL is unsupervised, but in this case I have to tell the agent which type of environment it is in during training. Then when I don't give the label for the environment, it will tell me what environment it is in( classification). Im not sure how to wire up the RL algorithm to include supervision.   For example what would the reward value look like?
If so, can you show me some examples (especially code/githbub links)?
I would greatly appreciate any pointers"
"[Tensorflow Noob] Given an array of indicies, how may I transform them into their values stored in a different array?",2,6,False,False,False,learnmachinelearning,1506801376,True,"**Edit: Nvm found answer.  tf.gather (no nd at the end)**

Hello all :) 

So the title is probably confusing/poorly worded (sorry!). What I would love to have is a tensorflow way of converting each of these index's into their values, if possible.

Such as, this is the array of indicies, with only a shape of [10]

    [25502 31395 10260 42003 39566 33620  9563 48843 11186 22059]

And I have this other array of values corresponding to it, with a massively different shape of [55,000]

    [1, 1, 1, 3, 4, 5, 10, 11, ..... 19, 20, (etc)]

And I want to get out of it an array like this with shape of [10] of the values that were stored at the index locations in that [55,000] array

    [7, 8 , 8 , 8, 8, 8, 9, 1, 2, 1, 0] 


**Prior attempts**

I found this method ""tf.gather_nd"" that I thought would do what I wanted it to, but it's complaining that the shape of my two arrays are too different. Which I intentionally cherry picked only these top 10 indicies from it.

https://www.tensorflow.org/api_docs/python/tf/gather_nd

The exact error code:

    ValueError: indices.shape[-1] must be &lt;= params.rank, but saw indices shape: [10] and params shape: [55000] for 'GatherNd' (op: 'GatherNd') with input shapes: [550000], [10].

    tensorflow.python.framework.errors_impl.InvalidArgumentError: indices.shape[-1] must be &lt;= params.rank, but saw indices shape: [10] and params shape: [550000] for 'GatherNd' (op: 'GatherNd') with input shapes: [55000], [10].

An oddity I noticed was when PRINTING like so, I get them automatically transformed. But I can't seem to do this when in a session. I encounter a different error saying I can't index like that.

    print(""prediction "", trainingLabels[predm])"
Having some trouble getting my LDA prediction to workout (in R),4,3,False,False,False,learnmachinelearning,1506817802,True,"I have 2 classes, red and green. Both are simulated from a  Bivariate normal with equal covariance matrices.

I used 

&gt; lda.redgreen &lt;- lda(redgreen,Y, CV=FALSE)

&gt; abline(lda.redgreen)

To plot my classifier onto my data points. I wanted to be sure that everything was working, so I tried picking a few points above and below my LDA line to see if they were classified properly, and it doesn't seem like it's working.

I used 

&gt; predict(lda.redgreen,c(0,0))

Which should have classified (0,0) as red, but instead it's classifying it as green. Several other points are displaying the same problem

Am using the predict function incorrectly?

Thanks in advance for any help."
Need a buddy,3,4,False,False,False,learnmachinelearning,1506822768,True,"I have completed a couple of mooc on deep learning and I have a good understanding of the concepts and math. However, it has been close to 15 years since I wrote my last program and my language skills are in the c, c++, java arena. I have a few ideas that I want to try out and am I reaching out to folks who have similar interests and are better at python than I am. If anyone is interested, please pm me. "
Got a question,1,0,False,False,False,learnmachinelearning,1506839067,True,"So for what kind of dataset, I should use what algorithm"
text and image analysis in ML?,4,6,False,False,False,learnmachinelearning,1506839265,True,"I don't have any experience in ML, and i want to do some text and image analysis, what should and how should i learn? "
Epoch and batch size for infinite continuous data.,0,5,False,False,False,learnmachinelearning,1506843218,True,"I'm using Keras and simply want to test an image for ""imageness"". My program will randomly feed either a downloaded image or a field of random pixel values to a Keras CNN. How do I structure the feeding of data? I don't get the need to collect, say, 64 images in memory and then feed them through in a batch because I'm still just feeding them through individually anyway. I think there's a conceptual element I'm just not seeing and would appreciate any guidance."
The concept of return period and its relation to Geometric distribution,0,4,False,False,False,learnmachinelearning,1506846384,False, 
"I like finding patterns in information and then interpreting those patterns and making predictions. With that said, I'm having a hard time distinguishing between data analysis and machine learning. Which would match my interest in pattern recognition?",1,6,False,False,False,learnmachinelearning,1506866848,True,"Using code to create things is awesome, but I think I have a special knack for patterns. I'm also split on what's important: SQL? MATLAB? Python? R? Linear algebra? Not sure which tools are the most important, and where to start and what to use concurrently. The steps I guess, and the important stuff. though learning Python has beeen a breeze coming from JavaScript).

Also I think I enjoy statistics (which uses pattern matching). I'm not sure how much of a role it plays in each. I might even be wrong about stats using patterns. I think SQL does. Oh I don't know. Plus I'm trying to learn linear algebra. I don't think I'm bad, nor do I think I'm amazing, at math but I haven't studied math since college like 7 years ago.

Any insight would be much appreciated!"
RNN with multiple different sequence types?,0,4,False,False,False,learnmachinelearning,1506868207,True,"So I've just started playing around with RNNs lately and can manage to do some simple stuff like word and char RNNs, but I have a problem I'd like to tackle that involves multiple sequence types and I'm not sure if it's possible to implement in a RNN. 

To elaborate a bit on what I mean by multiple sequence types:
I have several thousand numeric sequences of differing lengths which I would like to train on and then use the model to predict new sequences. However for each of these numeric sequences I also have an identical length sequence made up of letters. The letters have some effect on the numeric sequences (though I'm not sure how much of an effect) and so I believe the RNN should be able to use the letters sequence to improve prediction accuracy. 

So rather than feeding the model a list of sequences in training and then predicting new sequences I want to feed it two lists in training (one numeric sequence and one letters sequence) and then when the model is built I will give it a sequence of letters which it will use to predict a numeric sequence. Anyone know if something like this is possible or know of any similiar examples?  This is probably explained terribly so just ask for clarification if needed, Thanks. 

 "
tensorflow - issue understanding neural network output,0,2,False,False,False,learnmachinelearning,1506871358,True,"Hi

I have a mathematical understanding of neural networks, followed multiple online tutorials and decided to make my first little project using neural nets. Disclaimer: my mistake may be very simple and stupid....

I am trying to make an autoencoder [as shown here](https://youtu.be/GWn7vD2Ud3M?t=104).

My neural network takes 12 matrices each containing 128 points as input for training (one at a time). If I understood correctly my autoencoder should be able to compress this 128 sized matrix to -in my case- a 84 dimensional matrix. Those matrices actually represent keypoints I extracted from 12 of from the same object.

The end goal of this project would be to do one class classification (""is it object A or not?""). To do this I would like to check the compressed representation of the training data and compare it with my testdata (teX), if it is the same then the object can be classified as being object A, if it isn't the same then it is not object A. The testdata is 1 single matrix containing 128elements from another new picture of the same object. Ideally it should compress the matrix to the same matrix as in the training phase (or at least something very close).

Yet I am a bit lost on how to check this and how to check whether my neural net is doing what I expect it to do. Could someone give some feedback or provide some help in order to have a better understanding of what s going on? 


Thx!

The output currently being generated:

    (0, 23.844204)
    (1, 14.370811)
    (2, 10.103552)
    (3, 7.5938435)
    (4, 6.2731924)
    (5, 4.9853754)

    ...
    (996, 0.61525333)
    (997, 0.61521661)
    (998, 0.6151799)
    (999, 0.6151433)

my code:

    import tensorflow as tf
    import numpy as np
    import pandas as pd
    import matplotlib.pyplot as plt

    n_visible = 128
    n_hidden = 84
    corruption_level = 0

    def getKpts():
        fname = ""/home/myFile.csv"" #contains 128 datapoints for every valid picture
        embeddings = pd.read_csv(fname, header=None).as_matrix()
        embeddings = np.matrix(np.array(embeddings))
        return embeddings

    def model(X, mask, W, b, W_prime, b_prime):
        tilde_X = mask*X
    
        Y = tf.nn.sigmoid(tf.matmul(tilde_X, W) + b)
        Z = tf.nn.sigmoid(tf.matmul(Y, W_prime) + b_prime)
        return Z


    X = tf.placeholder(""float"",  [None, n_visible], name='X')
    mask = tf.placeholder(""float"", [None, n_visible], name='mask')

    W_init_max = 4* np.sqrt(6. / (n_visible + n_hidden))
    W_init = tf.random_uniform(shape=[n_visible, n_hidden],
                               minval =-W_init_max,
                               maxval =W_init_max )

    W = tf.Variable(W_init, name='W')
    b = tf.Variable(tf.zeros([n_hidden]), name='b' )

    #weights between encoder and decoder
    W_prime = tf.transpose(W)
    b_prime = tf.Variable(tf.zeros([n_visible]), name='b_prime')

    Z = model(X, mask, W, b, W_prime, b_prime)

    cost = tf.reduce_sum(tf.pow(X-Z, 2))
    train_op = tf.train.GradientDescentOptimizer(0.02).minimize(cost)

    #training data
    trX = getKpts()

    #test data
    teX = [-0.068539813160896,0.057979639619589,-0.13952530920506, .....]

    teX = np.matrix(np.array(teX))

    with tf.Session() as sess:
        #tf.initialize_all_variables().run()
        tf.global_variables_initializer().run()
        for i in range(1000):
            for j in range(0, len(trX), 1):
                input_ = trX[j]
                mask_np = np.random.binomial(1, 1-corruption_level, input_.shape)
                sess.run(train_op, feed_dict={X: input_, mask: mask_np})
            mask_np = np.random.binomial(1, 1, teX.shape)
            print(i, sess.run(cost, feed_dict={X: teX, mask: mask_np}))
    







"
Regression model tutor needed,1,4,False,False,False,learnmachinelearning,1506876883,True,"I am doing a lab that i need assistance.  I don't want you to do it for me, rather just help me work through it.   This would be session do on Skype and would be an hour an evening eastern US.  This is a paid gig.  :) "
Multiple Kernel in SVM,0,1,False,False,False,learnmachinelearning,1506881606,True,I want to increase the accuracy of my predictions made in libsvm using multiple kernels like rbf and poly-kernel. How can I do that in LIBSVM?
[Tensorflow code help / SMV] Looking to convert the MNIST data set into an array of -1 / 1 based upon number type. What's the best way?,7,4,False,False,False,learnmachinelearning,1506892076,True,"Hello all! 

I'm currently using the MNIST data set and so I have the digits 0-9 to break down like so:

For the training data set, convert the labels of the training data set into either [-1] if it is _not_ the label I specify, or [1] if it _is_ the label I specify.

For instance, if I wanted to have only the array values that are equal to the number ""3"" be equal to 1 and all others be equal to -1.

This is critical for me for applying these labels as weights in an SVM."
"In the exression of dz[1], why do we use element-wise multiplication operator ( * ) ?",5,16,False,False,False,learnmachinelearning,1506928948,False, 
tensorflow - How to correctly print the value of my tensor?,1,1,False,False,False,learnmachinelearning,1506944244,True,"Hi

I am trying to print the value of my tensor but get a strange error. Could someone tell me how to do it correctly?

    result = sess.run(cost, feed_dict={X: np.matrix(np.array(reps[0][1]))})
    if result is not None:
        confidence = (tf.cond(tf.less(result, 0.53), lambda: getCertitude1(result), lambda: getCertitude2(result)))
        print(""result: "" + str(result) + "" confidence: ""+str(confidence))

outputs: 
    
    result: 0.488459 confidence: Tensor(""cond/Merge:0"", shape=(?, 128), dtype=float32)

So I tried as follows:

    confidence = sess.run(tf.cond(tf.less(result, 0.53), lambda: getCertitude1(result), lambda: getCertitude2(result)))
    print(""result: "" + str(result) + "" confidence: ""+str(confidence))

Which then outputs:

    2017-10-02 13:31:24.098024: W tensorflow/core/framework/op_kernel.cc:1148] Invalid argument: Shape [-1,128] has negative dimensions
    2017-10-02 13:31:24.098114: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Invalid     argument: Shape [-1,128] has negative dimensions
    	 [[Node: X = Placeholder[dtype=DT_FLOAT, shape=[?,128], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
    2017-10-02 13:31:24.100074: W tensorflow/core/framework/op_kernel.cc:1148] Invalid argument: Shape [-1,128] has negative dimensions
    2017-10-02 13:31:24.100207: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Invalid         argument: Shape [-1,128] has negative dimensions
    	 [[Node: X = Placeholder[dtype=DT_FLOAT, shape=[?,128], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
    2017-10-02 13:31:24.100679: W tensorflow/core/framework/op_kernel.cc:1148] Invalid argument: Shape [-1,128] has negative dimensions
    2017-10-02 13:31:24.100755: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Invalid argument: Shape [-1,128] has negative dimensions
    	 [[Node: X = Placeholder[dtype=DT_FLOAT, shape=[?,128], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
    Traceback (most recent call last):
      File ""autoEncoder2.py"", line 173, in &lt;module&gt;
        confidence = sess.run(tf.cond(tf.less(result, 0.53), lambda: getCertitude1(result), lambda: getCertitude2(result)))
      File ""/home/yalishanda/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 789, in run
        run_metadata_ptr)
      File ""/home/yalishanda/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 997, in _run
        feed_dict_string, options, run_metadata)
      File ""/home/yalishanda/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1132, in _do_run
        target_list, options, run_metadata)
      File ""/home/yalishanda/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1152, in     _do_call
        raise type(e)(node_def, op, message)
    tensorflow.python.framework.errors_impl.InvalidArgumentError: Shape [-1,128] has negative dimensions
    	 [[Node: X = Placeholder[dtype=DT_FLOAT, shape=[?,128], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

    Caused by op u'X', defined at:
    File ""autoEncoder2.py"", line 91, in &lt;module&gt;
        X = tf.placeholder(""float"",  [None, n_visible], name='X')
      File ""/home/yalishanda/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py"", line 1530, in placeholder
        return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)
      File ""/home/yalishanda/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 1954, in _placeholder
        name=name)
      File ""/home/yalishanda/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 767, in apply_op
        op_def=op_def)
      File ""/home/yalishanda/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2506, in create_op
        original_op=self._default_original_op, op_def=op_def)
      File ""/home/yalishanda/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1269, in __init__
        self._traceback = _extract_stack()
    
    InvalidArgumentError (see above for traceback): Shape [-1,128] has negative dimensions
    	 [[Node: X = Placeholder[dtype=DT_FLOAT, shape=[?,128], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
    

Could someone tell me how to correct this?


"
K-Means Clustering in Python from Scratch,2,28,False,False,False,learnmachinelearning,1506946294,False, 
"If all of the layers in my feed-forward Neural Network are the same, could I compute the derivative like so?",0,3,False,False,False,learnmachinelearning,1506946781,True,"Would I be able to compute a general derivative for the weights coming into any layer based on the error of that layer's output (which comes from my error function)?
 
Example:

Doing that would result in something like `Errors * sigmoid_prime(outputs) * inputs` for a basic net that uses sigmoid activation and no biases. Technically, the `Errors` is the (target - actual) extracted from the error function by the chain rule.

The output layer is easy, since we have target and actual 
 work with. For the rest of the layers, we ""backpropagate"" the error by multiplying the transpose weights to figure out how much each node was to blame... and then plug that matrix into the `Error` part of the derivative equation.

Is this procedure correct? Viable? Best practice?

Thanks!"
"Tensorflow, trying to training pairs of variables in a set of 10 variables. Confusion and issues! :(",0,2,False,False,False,learnmachinelearning,1506948666,True,"Suppose I have two variables ""b"" (a scalar that is added as a bias to the model), and ""w"" (a vector of ~700 floats that the model has to tune). 

_Problem? My model needs a particular W and a particular b associated with 10 different potential inputs (MNIST data set)._ And each pair of W and b must be trained explicitly for each potential input... (For binary classification for each input.)

I initialize these variables like so

    W = tf.Variable(tf.random_normal([28*28, 10]))

    b = tf.Variable(tf.random_normal([10]))

But the problem is, during my actual equations... _I only want to handle one W, and one b, at a time._


So when I perform operations like this in my code, I am struck with an error.

    ValueError: Shape must be rank 2 but is rank 1 for 'MatMul' (op: 'MatMul') with input shapes: [10,784], [784].


and

    ValueError: Dimensions must be equal, but are 784 and 10 for 'Add' (op: 'Add') with input shapes: [10,784], [10].



How can I resolve this? I'm pulling my hair out trying to figure out how to do this without losing the ability to maintain the variables W (all of them as defined) and b (all of them as defined)."
why the Least Square Error?,1,2,False,False,False,learnmachinelearning,1506948890,False, 
How to deal with a peak of misidentified events?,0,1,False,False,False,learnmachinelearning,1506954287,True,"On complicated classification tasks, it may happen that a number of events of (say) class 0 look so similar to events of class 1 that a machine learning classifier will rank them as class 1 with high certainty. 

The result in a 2-classes problem [may look like this](https://i.imgur.com/s4upyU4.png): as we move from low to high ""scores"", the background curve decreases monotonically - until reaching a minima, before increasing again. As a result, we see a small background peak at 1.0 and a small signal peak at 0.0.

This picture was obtained with multi-layers perceptrons (and in several subsets of the data), but a similar shape was obtained using gradient-boosted decision trees. Thus this comes from the data itself, and the conclusion that some observations of the background class look much like signal events. 

Depending on the problem at hand, this peak, however tiny, can be extremely annoying (e.g. if the real-case application has orders of magnitude more background than signal. Or if one wants to estimate real-life background using simple extrapolation). 

The question would be: how would you deal with that? Is this common, are there known techniques to reduce these peaks of misidentified events in the first and last bin?"
Output of intermediate layer PyTorch,5,2,False,False,False,learnmachinelearning,1506960044,True,"Using Torch, the output of a specific layer during testing for example with one image could be retrieved by layer.output[x]. Is there any equivalent approach in PyTorch? I want to print the output of a convolutional layer using a pretrained model and a query image."
Help with Senior Project,2,0,False,False,False,learnmachinelearning,1506966980,True,"Hello,

I am working on a senior design project, and I am trying to get an idea for what tool would be best.  My problem is that I am working on a mobile robotics platform trying to track a person.  We are using OpenCV to train a classifier to follow a specific person.  My job is make a ""Driving Toolbox"" that will take the image and figure out the location of the face that was found and reposition the camera to be as close to center as possible.  The data that opencv will return is an XY coordinates from the upper left of the box that is created.  I would like to utilize machine learning if possible to make the adjustments.  I have written mostly C++, Matlab, and some Python. 

My Questions for this project could I use machine learning to accomplish my goal or should I design my own algorithm?
And if machine learning could be used what framework would be good, I know Matlab has some frameworks so does C++ I am just not familiar on where to start."
Random Cropping as Data Augmentation?,1,3,False,False,False,learnmachinelearning,1506978166,True,"I'm trying to implement random cropping on images as a form of data augmentation. I'm using these images as training data for a CNN. Here are my questions:

* Since the CNN has a fixed input size, after cropping, I need to bring my image back up to the original size. Is it better to pad the region outside of my crop with whitespace, or the reflection of the stuff inside the crop, or should I stretch the image back up to original size? If the latter, is there a conventional algorithm for stretching back up when the crop's dimensions aren't integer divisors of the original size? (do I fill in pixels with whatever was closest in the smaller image, or a weighted average of nearby pixels, etc)

* How do I determine a safe maximum amount of cropping? Should I treat this as a hyperparameter to test and optimize?

* Should I randomly crop my original training set differently between every epoch, or once before all of my training? And is this the same for other forms of random data augmentation? (e.g. random hue shift, which I already have implemented)

* Is it best to use these random crops alongside the original images? Or if I crop one, should I remove the original from the training set? (I recognize the importance of using methods that maintain the balance between my classes whichever I do)"
Machine learning,0,20,False,False,False,learnmachinelearning,1506978570,False, 
How long/much should you train your neural network?,7,3,False,False,False,learnmachinelearning,1507015835,True,"Hello

I use 10k iterations to train my neural network using backpropagation. Now depending on my trainingdata it happens that training makes my the value of my loss function increase rather than decrease after a certain time.

What happened:

    iteration 1 untill 4300: 11.6 decreases to 0.57253
    iteration 4300 untill 10k: 0.57253 increases to 0.57719

Why does my loss function suddenly increase? How can I find the optimal number of training iterations so that I don't have this increase?
"
How to prepare a DevOps pipeline for an ML based project,0,1,False,False,False,learnmachinelearning,1507038242,False, 
A guide for machine and deep learning?,4,2,False,False,False,learnmachinelearning,1507043651,True, 
Does it make sense to create polynomial features for use in a neural net?,7,4,False,False,False,learnmachinelearning,1507044707,True,"I'm trying to get a small boost in performance by using the most important polynomial features in a neural net. But does that make sense? Will the net learn the relationship / interaction between features without creating them manually?

I'll likely test it anyway but I have a lot of data so training time is long and I want to see if I'm spinning my wheels :)

Thanks!"
Possible to train on 3DS files?,6,2,False,False,False,learnmachinelearning,1507060018,True,"Is it possible to train CNN classifier using 3D images? 
Meaning.. if I have a 3D model, i'd like to train on various perspectives of the 3D image (from top, front, left, right).  If possible, any tutorials ?


If not, do I need to render out the 3D images onto 2D first and then train? (This seems wasteful)"
How much math is needed to really grok Machine Learning?,10,15,False,False,False,learnmachinelearning,1507073140,True,"Hey!

I want to learn Machine Learning and integrate it into my career. What kind of math background is required to really comprehend the research? Unfortunately my background has always been a bit light, and I fear I may have to go back and do some legwork before I can even start with the basics. "
"machine learning, data mining, natural language processing books",2,1,False,False,False,learnmachinelearning,1507083899,True,"Hi, Im starting a university project where I have to do data mining on SE repository using nlp. Ive decided to do this using machine learning and preferably in python. I just wanted to know if anyone has had any good experiences with books which cover these topics from a somewhat beginner level and is more towards practical uses."
Duplicant or similar document detection,0,1,False,False,False,learnmachinelearning,1507087543,True,"I'm not sure if this is the place to be for this question, but i'll try it anyways.  

I want to create a tool that will compare documents in a large database against each other, looking for duplicates or near duplicates.  The files may include images (JPG, PNG, ...) documents (PDF, word, ...).

How would I go about doing this with something like Python?  What would be the recommended steps to accomplish the desired outcome above?  

Thanks!"
Feature Importances of Cross-Validated Model?,1,1,False,False,False,learnmachinelearning,1507094612,True,"Is there any way to get at the feature importances of a cross-validated model?

Here's my cross validation

    kfold = model_selection.KFold(n_splits=25, random_state=seed)
    cart = RandomForestClassifier()
    num_trees = 1000
    model = RandomForestClassifier(n_estimators=num_trees, random_state=seed)
    results = model_selection.cross_val_score(model, X, Y, cv=kfold)
    print(results.mean())

Which performs with ~.73 accuracy.

I'd like to get the feature importances behind that score, but instead, the closest I can seem to get is

    results=model.fit(X,Y)
    importances = model.feature_importances_
    print(importances)

If I'm not mistaken, because I had to refit, that's a totally different animal. The average cross-validated score is 73% accuracy, but any given random forest could perform at 85% or 60% or 3%, right?

Furthermore, there are 50 features, and the importances don't get much higher than 2%. So the importance is spread evenly, ergo probably randomly between them, right? But when I ran them through a t-test, half of my features have p-values &lt; .05. Does it seem like something went wrong?

Finally, my general plan here is to create a few datasets with different importance cutoffs (eliminating the features that don't meet that bar), run them through some parameter tuned cross validation, and see what set of features performs the best. Is that likely to cause overfitting? Or any other problems down the road?

Any ideas would be appreciated. I'm going a little cross-eyed trying to figure this out. Thanks a lot."
"Chris Albon's (data scientist) Tutorial Site - I use it all the time to check for how to do something in Pandas, Scikit-Learn, etc.",9,67,False,False,False,learnmachinelearning,1507095684,False, 
Should I try to get a job in data analysis before moving into machine learning?,4,3,False,False,False,learnmachinelearning,1507096082,True,"I'm switching fields into data science and I love machine learning. Currently, I'm spending most of my time studying machine learning (and I just started studying deep learning). Is it difficult to land a job in machine learning without first landing a data analyst job?

Thanks for the help."
TWIL (This Week I Learned) - Share something new that you have learned this week!,1,1,False,False,False,learnmachinelearning,1507100715,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
What does baseline mean in a research?,4,1,False,False,False,learnmachinelearning,1507103451,True,"I am not 100% sure about what baseline means in a research. 
For example, what does the following statement mean?

""The only baseline we use for this
subtask is a random classifier. It makes no assumption
about the underlying class distribution,
labelling each context as “pun” or “non-pun” with
equal probability. On average, its recall and accuracy
will therefore be 0.5, and its precision equal
to the proportion of contexts containing puns.""

Please help!"
Achievable goal in an undergrad-level research?,1,1,False,False,False,learnmachinelearning,1507107948,True,"I am doing an undergrad research with a professor, and my task is to pick a topic that I am interested in doing a research. 

The topic that I picked was 'pun detection' in NLP. (related paper: http://aclweb.org/anthology/S17-2005)

There were several systems that showed significant results, and my professor told me to look on those.

My question is, what can be my goal related to this task? Is it normal to just analyze one of the best-performing systems and try to find a way to improve it? 

Also, is it a good idea to start with writing a program that imitates what the paper of the best performing system explains?

I am totally new to research, so I have no idea what to do next. 
"
Are there fields / topics in ML where a poor student can work on without access to clusters and multiple GPUs?,6,1,False,False,False,learnmachinelearning,1507115217,True,"I am looking for a topic for my diploma / master thesis but I won't have access to powerful hardware. I assume that training for nlp or speech recognition doesn't require the same computational power as, say, image recognition.

Is my assumption correct? Do you have any advice to give?
Thanks in advance."
Good resources to learn Information Theory (videos/books),2,1,False,False,False,learnmachinelearning,1507122827,True,"I'm working on topics related to generative models, in particular GANs and VAEs. While reading the literature for this, I'm having some difficulty understand the information theoretic concepts/heuristics used. Any pointers for good resources?"
Lasso Regression in R,0,2,False,False,False,learnmachinelearning,1507139974,True,"Hi, I am currently looking for recommendations on online courses to learn Lasso and Ridge Regression in R. I know about Experfy (where you can learn and get certified) as well as Coursera, but was wondering if anyone had any other recommendations for someone that was trying to learn from scratch. "
Looking for the name of one online course,7,1,False,False,False,learnmachinelearning,1507141153,True,Not too long ago I read a post here about online courses. One suggested andrew Ng's ML course on coursera and his deep learning course. However there's another he or she suggested taking in between the two courses. I forgot the name of the course or the instructor. I know it's vague but can someone remind me what it is?
Is this blog post over complicating things?,0,1,False,False,False,learnmachinelearning,1507155756,True,"Hey all, I'm reading through here: https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/ and the author takes the following approach to backprop:

1.) Calculate derivative for output layer error w.r.t hidden-output weights.

2.) Calculate derivative for output layer error w.r.t input-hidden weights.

3.) Plug in the numbers.

Hmm, ok. So that's valid. But he never back propagated the errors like I'm used to. What I expected was:

1.) Calculate derivative for output layer w.r.t hidden-output weights.

2.) back propagate error by using the hidden-output weights to determine how much each hidden node is to blame.

3.) apply the same formula from step 1* to step 2 results, now that the hidden units have their own error

---

Are these the same thing? Is mine actually wrong? Thanks

---

\* I guess I should mention I expect this formula to look something like `-(target - output) * output * (1 - output) * inputs_from_previous_layer`."
Is long training time normal in machine learning?,7,2,False,False,False,learnmachinelearning,1507165011,True,"Hey guys/gals, I'm currently playing with Kaggle's [digit recognizer](https://www.kaggle.com/c/digit-recognizer) which has the size of 42000x783, I'm trying to classify it with logistic regression, knn and naive bayes. Naive bayes runs pretty fast, but logistic regression and knn is painfully long. Is this a bad code problem?

Edit: [My code](https://pastebin.com/sEuzU9Uj)"
Problems if I want to apply ML on environment data,0,3,False,False,False,learnmachinelearning,1507182942,True,"Recently I want to apply ML on air pollution forecasting, PM 2.5. However, air pollution problem not only affected by metageography factor, but also relative to human activities, such as traffics, manufacture...etc.

And human effect is not easy to take into consideration.

I have search for paper and journals, but most of them seems didn't consider human's effect, which only apply metageography features. (ex. Apply deep neural network with climate data)

I wonder if this is OK to go on forecasting like this? That I don't consider the human's effect, only the environment feature?
Neural network is a black box, I'm afraid I would ultimately come up with a precise result, but still don't know the Know-How.

Thanks for helping!"
Help: Using CNNs on Large Images with Small Discriminatory regions,1,3,False,False,False,learnmachinelearning,1507189399,True,"Thanks for your attention. I'm doing a CNN project where I have a set of tissue sample images and a simple Boolean for each image, cancerous or not. Most of each image is presumably non-discriminatory. 

My goal is to produce a net that can identify bounding boxes around key cancerous features in each image. Currently my model does something like this: 

    Input (512, 512, 3)
    
    3x3 Conv (510, 510, 128)
    
    3x3 MaxPool (170, 170, 128)
    
    ...
    
    3x3 Conv (32, 32, 128)
    
    1x1 Conv (32, 32, 32)
    
    1x1 Conv (32, 32, 1)
    
    Dropout
    
    Global Max Pool

I feel as though I'm missing something with this method. My major goal is to accurately identify regions of interest, not maximize accuracy. Any alternative approaches to this problem would also be appreciated. "
NaiveBayes for classifying 3 types of texts,6,8,False,False,False,learnmachinelearning,1507191916,True,"Hey, guys! I've started playing with Python and ML, but I have got a problem. I'm trying to train NaiveBayes with 3 kinds of twitter posts. Posts talking about that somebody is sick, somebody is recovered (healthy) and neutral (like wow or something out of health subject) I've achieved pretty satisfying accuracy for classifying posts talking about illness, but I've still got a problem with spotting healthy &amp; neutral posts. I've got about 1k posts for each kind and using ~95% for learning and ~5% for testing.

 Any tips or ideas for me? :) 

Everything starts in main.py, training process in naiveBayes.py file
https://github.com/jpomykala/TwitterHealth-NLP/tree/master/src
I've got an experience with other languages but this is my first time with python, so it can be messy. "
Learn about word vectorization with this introduction followed by a small tutorial !,2,27,False,False,False,learnmachinelearning,1507211771,False, 
Singular Value Decomposition Method with Examples and Applications,0,15,False,False,False,learnmachinelearning,1507212283,False, 
Pixel 2,2,0,False,False,False,learnmachinelearning,1507220546,True,"Google says portrait mode on a single camera is possible due to machine learning. It also says it works on objects too. This includes machine learning so, will this feature always be in beta? "
When to use which ML algorithms for computer vision?,1,2,False,False,False,learnmachinelearning,1507235119,True,Is there a good set of guidelines or a flowchart that explains when to use which machine learning algorithms for computer vision problems?
Does this feature selection strategy make sense?,0,1,False,False,False,learnmachinelearning,1507271354,True,[deleted]
Weekly Show-off!,1,3,False,False,False,learnmachinelearning,1507273520,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
How can a neural network be trained to identify that the input belongs to none of the trained labels?,11,14,False,False,False,learnmachinelearning,1507283361,True,"Hope I'm right here! I try to learn more about neural networks and while I understand how a network could be used to differentiate between certain labels (always pick the label of the output neuron with the highest output value), I don't really see the concept of how a neural network can differentiate between different labels AND noise. In other words: How can a neuronal network identify different labels, but also identify that there is none of the previously trained labels in the input? How can this behavior be achieved?
"
When do you use Boruta v RIDGE for feature selection?,0,1,False,False,False,learnmachinelearning,1507284901,True,[deleted]
Best feature selection method for a small dataset?,1,2,False,False,False,learnmachinelearning,1507293687,True,"I'm partial to wrapper methods, but I don't want to risk overfitting."
What is a good method to deal with time series data in tensorflow?,1,7,False,False,False,learnmachinelearning,1507302774,True,"I know I want to convert it to protocol buffers.  Presently the data is in start/stop dates.  There's way way too much data to make a separate frame for every day, for instance.

I understand this is kind of a big question, is it mainly going to be preprocessing in python (non-Tensorflow specific code) to get tensorflow the data it needs or are there Tensorflow specific libraries or methods for dealing with this kind of data?

edit: I plan to use an LSTM..

Any good tutorials?

Thanks in advance,

(It's the WSDM churn kaggle btw)

----
edit: Speculative self-answer:  Upon looking into it, and the lack of response in a few forums, I have a feeling that tensorflow has no library for this sort of situation.  Storage is relatively cheap, and the additional complexity of data that is not in tensor form is outside of its scope.  Plus, I think the mental image gets muddied if the data representation isn't somewhat set in stone, no matter how inefficient it is.  (this is relatively new tech, we are still working at a low level representation, and that is okay.  Storage is cheap, calculation expensive.)

I am going to repurpose an external 3TB external HDD, prepare the data, and read it in.  This reference for tensorflow provided perspective for me.

https://www.tensorflow.org/api_guides/python/reading_data

Still feel free to comment if you've got anything :)

"
Matplotlib Lead Dev on Why He Can’t Fix the Docs | NumFOCUS,0,16,False,False,False,learnmachinelearning,1507303464,False, 
Complete beginner. Advice on creating a syllabus?,0,1,False,False,False,learnmachinelearning,1507310125,True,[removed]
Predicting tweets which will engage with my followers,0,1,False,False,False,learnmachinelearning,1507312352,True,"Hello,

So I'm writing a Twitter bot in Python and one feature it has is to post content from an RSS feed. What would be a good method to explore to predict which articles to post? I don't want to be too spammy and just post them all. I've got data from a few weeks of randomly posting which I could use to train, and the plan would be to train it periodically so it can learn as it goes.

Any methods or pointers gratefully received!"
Is it possible to do long text generation from keyword inputs using ML [xpost from r/MLQuestions],0,1,False,False,False,learnmachinelearning,1507318072,False, 
[Noob to tensorflow / SVM] Help me (Please :(!) understand what this equation is trying to do.,0,1,False,False,False,learnmachinelearning,1507352198,True,[deleted]
[Noob to tensorflow / SVM] Help me (Please :(!) understand what this equation is trying to do.,2,4,False,False,False,learnmachinelearning,1507359657,True,"The equation I am trying to wrap my head around:

https://imgur.com/a/PLy9e

So for this equation I have:

X: which is going to be a 784 array (representing pixels)
b: a 10 array (One for each class)
W: a 784 array for each class. So 10x784.
yi: Basically saying ""is this image actually one we want"". This is y is going to be like this.

[[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]]

To the best of my understanding this is a binary classifier but to be a little straightforward: I am having a difficult time visualizing how to do this in code. By hand this is super easy, but in code? I am a complete mess and utterly depressed with how poorly it's going.

So how it's binary is that for each of the 10 columns (made one for each class) it will determine a score. The column with the highest score will indicate the class. (Highest score of 10 columns.)

But I was inspired by this lecture here, which spoke of taking all of the weights as W and all of the images as X and then add weights respective to that image through the b values.

https://imgur.com/a/QG63q

(From this lecture: https://www.youtube.com/watch?v=vq2nnJ4g6N0&amp;t=676s )

But this doesn't make sense in the context of my equation, to me at least. As a tensorflow noob.

Why I say this is that my output is like THIS for each pixel in the MNIST data set.

This is during the W(transpose) * xi part. So I have that list of 784 weights * 10 values corresponding to each value after this.

Exactly like this (*for each 784 pixel)
 [ -3.70839387e-02   1.66334331e-01  -4.85728860e-01  -2.08086282e-01
    4.24912572e-01   5.98199442e-02   3.63232970e-01   2.54323278e-02
    2.49857917e-01  -2.82403171e-01]

And then I can add using broadcasting no issue.

(Yet again *784)

 [  7.38390207e-01  -7.84319460e-01   1.36726427e+00   1.19699168e+00
   -6.27497494e-01  -1.87203377e-01  -3.88512850e-01  -3.77066463e-01
    2.91505694e-01  -1.13544297e+00]]


**But I don't get how I can make any sort of prediction with this.** :/

Like I am meant to at this point make a ""prediction"" with just this. And I don't get how I could without summing the terms up.

Like each of the pixels must be multiplied by the Y value which is either 1 or 0. (Just using one hot encoding for now and it gives me those easily enough.)

So my Y values I am passing in are exactly like

[[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]]


So I don't get how I can keep these equations parallel.

Like if I was writing it in C++ or java or some other language I'd just do the equations one at a time, tensorflow works in ways I totally do not understand right now.

Is it even possible to do these equations in parellel?

Because I get to the point where I add that bias term (""b"") and then hit a wall.

Although multiplying it by y does produce a result I suppose I'd expect? (Only the one term that represents the label is actually kept.) So maybe my issue is later down the line during summation/max.

 [ 0.         -0.         -0.10758113  0.         -0.         -0.         -0.
   0.         -0.          0.        ]]


And a TF maximum like what the equation says produces this.

 [ 1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.11692977]]


I am just so confused with what tensorflow does. I don't get what is happening."
"Weekly Status Check Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",3,6,False,False,False,learnmachinelearning,1507359910,True,"Let's have a  meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
Deep learning for java: dl4j install,0,12,False,False,False,learnmachinelearning,1507378556,False, 
The basics of Negative Binomial distribution,0,11,False,False,False,learnmachinelearning,1507404580,False, 
Recommender systems: Improving a collaborative filtering system #1 (Dimensionality reduction),1,8,False,False,False,learnmachinelearning,1507411151,False, 
What sort of model would be able to predict a series of tuples of floating point values?,15,2,False,False,False,learnmachinelearning,1507443538,True,"i have a bunch of values like

    (0.44, 0.5)
    (0.23 0.12)
    (0.62, 0.99)
    (0.13, 0.2)

Each value in the series is dependent on the previous 2 or so - assuming I already have a few tuples and want to start predicting what the 'next' values' should be, how would I go about this?

I don't think an LSTM is fit for this task, since i've seen them predicting things like alphabet characters (strictly categorical?)

Is there a method or type of architecture I could implement in Keras that would help me predict new values? So far I've been using a network with an input of (1, 4) (for each value in two tuples), a few fully connected layers, and an output of (1,2) to predict the ""next"" tuple after that, but it's just spitting out the same tuple over and over again so i'm not getting meaningful results (guessing it's found a local minimum).

A very basic rundown of another model architecture I could try (e.g. which types of layers-  nothing too extensive) or links to anything would be greatly appreciated. Thanks"
some essentials for budding machine learning engineers,0,3,False,False,False,learnmachinelearning,1507443584,False, 
"Unordered, variable-size bags of words as input",0,1,False,False,False,learnmachinelearning,1507445108,True,"I have photos with unordered keywords associated, along with labels for interesting and uninteresting photo pairs, and I was wondering how I might go about training a net to spot interesting pairs. Maybe pick a maximum number of words (viewed as numbers), choose a 'no-word' word as filler to create arrays for a fixed-size-input net, then put each resulting array through as many permutations as I have patience for? Else how to process variable-length input in an RNN context-free, as it were? E.g. keywords for the 1st photo: 'yellow truck skull graffiti', and the ones numbered 1000: 'filter red bench square port basket jacuzzi', 'mural woman arms_open color', 'demolish collapse pillars', 'stone_wall stone_structure door look_through', 'purple vanishing_almost stairs balustrade'.

My effort with a siamese network and photo histograms here:

https://www.reddit.com/r/learnmachinelearning/comments/74th1u/weekly_status_check_meeting_share_your_progress/"
Understanding decision tree learning,0,34,False,False,False,learnmachinelearning,1507454246,False, 
TruncatedSVD - Number of components for text features?,0,5,False,False,False,learnmachinelearning,1507473054,True,"Heya,
Just did the DataCamp chapter on PCA. They said that when analyzing text you get a sparse matrix, and that since PCA doesn't handle that well, you should use TruncatedSVD. They pass n_components=3 in some illustrative code. That's where I kinddof got lost. n_components is the desired dimensionality of output data, so if I analyze a corpus and probably have 1000s of words/features, I sincerely doubt reducing the number of features to 3 would generate a very informative model.

Anyone has any insights on that?

Also, how _would_ you choose the number of components for a dimensionality reduction on tokenized text features?

Thank you in advance!"
Help with binarizing MNIST dataset?,0,1,False,False,False,learnmachinelearning,1507494914,True,[deleted]
Some CNN and ML questions.,4,3,False,False,False,learnmachinelearning,1507496770,True,"Hi there! I'm a student preparing a research project on Machine Learning. There are a few things I have had difficulty finding information for though. What I want to make is a neural network that recognizes handwritten Japanese characters, and improves on existing designs used by Google Translate, ect. Think of the MNIST digit recognition that every CNN tutorial uses, but with Japanese instead of numbers.

One thing I have had difficulty finding information on is online learning for neural networks. I'm not sure if this is possible, but I would imagine it is. I would like to train the machine to recognize characters, and then improve on the machine whenever someone uses it. The machine will always be supervised even when learning online in this case. I think it would be something very similar to [this.](https://quickdraw.withgoogle.com) If you know of any good resources that would cover something like this, please let me know.

Another thing I would like to know is if it is possible to have a variable number of output nodes. Using MNIST as an example, if I train the machine to recognize digits 0-5, and then give it 6, it would of course make a mistake. After seeing that the actual result is 6, could it add a new output node that will become better and better and recognizing 6 as it sees it more? I haven't seen any examples of this online, but I believe it would be possible to code by using an vector for the output nodes and adding elements to that as they are discovered.

Thanks in advance for any help!"
Where to Start Coding?,5,7,False,False,False,learnmachinelearning,1507502480,True,"Hi, I'm taking an ML course at my university. I love it, but we are only hitting on the theory/algorithms and their analysis. I want to start coding my own ML projects. Where can i start? A lot of tensorflow tutorials(specifically chatbot's) have a lot of projects on github but you can't run them without having several issues. 

EDIT: I would prefer something in python or java
"
Question on what ML can do regarding repeating a number sequence.,2,3,False,False,False,learnmachinelearning,1507525742,True,"If i have a sequence of numbers, lets say a sequence of bytes or hexes.

Could ML produce a neural network that would repeat the same trained sequence?

The other two key points to assist the network learning this would be the sequence of numbers it has printed so far and the index in the sequence it is currently up to.

The sequence of numbers would have no obvious pattern for example:

[3, 5, 8, 1, 0, 1, 1, 9, 4]

I have a programming background and have spent a fair few days trying to find leads on how to make something like this and so far iv found the Accord.NET library and that it could be done through Linear Regression, but i'm still new to ML.

If anyone has any advice, leads or insight i would appreciate it a lot."
"Low Cross Validation Score, High Predictive Power?",0,1,False,False,False,learnmachinelearning,1507529524,True,[deleted]
Papers accompanying Deepmind's Atari paper,4,1,False,False,False,learnmachinelearning,1507536590,True,"For a school project I'm trying to figure out how the Atari model from DeepMind, but I'm struggling to find articles explaining the grain of Reinforcement Learning. Are there any papers that could help me out?"
My ANN optimizes so much better with Adam optimizer compared to SGD. What does that mean?,1,3,False,False,False,learnmachinelearning,1507539432,True,"Hi,

I have a classification model built with ANN (softmax, categorical cross entropy).

Tried many different topologies that never worked until I changed the optimizer to Adam without really understanding what it means and suddenly the validation accuracy and more importantly test accuracy got close to 1. Just seems too suspicious.

What does it mean about the data that it suddenly works so well with Adam?

Thanks."
[Newbie] Filter bad/low quality profile pictures,0,1,False,False,False,learnmachinelearning,1507546304,True,"Hello, I'm new to machine learning but I'd really like to to create this app where I could filter out unprofessional / low brightness / awful quality / ""stupid""  profile pictures. 

I'd like the allowed profile pictures to look  [something like this](https://imgur.com/a/CMycm). Or pictures similar to a person's ID or resume like.

 My question is, what would be the best approach to achieve something like this?"
Twitter sentiment analyses using Naive Bayes Bernoulli + Bag of words. Unsure what I am doing wrong.,6,10,False,False,False,learnmachinelearning,1507547260,True,"New to machine learning. Doing a bag-of-words style twitter sentiment analyses. Ran 10 fold cross validation, examined the best parameters for max_features as well as alpha value across all trials and chose the best ones for the test Data. Achieved 97% accuracy with training data. However when I submitted the test data for evaluation, this number was 68%. What am I doing incorrect? I thought the whole point of cross validation was to avoid over-fitting the data?"
"AI Journal (Machine learning, Deep learning, NLP, Computer vision)",0,3,False,False,False,learnmachinelearning,1507548445,False, 
How important is it to keep the number of features small in an LSTM?,0,3,False,False,False,learnmachinelearning,1507566693,True,Is it important at all?
From-scratch neural network implementations -- am I wasting my time?,15,19,False,False,False,learnmachinelearning,1507569249,True,"Hello! 

So, for some context, I’m 16 and I’ve been interested in machine learning for a few months now. I just spent the last 5-6 months getting a firm grasp of basic feed-forward Neural Networks and the back-propagation algorithm. I’ve yet to experiment with more than 3 layers and varying activation functions, but I think I get the general idea and am able to implement them on my own now without google/stackoverflow. In all this time, I haven’t touched a single library.

Now, I’m feeling a little braver and have decided to explore LSTM Recurrent Neural Nets, Reinforcement Learning, and GANs. The problem is that these things are starting to go way over my head. For all I know, it could be years before I become proficient in vanilla RNNs alone — forget the confusing LSTM algorithm. And even in a best-case scenario, when I’m applying for jobs in a few years I’ll certainly have missed out on a lot of practice with the tools (libraries) that we’ll be using on a day-to-day basis. Am I giving myself an advantage or a handicap? 

I would really appreciate some advice from people with more world experience and perhaps experience in the field. The choices I make now will definitely shape how I spend the next few years of my life studying so I want to make sure they're informed. All in all, I'm reminded of the days when I used to make HTML games -- I feel like the path I'm on is like re-creating a JS physics library."
Training image classifier on 2D images converted from 3D CAD files?,1,2,False,False,False,learnmachinelearning,1507571059,True,"Instead of having to manually downlad images, cropping, cleaning, etc... I thought, wouldn't it be smarter to render out 2D images of objects if they had 3D CAD design files?

What is the drawback of doing this? the only one I can  foresee is that an image classfier trained this way won't be able to tell when there's ""noise"" around the object, like if a hand is over it or part of it is missing from the image. (Could be wrong)"
Keras tutorial for multi-output regression,0,1,False,False,False,learnmachinelearning,1507580245,True,"Has anyone come across any good tutorials/examples for multiple output regression implemented in Keras? More specifically, I am interested in implementing a neural network that takes an image as input and predicts several continuous measures as output."
[Help a Noob] Cookie Clicker,2,2,False,False,False,learnmachinelearning,1507590095,True,"Hello everyone. 

I've been wanting to get into machine learning lately, and i think i found a good starter project. 

It's really dumb, but i want to make something that can play cookie clicker very effectively. It started with someone bringing up the game at work, and for some reason it seems like a fun project to learn on. 

Now i'm a total novice at machine learning, i've never done anything with it previously, and the only programming language i think i'm halfway decent with is Python. I was wondering if you have any recommendations on where to start with this. 

Even just some pointers of where to start looking would be immensely helpful. 

Thanks!"
Applying clustering algorithm to output of matrix factorization (collaborative filtering),0,1,False,False,False,learnmachinelearning,1507592046,True,"I'm looking for references on clustering the points (in latent factor space) output by a matrix factorization collaborative filtering algorithm.

In particular I'm using something like [Bayesian Personalized Ranking](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.165.7857&amp;rep=rep1&amp;type=pdf) (so no ratings, just presence or absence).
The objective BPR optimizes is ranking items j for user i. My usecase is somewhat more symmetric (items and tags, not users and items), so I'd like to do stuff like cluster tags, cluster items, show similar items to a given item, show similar tags to a given tag, recommend items for a tag, recommend tags for an item, etc.

Is there a more natural algorithm than BPR to use with all of this post-processing (to accommodate the asymmetry I was considering switching to a more standard weighted least-squares approach: [1](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.192.6482&amp;rep=rep1&amp;type=pdf), [2](http://yifanhu.net/PUB/cf.pdf)) ? Any theoretical guarantees or practical experience?

X-posted from r/MLQuestions after no answers"
Correct structure of the convolutional neural network for shape identification task (tensorflow),0,1,False,False,False,learnmachinelearning,1507595071,True,"There are plenty of materials on how-to create correct structure of the neural network which goal is to classify images. MNIST or Google's notMNIST datasets and their tutorials, for example. Those nn structures take as an input single image vector (for 28x28 image vector length of the vector is 784) and usually return one-hot encoded vector indicating predicted class of the object on the image.

What I'm trying to do is to create neural net that will take as an input two images and not only detect shapes on them but also decide whether depicted objects are the same one instance. The goal is to create a net that will identify faces: given two pictures of the same person, taken at different angles, light conditions or with different facial expression, neural net should confirm that it is the same person indeed.

But firstly, I want to start with something simpler: create network for simple shapes identification - for example, letters. I want to train my network on letters 'a' - 'h'(for example) in such way, that it will be able, eventually, to identify correctly also pairs of 'i' and 'j' letters.

How should I build my net, using tensorflow? Should there be two independent convolutional nets for each input image that merge in the final layers, producing one number - measure of the similarity? What is the correct way of coding this in tensorflow? Thanks.
"
Any ML enthusiasts in Manhattan want to get together weekly to discuss papers and/or work on Tensorflow projects?,2,1,False,False,False,learnmachinelearning,1507601219,True,"Hey guys! I'm a recent college graduate working at a startup in Manhattan. Back in college at Cornell, I was really focused on machine learning. I took a Ph.D. level ML course, read several papers a week, and did my own research using Tensorflow ([Arxiv link](https://arxiv.org/abs/1612.04035)). I love my job, but I also miss machine learning!
I figured that there's bound to be lots of other people in the area with similar interests. My idea is that we could meet somewhere once or twice a week and do any of the following:

* Discuss papers we've read recently
* Present interesting topics to each other
* Brainstorm ideas for research (or just fun) projects
* Work on projects collaboratively

If there's any interest I'd love to get a group together and start planning the first meetup!"
Newbie looking for advice on initial planning/approaches (basic search algorithms),2,4,False,False,False,learnmachinelearning,1507604397,True,"So, I've only been seriously learning to code for about a month.  In that time, I chose python as my language and completed a really great Coursera course.  I then started another MIT Edx Python course and, at the same time, an AI Edx course.

&amp;nbsp;

The AI course has a project in which I'm asked to use breadth first search and depth first search to solve a 9 square puzzle.  Basically [THIS](http://mypuzzle.org/sliding).  I've made some great progress and actually have BFS working well.  The problem though, is it took me a ridiculous amount of time to figure it out.  I wrote the code first using classes, but this became too complicated.  I then did a strictly functions approach, but the solution takes much longer than it should (Edx gives estimated times code should take).  The problem, I discovered, is that I've used lists[] in some places where sets() would be much faster.  At this point, I'm exhausted with this project, and everything is so interconnected with the functions that changing some aspects to sets() really requires a complete rewriting of the majority of the functions.  

&amp;nbsp;

My main point with all this is that on one hand, I feel like I've learned a lot about the syntax of Python and the theories behind simple search algorithms... BUT... I haven't learned how to appropriately choose data types, architecture flow, when to use classes or not... **I haven't learned how to efficiently plan out the solution to a problem.**  I haven't learned to *think* in the ways that code can be effective.  I don't want all these hours of work to go to waste and not pull out a more effective way to complete a project.  Do you guys and gals have any advice?  Is there a helpful systematic way of attacking coding/ML challenges?  Are there rules for when to use a classes approach and when to just use functions?  Should the program complexity (O(n), O(n^2), etc) be figured out before writing the program?  Is this even possible?  Any and all advice is much appreciated.  I really am enjoying this stuff, but I don't have a benchmark to measure time against and I don't know anyone with real experience, so progress feels slow and I'm getting a little discouraged...
"
Question about Data Format,0,2,False,False,False,learnmachinelearning,1507641871,True,"Hi everyone, I apologize if this question is rudimentary. I am working my way through the many recommended ML courses, but I wanted to get started on some of my projects while I am doing that so that I can cement my learning better.

I have a question about how to exactly format my data. Suppose I want to see how subreddit growth and activity affect stock prices. 

Should I format my data in such a way that I structure it more or less? What I mean by this, is what is a more effective way to feed this data to a ML program. 

Potential Way #1: Raw data aka timestamp of post or comment.

Potential Way #2: Data structured as daily (or hourly) growth in terms of raw numbers (e.g. +1000) and percentage (e.g. +2%) for both subscriber count and activity (comments + posts). 

I would really appreciate some advice here as I'm still wrapping my head around the proper way to do things. Thanks!"
salesforce/pytorch-qrnn,1,7,False,False,False,learnmachinelearning,1507642575,False, 
What's the best way to run a production Machine Learning solution on the cloud?,4,12,False,False,False,learnmachinelearning,1507646932,True,"I have several models in an ensemble that are retrained daily — each day getting new data from various APIs, storing it in a SQLite database, cleaning and processing it, and then using it in the model to make predictions.

I’d like to know what the best way is to run this all on the cloud. I'm fine with paying, as long as it's not outrageous :)

Thanks!"
How to perform unsupervised anomaly detection in time-series data (python)?,3,9,False,False,False,learnmachinelearning,1507649588,True,"I have time-series GPS data (location, direction, speed, acceleration) of car journeys and I am trying to detect anomalies (accidents) based on the available data, but I am not sure how to construct a model that is able to detect these anomalies/accidents without knowing that they are accidents (and also assign confidence/seriousness rank to these events). Any suggestions would be appreciated."
"Any way to analyze sheet music? Any large data sets already made, a library for sheet music, etc.",1,2,False,False,False,learnmachinelearning,1507650395,True,"For my research, I need to find a way to manipulate datasets of sheet music to do things. From what I've seen, there is music XML but I'm not sure what the best dataset would be. Does anyone have any suggestions as to what to use?
"
Classification results wildly different on Linux and Windows (Keras/TF),0,1,False,False,False,learnmachinelearning,1507653219,True,[removed]
"This week we bring you interviews with 7 speakers from The Artificial Intelligence Conference 2017, including Mo Patel &amp; Laura Frølich of Think Big Analytics, Ion Stoica of UC Berkeley/RiseLab and more! Check it out!",0,7,False,False,False,learnmachinelearning,1507655428,False, 
Building an AI that identifies groups and regions of star systems according to the Hertzsprung–Russell diagram,3,6,False,False,False,learnmachinelearning,1507668156,True,"For my final year university project I am taking an interest in machine learning and I would like to develop an AI that can be trained to detect features of star systems in the H-R diagram.

If you aren't aware, the [H-R diagram](https://en.wikipedia.org/wiki/Hertzsprung%E2%80%93Russell_diagram) is a scatter graph comparing stars' absolute magnitudes or luminosities versus their stellar classifications or effective temperatures. 

What I would like to know is would it be possible to build an AI system that is able to detect groups/features/regions that are shown on the graph through processing the raw data of the graph. How would I go about doing this? What would be the best technique to use?"
Open source Deep Learning tutorials,0,1,False,False,False,learnmachinelearning,1507688749,False, 
An introduction to data augmentation and pseudo-labeling,0,2,False,False,False,learnmachinelearning,1507699501,False, 
TWIL (This Week I Learned) - Share something new that you have learned this week!,1,8,False,False,False,learnmachinelearning,1507705514,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
Question about loss function(MSVE) in Reinforcement learning,0,3,False,False,False,learnmachinelearning,1507714965,True,"I am trying to build a temporal difference learning agent for Othello. While the rest of my implementation seems to run as intended I am wondering about the loss function used to train my network. In Sutton's book ""Reinforcement learning: An Introduction"", the Mean Squared Value Error (MSVE is presented as the standard loss function. It is basically a Mean Square Error multiplied with the on policy distribution. (Sum over all states s ( onPolicyDistribution(s) * [V(s) - V'(s,w)]² ) )

My question is now: How do I obtain this on policy distribution when my policy is an e-greedy function of a learned value function? Is it even necessary and what's the issue if I just use an MSELoss instead?

I'm implementing all of this in pytorch, so bonus points for an easy implementation there :)"
[D] What is your process when you attack a new machine learning problem?,1,12,False,False,False,learnmachinelearning,1507725944,False, 
Embarrasingly Fast Random Subset Sampling,0,3,False,False,False,learnmachinelearning,1507740004,False, 
"Introduction to Docker for data science, building a simple Jupyter container",2,26,False,False,False,learnmachinelearning,1507753111,False, 
How Should Text be Input/Outputted to/from a NN?,0,1,False,False,False,learnmachinelearning,1507762709,True,"Title pretty much explains my question. I've been looking at [torch-rnn](https://github.com/jcjohnson/char-rnn) and it seems to use the JSON and HDF5 file formats to preprocess text, but I've no idea how to input that data into a neural network, or how to handle the output."
Monthly ELI5 (Explain Like I am Five) Thread,2,3,False,False,False,learnmachinelearning,1507764010,True,"Top comments need to be in the format of: `ELI5 $CONCEPT_NAME` and the replies should provide a clear explanation in a layman's term.
Here are the relevant rules from /r/explainlikeimfive breaking down the meaning of ""ELI5"":

- E is for Explain - merely answering a question is not enough.

- LI5 means friendly, simplified and layman-accessible explanations - not responses aimed at literal five-year-olds.
"
What are some good portfolio pieces for beginners?,6,14,False,False,False,learnmachinelearning,1507770608,True,"I've been self-teaching myself software development for some time and recently started Andrew Ng's coursera course for Basics of Machine Learning.

I'm starting with the fourth week and loving it so far, but it's pretty clear there will not be very much in my portfolio by the end of it. It focuses on completing assignments that teach you the concepts, but don't necessarily produce unique projects.

I would like to actually have useful machine learning projects in my portfolio that would challenge me and also can be shown to prospective employers, but this field is new to me and I have very little idea of where to start. 

So far I've had no issue brainstorming ideas for standard software projects to fill my front-end/back-end portfolio, but the unique data requirements for machine learning can be a bit limiting.

What are some quick wins for a beginner to start filling out their portfolio in machine learning?

Thanks in advance!"
Essential Statistical Concepts for Machine Learning Starters,3,10,False,False,False,learnmachinelearning,1507776225,False, 
Submitting papers help - Arxiv verification,0,1,False,False,False,learnmachinelearning,1507781163,True,"Hi,

We are an industrial ML Lab and are trying to push out our first papers in Arxiv CSCL and CSCV . Since our emails are not verified, arxiv wants our submissions to be endorsed. What do you think is the right method ?"
Efficient Methods and Hardware for Deep Learning,0,3,False,False,False,learnmachinelearning,1507781560,False, 
Recurrent networks ans derivatives?,0,1,False,False,False,learnmachinelearning,1507783309,True,"Hi all!
I'm currently working on a project where I'm building a neural networks model for prediction/simulation. In this application the derivatives of the input variables are of importance. I would like to start a discussion regarding recurrent networks and derivatives.
Say that you have a recurrent networks with 1 lag/back loop, then the output y_t will be a function of x_t and x_{t-1}. One simple approximation of the derivative is x_t - x_{t-1} which is called the ""delta"".
Would you say that a recurrent networks with 1 lag/loop can capture the structure of the first order derivative? And are there any articles discussing this?
KD"
I'm starting Mathematical Saturdays this weekend for learning mathematics of Machine Learning.,22,43,False,False,False,learnmachinelearning,1507794060,True,"Hi guys,

I've just started learning Machine Learning. I have no math background. So, I'm trying to create a community of ML beginners who are interested in learning ML together.

As an initiative, I'm starting Mathematical Saturdays this weekend, for learning all the mathematics involved in Machine Learning. So, if you're currently struggling with all the math in Andrew Ng's course, join me and let's create a community of future ML engineers.

If you are interested, here is your Discord Invitation: https://discord.gg/e9Hxmha . Also, share/tweet this with #MathematicalSaturday on Twitter.

Thanks for reading. "
Self contained TensorForce demo implementing a XOR logical gate,0,2,False,False,False,learnmachinelearning,1507795899,True,"[I was looking](https://www.reddit.com/r/MachineLearning/comments/7304ml/d_simple_and_basic_python_script_implementing/) for a **simple** example of reinforcement learning written with [TensorForce](https://github.com/reinforceio/tensorforce) without too many dependencies (like OpenAI Gym, etc...), but since I didn't find anything really simple I wrote something on my own:

https://github.com/LF-78/tensorforce-xor/

Any feedback is welcome, I hope it can be useful to other RL beginners like me."
What ML approach to use for this data structure?,0,3,False,False,False,learnmachinelearning,1507803647,True,"I have data that looks like this, where column 3 contains pieces that are components of column 2, although they don't add up to column 2.

Item name -- Main value -- Component values

A -- 500.678 -- 100.234, 200.456

B -- 340.444 -- 120.112, 122.888, 20.326

C -- 1000.563 -- 201.345, 302.555, 60.333, 300.987, 121.321

and so on

I have 5 different groups, with each group containing several thousand members. I suspect there exists some signature within each group. The signature can be:

1) some value(s) in column 3 (there might be a common value across multiple [not all] members in a group)

2) differences between values in column 3 (if I do all-vs-all subtractions in column3 of each item, there might be a difference value common between multiple [not all] members. Alternatively, a difference value -- although not the same -- could belong to a series)

3) differences between values in column 2 and 3

Theoretically using the component patterns in Column 3, I should be able to tell whether an item belongs to group 1/2/3/4/5. However, this is not a typical ML classification data structure where each column in the training matrix is a specific property. It also would be difficult to code using specific rules - the patterns are quite variable to the human eye - and so I thought ML would be better. However, I'm perplexed because I'm not sure which ML approach I can use to address this question."
Learning Missing values ?,3,3,False,False,False,learnmachinelearning,1507808305,True,"How do i learn missing values in input of neural networks ? 
As in [0,1,missingval] 
with a dataset of complete values .

I've tried removing random entries and setting them to 0 , setting that as my input and the complete values vector as the output of my layers , however i got massively false outputs even though my network converged  ..."
"1 Are there any good beginner's tutorials for Tensorflow Serving, i find the official tutorial of Tensorflow Serving quite verbose.",0,1,False,False,False,learnmachinelearning,1507808647,True,"I have been trying to build a serving for my text classification model since the past one week and haven't been successful since then. I have so far been successful in saving and loading my model from checkpoints.
"
Bayesian Nonparametrics: Dirichlet process and its applications,0,8,False,False,False,learnmachinelearning,1507816344,False, 
Machine Learning Spotlight I: Investigating Recurrent Neural Networks,0,15,False,False,False,learnmachinelearning,1507817911,False, 
An awesome collection of machine learning resources from github,2,20,False,False,False,learnmachinelearning,1507824760,False,[deleted]
Selecting a topic modeling algorithm/workflow,0,1,False,False,False,learnmachinelearning,1507826822,True,[deleted]
Is it still possible to access the Coursera ML course for free?,3,1,False,False,False,learnmachinelearning,1507830417,True,"When I click enrol on the page, I am presented with two options, both of which cost money. Is there any way to access the course material for free?"
JupyterLab+Real Time Collaboration | PyData Seattle 2017,0,12,False,False,False,learnmachinelearning,1507861614,False, 
[x-post from /r/datascience] Working through Andrew Ng's deep learning courses. Here are my lecture notes from week 2! (Mathy notes on vectorized logistic regression).,3,4,False,False,False,learnmachinelearning,1507864030,False, 
Need suggestions,0,1,False,False,False,learnmachinelearning,1507865677,True,"Hello r/learnmachinelearning, i'm a final year student currently trying to find a data mining or other techniques to perform predictions/forecasting on stock supplies(inventory) for my final project. Can I get some suggestions? Thanks in advance :)"
Creating a random sentence while every n-word needs to be specific words?,0,1,False,False,False,learnmachinelearning,1507866160,True,[deleted]
Weekly Show-off!,0,4,False,False,False,learnmachinelearning,1507878321,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
An awesome collection of machine learning resources from github,0,58,False,False,False,learnmachinelearning,1507887655,False, 
"Interest in curated+explained paper newsletter, with paid/ad enabled extras?",4,5,False,False,False,learnmachinelearning,1507891319,True,"So, obviously, dirty shilling incoming. I'm poor and need to buy food and bitcoin\^\^


I've just started reading and writing up literature for my PhD and was wondering if there would be interested in a weekly (possibly more frequent if demanded)  freemium newsletter based on the current literature, with comments by me. The basic idea would be three tiers something like this:

1. Premium: pay 10-15 bucks a month, get a weekly digest of the top papers sorted by your interests (I'm gonna make a Webinterface), access to previous issues including fulltext search and 1 ""until it is cleared up or you can figure the rest out yourself""(still have to think about this a bit more) online tutoring per month with me, via email or a ticket/GitHub issue style interface
2. ""Willing to be advertised to"", access to the newsletter, and I'm gonna use you to fish for non-invasive advertising deals
3. ""Free"": between 3 - whatever makes sense of the articles that fit your interests, with a link to upgrade if you want more

This is basically an idea to make some cash while hopefully providing something useful to people. I'd be thankful for feedback and suggestions to make it workable if this at all interesting for the subs community"
"Hi r/learnmachinelearning, I'm the new mod!",4,18,False,False,False,learnmachinelearning,1507894325,True,"So I'm making this post to announce myself. /u/thundergolfer , here's the tag you asked for.

I'm /u/Badmanwillis, redditor for four years, head mod of /r/robotics for about three, maybe longer.

I've alway try to use a gentle touch when modding, I don't want to be a mod known for swinging the banhammer. [I'm always willing to engage with the community, and listen to feedback](https://www.reddit.com/r/robotics/comments/483itp/tightening_the_rules_for_submission/).

I've also wrote the r/robotics wiki, and made a helpful ""where do i start bot""; when I get the time I'll look into the wiki here as well.

As for my experience in machine learning: I'm new. I've taken Andrew Ng's Machine Learning course, on Coursera, and have been completing a number of tutorials from machine learning mastery over this summer. While I’m not an expert now, It's a subject I have a real passion for, and am currently working on some small projects using CNNs.

I'd like to think that I'm a good fit as a mod due to my experience with modding, and lack of experience with machine learning. I'm no expert, so we can all learn together!

If you have any questions or thoughts, please leave a comment, I'm happy to chat.
"
Getting into Machine Learning,2,4,False,False,False,learnmachinelearning,1507915625,True,"Hi everyone!

I'm a senior Applied Math and Statistics double major and am currently applying to Statistics Ph.D programs. Most of my courses in undergrad have been stats related (applied stats, probability, stats theory, SAS/r programming) but i've also taken classes such as partial differential equations, cryptology, and python programming. 

I did a clustering analysis research project and this past summer I worked on image processing algorithms and I think it's extremely interesting. I think I want to get into supervised machine learning for image processing. I know neural networks are the ""hot"" thing currently but I'd also be potentially interested in random forests, naive bayes, and logistic methods.

I don't really know much about this field and am not sure how I'd fit in as a math/stats person rather than a computer scientist. The programming languages I know are SAS, R, Mathematica, MatLab, and Python.

I know a lot of code and software has been written for these things so I wouldn't have to write it from scratch. Do I have applicable skills to get into this kind of research? Will I be able to find someone to work with in a Statistics grad program? Or is this research only done in a CS grad program?"
Please help me understand backpropagation well,2,1,False,False,False,learnmachinelearning,1507918023,True,"I am taking Machine Learning course on coursera.org. I have completed 5 weeks...  
But I am not getting a feeling that I understood backpropagation well, can anybody please provide any website/article/textbook from which I learn this concept again to better understand it?  
The resource can be math heavy, I want to learn the derivations too...  
thanks"
Linear Regression and Multiple Regression - Deriving with the Least Squares Approach,0,2,False,False,False,learnmachinelearning,1507922293,False, 
How is this achieved?,1,2,False,False,False,learnmachinelearning,1507922671,True,"I've been playing with TF object detection API to train/detect on custom dataset. I've seen videos where the network is able to not only detect, but also track the object with unique ID like this:

https://vimeo.com/221608117

How is this done? are there any TF or Keras examples on how to achieve this? Can this be done w/opencv's multitracker?"
Intuition for dueling network's improved performance over regular DQN,0,1,False,False,False,learnmachinelearning,1507926805,True,"Hey all,
I'm currently reading up on dueling networks (https://arxiv.org/abs/1511.06581) and I'd like to intuitively understand why the architecture performs so well in practice. As I understand, the key point of dueling networks is the explicit creation to two streams in the hidden layers, one to estimate the state value and another to estimate action-advantages. However, I'm having trouble seeing how this is any different from normal DQNs. For example, you can also mentally partition the last hidden layer in a normal DQN network into 1 and N - 1 nodes, and designate the one node as representing value and the others representing advantages, and this seems equivalent to the dueling network architecture. In fact, the only remaining difference I can see is the way the value and advantage streams are recombined to estimate Q using Eq 9. Is this recombination algorithm the key to why dueling networks work so well, or am I misunderstanding something else completely?

Thanks in advance!"
New Theory Cracks Open the Black Box of Deep Neural Networks,2,4,False,False,False,learnmachinelearning,1507954492,False, 
High School Student - Who should I go to for cloud services?,2,1,False,False,False,learnmachinelearning,1507955713,True,"I'm a high school student in the US, and I want to get into machine learning. I'd like to do a project with tensorflow - something with pattern recognition? (train the neural network with a bunch of images and then ask it to identify objects)

The issue is, I don't have powerful computers, so I'd need a cloud service/server to run my program. I've looked into AWS, Google Cloud Platform, and DigitalOcean. I'm also considering contacting some universities to see if they can lend me a server.

Am I overthinking this? How much processing power do you need for a cnn? What's the best cloud service for cnns? I'd like to spend as little money as possible, I can try to ask people for free credit/sponsorships.

Any advice is welcome, thanks!"
XGBoost + Linear Regression for time series?,0,3,False,False,False,learnmachinelearning,1507957567,True,I've seen kaggle competitions and other example where folks talk about the predictive power of a combination of XGB and Lin. Regression for time series. How exactly would you do that? A coded example in python would be of great help.
New 'Getting Into ML' Guides in Sub WIKI,10,14,False,False,True,learnmachinelearning,1507957630,True,"Hey subscribers of r/learnmachinelearning, 

I created a set of guides that hopefully can in future provide guidance to people new to Machine Learning and looking to get more involved with it. 

Recognising that not everybody wants the same thing out of the Machine Learning field, I've create different guides for different 'use-cases'

* The **High Schoolers** guide if, quite obviously for people not yet out of high school but interested in ML
* The **Engineers** guide is for people that are interested in ML but don't really want to do academic research 
* The **Academics/Researchers** guide is for those that want to do research, to innovate, and to push the frontier of artificial intelligence
* The **Hackers Guide** is for the most casual ML enthusiastic; someone who just wants to build cool projects on the weekend or at hackathons or on lab day 

-----

I'd love to get feedback on them. You can find them on the newly cleaned up [Wiki index](https://www.reddit.com/r/learnmachinelearning/wiki/index) page for the sub. 

Put your thoughts and feedback in this thread, or just message me directly. I don't think you can comment on the wiki articles themselves unfortunately."
"Now anyone can explore machine learning, no coding required",0,0,False,False,False,learnmachinelearning,1507960289,True,"Now anyone can inch up close to machine learning. It’s teachable in the form of an AI experiment “made with some friends from Google.”

You, yes you, can [teach](https://teachablemachine.withgoogle.com/) a machine (forget coding) using your camera. You can do it live in the browser.

Specifically, step into their invite to explore the Teachable Machine and you get to train a neural network locally on your device, without sending images to any server. No images are stored on Google servers—the training happens locally on your device.

Get some more details from this video https://www.youtube.com/watch?v=6VwVybOAkWA

Read more [here](http://www.rtoz.org/2017/10/14/now-anyone-can-explore-machine-learning-no-coding-required/)
"
"Weekly Status Check Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",0,5,False,False,False,learnmachinelearning,1507964710,True,"Let's have a  meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
Building a Simple Neural Network from Scratch in Python,12,48,False,False,False,learnmachinelearning,1507968429,False, 
most accurate prediction on how long would it take about for at least ml in dota 2 to win vs a human in a 5v5 (ml vs humans) - given the news that ML wins 1v1,1,0,False,False,False,learnmachinelearning,1507970561,True,"links to the best highest quality summaries, resources, video summaries related to the overall question would be good
"
Support Vector Machines for Classification,0,6,False,False,False,learnmachinelearning,1507981207,False, 
How to get started with Word2Vec?,0,3,False,False,False,learnmachinelearning,1507982512,True,"Hello everyone! I'm currently studying computer science in my master degree.
For a subject called ""machine lerning"" in this semester I have to do a presentation about ""Word2Vec"". I'm completely new in this machine learning area and need some help to get started.
Does anyone now good sources/papers to help me find good explanations for a good start? The focus should be on Word2Vec and the methods ""Continuous Bag-of-Words model"" (CBOW) and ""skip-gram"".
Thank you for your help!"
Anomaly detection project,0,2,False,False,False,learnmachinelearning,1507990571,True,"Hello guys.

I am currently doing my master's degree on major that is strictly connected with machine learning and I've been thinking on doing some ""bigger"" project as a preparation for my master's thesis project.

What I have in mind is system for anomaly detection: I am training my classifier/s using dataset containing objects of M classes, but during the ""testing"" phase there is a possibility of appearing objects from completely new, previously unknown class.

The biggest problem for now is lack of the data that I could use for doing this project - I would be very grateful for any suggestions (it would be ideal if the data was medicine related but that is not necessary at all). Also do you guys have any tips regarding those kind of projects - like things I should always remember about or maybe some interesting aspect of this particular problem that I should take into consideration / explore thoroughly when realizing this project. 

I am fairly unexperienced yet and I would appreciate any help really."
CLI tool for launching AWS Spot instances,0,1,False,False,False,learnmachinelearning,1507998361,True,"Recently I've been using AWS Spot instances to train some deep learning models. I've found the aws console can be a bit frustrating to use, so I wrote a simple CLI tool to help automate my workflow of launching, snapshotting and destroying instances. I thought it might be useful for others: https://github.com/samuelreh/spotr

It's a bit of a WIP; still needs a bit of polish. Just checking to see if anyone would find it useful. It's kind of like a simple floydhub."
Explanation of what an activation function is in an artificial neural network,0,1,False,False,False,learnmachinelearning,1508009949,False, 
Worth it to upgrade to GPU for Andrew Ng's DL course?,3,1,False,False,False,learnmachinelearning,1508010104,True,"I recall watching a video in the series where Andrew Ng said he didn't use a GPU to run the code in the course thus far. 

I guess that might have sufficed for a simple NN, but given how computationally expensive it is to run a CNN (which is the next installment in the series), do you guys think it's worth it to upgrade to a GPU?


"
Poisson distribution basics,0,9,False,False,False,learnmachinelearning,1508020255,False, 
Yesterday I wrote a couple of pages on neural networks and back propagation. Did I get it right?,0,1,False,False,False,learnmachinelearning,1508021116,True,[deleted]
Beginner's Question,5,1,False,False,False,learnmachinelearning,1508035993,True,"Hey everyone!
I am trying to format my dataset for input. This is actually proving to be the most difficult part. The issue is that I have a database where there's one field for the the customer ID, and a second field is a code which describes something about the customer. There could be hundreds of thousands of codes applied to one customer, each represented in a different row.

So example:

ID, Code

1, 1234

1, 2345

2, 1234

3, 5678

...and then there are some other fields as well, which I'd like to use to predict whether or not there's a potentially missing code (or code that was added incorrectly) based off the training dataset.

What would be the best way to format this data? Would the ""one hot encode"" method be practical for so many potential codes?
Being from the SQL/ RDBMS world, my biggest problem is visualizing this formatting translation. Once I get there, I'm familiar with Python.

Any help is appreciated!"
hello people! newbie here,0,0,False,False,False,learnmachinelearning,1508036592,True,"hey! im new to reddit in general but decided to join to talk to other people into ml/ai. recently graduated highschool and headed to uni for comp sci, and whilst doing this program am planning on learning ml also. just wanted to say hi and that i look forward to being a part of this community! As a point of discussion, how did u folks get started with ML? what difficulties did u guys face? "
How to evaluate the performance of a Random Forest Regressor?,0,5,False,False,False,learnmachinelearning,1508046372,True,"I have a random forest regressor which shows no change in the coefficient of determination (0.68) as I change the number of trees, but a significant drop in the OOB error from 20 to 50 trees.

Why would the OOB error change but not the coefficient of determination? And which one should i use to evaluate the performance?

Thanks"
Building your own Neural Network for Digit Recognition,0,2,False,False,False,learnmachinelearning,1508047787,False, 
most effective/accurate ML based 1-line key point/summariser of text and video content? since 99% of uneducated ppl are shitty and dont know how to communicate/write/speak,1,0,False,False,False,learnmachinelearning,1508066436,True,"

in chrome extension form, or something to copy/paste into, and it speaks back to you (tts)


"
Getting negative loss with KLqp inference,2,1,False,False,False,learnmachinelearning,1508070930,True,"I am trying to use a neural net for non-linear regression and even though I am getting [a decent fit](https://discourse-cdn-sjc1.com/standard2/uploads/edwardlib/original/1X/fc9e9fbd873013046810d4a445ee33bc7c676e94.png) my loss at the end of inference hovers around -1000. I can't really say I know what goes on under the hood, still in the process of learning it, so do you have any ideas why this happens?"
"Neural Network implementation in Javascript, by an example",1,21,False,False,False,learnmachinelearning,1508071731,False, 
What are the best books / resources on ensemble methods?,0,3,False,False,False,learnmachinelearning,1508087365,True,"As in the title. They need not be beginner friendly, but I'm looking for anything that's expansive / definitive on it."
Visualizing the Confusion Matrix,0,11,False,False,False,learnmachinelearning,1508092140,False, 
Useful/Helpful ML Project Ideas List 2017 v.01,1,0,False,False,False,learnmachinelearning,1508110060,True,"#1

something that once you press start/begin for a 'process', works like this way. 

1. shows you a task/goal/item. 

2. after a custom-set, pre-set time has passed like 3 minutes, shows you another step/task/goal -- (each step/task/goal has a specific set time relative to the previous)

3. continues until the entire set of steps/task/goal/process ends


like for recipes and many many many things


---

#2

something that shows key goals, and all path-dependent goals. path-dependencies can be connected to multiple key goals. shown in clearly visible and exceptional UI

---

#3

chrome extension or something that,

shows the quality of a site and page based on the valutation of intelligent and highly educated users?


---

#4

chrome extension or something that,

shows the rounded %/ratio of youtube votes as a % of views upon search -- should be able to custom colour-coded


---

#5

in chrome extension form, or something to copy/paste into, and it speaks back to you (tts),

most effective/accurate ML based 1-line key point/summariser of text and video content? since 99% of uneducated ppl are shitty and dont know how to communicate/write/speak 


---

#6

most effective/accurate ML based 1-line key point/summariser of text and video content? since 99% of uneducated ppl are shitty and dont know how to communicate/write/speak

---

#7

chrome ext or something,

best auto-outliner of video content since academic uploaders, and basically all uploaders, are shitty and don't have timed links or TOC links

---

#8

"
best highest quality things on ARXIV related to everday life,1,0,False,False,False,learnmachinelearning,1508114791,True,"arxiv seems to have a wide/range of things/topics, etc.

* 
https://www.reddit.com/domain/arxiv.org/top/?sort=top&amp;t=all

* https://news.ycombinator.com/from?site=arxiv.org


https://www.technologyreview.com/s/609120/now-theres-an-iq-test-for-siri-and-alexa/ seems important and yet it's not top/popular/populist on either of the above

---


doesnt seem like there's any way/method to class/ml/type/organise/arrange/filter

by highly specific categories or anything

* https://chrome.google.com/webstore/search/arxiv?_feature=free&amp;_feature=5stars&amp;_category=extensions

* https://www.google.com/search?q=site:chrome.google.com+arxiv&amp;tbs=qdr:y

unless im mistaken?

---

i dont understand what arxiv is for or what they focus on? it's unclear

link to best highest quality things on ARXIV that is helfpul/useful to everday life?

highly impactful on everyday life? high effects on everyday life?

or helpful/useful to my life?

how's it relevant?"
[D] What are some errors that you still make or use to make that you think others should know about.,0,15,False,False,False,learnmachinelearning,1508124717,False, 
How to import image datasets as inputs with labels in Keras/Tensorflow?,8,8,False,False,False,learnmachinelearning,1508168346,True,"I'm trying to build an Image Classifier, as shown in [this video](https://www.youtube.com/watch?v=cAICT4Al5Ow&amp;t=190s)
However, I'm struggling to import my image data. How could you do this?
I have a directory with all my images sorted in different subfolders, for example:
imagedata/cats/ is where I store my images of cats downloaded from the internet

imagedata/dogs/ is where I store my images of dogs downloaded from the internet."
"are single layer ANN's appropriate for learning/teaching? (e.g. input layer straight to output, no hidden layer?) [xpost /r/MachineLearning]",2,2,False,False,False,learnmachinelearning,1508171048,True,"I am working on some content to teach ANN's to gradeschool kids.  I've run across a couple good articles, most of which model a simple XOR problem, using three layers (input, 1 hidden, output).

however, [this](https://medium.com/technology-invention-and-more/how-to-build-a-simple-neural-network-in-9-lines-of-python-code-cc8f23647ca1) article is a little different in that it simply goes straight from inputs to outputs, with no hidden layer in between.  Most other articles seem to follow the three layer approach for hello world ANN models.

Does this technically qualify as an ANN for teaching purposes, or must we have at least three layers to be an ANN?  (input, 1 hidden, output).  I want to use this simpler model as the first ANN in the content I am producing, but...but only if it technically qualifies as a neural net.

Thanks!"
Question about clustering,1,1,False,False,False,learnmachinelearning,1508175279,True,"I think this is the best place to ask, but am not sure.

I have a very very large dataset generated by machinelearning algorithm.  The output is a table that contains, essentially, the closeness value between every combination of data in the previous table.

I am having trouble figuring out the way to most efficiently cluster the data so I can get what are essentially groups of similar records according to my own definition.  (If I run clustering tools on the original data, the're not smart enough to recognize the situations where the records do or don't match)

So what I've got is a table like this.



 ID1   | ID2  |  Value 
------|----|-------
1 | 2 | .02
1 | 3 | 1
1 | 4 | .9
2 | 1 | .02
2 | 3 | .8
2 | 4 | 1
3 | 1 | 1
3 | 2 | .8
3 | 4 | .25
etc | etc | etc

(Id's 1 and 2 are close, and 3 and 4 are close and should appear in the same cluster)

I need to cruise through millions of rows and get back clusters of n records that use my values for closeness.  

If anyone could point me towards a general approach or a tool that might work, any help would be appreciated.  I'm not a dev, just the boss."
Question about what algorithms to use for simple case,1,1,False,False,False,learnmachinelearning,1508176979,True,"Say I have two datasets, each set contains a list of datapoints consisting of a datetime, and scalar value. (2017-01-01, 55). What kinds of algorithms do I use to look for 'interestingness' between the dataset, to find correlations? "
Network topology for regression-based problems?,0,5,False,False,False,learnmachinelearning,1508179430,True,"From experience, what routes would you suggest for solving a regression-based problem, in terms of network topology for a DNN?

Let's say you have a benchmark root mean squared error from a gradient-boosted decision tree, or regular GLM. You're trying to beat this with a DNN. An initial single hidden-layer dense NN that is extremely wide doesn't yield good results, nor does a deeper network with less units.

Is there a 'rule of thumb' on network topology/a path that one should take, or is this entirely experimental, throw it at the wall and see what sticks?"
Sigmoid in backpropagation ?,5,3,False,False,False,learnmachinelearning,1508181860,True,"Hello ,

I've written a Feedforward model on numpy and now i'm looking to add a sigmoid function to the model . However my model outputs huge numbers at beginning of training than i'm looking to map between (0-1) .
 
basically the problem is that the model will continuously output 1 if i plug in the sigmoid function , and the derivative will also be valued 0 (sigmoid * (1-sigmoid ) ) so no changes will occur to the NN .

How can i avoid this ? "
The (Simplified) Theory of Convolutional Neural Networks,0,23,False,False,False,learnmachinelearning,1508187095,False, 
Pytorch NMT Implementation using Quasi-RNN,0,1,False,False,False,learnmachinelearning,1508201043,False, 
How useful is mathematical theory in learning Machine Learning?,1,4,False,False,False,learnmachinelearning,1508204297,True,"I'm talking things like runtimes and Turing machines. 

I'm currently a Master's student studying AI and my course requirements gives me a choice between two classes: Computability (Turing machines, decidability, recursive enumerability; many-to-one and polynomial-time reductions; NPcompleteness, Cook-Levin Theorem; Recursion Theorem.) or a course on programming languages (Formal languages and grammars; recursive descent parsing; data types, expressions, control structures, parameter passing; compilers and interpreters; memory management; functional programming principles.) I'm currently taking a course on algorithms and it's definitely one of the hardest courses I've taken in my college career. The Computability class sounds like it will be more of the same and I'm wondering if it is worth it to take this class or if it's a section of CS that doesn't come into play too often in AI.
"
"Noob question - can I start with a ""generic"" first layer for a CNN?",5,10,False,False,False,learnmachinelearning,1508222830,False, 
"Zero vector better than prediction with MAE score, what does it mean?",2,1,False,False,False,learnmachinelearning,1508234060,True,"I've been working on a very noisy problem with very low signal. After some effort I did manage to reduce my training MAE (mean absolute error) error significantly - however it still does worse than an all-zero vector.

The thing is that when i shuffled my prediction, on avg, gives worse results than unshuffled, indicating there is indeed some truth to my prediction.

What does that all mean? How come an all-zero vector does so much better?

Thanks"
How to implement scientific papers,6,7,False,False,False,learnmachinelearning,1508239889,True,"I have been playing around with deep learning. I successfully built working models of seq2seq, fully convolutional ae, etc. I understand the basic concepts using tensorflow and keras.

Recently I have started studying probability theory, and information theory (I have a background in physics), so I can understand deep learning papers to a certain degree. But I have trouble pairing some expressions in these papers with code.

Are there any step-by-step tutorials on implementing a machine learning paper? Just for a single paper or as a general guideline. Currently I am reading Adversarial Variational Bayes (L. Mescheder, et al.)."
Introduction to Machine Learning eBook - good material to get started.,1,13,False,False,False,learnmachinelearning,1508244878,False, 
Using test data to tune model [cheating?],6,1,False,False,False,learnmachinelearning,1508254715,True,"Hi, I'm struggling with a doubt here. Let's say I have a training set of data. I've learned the models for my classification problem using a machine learning algorithm (not important which model).

I have been given a test set, with 1000 examples, but I don't have access to its labels -- I want to predict them. Let's say I use some properties from the test set to tune my model (without the labels!). Is this considered cheating? If so, why?

Thanks in advance for your clarification!"
Google created machine-learning software that can program machine-learning software.,4,9,False,False,False,learnmachinelearning,1508255049,False, 
"How many ""neurons"" could you easily run on a typical PC?",2,1,False,False,False,learnmachinelearning,1508274261,True,[deleted]
"when the batch size is equal to one, how it affects the functioning of the neural network",4,3,False,False,False,learnmachinelearning,1508276476,True,"I understand the meaning of the batch size, but I can't understand if setting the size of it equal to 1 change how the loss function works. I am new to machine learning so any help is appreciated."
Deep Learning Fundamentals - YouTube Playlist,13,60,False,False,False,learnmachinelearning,1508297698,True,"This [Deep Learning Fundamentals YouTube playlist](https://www.youtube.com/playlist?list=PL_SSujepRkqy0QhD4RK_3VCd2O5valQit) covers essential topics in deep learning for beginners. The videos give short, general explanations of deep learning concepts and also show the technical implementation of some of these topics in code using the neural network API, Keras (written in Python). The playlist is still being developed, with new videos being added regularly. 

Some topics so far include:

- Machine learning overview
- Deep learning overview
- Artificial Neural Networks (ANN)
- Layers in an ANN
- Activation functions
- Training a model
- How a model learns
- Loss functions
- Data sets: train, validation, and test

Additionally, if you’re interested in focusing more on the coding aspect, you can check out my [Deep Learning with Keras playlist](https://www.youtube.com/playlist?list=PL_SSujepRkqyjjbWnXQBzKXXm86UQ53Ic). It gives step-by-step tutorials for getting started with deep learning using Python and Keras.
"
How do I focus on a subregion within images for classification in deep learning?,14,1,False,False,False,learnmachinelearning,1508307796,True,"I have a dataset consisting of images, where the images have a lot of noise in it except for a recognizable region within which the classification must take place.

For instance,

/--------$$&amp;:&amp;/
//&amp;:@;&amp;@:@!/
/:&amp;(1111111:&amp;/
/$/1122111$/
/&amp;/1111111$/
/---------////

In that example, the region I need to focus on is the area of 1's, and I need to classify whether it contains any 2s or not. Can I train a network to first identify the region of 1s, then pass that output region to a classifier to detect whether it contains any 2s? 

Hopefully this is making sense. I don't want to have to manually crop my images down to the 1 regions. "
TWIL (This Week I Learned) - Share something new that you have learned this week!,0,2,False,False,False,learnmachinelearning,1508310314,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
How do we fit a linear regression classifier and plot its learning curve?,5,2,False,False,False,learnmachinelearning,1508318452,True,"As stated in the title how do we apply a linear regression to a dataset, of 64 features and 1 label(or any data set) and how do we plot the learning curve of it?"
Elman Recurrent Neural Network Simulator,1,5,False,False,False,learnmachinelearning,1508322524,False, 
How best to quantify probability density change?,2,3,False,False,False,learnmachinelearning,1508336097,True,"Hey,

I've got some time-series data, and, starting with a prior normal distribution, I wanted to see and quantify the change in its shape as I move a sliding window across the time-series.

I don't know what the accepted approach to this issue is - what parameters' change should I be plotting over time.

There's also the part of separating the noise from the trends, but as I understand it a fourier filter can be used there.

Should I just be using mean and standard deviation? Isn't that assuming a normal distribution?"
Pre-Trained Models,3,1,False,False,False,learnmachinelearning,1508336194,True,"I have some data in rgb format; not real life pictures.  I assume I have to train my own model given this or could I benefit
 from the pre-trained models that Keras /tensorflow offers?"
Just testing,0,1,False,False,False,learnmachinelearning,1508336229,True,[deleted]
VGG19 Minimum Image Size,5,1,False,False,False,learnmachinelearning,1508337152,True,"I have an image 520x62x3 which gives me issues when I try to implement VGG19; Specifically when I try to implement the Max2dPooling.  So I was wondering what is the realistic minimum size for the model to work; or special tweaks that are required to make it work.
"
What mathematics resources would you recommend to a complete ML Noob,23,37,False,False,False,learnmachinelearning,1508342009,True,"Hi,
So my question is, what Mathematics resources would you recommend for a complete Machine Learning newbie who knows just the basics of Python? Can you recommend some good resources for learning Linear Algebra, calculus, statistics &amp; probability or anything you could think of in mathematics for Machine Learning? "
Need advice on language modeling usong LSTMs,4,4,False,False,False,learnmachinelearning,1508342636,True,"1. Do I simply divide my corpus into words?
2. How long should input sequences be?
3. In generating input sequences do I have to take into account the start and end of sentences?
3. How is this generally done in a research setting?

I'd really appreciate the help."
Are there significant disadvantages to using autograd to calculate the gradients (rather than hardcoding backprop for the architecture type)?,0,1,False,False,False,learnmachinelearning,1508356456,True, 
Question for Machine Learning in cloud,3,6,False,False,False,learnmachinelearning,1508367072,True,"Is there good recommendation where I can train and test my models in cloud, preferebly some variant for free?  I have low end laptop so I just want to practice."
"when we do CAPTCHA which i guess helps with self-driving cars, are we supposed to select every single pixel? sometimes when this is done, it gives an error",1,2,False,False,False,learnmachinelearning,1508388133,True,"when we do CAPTCHA which i guess helps with self-driving cars, are we supposed to select every single pixel? sometimes when this is done, it gives an error"
how to group sentence on the basis of their context?,2,6,False,False,False,learnmachinelearning,1508400641,True,"I need take care of sentences and cluster them to groups based on their context or understandings.
what should i learn first and where to start from?"
Top 6 errors novice machine learning engineers make,0,1,False,False,False,learnmachinelearning,1508405451,False, 
Optimizing python convnet,1,8,False,False,False,learnmachinelearning,1508407804,True,"Hi. I have implemented different NN layers in numpy to learn backprop. Now I am wondering what can be done to speed them up a bit.

I basically have two questions:
1. When looping over pixels in the convnet, is there a way to paralellize this very easily in python?

2.(most important) 

My forward pass is the following (per pixel):

    A[:,i,j,:]=numpy.sum(X2[:,hpad+i-hpad:hpad+i+hpad+1,wpad+j-wpad:wpad+j+wpad+1,:][:,:,:,:,numpy.newaxis]*self.W[numpy.newaxis,:,:,:,:],axis=(1,2,3))

Backward pass:

    tmpdW+=numpy.sum(err[:,i,j,:][:,numpy.newaxis,numpy.newaxis,numpy.newaxis,:]*X2[:,i:i+2*hpad+1,j:j+2*wpad+1,:][:,:,:,:,numpy.newaxis],0)
    dodi[:,i:i+2*hpad+1,j:j+2*wpad+1,:]+=numpy.sum(err[:,i,j,:][:,numpy.newaxis,numpy.newaxis,numpy.newaxis,:]*self.W[numpy.newaxis,:,:,:,:],-1)

dodi is backpropagated error. This works, but I am wondering if it can be optimized by rewriting the numpy code? For instance if I would write a MLP layer back prop as 

    dW =np.sum(X.T[:,:,np.newaxis],err[np.newaxis,:,:],1) 

instead of 

    dW=numpy.dot(X.T,err)

 it would be way slower. Maybe its possible to use tensordot or something?"
Regression spline,3,4,False,False,False,learnmachinelearning,1508408951,True,Please what does degree of freedom mean in regression spline 
I made a video on How machines learn. What do you guys think?,0,1,False,False,False,learnmachinelearning,1508421111,False, 
Improving Real-Time Object Detection with YOLO,0,11,False,False,False,learnmachinelearning,1508421211,False, 
Keras Model Accuracy,8,8,False,False,False,learnmachinelearning,1508424457,True,Is there a way in Keras to load a model and know what was the accuracy of the model? As I lost the original output and I not sure how to get the information now.
Looking for a multi-task learning package in Python,0,4,False,False,False,learnmachinelearning,1508430379,True,"I'm interested in using Multi-task learning with SVMs, in Python, similar to [Regularized Multi–Task Learning by Eveniou and Pontil (2004)](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.93.6440&amp;rep=rep1&amp;type=pdf). I was wondering if anyone is aware of a package that implements such a technique - I haven't found anything that is compatible with SVMs, and in Python.  Thanks."
Deep reinforcement learning tutorial with a top down approach,2,16,False,False,False,learnmachinelearning,1508454665,True,"Hello, 

I'm looking for a deep reinforcement learning tutorial with an approach close to fast.ai's one : learning from code and then going into the mathematical details as we go deeper. When things are too abstract I kind of struggle to follow the courses. Would you know of any ?  

If it could be in text format rather than video then it's even better (but videos are fine) :D 

Thanks a lot."
[D] What is the tool or tools you use for machine learning?,0,1,False,False,False,learnmachinelearning,1508463464,False, 
AlphaGo Zero: Learning from scratch,0,1,False,False,False,learnmachinelearning,1508464627,False, 
Weekly Show-off!,4,2,False,False,False,learnmachinelearning,1508483120,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
Does backpropagation has any alternatives for calculating gradient?,3,1,False,False,False,learnmachinelearning,1508496362,True,"Hi,

There are a million cost functions, gradient based optimisation methods, activation functions etc.. I am wondering whether there is anything else for computing gradients. If not, is there a reason?"
"for the 'typical' model of CAPTCHA, do you have select every single pixel?",0,1,False,False,False,learnmachinelearning,1508503583,True,"like on reddit, cl, etc.

see https://www.reddit.com/r/learnmachinelearning/comments/77ca0l/when_we_do_captcha_which_i_guess_helps_with/"
Vectors in machine learning,0,1,False,False,False,learnmachinelearning,1508508942,False, 
Looking for a 256x256 unlabeled GAN,1,2,False,False,False,learnmachinelearning,1508520193,True,Currently is there a GAN with the ability to generate 256x256 images without any labels/hints/marks/pairs/cross-domain-pairs? I do not care the quality of results but it should not only predict noise maps..
Help with backpropagation for machine learning the MNIST dataset,7,11,False,False,False,learnmachinelearning,1508521342,True,"So, I'm using Michael Nielson's machine learning book as a reference for my code (it is basically identical): http://neuralnetworksanddeeplearning.com/chap1.html

The code in question:

        def backpropagate(self, image, image_value) :
    
    
            # declare two new numpy arrays for the updated weights &amp; biases
            new_biases = [np.zeros(bias.shape) for bias in self.biases]
            new_weights = [np.zeros(weight_matrix.shape) for weight_matrix in self.weights]
    
            # -------- feed forward --------
            # store all the activations in a list
            activations = [image]
    
            # declare empty list that will contain all the z vectors
            zs = []
            for bias, weight in zip(self.biases, self.weights) :
                print(bias.shape)
                print(weight.shape)
                print(image.shape)
                z = np.dot(weight, image) + bias
                zs.append(z)
                activation = sigmoid(z)
                activations.append(activation)
                count += 1
    
            # -------- backward pass --------
            # transpose() returns the numpy array with the rows as columns and columns as rows
            delta = self.cost_derivative(activations[-1], image_value) * sigmoid_prime(zs[-1])
            new_biases[-1] = delta
            new_weights[-1] = np.dot(delta, activations[-2].transpose())
    
            # l = 1 means the last layer of neurons, l = 2 is the second-last, etc.
            # this takes advantage of Python's ability to use negative indices in lists
            for l in range(2, self.num_layers) :
                z = zs[-1]
                sp = sigmoid_prime(z)
                delta = np.dot(self.weights[-l+1].transpose(), delta) * sp
                new_biases[-l] = delta
                new_weights[-l] = np.dot(delta, activations[-l-1].transpose())
            return (new_biases, new_weights)

My algorithm can only get to the first round backpropagation before this error occurs:

      File ""D:/Programming/Python/DPUDS/DPUDS_Projects/Fall_2017/MNIST/network.py"", line 97, in stochastic_gradient_descent
        self.update_mini_batch(mini_batch, learning_rate)
      File ""D:/Programming/Python/DPUDS/DPUDS_Projects/Fall_2017/MNIST/network.py"", line 117, in update_mini_batch
        delta_biases, delta_weights = self.backpropagate(image, image_value)
      File ""D:/Programming/Python/DPUDS/DPUDS_Projects/Fall_2017/MNIST/network.py"", line 160, in backpropagate
        z = np.dot(weight, activation) + bias
    ValueError: shapes (30,50000) and (784,1) not aligned: 50000 (dim 1) != 784 (dim 0)

I get why it's an error. The number of columns in weights doesn't match the number of rows in the pixel image, so I can't do matrix multiplication. Here's where I'm confused -- there are 30 neurons used in the backpropagation, each with 50,000 images being evaluated. My understanding is that each of the 50,000 should have 784 weights attached, one for each pixel. But when I modify the code accordingly:
            
            count = 0
            for bias, weight in zip(self.biases, self.weights) :
                print(bias.shape)
                print(weight[count].shape)
                print(image.shape)
                z = np.dot(weight[count], image) + bias
                zs.append(z)
                activation = sigmoid(z)
                activations.append(activation)
                count += 1

I still get a similar error:

    ValueError: shapes (50000,) and (784,1) not aligned: 50000 (dim 0) != 784 (dim 0)

I'm just really confuzzled by all the linear algebra involved and I think I'm just missing something about the structure of the weight matrix. Any help at all would be greatly appreciated."
Trouble training fully convolutional model,4,3,False,False,False,learnmachinelearning,1508542397,True,"I am working through a project to better understand how object detection and localization work. The concept is based off of YOLOv2, and I am using pytorch. I am having trouble getting the my model to predict the correct 'confidence' (is there an object in a cell), so I have dumbed the problem down as far as possible and still cannot figure out what is happening. 

Here is where I am at: I divide my large input image into a 2x2 grid, randomly choose if a dot should go in each cell, choose a random location in the cell, and choose a random size for the dot. Then train the model to predict if a dot exists in each cell.  When I use a fully convolutional CNN, the model will only get to ~ 80% accurate, adjusting the learning rate, activation functions, number of filters on each convolution, weight decay, etc has not gotten any better than ~80% accurate at detecting if a dot is in each cell. However when I put a couple fully connected layers on top, it learns very quickly and gets up to 100% accuracy almost instantly.

TLDR; 6 layer CNN with a 4 layer CNN head will not learn to detect a white dot on an all black background. Using the same 6 layer CNN with 2 fully connected layers learns this very quickly. 


Any ideas on what is happening? [Here is a notebook with a side by side comparison of the two models.](https://github.com/denck007/Simple_Object_Detection/blob/master/Dot_tracking_2x2_FC_vs_FC-NN.ipynb) "
What is a recurrent cell?,4,4,False,False,False,learnmachinelearning,1508557184,True,"I am reading this [blog](http://www.asimovinstitute.org/blog/) and came across this image of a [recurrent cell](http://www.asimovinstitute.org/wp-content/uploads/2016/12/rnncell.png) . Both recurrent cell looks like a feed forward cell except it had this weird lines in the end and starting of the two recurren cells. 
What does this mean?

From the blog 
&gt;Recurrent cells have connections not just in the realm of layers, but also over time. Each cell internally stores its previous value. 

when comparing to a normal feed forwading cell what happens to a recurrent cell? 

Does the recurrent cells have separte matrices at seperate time intervals to store previous values?"
"best highest quality semantic (positive/negative) analyzer currently in 2017 -- for each of music, art, and everything else",0,1,False,False,False,learnmachinelearning,1508562029,True,"coudl be a company or anything

best highest quality semantic (positive/negative) analyzer currently in 2017

saw https://www.reddit.com/r/botwatch/comments/5lgn6s/i_created_a_bot_that_analyzed_a_users_comments/"
"Weekly Status Check Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",5,7,False,False,False,learnmachinelearning,1508569510,True,"Let's have a  meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
GAN: run generator optimizer twice vs using a different learning rate,0,4,False,False,False,learnmachinelearning,1508600788,True,"I'm working on a GAN implementation and reviewing the DCGAN TensorFlow implementation.  The code runs the optimizer twice for the generator so it can keep up with the discriminator.  I was wondering if it would perform better and be more flexible to just use different learning rates for each optimizer?

[DCGAN model on github](https://github.com/carpedm20/DCGAN-tensorflow/blob/master/model.py)"
A brief introduction to Slow Feature Analysis,0,1,False,False,False,learnmachinelearning,1508602027,False,[deleted]
TensorFlow 101,2,46,False,False,False,learnmachinelearning,1508603832,False, 
Does Poisson distribution arise from the binomial distribution?,0,0,False,False,False,learnmachinelearning,1508618629,False,[deleted]
How do we know how many hidden layers and how many neurons per hidden layer is needed?,4,4,False,False,False,learnmachinelearning,1508619094,True,"So I became really interested in machine learning (in a basic level), and found that NN model which is: input layer - hidden layers - output layer.

However, I still don't understand how people determine how many hidden layers/neurons are needed. Is that an arbituary number? Is there a rule?"
Question on reduced weighted least squares in a regression setting.,2,2,False,False,False,learnmachinelearning,1508620099,True,"The question is from Elements of Statistical learning, number 2.6.
[I posted the full question on stack exchange](https://stats.stackexchange.com/questions/309199/proving-that-the-fit-for-a-regression-problem-with-tied-input-values-can-be-obta), where it might be a little easier to read.

If anybody has any thoughts or suggestions, I'd really appreciate it.

Thanks in advance."
"Migrating to ML from regressions. Can machine learning ""see"" independent variables as ""objects"" -- can I give traits to them?",0,1,False,False,False,learnmachinelearning,1508636452,True,"Say I want to build a win-loss-draw ML chess model. Magnus Carlsen will be playing White against Levon Aronian. In a ridge regression, the design matrix has a one for m_carlsen_white, a one for l_aronian_black, and zeros for all the other player halves in the dataset. There's some room for interaction terms/throwing in other independent, related variables, but what if I want to do something like, instead of just having a column for each player and White/Black, have ""objects"" consisting of details like:

Name/Color/ELO rating/Recent Form/Minutes per first 20 moves/age of first 2700 rating. 

And then, if that's possible, is it possible to run for two ""result vectors"" at once? One will be a bespoke scoring system to track outcomes, the other for move numbers through a certain phase."
Let’s build a reddit bot together!,26,39,False,False,True,learnmachinelearning,1508637362,True,"/r/LearnMachineLearning is initiating [an open-source project](https://github.com/LearnMachineLearning/RedditCommunityBot) in which we will create a bot that helps us moderate the /r/LearnMachineLearning community. Of course, given that we are a subreddit dedicated to learning machine learning, we will want our bot to be using some kind of machine learning. Therefore I am looking for suggestions of **bots that uses machine learning to moderate our subreddit**. Please use upvote to cast your vote for your favorite reddit bot ideas. This thread is under the contest mode, so only mods can see scores.

Any other suggestions on how to proceed in terms of logistics are also welcome on this thread. 

I’ve bounced the idea previously on our [Discord server](https://discord.gg/4appNZm) and gotten a couple of suggestions which I will replicate below. "
Neural Network doesn't always train properly?,1,5,False,False,False,learnmachinelearning,1508643695,True,"I'm new to Machine Learning and decided to create a Neural Network from scratch with MSE cost function and gradient descent for back propagation. The network is initialized with random weights and biases.

When trying to solve XOR, my neural network seems to work most of the time. However, sometimes when I run the neural net, there are instances where it does not train properly and completely fails the test cases.

Is this normal? If not, could someone analyze my code to point out what I am doing wrong? I've included seeds in the code for instances where it works properly and not properly.

Thank you!

Neural Net Code:
https://github.com/BrianSantoso/NeuralNet/blob/master/nn2.py"
Let's test the Google AI Experiment - AI victory,1,1,False,False,False,learnmachinelearning,1508663848,False, 
Some helpful resources for Neural Networks,0,1,False,False,False,learnmachinelearning,1508679423,False, 
My math cheatsheet on machine learning and learning theory,1,1,False,False,False,learnmachinelearning,1508710166,False, 
How much does over-fitting matter when using an autoencoder for dimensionality / feature reduction?,5,5,False,False,False,learnmachinelearning,1508720184,True,"I'm currently playing around with stacked autoencoders in order to reduce the dimensionality of a dataset that has roughly 700 features.

So I'm wondering... if I'm just using this for feature reduction (and I retrain / encode every time I need to make predictions on new data), does it really matter if I overfit? Wouldn't that just be a better representation of the data? I'd still try to get a good validation score, but if I'm just using the encodings and it's always retrained, then I won't ever have to worry about it accurately representing out of sample data because it will never see any.

I know I could just test this but unfortunately, I'm using walk-forward validation on several LSTMs so any testing I do takes a very long time, even with fewer features.

Any insight would be greatly appreciated!"
"How do I do gradient descent back propagation on an ""area"" loss?",4,3,False,False,False,learnmachinelearning,1508726985,True,"Suppose I am doing a convolutional network. So, input to the net is an image, and its output is also an image. But, actually, the input to the net will generally be a subset of the input image, and the output will generally be a single pixel. (The CNN is then applied across the whole input image to get the full output image.)

The mean squared loss, for example, would be a pixel loss -- just (training_data - net output)^2 per pixel.

However, the kind of loss I want to compute is a function of a square window of the training data versus a square window of the network output. For example, suppose I am doing a structural similarity index as the loss function. Then, I need NxN pixel windows of both the target image as well as the output of the network.

However, I don't understand how you can feed back the result of multiple invocations of the CNN (to get the output NxN pixels.) And I haven't been able to find any tutorial that explains how that works.

My mental model of a CNN (used for image processing) is that it is effectively out = f(in), where in is MxM pixels, and out is a single pixel. 

Am I misinterpreting things? Should that be, instead, in is (M+N)x(M+N) pixels, out is NxN pixels, and there you go, you have all of the pixels you need to compute your loss? And when that is back-propagated, you kind of get an average correction to the net parameters, as you're applying the result of NxN invocations of the CNN, rather than just one."
[Beginner] Why does my neural network perform poorly?,4,20,False,False,False,learnmachinelearning,1508733680,True,"Hello,

I'm an undergraduate student taking my first course in machine learning, but I absolutely love it and I've been voraciously consuming as many articles and materials that I can find, suitable for my level. My class has gone over MLPs, so I wanted to try to implement one from scratch.

The resources I used included my class's lecture notes, Andrew Ng's Coursera exercise, the MIT Deep Learning lecture available on YouTube, and many miscellaneous articles concerning activation functions and cost functions. In the end, I came up with this: [GitHub link.](https://github.com/trebledawson/Machine-Learning-Examples/blob/master/Python/feedforward_neural_network.py)

It works sort of okay, but I find that it does not perform as well as I would have expected. It does not seem to be able to draw a nonlinear decision boundary, and furthermore the scipy minimize function frequently does not converge, even when the training data is completely linearly separable. 

Included (though commented out) is a different implementation of the backpropagation algorithm and training, which does not rely on the scipy minimize function but rather directly updates the node weights. I could not get this algorithm to converge within a reasonable number of epochs. 

I would be extremely grateful for any help that anyone could give regarding this program. In addition to being new to machine learning, I'm also relatively new to Python, so please forgive any style issues. Thank you very much.

Edit: Several of the hyperparamters and class attributes pertain only to the commented-out backpropagation and training algorithms. Sorry for being unclear."
Visualising Activation Functions in Neural Networks,0,1,False,False,False,learnmachinelearning,1508770807,False,[deleted]
How Long Is The Data - A Fast Track Recommender Systems Curriculum: Going from 0 to 60,0,1,False,False,False,learnmachinelearning,1508775498,False, 
Looking for recommendations for an NLP approach for a project that I am working on,2,7,False,False,False,learnmachinelearning,1508784899,True,"Hi, I have a background in computer vision and machine learning but I am not very knowledgeable about NLP. I am looking for pointers on how we might approach a task that we are looking at.


We are trying to identify when passages of text are talking about the same thing, and how closely the subjects of these passages match.


For example (these are made up examples) if I have a paragraph which discusses fishing and another paragraph which discusses the history of Mexico, I'd like to be able to tell that they are talking about completely different things But If I have a paragraph talking about fishing for Trout, and another paragraph which is a review for a new fishing rod, I'd like to be able to say that they are more similar. And I'd like to be able to tell that two paragraphs which talk about fishing for trout are even more similar.


I've been told that Word2Vec might be a good place to start looking. Can people recommend some successful, well established algorithms or methods to look at? Are there companies that are doing something like this already?"
How do Alpha Go policy networks choose only among legal moves?,4,14,False,False,False,learnmachinelearning,1508789303,True,"Everywhere I found it was written that the value network gives an evaluation of the board and that the policy networks give each legal move a probability of being chosen. How is this achieved? Don't you need a fixed architecture and therefore a fixed amount of output nodes?
"
"Low rank filter vs. full rank filter - what is the ""rank""",2,1,False,False,False,learnmachinelearning,1508795308,True,"I understand the concept of median filtering.  Still, I'm having trouble understanding the ""rank"" in rank filtering.  When someone is describing a low-rank filter vs. a full rank filter, what determines the  rank of a filter?  Thanks. "
UI Personalization With AI: Where To Start,4,0,False,False,False,learnmachinelearning,1508801144,True,"Hey there, 

Im trying to come up with a good place to start for a pretty simple idea, and I am hoping some of you good folks might be able to push me in the right direction, or simply give me advice. 

I am working with a simple menu, used by lots of different users. As of right now the menu is static, showing the items in the same order for each user. However, I think it would be pretty cool to be able to personalize the menu, moving the most used items for a specific user to the top. 

I think this would be a pretty common use case of machine learning. One would think there would be pre-made libraries for this sort of task. As of right now, I am just unsure where to start. If you have any resources, or advice, it would be greatly appreciated. 

Thank you, "
Programming Language?,6,2,False,False,False,learnmachinelearning,1508807694,True,"So I'll be starting to attempt to learn machine learning/deep learning; I have an idea of where to start learning but I'm just wondering what programming language would be commonly used (I know the BASICS of Python, C, a little more in Java, and vaguely know Lua. What programming language would be the ""best"" choice in most cases?"
How/Where to start learning ML?,12,6,False,False,False,learnmachinelearning,1508823695,True,"I am familiar with python and doing graduation in Information Technology, i want to get into ML. How should i start learning, what are the prerequisites and where should i learn from."
What is the best way to work on matrix in Python?,7,0,False,False,False,learnmachinelearning,1508831609,True,"I'm doing machine learning with python these days, and before that I use Matlab. Methods to deal with data is different between python and matlab. 

Python has several datatype: dataframe, list, array... and different characteristics of them. 

While I read from csv file, I get a dataframe, and I when I want to get a value, I should call:

dataframe.iloc[row, column]

And I have faced some problem, while I call dataframe.iloc[1,:] from an m*n dataframe, I thought it should return a dataframe with shape:

(1,n)

 but it rather return a strange shape :

(n,)

While I can't get what is this. I wonder if dataframe is not preferred to work on matrix, what is the usual way to deal with matrix in python that everyone usually do?"
"A simple, straight-forward jupyter notebook implementation of CycleGAN using PyTorch",0,1,False,False,False,learnmachinelearning,1508831880,False,[deleted]
"A simple, straightforward jupyter notebook implementation of CycleGAN using PyTorch",1,17,False,False,False,learnmachinelearning,1508832495,True,"My implementation of [CycleGAN] (https://arxiv.org/abs/1703.10593) after I found the code on their [project page] (https://junyanz.github.io/CycleGAN/) too hard to understand. 

I've tried to make this beginner-friendly and easy to understand (but you're still gonna have to read the paper!). 

Code: https://github.com/prateekmalhotra/CycleGAN-straightforward

Feel free to contribute, post your results, and ask any doubts :)"
Which is better.?,2,2,False,False,False,learnmachinelearning,1508851968,True,"Hey, I am having past data for a list of customers who are actively replied/picked up my call like call received time/ mail opened or clicked time. 

From this data, I want to predict future best times like best time to mail/call today, tomorrow, like every day.

But I am confused like a hell to proceed with this thing. 
1)Find exponentially weighted moving average average 
2)Use clustering or KNN 
(or) any other ways I can solve this thing.?"
How to install older version of skimage (pyhton)?,0,1,False,False,False,learnmachinelearning,1508853162,True,[deleted]
Unstructured Data for machine learning algorithm,1,5,False,False,False,learnmachinelearning,1508859149,True,"**Overview of the problem:**

So I am working for a supply chain management company and we have a lot of data in form of PDF's with different formats from different suppliers. We need this data into our database, for this we have people manually entering data into the database and also we need to classify if we can take the risk of dealing with a particular vendor in future (Kind of risk analysis). Recently we had a proposal to prove that this thing can be done partially (50-70%) with help of machine learning so that it can be implemented in future.

**About the data:**

All the data is in pdf's and I believe it can be extracted using any number of python tools. But the real problem is the data itself.

*Extraction of data can not be hard coded as there are different formats for different vendors.

*There are different names for the things that mean the same thing (Example: a vendor is same as a provider or supplier(at least in our case it is))

*The algorithm should be able to extract as well as classify a few things.

**Question:**

Is there a specific way in which it can be proved that this it conceptually possible and that this idea can be further explored?
"
Is there any opensource implementation of Mask RCNN with pretrained model?,0,2,False,False,False,learnmachinelearning,1508870870,True,"Hi,

I know that there are a ton of object detection pretrained models and implementation (yolo,ssd,frcnn). 
Is there any open implementation of mask rcnn or something similar, with weights? I was not able to find anything."
Setting Up an NLP Problem: Identifying which Features of Certain Articles get Shared the Most,0,1,False,False,False,learnmachinelearning,1508871505,True,"Hey guys,

Wondered about a likely simple NLP problem - a friend is a journalist, and I'd like to explore possible reasons for which articles get the most shares and why.

Right now I have access to:
* Number of shares across different social media platforms
* # views/comments
* Article Headline
* Article Text

I've worked on an NLP problem before, but it was more along the lines of sentiment classification rather than feature identification.

Where do I start? Would this be an unsupervised problem?
"
Help with RL code?,0,1,False,False,False,learnmachinelearning,1508871596,True,"Hello everyone!
I'm trying to put together a reinforcement learning algorithm. Currently the token problem is pathfinding in a simple maze (actually just a random walk before I expand the scope a bit). I wrote my code, and it runs and does... SOMETHING. I'm not sure what's wrong with it, but I told it to run 10 million episodes on a very simple problem and the answers are very much less than satisfactory.

Can somebody help me figure out what's wrong with my code? I think I'm missing some key part of the algorithm here...

Here is a [pastebin link](https://pastebin.com/MMF9rsak) to the code."
Spotify’s Discover Weekly: How machine learning finds your new music,0,1,False,False,False,learnmachinelearning,1508872887,False, 
tensorflow's `Experiment` interface,0,1,False,False,False,learnmachinelearning,1508873603,True,[deleted]
Visualising Activation Functions in Neural Networks,0,1,False,False,False,learnmachinelearning,1508884120,False,[deleted]
Model instantly overtrains,12,3,False,False,False,learnmachinelearning,1508887483,True,"I have a small amount of training data that I've set aside as validation (10%). From the very first epoch I can see that the validation set accuracy only gets worse.

I don't really know what to do in this situation. I'd expect it to get better for at least a few epochs before getting worse, but it instantly gets worse.

Any ideas?"
What are the output dimensions and number of parameters for a fully connected layer in a convolutional neural network?,1,0,False,False,False,learnmachinelearning,1508904099,True,[deleted]
Does WEKA contain tools for multiple kernel in SVM?,0,1,False,False,False,learnmachinelearning,1508905702,True,Is there any other machine learning tool or package where I can implement multiple kernel in SVM like [ in this link](https://hal.archives-ouvertes.fr/cel-01003007/file/Lecture9_Multi_Kernel_SVM.pdf) without having to code the entire kernel anew?
How much programming knowledge do i need to do Andrew Ngs ML course.,12,8,False,False,False,learnmachinelearning,1508911620,True,"I want to do Andrew ng's course in machine learning in my uni break. AI and deep learning really interest me. Im just curious how much programming knowledge do i need to do it, or can i learn it on the course. I plan on learning Python because i understand it's much more useful in the ML industry. But can i teach myself as i go, or should i learn programming first?
I know the course is done in Matlab, but i would prefer to do it in Python. Anyone done anything similar? would love your thoughts. FYI: I am a 3rd year Civil Engineering student, so have a fairly good maths background ie; Linera Algebra, Calculus...etc."
TWIL (This Week I Learned) - Share something new that you have learned this week!,1,5,False,False,False,learnmachinelearning,1508915114,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
Want to train AI w. simulated physics. Tools?,3,4,False,False,False,learnmachinelearning,1508917625,True,"I'm 3d modeller and animator, so not a programmer. Are there end-user friendly tools for improving simulated movement over many generations? Sort of like the Google walking robot..

If there suitable parts like ODE for physics modeling, that'd be also good to know.. How can you make something like ODE generational. Cab you rent processing for that? I can hire someone to put them together, just would like some pointers towards what's out there as far as components go. "
Machine Learning mathematics for my highschool thesis(?)?,6,3,False,False,False,learnmachinelearning,1508925933,True,"Hello,

I'm a 16 year old highschool student and I've been intrested in machinelearning for a while. I've done some projects involving machinelearning in the past and I have to write a ""thesis"" in the last two years of highschool, we have to choose a subject and do research related to that subject. So I thought I'd choose maths and research the math related to machinelearning. 

I'm not where I should start though, and if I should try it at all. So I thought I'd ask you guys for suggestions and maybe a point in the right direction(?).

Thanks for reading.
 
EDIT: I've already read [the highschoolers](https://www.reddit.com/r/learnmachinelearning/wiki/getting_into_ml_high_schoolers_guide) guide on the wiki"
Looking for a content transfer.,0,3,False,False,False,learnmachinelearning,1508933694,True,"There are many style transfer or image analogy methods but these transfers are not what I actually need. I am looking for a content transfer. For example, there is a tree in image A and a lake in image B, image A and B are in same style. Then I need a image C with a tree and a lake. I know some image mapping methods can do that, to some extent, but these mapping methods need a trim map and I need to put the tree or the lake mannually... Can the ""composition"" ability be learnt by NN or is there any reseachs?"
"Watching Andrew Ng course, he mentioned tying adding polynomial features when troubleshooting, but wouldn't a NN already take into account any polynomial relationships among the features?",4,9,False,False,False,learnmachinelearning,1508942803,True, 
Comparison of neuroevolution methods,0,3,False,False,False,learnmachinelearning,1508942839,True,"I have been looking into neuroevolution and I would like to try it for my next project, however there are many different libraries and methods I am having problems with finding one that might suit my needs. Can anyone point me to some literature that compares different neuroevolution methods in terms of theirs advantages/disatvatages/usual applications. I am looking to predict/extract information from time series."
Poisson distribution - Part II,0,2,False,False,False,learnmachinelearning,1508944895,False, 
Is Machine Learning for me?,11,16,False,False,False,learnmachinelearning,1508945528,True,"I'm sorry if this is not an appropriate question for the subreddit but I figure this is the best place to ask as a newbie.

I'm in my undergrad in Computer Science (Software Development) and love coding and OOP. Software Engineering has been my goal for a while, the thought is thrilling. I'm also a Math major and love numbers and working with them. 

Recently I've watched many videos on Machine Learning and it seems so fucking cool. However, the programming seems very limited. I have seen things on Machine Learning Engineering which seems to be a sort of hybrid.

If someone loves coding, is Machine Learning getting away from that field? I like writing algorithms, but it seems most of the primarily used algorithms are already made. Is Machine Learning Engineering a specialty I should look into?

I'm simply overwhelmed by how awesome I think ML is, but I don't want to give up programming/Software Engineering. I don't want to just work with data as a Data Scientist but I think the things they come up with at the same time are super cool....

Any advice?"
Visualising Activation Functions in Neural Networks,0,1,False,False,False,learnmachinelearning,1508947028,False,[deleted]
Help with seq2seq RNN,6,8,False,False,False,learnmachinelearning,1508948137,True,"Hi friends,

I've got a dataset of news articles and keyword combinations. 

I've been trying to use the PyTorch seq2seq RNN tutorial [here](https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation.ipynb) but I think my input and output vectors are too large (100x1, whereas the tutorial uses 10x1)

I've seen people develop chatbots with Q and A corpuses, is it too much to do the same with keywords and short news articles?

Any help would be so wonderful!"
Need help with quasi euclidean metric,6,3,False,False,False,learnmachinelearning,1508950426,True,"I'm doing a project on similarity measure and i'm trying to implement quasi-euclidean metric to calculate difference b/w images pixel-by-pixel. Now i agree this might not be the best way out there but i'm just experimenting. 
The problem is, i can't figure out how to exactly write it's code.
Like i understand the distance function but i can't figure out how to check the condition abs(x1 - x2) &gt; abs(y1 -y2) for every pixel.
It would be immensely helpful if someone could write a part of the function or guide me to some resource that has stuff related to this. "
Visualising Activation Functions in Neural Networks,2,4,False,False,False,learnmachinelearning,1508958392,False, 
Total Beginner - How do I put data into a format that the various sklearn models can understand?,5,3,False,False,False,learnmachinelearning,1508965191,True,"I'm struggling with getting started.

How do I create and format features for a predictive model?

I took the Udacity ML course and I can work through using the various classifiers, but I have no idea how to prepare the data before it can be used. This was already done for us.

***
Let's say I want to use Reddit posts to try to identify spam. I have a dataset of ~200 accounts that have been labeled as spam. 

I know what features to look for, and I can spot a spam account by eye, but I have no idea how to convert that into a format usable for ML.

Example features:

1. Account age - an integer
2. Subreddits they post in. - list of dicts? as {subname:count}
3. Account name - an integer corresponding to which regex pattern it matches.

***
Looking at the sklean docs, I need X and y. 

X is ` {array-like, sparse matrix}, shape (n_samples, n_features)`

y is `y : array-like, shape (n_samples,)`

X will be my features and y will be my labels

So if I understand this correctly, X needs to be a 2D array where each row is a list of features that belong to (in this case) a specific Reddit account.

    X = [[f1, f2, f3,...], [f1, f2, f3,...],...]
    y = [a1, a2, a3,...]

So how would I convert the example features above into this format?

I THINK this is the goal:

X^^1 = `[account_age, [{sub_name1:count},{sub_name2:count}], regex_num, ...]`

but don't they have to be converted into floats somehow?

Am I on the right track at least?"
"AlphaGo Zero’s win, what it means",0,1,False,False,False,learnmachinelearning,1508972084,False, 
Using NLP to clean data,10,5,False,False,False,learnmachinelearning,1508984611,True,"I've got some data where one of the columns is the name of an office represented as a text string. Sometimes, due to inconsistencies in naming convention, the same office name can be entered in different ways. i.e. Program Evaluation vs. Prog. Eval.

I'd like to be able to automatically identify this and fix it. I've thought about doing some NLP like word2vec or LDA models to group offices that are very similar, but there are so many offices that have similar names that are different this doesn't appear to be a viable option. 

I've also thought about doing a more rules-based fix. This, at the moment, seems more do-able. If the office name has not been seen before I could calculate the distance of the office name to all the other office names using a metric like [Levenshtein distance](https://en.wikipedia.org/wiki/Levenshtein_distance) and see if there are any it's very similar to. Then I could flag this for review by a human. 

Those are the two approaches I'm considering, but only one of them seems viable at the moment. I'm just wondering if anyone has had this problem before and what they did to solve it? "
RL - Learning From Humans,1,4,False,False,False,learnmachinelearning,1509019218,True,"In a reinforcement learning environment, such as creating an algorithm to play Mario Kart, does it learn differently if I first show it how to play the game, as compared to having it learn its own? Of course I know learning from a human expert causes the algorithm to learn much faster, but my question is this: If you show it a perfect game of Mario Kart, does it learn differently than if it learns to play a perfect game on its own? Like does it learn to generalize better (for a more robust algorithm) when it learns on its own, or does it not matter how it learns to win?
"
Introducing Amazon EC2 P3 Instances,2,11,False,False,False,learnmachinelearning,1509020214,False, 
Machine Learning Algorithms: Which One to Choose for Your Problem,2,38,False,False,False,learnmachinelearning,1509025708,False, 
Another request for NLP algorithm suggestions,0,1,False,False,False,learnmachinelearning,1509038907,True,"Hey guys, 

This is my second request for suggestions for algorithms for a task that we are currently considering. My first request was [here](https://www.reddit.com/r/learnmachinelearning/comments/789y27/looking_for_recommendations_for_an_nlp_approach/). Thanks so much for the first round of suggestions! It has been really fascinating and helpful. You guys are an invaluable resource.


I think that I can detail the task a bit more accurately now, so I'm wondering if there are other algorithms that I should be looking at, and if the original suggestions are still relevant.

* We have a list of various items: x1, x2, ... xN
* For each item we have a list of corresponding documents. For example, for item 1 we might have M documents: d1_1, d1_2, ... , d1_M

This is where it gets a bit tricky. We can make a very rough estimate about how much each document actually describes what the corresponding item is. Some documents will be short paragraphs that specifically describe what the item is, others will only discuss some aspect or feature of the item. Some of the documents may only mention the item tangentially. But we do have a very rough estimate about how much each document focuses on the item, and we can toss out the documents that aren't particularly useful beforehand.

Here's the task: **Given one of the items, we want to find other items in the list that are similar, based on the corresponding documents.**


For example, let's say that we have three items (this is a made up example): 

* x1: Honda Accord
* x2: Ford Mustang
* x3: McDonald's Big Mac

obviously we can see that x1 and x2 are similar and x3 is not related. For each item we have a series of documents. 

For example (once again made up) let's say:

* d1_1: a textual description of the Honda Accord
* d1_2: a technical description of the Honda Accord
* d1_3: a consumer review of the Honda Accord
* ...
* d2_1: a textual description of the Ford Mustang
* ...
* d3_2: a news article about the Big Mac

**Let's say this specific task is to find items that are similar to item 1. We would like the algorithm to discover that item 2 is similar, based on these available documents.**

In our actual task, we have tens of thousands of items and many times more documents. I know this is a pretty complicated task but we'd like to look into seeing if this is possible and if so, which algorithms we should be looking at.

Once again, thank you all so much!!!"
Channels first with Keras?,1,2,False,False,False,learnmachinelearning,1509058541,True,"EDIT: figured it out; needed to pass `data_format='channels_first'` with each conv layer

I'm trying to use my keras model with a keras-to-caffe conversion script; Whenever I try to run the script, it loads my model and then gives me an error that says ""only channels-first is supported"". I'm feeding my model images with the shape (24,24,3) - but it wants (3,24,24).

Whenever I try to train my model on images of the shape (3,24,24), i get this error (it thinks im feeding it a 3x24 image with 24 channels, i believe);

    ValueError: Negative dimension size caused by subtracting 3 from 1 for 'conv2d_2/convolution' (op: 'Conv2D') with input shapes: [?,1,22,32], [3,3,32,64].

How can i feed my keras model channels-first images?

(Model code in case anyone needs it: i'm just doing a simple classification problem)


    input_1 = Input(shape=input_shape) # input shape is 24,24,3 - needs to be 3,24,24


    conv_1 = Conv2D(32, kernel_size=(3, 3),
                 activation='relu',
                 input_shape=input_shape)(input_1)

    conv_2 = Conv2D(64, (3, 3), activation='relu')(conv_1)

    pool_1 = MaxPooling2D(pool_size=(2, 2))(conv_2)
    
    drop_1 = Dropout(0.25)(pool_1)
    
    flatten_1 = Flatten()(drop_1)
    
    dense_1 = Dense(128, activation='relu')(flatten_1)
    
    drop_2 = Dropout(0.5)(dense_1)
    
    dense_2 = Dense(128, activation='relu')(drop_2)
    
    drop_3 = Dropout(0.5)(dense_2)
    
    dense_3 = Dense(num_classes, activation='softmax')(drop_3)
    
    model = Model(inputs=input_1, outputs=dense_3)
    
    model.compile(loss=keras.losses.categorical_crossentropy,
                  optimizer=keras.optimizers.Adadelta(),
                  metrics=['accuracy'])
    
    model.fit(x_train, y_train,
              batch_size=batch_size,
              epochs=epochs,
              validation_data=(x_test, y_test),
              verbose=1)

"
Need help improving the accuracy of CNN. In Keras and TensorFlow.,4,3,False,False,False,learnmachinelearning,1509080097,True,"CNN link : https://github.com/magician03/signature-recognition-deep-learning/blob/master/main-1.py

I need help improving the accuracy of my deep learning CNN model. I am not sure what to do and how to do this. Images are of originally 128*64 and I'm resizing them to 256*128. Currently the accuracy is 1-2% . This is 8 an layer CNN model."
"Gensim how to get context, target data?",3,3,False,False,False,learnmachinelearning,1509082800,True,"Is there any way to get the context words, target word data used by gensim (before it is used in word2vec)?  I want this data and gensim seems to be very fast at generating it.

For example: The brown fox ran away -&gt; ((The, brown, ran, away), fox)"
Weekly Show-off!,1,1,False,False,False,learnmachinelearning,1509087918,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
Low accuracy in classifying MNIST dataset using Nearest Neighbour,5,3,False,False,False,learnmachinelearning,1509089500,True,"Hi there, as title I tried to classify the MNIST dataset using the NN algorithm with Euclidean distance. I have not done anything to the data. I am using the whole training set which has 60000 data points. 

The accuracy on the test set (10000 data points) is surprisingly low, only around 27%. Is this something to be expected or have I done something wrong? 

Thanks!"
After completing available Deep Learning Specialization courses - why do I think it's unique,2,12,False,False,False,learnmachinelearning,1509093816,False, 
Single class image classifier?,4,1,False,False,False,learnmachinelearning,1509102352,True,"First of all: I'm new to Machine Learning, I'm still following courses so if I say something obviously stupid pardon me. Also english is not my main language.

I want to build an Image Classifier that's able to recognize a single class. I used this repo to fine-tune a bunch of ConvNets (VGG16, DenseNet and ResNet).
For each architecture I downloaded its ImageNet pretrained weights, trained it on 12000 CIFAR-100 images + about 200 images belonging to the class I'm interested in and validated on another 400 images, for a total of 101 classes.

The problem is that all models overfit quickly and the validation set only reaches about 73%.
Is there any way I can get better results? Is it wrong to do this kind of fine-tuning in the first place?

Thank you."
"Hi /LML, I am a high-school student with no knowledge of programming and the like. What can I actually be able to learn and apply from /LML as a hobby, at least until I get into a CompSci degree program",6,1,False,False,False,learnmachinelearning,1509107838,True, 
Best Machine Learning resources voted by the lecture hunt community,0,1,False,False,False,learnmachinelearning,1509114261,False, 
Looking for ideas on data augmentation based on GANs,2,0,False,False,False,learnmachinelearning,1509120031,True,"Hi,

I'm working on a project that involves tabular data. As always, I need more data, so I'd like to generate more of it.

I know some people use white noise, but I'd like something smarter. More precisely, I think a *good* generated row should fool someone who's trying to detect what is real data from what is generated data.

I beleive that is what GANs do, with the idea of a generator and a discriminator.

**Are there reference examples / papers of the use of GANs for data augmentation on tabular data (not image) that I should read plz ?**

Thanks

PS : I'm opened to criticism and ideas, feel free to suggest other approaches."
Need to predict parent child relations. 'corgi' should predict 'dog',1,1,False,False,False,learnmachinelearning,1509123330,True,"For example, let 'deep learning' be the term I want to predict that the parent is 'machine learning' 

 2nd example, let 'corgi' be the term, I want to predict that the parent is 'dog'  

how should I go about achieving this?"
Can a layman benefit from learning machine learning?,9,14,False,False,False,learnmachinelearning,1509128851,True,"So, I am a beginner. In fact, I am not even a beginner, as I haven't even started yet. I hope this is a proper place to ask this question.

A little that I know about AI (which is very little), makes me interested to know more. At the same time, I would like to be able to use what I learned. For example, I learned the most basic things about programming and it was very useful to me.

Programming, though, it seems most people can learn from scratch. Maybe not well, but at least enough to be a useful skill.

Does the same apply for machine learning? Can you learn it from scratch? Since I don't intend to formally study machine learning or related fields, does it make sense to even start learning it?

My first impression is that you need a background in either programming, AI, mathematics,... or you won't understand it.

So, can a layman realistically learn enough to understand at least basics and enough so that he could use his knowledge?"
"I'm writing a blog post series to demystify the ML production ecosystem, here's part 1 of 3: Build!",0,26,False,False,False,learnmachinelearning,1509153215,False, 
Does a variable-length time series LSTM/GRU learn its own length implicitly?,0,1,False,False,False,learnmachinelearning,1509160238,True,[deleted]
Does a variable-length LSTM/GRU learn each sequence's length implicitly?,5,4,False,False,False,learnmachinelearning,1509162660,True,"Or should I include it as an explicit feature?

Thanks"
It ought to be a rule on this subreddit to not post a question without answering a different one.,6,0,False,False,False,learnmachinelearning,1509163296,True,"No one's on these boards,- it's a blooming field, and people with expertise have a million different things to do.  There's a million valid questions and practically no answers.  So please do answer something when you post here.  Because if we don't help each other out, who will?"
"Weekly Status Check Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",0,1,False,False,False,learnmachinelearning,1509174312,True,"Let's have a  meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
My First Month as a Junior Data-Scientist,8,30,False,False,False,learnmachinelearning,1509203039,False, 
FizzBuzz interview,2,4,False,False,False,learnmachinelearning,1509203120,True,[deleted]
Trying to create my own ML mind map. Hoping some more experienced ML'ers will fact check me? [xpost /r/Machinelearning],0,1,False,False,False,learnmachinelearning,1509220209,True,"I'm not really happy with the mind maps I've been able to find on Google, most of them are algorithm based.  I want to make a good one that is problem/solution domain based.  Do I have this right for my top level nodes?  Here is where I am headed so far: https://imgur.com/gallery/CugcS

My questions/doubts about what I have so far are:

&amp;nbsp;

- Is my starting point below generally correct?  e.g. no high level subclass is missing, and everything presented as a subclass deserves to be here?

- is Hybrid learning always just a combination of supervised and unsupervised?  Or, are there real examples of other hybrid models (e.g. 'reinforcement' and 'supervised', etc.).  I know _theoretically_ we can combine any methods...I'm looking for what's real/applied/demonstrable today.

- does Reinforcement learning belong at this high level, or is it actually a subset of one of the others (or one I've omitted)?  

&amp;nbsp;

1. Machine Learning

    1.1 Supervised (uses labelled data to train and validate)

    1.2 Unsupervised (uses unlabeled data, or ignores labels if they are present)

    1.3 Semi-supervised (uses partially labelled (mostly unlabeled) data)

    1.4 Hybrid (combines a supervised method and an unsupervised method)

    1.5 Reinforcement Learning (uses data from the environment)  

&amp;nbsp;

Thank you!"
Neural network overfitting from the beginning of training.,4,2,False,False,False,learnmachinelearning,1509222181,True,"I'm training a convolutional network on a task similar to video classification and I'm seeing a gap between the training and the validation error that starts at 10% after a few thousand iterations and progressively increases until it's about 30% (i.e. the difference between training and validation error is 30% and the validation error is higher).

I've already rigorously analyzed my data preprocessing and loading pipeline and came to the conclusion that the training and validation data are processed in the same way.

I've always thought that overfitting happens towards the end of the training procedure, that's why we use early stopping. However, my model is overfitting from the very beginning. Does anyone have a similar experience?"
Best free online courses for NLP / general ML?,7,2,False,False,False,learnmachinelearning,1509222441,True,I'm being thrown head first into the deep end at work and want to get up to scratch with NLP fast. General machine learning wouldn't hurt. Any recommended courses? Python Data Science tools (i.e. numpy etc.) would be useful too.
Classifying Hand Tools - Why does Keras think my hand is a hammer? (details in comments),2,2,False,False,False,learnmachinelearning,1509228023,False, 
Please help to understand this part of NLP research paper.,0,1,False,False,False,learnmachinelearning,1509233971,True,"I've been reading a research paper related to Pun Detection task in NLP, and there are some parts that I don't understand. (I'm a noob).

LINK: http://www.aclweb.org/anthology/S17-2011 

First in the 3. Heterographic Puns section, I don't understand what it means by separating the context into n-grams and pair them. Is it something like:

('I', 'am', 'a', 'boy') -&gt; ('I', 'am', 'a'), ('am', 'a', 'boy')

And I also don't get the following sentence that says:

For each of these original n-grams, the corpus is
searched for n-grams that are at most one word
different.

How does this actually work?

Second, I don't actually get how the ratio and the score are computed. Don't know what to put in for ||w|| and why we need to subtract 1 / ratio^n from the frequency different.

It would be great if anyone could help me understand this.

Thanks

"
VC Dimension Help,1,1,False,False,False,learnmachinelearning,1509240874,True,[deleted]
Can I make a machine learning fighting game AI in 2 months for a Science Fair project?,3,1,False,False,False,learnmachinelearning,1509245805,True,"I'm in G9 and I have 2 months to make a Science Fair project. I would like to create a simple machine learning AI for an open-source multiplayer fighting game, or (If it isn't too difficult to code AI for non-open source programs) Super Smash Bros. I know basic Python, Java, and C++. Is it possible for me to do this project, and what is the best way to learn how to do it?"
How researchers validate output of GAN,1,2,False,False,False,learnmachinelearning,1509252578,True,I was watching this [video](https://www.youtube.com/watch?v=XOxxPcy5Gr4). The images generated by the GAN are pretty good but how do we know and validate images generated by GAN are of **new and unseen** images and not generated by an overfitted neural network.
Standard way to measure similarity b/w 2 images?,6,3,False,False,False,learnmachinelearning,1509259587,True,Is there an industry standard way to measure similarity between 2 given images whose code is available or can be easily implemented in python? I want to use it's similarity measure as a benchmark for a project i'm working on. 
Learn PyTorch with no Deep Learning background with Sung Kim's PyTorchZeroToAll,6,40,False,False,False,learnmachinelearning,1509264914,False, 
Why cant we calculate the derivative of a classifier function in respect to its hyperparameters?,0,1,False,False,False,learnmachinelearning,1509273878,True,"Hey there,

hyperparameter optimization is treated as derivative free optimization, right? So I would like to know what makes classifiers (kNearestNeighbors, DecisionTree, SVM) non differentiable. I guess, I'm lacking some basic understanding of how these classifiers work and I'm not capable solving my problem by googling it.


Thanks in advance!
"
Trying to understand better ML in order to write my own library for a project,0,1,False,False,False,learnmachinelearning,1509281791,True,[deleted]
How to not end up in a local minimum?,3,6,False,False,False,learnmachinelearning,1509282441,True,"Hello! First post on this sub, I'm trying to understand better ML in order to write my own library for a high school project, I've read [this book](https://www.amazon.com/Make-Your-Own-Neural-Network-ebook/dp/B01EER4Z4G) and watched some tutorials online but I still have one doubt that won't go away:   
  

If the cost functon has many minima and looks something like [this](https://sebastianraschka.com/images/faq/visual-backpropagation/nonconvex-cost.png), how can I train my neural network so that the cost function reaches the global minimum and not a local minimum?

The book states:

&gt; To avoid ending up in the wrong function minimum, we train neural networks several times starting from different points to ensure we don't always end up in the wrong minimum. This is done by choosing different starting weights.

But later in the book, when a real neural network is built, I don't see this being applied, random weights are chosen only once and are trained against a set of data multiple times (5 epochs), but how can I make sure I'm not ending up in a wrong minimum?

[Code given by the book](https://gist.github.com/hellix08/0ac2dcfcd2f54b7217e283e1519f910b)"
Gridsearch CV and ridgecv in sklearn,1,1,False,False,False,learnmachinelearning,1509303969,True,"Hey everyone,

I am trying to solve a regression problem and am using svr and Ridge regression to compare the results. I wanted to clarify if the ridgecv function in sklearn is the same as calling grid search and running Ridge through that. Thanks "
Can you recommend any methods for object segmentation in images?,2,2,False,False,False,learnmachinelearning,1509306886,True,"I am looking for models, which have opensource implementation and also available models. Want to train it alter on new categories.
I heard about some, such as Mask-RCNN, Unet and fully convolutional, but don't know how mature these are, and how easy it is to work with them.
Any coment would be helpful!"
Preprocessing medically coded data into numeric data for computation,3,1,False,False,False,learnmachinelearning,1509309176,True,"I'm currently working on a project to diagnose medical diseases from free-text clinical notes. I've done NLP on medical text and I extract clinically relevant terms and identify their coded term in a medical dictionary. For example, the term ""Angina"" gives me a code of ""C0040861"".

What I end up with is a massive list of codes for each patient. I'm wanting to classify these lists into a type of disease which I have some labelled data for, however, I'm having difficulties putting these codes into a numerical format to use in a simple ML algorithm (probably a simple backpropagation network as a proof of concept).

If anyone has techniques/tips, or even algorithms that work on this type of problem would be greatly appreciated!"
How could one pursue MS/PhD in machine learning after having undergraduate degree in engineering but not in CS?,5,2,False,False,False,learnmachinelearning,1509318073,True,"I have undergraduate degree in mining engineering from India. But I am interested into machine learning and since my sophomore year I am participating in data science competitions and have done an internship and my final year project in ml topics. And I want to pursue either ms or PhD (I don't know whether ms or PhD ) in ml. I have completed my graduation in 2017 and currently working in a metal mining company. I need suggestions on the steps (other than GRE and TOEFL) that I should follow so that I must be ready to apply for MS or PhD in 6-8 months. Also I need suggestions on whether I should target for US, Canada, Europe or any other country since I want to do MS/PhD affordably."
AWS Spot Instance Sync,1,1,False,False,False,learnmachinelearning,1509320141,True,"Using Keras on a spot instance, I would like to automatically transfer any models saved  in my instance and transferred to my local drive or S3. 

Not sure the easiest way to do this. The motivation for this is sometimes my instance is killed for my bid price being too low."
Just came across this awesome website and wanted to share it,1,36,False,False,False,learnmachinelearning,1509322842,False, 
Loan Default Modeling and Machine Learning,0,1,False,False,False,learnmachinelearning,1509331340,True,"Hello everyone. I found this site that runs through a ""hello world"" exercise for machine learning in R. After reading through, the biggest take away is that you just throw in the data, and the various methods will take care of generating a model, i.e., find the best predictors for loan default in my case. 

Is it really that simple? So far what I've been doing without machine learning is computing glm() and just going through trial and error with variables to get the best model. 

Here is the link I am referring to. https://machinelearningmastery.com/machine-learning-in-r-step-by-step/"
Proving a hypothesis space is PAC learnable,0,2,False,False,False,learnmachinelearning,1509337136,True,[deleted]
Any suggestions for resources discussing how to incorporate error bars on data?,0,1,False,False,False,learnmachinelearning,1509337879,True,"I am considering applying Random Forest to a problem with multiple parameters where each data point has (possibly large) non-uniform error bars in each dimension. One approach was to simply neglect the error bars, although I'm finding that including uncertainties with the data will be an important step for my analysis. Thus I was wondering if there were any texts/tutorials with regards to handling errors for Random Forests (and even other machine learning algorithms). "
How impressive/difficult is building an algorithm that can tell whether a cancer cell is malignant or benign based on numerical data?,1,1,False,False,False,learnmachinelearning,1509345473,True,Using python + either tensorflow/sklearn and a csv of raw data as the data?
Pytorch implementation of CNN gradient visualization &amp; image generation techniques,1,7,False,False,False,learnmachinelearning,1509348587,False, 
"In very noisy data, the MAE of my estimation improves substantially when I divide it by 10.",2,1,False,False,False,learnmachinelearning,1509361851,True,"I have an extremely noisy dataset, and I try to minimize the MAE. Apparently, when my linear regression makes its prediction - it has something like -1000 MAE (when compared to the MAE of an all-zero vector), and as I divide the estimation of every observation by some factor, it improves dramatically:


* factor 1.5 |  mae: -458.303432094
* factor 2 | mae: -211.376918945
* factor 3 | mae: -50.0865186752
* factor 4 | mae: -2.34636554994
* factor 5 | mae: 15.2679777338
* factor 7 | mae: 25.0762924364
* factor 10 | mae: 25.0904607219
* factor 13 | mae: 22.3588382822
* factor 15 | mae: 20.5381352161
* factor 20 | mae: 16.7937150084

*Note: the MAE is sometime negative because it is compared to the MAE of an all-zero vector. So -1000 means that the MAE of an all-zero vector is better than the algorithm's prediction by a 1000*

Why is it that my linear regression guesses numbers that are so big, such that they harm the MAE score so significantly? Is there any good method to deal with that?"
Learning ML by working together,13,8,False,False,False,learnmachinelearning,1509373161,True,"Hey,
I am fairly new to Machine Learning and find it hard to dive into all these different ML algorithms and Neural Network structures and I can imagine that some of you feel the same.. So I thought we could start a learning group to gain more knowledge with less time researching different topics. If everyone  in this group researches a topic and prepares a presentation, one doesn't only teaches the others, but also reinforces the stuff he has learned, by teaching the others. (a win-win situation!!).
If anyone is interested, tell me in the comments."
Can regression tree really be used for time series forecasting?,0,1,False,False,False,learnmachinelearning,1509379070,True,"What a regression tree does is effectively subdividing the space to generate a stepwise line. Why would it be useful for time series forecasting? It does not take into account the seasonality or trend. Therefore it would simply output the same value for the next time step as the current time step. For example, if there are 1000 time steps in the training data, isn't the effort of fitting the previous 990 time steps a total waste since only the most recent time steps relevant for the prediction?

Could someone help me clear my doubt? "
Recommendation engine between two different data sets?,0,1,False,False,False,learnmachinelearning,1509381697,True,"This might be a stupid question, but how would you design a recommendation engine between two different pieces of structured data? For example:

User &lt;attribute1, attribute2, attribute3&gt;,
Movie &lt;attribute4, attribute5, attribute6&gt;,
Match &lt;0 or 1&gt;

If I had a data structure like so:

User, Movie, Match

User, Movie, Match

I would like to feed this model a User and Movie, and it predicts a likelihood of a match (0-1). Does such a model exist or could I extract it two models?"
I would like some feedback on how to use my time,2,3,False,False,False,learnmachinelearning,1509386940,True,"I'm a Third year CS student working on my BS, and working full time. So with that being said, I don't have a lot of free time. 

I've only taken calc 1, and will be doing 2, 3, Probability / Statistics, Linear Algebra by the time I graduate.

With my free time, should I work on studying Math, or firing up some simple projects and learning Libraries and Enviotments?

Employability isn't an issue I already work for a cool SOftware Company where I can start working on projects when I am ready I work.

I'm kind of leaning to really mastering Calculus then Stats since I am picking up a lot of my programming skills at work. 

If I work on projects Ill learn more about python and be able to jump into coursework a little easier down the line and have a higher level understanding of the concepts

I plan on doing a Masters right when I am done with my BS. Maybe a PhD if I can find some research opportunity as an undergrad."
SKLearn's predict_proba with Naive Bayes - How can I modify the output to be more easily understood?,1,2,False,False,False,learnmachinelearning,1509387890,True,"Hello,

I recently completed a small project where I got to toy around with SKLearn's Multinomial Naive Bayes classifier in Python.

I had to present my findings and during the presentation I was asked if it were possible to see how confident the classifier was when making it's predictions. I was aware of the predict_proba() function but I had not actually used it.

So, now I'm taking a look and the probabilities it returns are extremely small (as I would expect). It would be much better if I could some how transform these probabilities onto a scale that ranges from 0 to 100%. 

Any ideas how I would go about this?

"
The State of ML and DS 2017 - Cool overview by Kaggle,0,1,False,False,False,learnmachinelearning,1509390674,False,[deleted]
The State of ML and Data Science 2017 - interesting overview from Kaggle,1,2,False,False,False,learnmachinelearning,1509390711,False, 
What are websites that teach AI from first principles in an interactive manner?,0,1,False,False,False,learnmachinelearning,1509415451,True,[deleted]
What are some websites that teach AI algorithms in an interactive manner?,5,28,False,False,False,learnmachinelearning,1509415621,True,"My goal is to build my foundations from the ground up, starting with the low level algorithms (mini-max, alpha-beta pruning, etc). But rather than just learn them, I also want to actively *apply* them to problems.

Hackerrank has an AI section where you solve problems by writing AI algorithms, but it assumes a lot of pre-requisites, and so it isn't much of a guide (for a beginner, at least).


I'm looking for something that's simpler, with adequate tutorials, and fun!

EDIT: I should have been clearer, but I am *not* looking for tutorials to play around with high-level APIs (like tensorflow). That's completely antithetical to my goal, which is to learn things from the basics."
Are there an open source tools where I could give it features and it could do basic plots or correlations between them?,0,1,False,False,False,learnmachinelearning,1509422011,True,"I am mainly looking for such tools for other members of my team who may not know how to use plotting tools in python, but would be happy with a UI dashboard where they could play around with features and plot them. Does such a tool already exist?"
Specialization Course in Machine Learning and Deep Learning,2,7,False,False,False,learnmachinelearning,1509437625,False, 
Extract weapons from text,1,2,False,False,False,learnmachinelearning,1509461012,True,[deleted]
AI Academy from Intel heard about this on a TWIML podcast.,2,3,False,False,False,learnmachinelearning,1509461118,True,"Im starting to dive into machine learning and found Intel's AI academy in the podcast.

I checked it out and am starting to work through week 1, into to machine learning. 

What I like about it

* You download the material and just follow the instructions to get set up. Super easy. 
* The courses are given in Jupyter(sp) Notebook where you can either code up the examples in your own script or right on the course material.
* They give a PDF with pretty easy to follow along with slides and in the notebook, there are questions and exercises.
* All Data sets are provided for you

Cons, There are no lectures (As far as I know) and they expect you know programming and mathematics as most courses do.

I personally like not having the lecture as it makes it a little easier to just stop and think about what I need to learn or if something comes up it's a little easier to just open back up a PDF then start watching a lecture.

Id figured I share, it's nice to have something that is not a MOOC.

Sorry if this has been posted. I searched for AI academy and didn't see anything

[Podcast](https://twimlai.com/twiml-talk-051-intel-nervana-devcloud-naveen-rao-scott-apeland/)

[AI Acadamy](https://software.intel.com/en-us/ai-academy/basics)
"
TensorFlow (GPU) Setup on AWS - for Developers,2,15,False,False,False,learnmachinelearning,1509461508,False, 
"Any equivalents of Udacity's AI nanodegree, only cheaper (aka free)?",8,10,False,False,False,learnmachinelearning,1509479647,True,"Here's Udacity's [course](https://www.google.co.uk/search?q=artiifical+intellignce+nanodegree&amp;oq=artiifical+intellignce+nanodegree&amp;aqs=chrome..69i57j0l5.7912j0j7&amp;client=ubuntu&amp;sourceid=chrome&amp;ie=UTF-8).

Just like the course, I'm looking for something focused on DFS, BFS, sudoku solving -- that sort of thing.  **Not**  tensorflow tutorials, or anything that uses high level libraries."
udemy's machine learning course,3,1,False,False,False,learnmachinelearning,1509490748,True,"https://www.udemy.com/machinelearning/

im thinking about dropping 15 euros for it

im also the kind of guy who reads the lowest rating... and a lot of them say that it's just a tutorial on tensorflow, but the instructor doesnt actually explain how it works 

any feedback from these courses? "
What can you advice for a young Statistics student on becoming a data scientist and/or machine learning engineer?,2,1,False,False,False,learnmachinelearning,1509494702,True,"I'm currently in my second year to get a bachaelors degree in Statistics(I'm from Turkey so I'm not sure what is the equivalent form of my education in other countries. It's a 4 year program and they give you a bachaelors degree). I want to become a data scientist and/or machine learning engineer. Since my teachers are not even familiar with those specialties and also that those are considerably new fields, I can't get much help and I'm not sure what questions I should be asking. I'm thinking of starting to learn R slowly, and maybe work on my German in case I can't find the right master's program in my country. What can you advice? Thank you"
Q learning in python guide (request),0,4,False,False,False,learnmachinelearning,1509496033,True,Im looking for a guide to implementing q learning (ideally in python with a neural net).  I would like something fairly simple in the examples (like a card game) that doesn't really on some form of video game (aka no openai gym).  I want these type of examples as I find they are easier to edit and learn from.
TWIL (This Week I Learned) - Share something new that you have learned this week!,6,7,False,False,False,learnmachinelearning,1509519916,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
What is Hypergeometric distribution?,0,5,False,False,False,learnmachinelearning,1509523802,False, 
"New Languages, teams and analyzing data with Excel &amp; CSV files",0,3,False,False,False,learnmachinelearning,1509531843,False, 
Top 10 Machine Learning Algorithms for Beginners,0,8,False,False,False,learnmachinelearning,1509534739,False, 
Probability of classes in an UNsupervised setting? (Interview question),10,5,False,False,False,learnmachinelearning,1509538290,True,"Hello,
I had a very puzzling question in a job interview that made my choke. I was asked to outline a model that would give the probability Here's the basic setup:

You have data on all credit card transactions for a full calendar year for a certain CC operator. Data includes: cc identifier, transaction time, amount, description.

The question: give the probability a given CC was created before that calendar year started (or alternatively, the 1 - probability CC was created during the year).

My approach was to basically use a recency-frequency perspective (i.e. if a CC is used daily since seeing the first transaction forward, but the first transaction recorded is in June, it's probably a new CC, whereas a CC used once a month and we have a transaction in February, it's not unlikely the CC was created in previous year(s).

There are other things you can use too (like trying to work with the description text, see if the total amount spent a month ramps up from 0 to  something much higher, etc.), but what got me stumped me was the ask to give a model than can return a probability, as I don't have the true labels.

Any ideas? Insights?
Thanks! "
Help with adapting code from multi-class classification to binary classification,3,1,False,False,False,learnmachinelearning,1509540379,True,"Hi,

I have found some code for a 2-layer multi-class classification (it's from the cs231n assignment), but I want to adapt it to a single neuron in the output for binary classification instead of multiple neurons with softmax.

Anyone who can help?"
Approach to clustering similar images ?,3,1,False,False,False,learnmachinelearning,1509544594,True,"heres what I have and waht I have in mind:

I have a set of images, which many of them have a certain pattern and similar placements of objects in them.

I want to cluster them into a minimal amount of bins or a algorithmically determined amount of bins (think knn)


I have tried searching for things like ""clustering similar images"" but I dont get any good results for that because I get mostly results for image segmentation which I do not want

accuracy is not important for me, as this is for visualization purposes only, and as long as they *look* similar they can stay in the same bin.
*******
is there an algorithm or a model that does what I have in mind ?

*******
You might think: 
Another idea would be to analyze the images without any ml, but since the images have distinc patterns and non consistent colors across similar images in them I dont know how  I could do this without ml 

disclaimer: I am new to this please dont be all ""this would take budget of a billion dollars and a whole reasearch team"""
Has anyone taken the Elite Data Science Machine Learning Masterclass course?,19,13,False,False,False,learnmachinelearning,1509551959,True,"Hi everybody,

I recently came to know about http://EliteDataScience.com and the interesting course they are offering: https://elitedatascience.com/machine-learning-masterclass

It's available for $295. I am really sold on the way they have presented this course, but I don't know if I can trust them with that much money.

Anyway, I want to know if someone has taken that course, and do you recommend taking that course.

Thanks. "
Can someone explain this ensemble method explanation?,0,1,False,False,False,learnmachinelearning,1509557335,True,[deleted]
Tuning hyperparameters and utilizing IBM hardware using Tensorflow - best practices?,0,4,False,False,False,learnmachinelearning,1509562144,True,"I am training a CNN on my laptop and have access to IBM Data Science Experience and Bluemix. What is the best way to implement the training setup on remote hardware? Jupyter notebooks are kinda clunky. I thought it may be useful to put everything in a docker image, but are there cleaner options?

Ideally I would run the script on my laptop, but tensorflow would upload the data to their servers for running hyperparameter optimization code (I don't want to train dozens of CNNs on my GPU).

Those familiar with Tensorflow and IBM Bluemix/DSX, what do you think?"
question about Linear Regression (Binary Classification),1,2,False,False,False,learnmachinelearning,1509567317,True,"I'm can't figure out how the values for w in the following situation are determined. 

Don't need to watch this video to answer my question, but I'm going to use the example I got from it. the vid incase: https://www.youtube.com/watch?v=-Z2a_mzl9LM&amp;t=710s  

the question:
Probability of someone dying in 10 years where our input, x, consists of x1 = age, x2 = gender, x3 = cholesterol level. so x is a 3 element column vector equal to {x1, x2, x3}

Now we put w0 + w1x1 + w2x2 + w3x3 = a
Since a is not a probability, we will have to put it through the logistic function for it to output a number from 0 to 1 (a probability). We then put it through the logistic function, 
sigma = 1/(1+e^-a) where a is defined as above. This will allow a to be represented as a percentage, and that percentage will become our probability representing the chances of death in 10 years.

My question: mathematically, how does the model determine w? I don't quite get what to do. the x values given as that's our input, but how do we find w0, w1, w2 and w3 in this situation?"
Tensorflow vs Implementing a NN from scratch?,6,6,False,False,False,learnmachinelearning,1509572676,True,"I was wondering what would be the optimal strategy to learn about neural networks.

My goal, for now, is to deploy neural nets on problems and just tinker around with them. But I do realize the pitfalls of merely deploying a black box model (aka high-level library like Keras), without understanding the stuff under the hood. Plug-and-play with Keras is fun, but I don't think very fruitful in terms of learning.

Here's my background: I can code up a logistic regression model from scratch, and as such, I'm pretty familiar with gradient descent, the cross-entropy loss function, and I can derive the backprop equations. So, for a simple logit model, I know what's going on under the hood. 

I realize coding up a neural net scratch involves the same concepts, just that it's more math-y. More layers, more equations, different activation function for each layer -- that's when my head starts to spin.  

**I'm looking for that sweet spot where there's enough abstraction that I don't have to worry about manually computing gradients, but not so much that I have *no* idea what's really going on.  How do I get there? Should I invest in fully understanding a NN? Or should I get started with a framework like tensorflow already?** "
Math for Machine Learning Online Course,0,1,False,False,False,learnmachinelearning,1509581228,False, 
Video Classification using Tensorflow,1,3,False,False,False,learnmachinelearning,1509591764,True,Is there any good tutorial or code with good documentation on how to make video classification where each video have different number of frame?
Lear to do simple kernel tricks using SVM in python,0,2,False,False,False,learnmachinelearning,1509599887,True,"Hi, are you quite interested in knowing about why kernel tricks are so famous in doing classification problems? Then this msg is for you. I have published a kernel in Kaggle where I have experimented with different kernel tricks using SVM in sklearn package. Kindly skim through it and also comment for any improvement, I will take it has a great learning from you all! If I like my work vote me in Kaggle too! Here is the link:
https://www.kaggle.com/pradeepsathyamurthy/kernel-tricks-to-build-efficient-classifier-model"
Item recommendation for users in an online store?,2,3,False,False,False,learnmachinelearning,1509602837,True,"Hi, I'm trying to come up with a way of recommending items to users in an online storefront based on their previous order history (and that of other users). For reference, I have a bit of ML experience (all the basic topics - linear/log regression, binary classifiers, neural networks, etc). A couple cursory google searches tell me I should be looking at matrix decomposition or clustering based on user, but from my relatively inexperienced viewpoint these sound like they could be somewhat processing intensive at runtime (making predictions for a user when they request the page), which is something I'd really like to avoid. The algorithm being able to scale with a large number of users and a very large number of items (divided across categories, so at least I only have to recommend items within the category that the user is looking at) is definitely a concern, but if that complicates things I can ignore it for now in order to get something working.

Thanks for any pointers you can give me!"
Handwritten Signature Algorithm,12,3,False,False,False,learnmachinelearning,1509606980,True,"Hello Everyone! First of all I'm new to Image Processing and somehow a total beginner in Machine Learning. As the title say, can I have an advice regarding on which algorithm will I use in order to do my project Offline Handwritten Signature Verification System. The objective is simple, it just need to identify whether the test signature is Genuine or Forged. I'm already aware about the procedures like Image Acquisition, Pre-Processing, Feature Extraction, Creation of Feature Vector and Training and Testing to a Classification Method. On all the parts, only the Pre-Processing stage is what I understand up-to now. I'm having a hard time identifying which features to extract. I think Feature Extraction is off-topic because this is not an Image Processing Forum. Maybe you can help me in the Classification Method to be used. If you can also help me in the Image Processing part, it will be very much appreciated also. Thanks in advance!
"
Sklearn KMeans: Input Additional Data/Keep Labels the Same,0,3,False,False,False,learnmachinelearning,1509607274,True,"I'm using KMeans to cluster strings of sentences and it's working as expected. I implemented it similarly to the top answer of [this question.](https://stackoverflow.com/questions/27889873/clustering-text-documents-using-scikit-learn-kmeans-in-python)


I was wondering if it's possible to accept user input and have the text input clustered properly with the existing clusters.

If this isn't possible after the model has been fitted, is it possible to have the labels stay the same after every time I fit the model? I am using the model as an input to a linear regression model and would want the input values to stay the same. For example, a cluster can be labeled in the ""1"" but if I run it again, it will be labeled ""25"". I assume that if I can't add more data to the model after its been fit, I would just add it to my list and refit the model, but I would want the same labels to be produced.

EDIT: I used random_state=0 to get the same labels, but is there a way to add more data to the model? If I add more sentences to my input data, it changes the labels.

    documents = xmerge['comment'].dropna().str.replace('[^\w\s]','').tolist()
    #documents contains list of sentences 
    vectorizer = TfidfVectorizer(stop_words='english')
    X = vectorizer.fit_transform(documents)
    
    true_k = 250
    model = KMeans(n_clusters=true_k, init='k-means++', max_iter=5000, n_init=1, random_state=0)
    model.fit(X)
    
    labels = model.labels_
    
    
    #Print Results
    for i in range(X.shape[0]):
        print('\nComment: ', str(documents[i]), '\nLabel:', labels[i])
    
    input = ['test input']
    
    #Predict
    X_test = vectorizer.fit_transform(input)
    model.predict(X_test)      
      

When I run model.predict, I get this error:

    ValueError: Incorrect number of features. Got 2 features, expected 1187

I assume it's because when I vectorized the Tfidf score, there's less words in my input data."
Understanding Convolutions,2,3,False,False,False,learnmachinelearning,1509613236,True,"Hey, so I want to use an imporved wasserstein GAN to generate images and came upon [this implementation](https://github.com/farizrahman4u/keras-contrib/blob/master/examples/improved_wgan.py) in the keras-contrib repo.

Since it is explicitly written to work on the MNIST dataset I need to change the models, but I don't know exactly how, especially when it comes the generator:

    def make_generator():
        """"""Creates a generator model that takes a 100-dimensional noise vector as a ""seed"", and outputs images
        of size 28x28x1.""""""
        model = Sequential()
        model.add(Dense(1024, input_dim=100))
        model.add(LeakyReLU())
        model.add(Dense(128 * 7 * 7))
        model.add(BatchNormalization())
        model.add(LeakyReLU())
        if K.image_data_format() == 'channels_first':
            model.add(Reshape((128, 7, 7), input_shape=(128 * 7 * 7,)))
            bn_axis = 1
        else:
            model.add(Reshape((7, 7, 128), input_shape=(128 * 7 * 7,)))
            bn_axis = -1
        model.add(Conv2DTranspose(128, (5, 5), strides=2, padding='same'))
        model.add(BatchNormalization(axis=bn_axis))
        model.add(LeakyReLU())
        model.add(Convolution2D(64, (5, 5), padding='same'))
        model.add(BatchNormalization(axis=bn_axis))
        model.add(LeakyReLU())
        model.add(Conv2DTranspose(64, (5, 5), strides=2, padding='same'))
        model.add(BatchNormalization(axis=bn_axis))
        model.add(LeakyReLU())
        # Because we normalized training inputs to lie in the range [-1, 1],
        # the tanh function should be used for the output of the generator to ensure its output
        # also lies in this range.
        model.add(Convolution2D(1, (5, 5), padding='same', activation='tanh'))
        return model

As it says in the beginning, this basically pepares a Tensor that can then be made into a 28x28x1 image. And I'm pretty sure I understand what happens in the beginning: we expect a 100x1 noise vector as input and connect that to a fully connected layer with 1024 units. This is then connected to a 6272 unit FC layer which is then reshaped into a tensor with 128 7x7 layers. But after that my understanding get a little fuzzy. Especially since my understanding is that passing ""padding='same'"" to a convolutional layers ensures that its output has the same width and height as its input. So where are the dimensions of our noise tensor changed to 28x28? Which dimensions does it have after the transposed convolution?

I'm pretty sure that if I'd want to create color images I'd need to change the last layer from

    model.add(Convolution2D(1, (5, 5), padding='same', activation='tanh'))

to

    model.add(Convolution2D(3, (5, 5), padding='same', activation='tanh'))

But what would I need to do if I wanted these color images to be of dimension 64x64?"
CudNN on win8.1?,0,3,False,False,False,learnmachinelearning,1509615051,True,"Hello there. 

I recently switched to win8.1 due to limitations and bloats on Windows 10 but some people on the Internets says that cudNN isn't working on win8.1. Is this true? "
I honestly need some advice on math and programming.,14,9,False,False,False,learnmachinelearning,1509616760,True,"I have been taking Andrew Ng's machine learning course and I am now on week 4. One reason I like Andrew Ng course is that its not very advance math heavy most of the time. E.g I can understand the concepts of linear regression or one vs all just fine, what I mean by this is general concept on how everything connects with each other. My problem is I struggle a lot octave coming from a python background also advanced math. Til this day I don't understand the syntax of feeding parameters into fminuc. Since trying the programming exercise for week 4 I think I really hit a brick wall. I didn't understand any of the programming instruction. I did cheat and look up answers and then my brain clicks with the aha moment. I know this actually doesn't help myself at all but looking and reading over instructions for hours also doesn't help. MY current plan is taking statistics from Udacity and will try to connect with their own ML course that uses python.
I just don't know if I should keep going with coursera without complete understanding of octave. Do you guys have any advice for me? I'm kind of depressed about this."
Mix CNN and LTSM cells,0,2,False,False,False,learnmachinelearning,1509625105,True,"I would like to have a stacked or maybe a simple LTSM cell that works on time series. 

However first I would like to to some short term feature detection on the time series. I think a CNN network would be good for this. 

So My Idea is have a a 5x3 CNN layer, three units of time would be merged in a CNN cell and I have 5 parameters per time unit. This would output a new time series that I would run over with a LTSM cell. 

Would this work?
I am currently using Tensorflow as my Machine learning library, but I could switch to another if needed?

"
Probabilistic Graphical Models: a powerful framework to learn the models with dependency,0,22,False,False,False,learnmachinelearning,1509631961,False, 
What Mathematics course would you recommend before taking Andrew Ng's Machine Learning course?,12,20,False,False,False,learnmachinelearning,1509634171,True,"I'm thinking of taking Andrew Ng's Machine Learning course on coursera, but I am a bit afraid about the math because It's been a long time since I took a Maths class.

I know I should at least understand Linear Algebra and Calculus before Andrew Ng's Machine Learning course, but I don't know if I should take a quick crash course on these topics like Khan Academy or should I get some deep understanding of these topics by reading a book on these topics.

My main concern is that I don't want to feel stupid when I'm taking Andrew Ng's course. So please recommend me some appropriate mathematics resources.

Thanks in advance. "
Clarification on decision tree building using Gini index (CART) for split,0,3,False,False,False,learnmachinelearning,1509634248,True,"I understand how calculating the Gini index works for each column of a set of data and I understand how you can then choose which other column of data to split based on the purity of the index with respect to the parent node you are now splitting. Let’s say you have a set of data that contains columns: education (none, highschool, associates, bachelors, graduate), work_experience (none, 1 year, 2 years, 3more years), owns_credit_card (yes, no), marital_status (single, married, divorced), children (none, 1, 2, more), buys_house (low, average, high, very_high). So assume you are creating a decision tree to determine the likelihood that someone is going to buy a house. The target would be buys_house. I am wondering logistically how you would begin and end the tree. And I don’t even know if it’s logical to use Gini index for this set of data because I just made all those categories up but theoretically if it was already decided that this was the method we were going to use. Do you start with the node or column that has the highest Gini index (closer to 1) because it has less purity and therefore has the most options for nodes? Or do you begin the decision tree with the node that would have the lowest Gini index (closer to 0) because it is the most pure and exhaustive? And if there’s no rule stating either way- I’m also curious which would be the most optimized in regards to performance?
Thank you in advance for any advice as I am very new to all this stuff!

(PS: yes I also posted on regular r/machinelearning but I wasn't sure which was the best place for such a discussion- I will gladly remove from whichever it does not belong)"
Creating images using GANs,2,1,False,False,False,learnmachinelearning,1509644227,True,"Hey, so I want to create new images based on a dataset and decided that Improved Wasserstein GANs seem to be the way to go.

[With some help](https://www.reddit.com/r/learnmachinelearning/comments/7aaa92/understanding_convolutions/) I even managed to change [this implementation](https://github.com/farizrahman4u/keras-contrib/blob/master/examples/improved_wgan.py), which generates MNIST digits, so that the generator puts out differently sized, colored images, I think:

    def make_generator():
        """"""Creates a generator model that takes a 100-dimensional noise vector as a ""seed"", and outputs images
        of size 28x28x1.""""""
        model = Sequential()
        model.add(Dense(1024, input_dim=100))
        model.add(LeakyReLU())
        model.add(Dense(128 * 12 * 12))
        model.add(BatchNormalization())
        model.add(LeakyReLU())
        if K.image_data_format() == 'channels_first':
            model.add(Reshape((128, 12, 12), input_shape=(128 * 12 * 12,)))
            bn_axis = 1
        else:
            model.add(Reshape((12, 12, 128), input_shape=(128 * 12 * 12,)))
            bn_axis = -1
        model.add(Conv2DTranspose(128, (5, 5), strides=2, padding='same'))
        model.add(BatchNormalization(axis=bn_axis))
        model.add(LeakyReLU())
        model.add(Convolution2D(64, (5, 5), padding='same'))
        model.add(BatchNormalization(axis=bn_axis))
        model.add(LeakyReLU())
        model.add(Conv2DTranspose(64, (5, 5), strides=2, padding='same'))
        model.add(BatchNormalization(axis=bn_axis))
        model.add(LeakyReLU())
        model.add(Convolution2D(32, (5, 5), padding='same'))
        model.add(BatchNormalization(axis=bn_axis))
        model.add(LeakyReLU())
        model.add(Conv2DTranspose(32, (5, 5), strides=2, padding='same'))
        model.add(BatchNormalization(axis=bn_axis))
        model.add(LeakyReLU())
        # Because we normalized training inputs to lie in the range [-1, 1],
        # the tanh function should be used for the output of the generator to ensure its output
        # also lies in this range.
        model.add(Convolution2D(3, (5, 5), padding='same', activation='tanh'))
        return model

For 96x96x3 images, right?

So I load a set of small images and arrange it like the MNIST Dataset: 

    from keras.preprocessing import image
    image_array = []
    for file in glob.glob(""dataset"" + ""/*.jpg""):
        img = image.load_img(file)
        x = image.img_to_array(img)
        image_array.append(x)
    X_train = np.array(image_array)
    X_train = (X_train.astype(np.float32) - 127.5) / 127.5

But what I get is ... nothing. Just darker and darker uniform noise. ([Epoch 1](https://imgur.com/a/wlevF), [Epoch 10](https://imgur.com/a/OI2Ty))

Which is at least _something_ but is it even worth it to go down this road any further? Or is my thinking here fundamentally flawed?





"
Can Support Vector Machines be used with categorical features?,0,1,False,False,False,learnmachinelearning,1509648985,True,[removed]
Keras Linear Regression Questions,12,2,False,False,False,learnmachinelearning,1509654672,True,"I have some data which I want to predict values. I am not looking to classify the data into groups just return a value.

All my values are positive integers.

What should be my last layer of CNN? 
 I assuming  dense layer of 1; not the number of classes (possible outcomes - 'softmax')

As I there no negative numbers should I stick with the ""relu"" or should I use different activation?

Thanks






"
Where is my genetic algorithm going wrong?,4,7,False,False,False,learnmachinelearning,1509657165,True,"So I did a bit of reading (not very indepth at all; I wanted to jump into a project ASAP) on genetic algorithms yesterday, and today I wanted to implement my first ever GA. My goal is to, given an image, randomly generate an image, and keep changing its pixels so that eventually it matches the original image. In my test case, the original image is an image of Mona Lisa. Here is what I'm doing:

1) Initialize the first generation (each generation has 10 IndividualImages, each IndividualImage has a Color array of size [620][650] width x height) randomly.

2) Repeat the following steps:

a) In each generation, get the fitness of each individual, calculated as the number of pixels whose colours are in a small range (+- 10) of the original image's colours.

b) Get the 5 fittest, crossover each individual with each other individual (resulting in 5 choose 2 crossovers = 10 crossovers). The procedure for crossover is alternating pixels from the parents. [This image shows it better. Every circle is a pixel, and there are two parents](https://i.imgur.com/Jr4NP6Z.png)

c) Randomize 'mutationRate' number of pixels in each individual.

d) Repeat.

So the size of the image is 620 x 650 = 403000. Now, the initial fitness starts off at somewhere near 1500-1600. A mutationRate of 8000 caps out at about 2000 fitness. A mutationRate of 1000 caps out at about 2900 fitness. Lower values, and slightly higher values cap out even lower. Where am I going wrong? Why are the values so low, even after about 2000-3000 iterations? Here is my code, if you require it: (it is very dirty, I put it together really quickly cause I was rather excited):

[Main.java - contains the actual GA i.e. crossover and mutation
](https://gist.github.com/anonymous/e876ca03e5a2a4dd7c2927f0fcb5bf99)

[Generation.java - a collection of IndividualImages](https://gist.github.com/anonymous/238c3bf6edf249a6bef506ab9c55a358)

[IndividualImage.java - Contains the color array
](https://gist.github.com/anonymous/c4867b4947528e92baab346788afce20)

[MonaLisa.java - Contains the fitness function](https://gist.github.com/anonymous/630afa312c26da0d72c53144611782c6)

Thanks for the help."
Got about 99.5% score with decision tree - stupid mistake?,4,4,False,False,False,learnmachinelearning,1509659525,True,"Hey guys, I tried to solve the Titanic problem with a decision tree. Link here: https://www.kaggle.com/c/titanic
After creation of decision tree I tested the tree for my trainingsdata: accuracy 79%. That sounds possible, compared with what I have seen in the net before. 

Now I evaluated the given test data,  compared with the solution and got an accuracy from around 99.5%, which shouldn't be possible with a simple decision tree. 

Here's my code:  https://github.com/marvpaul/ContentManagementTasks/tree/master/Graded1

It would be awesome if someone can give me a hint why I get this score. I can't locate my fault :/

Edit: sorry, get my fault: I used an „incorrect“ file for validating my test data which only divide between male and female passengers. Female survived, male does not."
🔥 Latest Deep Learning OCR with Keras and Supervisely in 15 minutes,0,20,False,False,False,learnmachinelearning,1509668127,False, 
I am starting Andrew Ng's course on Coursera for Machine Learning. I found that the O'Reilly book is a little bit unhelpful on the insights with Python. Am I not ready for Machine Learning as a whole?,5,10,False,False,False,learnmachinelearning,1509670146,True,"I've got high school math but am in my third year of a Computer Science degree. Some technical notes:
* Programmed my Raspberry Pi to play Simon Says using a breadboard and buttons.
* Have programmed various things, almost had a working auto-drawing script when /r/thing was around, but unfortunately missed my opportunity as it finished, also in Python.
* Majoring in Networking and Security but have programmed a bit in the past with C#, Python and Ruby.

I am not an advanced programmer by any means, but I know the fundamentals, I suppose, as far as object-oriented languages go, just not really the in's and out's of many major libraries. 

Also, my mathematical ability is not the best, but I feel that it shouldn't be too difficult to grasp.

Is the fact that I can't really get away with the O'Reilly book a sign that I'm not ready full stop, or is it just I learn differently, because to me, I've really struggled with reading so much information and not really doing much, I mean, I know about Supervised, Non-Sup, Semi-Sup, Reinforcement, Batch vs. Online, Model-based etc. but I just couldn't really find the appeal when it came to the coding part of the book due to the lacklustre in-depth explanations provided. Literally just telling me to go read up on a library without any sort of info provided.

I feel like I'm more than capable, but I'm unsure.

Any suggestions? 

Thanks."
Tutorial: Submit a prediction to Kaggle for the first time,0,10,False,False,False,learnmachinelearning,1509670650,False, 
Bias-variance tradeoff in &lt; 100secs,0,1,False,False,False,learnmachinelearning,1509686261,False, 
Weekly Show-off!,0,2,False,False,False,learnmachinelearning,1509692718,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
I've loved reading Hands-On Machine Learning with Scikit-Learn and TensorFlow - Géron's book is so clear compared to some other resources!,0,1,False,False,False,learnmachinelearning,1509693657,False,[deleted]
Looking for a good overview of machine learning in python? Check out Hands-On Machine Learning with Scikit-Learn and TensorFlow - Géron's book is so clear and to the point!,1,14,False,False,False,learnmachinelearning,1509693736,False, 
"ULTIMATE GUIDE: Machine Learning: A Hands-On, Project-Based Introduction to Machine Learning for Absolute Beginners: Mastering Engineering ML Systems using Scikit-Learn and TensorFlow",1,3,False,False,False,learnmachinelearning,1509699159,False, 
Am I understanding the use of Theta in ML correctly?,1,1,False,False,False,learnmachinelearning,1509720609,True,"As far as I'm aware, theta is used as the unknown variables that predict certain things. For example, take the generic house pricing problem. If the house is £150,000 and 1200m2 and they're all similar in that area, due to it being coastal, could Theta in that instance be the location.

Due to my understanding Theta generates parameters X, Y. 

Therefore, location preference can generate the higher price x, and the size y. 

But AFAIK, we're not meant to distinctly know ""Theta"" due to the reason of needing the machine.

Another example:
An apartment is a lower price and smaller size due to it being an apartment, is theta in this instance the type of building, i.e. an apartment building, as the fact the **apartment building** leads to **smaller** apartments and that leads to **lower prices**.

Obviously anomalies are not counted for etc. But it's a general question to help my understanding.

Thanks.
"
Need help : AI and Machine Learning certificate course in 15 weekends,4,12,False,False,False,learnmachinelearning,1509720974,True,"Hello,

My wife currently works on Python. She is keen on learning Machine leaning. She already started to learn on her own. Today I saw this course ( refer link below) in my feed and suggested her to have a look. 

She went through the contents and felt those topics will definitely help her grow professionally. However the problem is fee. It is two lakhs INR ($3100, £2400). It is way beyond what we could afford. 

But IIIT in India is one of reputed institutions. Also a weekend only courses designed keeping working professionals in mind from such institute is a rarity. So we are thinking it would help. But neither me or she has any contacts who can counsel us regarding the prospects of the topics offered in this course or their demand/ necessity in future. So please go through the below link and suggest if that course really worth such whopping money ? If so, we can even take loan and join the course, else I can suggest her to continue learning online.

https://cie.iiit.ac.in/aiml/

Other doubts are :

Will the same courses be available online to learn on our own ?

Will a faculty member and lab facilities make difference in learning ?

Thanks in advance."
Weather Problem: Regression or Classification,3,0,False,False,False,learnmachinelearning,1509722818,True,"Lets say I have some weather data lake barometric pressure that I want to use to predict the temperature.  My weather is in a warm area so all temperatures  / labels are all positive.

Is this a regression problem or  a classification problem? I am not sure what model to use to predict the temperature outcomes."
Checking whether columns are identical modulo relabelling,1,0,False,False,False,learnmachinelearning,1509726666,True,"Sometimes a dirty dataset might have multiple columns that are identical except that the entries in one have been relabelled, e.g. two such columns could be 

1 2 3 1 3 2

a b c a c b

It would be useful to identify such pairs/tuples. 

Is there a name for this problem? It's difficult to find a useful Google query. And are there any known fast algorithms, beyond brute-force loops?"
Keras ModelCheckpoint: Linear Regression,0,0,False,False,False,learnmachinelearning,1509728318,True,"I am trying to save the model with the MSE in the file name. As this model is linear regression, accuracy is not needed. 

The only example in Keras; filepath is :
    weights.{epoch:02d}-{val_loss:.2f}.hdf5, 

How can I (or do i need to?) replace  the val_loss with mse?

As for checkpoint function itself:
    keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, 
    save_best_only=True, save_weights_only=False, mode='min', period=1)

I should use mode ='min' because I want ""save_best_only"" when MSE has been minimized?
"
"interested in learning more about genetic algorithms, looking for starter project recommendations to research. [xpost /r/machinelearning]",0,1,False,False,False,learnmachinelearning,1509728982,True,"Preferably some projects that are well documented, lots of code examples, and easy to understand the core concepts of GA. Not looking for 'hello world', maybe something 200-300 level? Thanks!"
Most visual resource I have seen for learning machine learning concepts. Youtube channel called 3Blue1Brown,3,61,False,False,False,learnmachinelearning,1509729119,True,"https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw/videos

By far the best visualizations I have ever seen. "
[Article] Making your First Machine Learning Classifier in Scikit-Learn.,0,3,False,False,False,learnmachinelearning,1509734068,False, 
3Blue1Brown finished his tutorial series about Neural Networks. Amazing piece of information for understanding the very basics of how it actually works.,4,33,False,False,False,learnmachinelearning,1509745213,False, 
Weird loss spikes and behavior while training autoencoder,4,1,False,False,False,learnmachinelearning,1509746089,True,"I'm trying to train a convolutional autoencoder to reproduce frames from a game of Pong as a pretraining step for teaching an agent to play Pong through a Q-learning algorithm (in order to force it to learn relevant covolutional kernels before I let it loose on the game). I've had decent success with this autoencoder so far, but I've noticed some weird things happening while training. [Here is a plot](https://i.imgur.com/U4gLP9D.png) of my most recent training session. 

Everything seems to be going fine for a while, but then there's this huge spike in the loss, which as you can see appears again later, at roughly the same 10^(-3) level. I don't really know why it's spiking so hard, especially because I'm using an adaptive gradient clipping method which clips at 5 times the average norm over the past epoch.

My running hypothesis is that there's a a very sharp cliff/wall/discontinuity in the error surface, and that after running along the previous flat region for so long, Adam has increased the adaptive learning rate by a large factor so that a single parameter update takes me from the bottom to the top of the cliff. I don't think gradient clipping would even be useful in that scenario, so I'm kind of at a loss for what to do. Go back to a previous checkpoint and decrease the learning rate perhaps?

The other thing that's confusing me is the behavior after the second spike. I've seen this happen before in previous training sessions, and I'm not sure why the loss behaves like this. It's a semilog plot, so straight lines are actually exponential attenuation of the loss, which would be fantastic if it were to continue at this rate all the way to low loss. All the other loss curves I've ever seen have the typical ""get to a low point really fast, cross some flat region, then drop really quickly again"" behavior, so this is new to me too.

Anyone have any advice/suggestions?"
How do I point my neural network script to load data from my sql server db using python?,1,2,False,False,False,learnmachinelearning,1509754794,True,Extreme n00b to python and and ML but am SQL server dba of sorts and biz intelligence analyst. I've seen 'load' and then a csv file but I haven't seen any code where it specifically calls a database. What's the code look like? I feel like this is a super basic question but I haven't seen any resources that specifically point out code for loading specific data sources.
Kmeans clustering fails due to Anistropic data,5,5,False,False,False,learnmachinelearning,1509769196,True,"Hello,
I am trying to do a Kmeans clustering on some data. Unfortunately, the clustering is not coming out well. Here is the [plot] (https://ibb.co/nRoG2b).
The code is pretty simple:

    kmeans = KMeans(n_clusters=2)
    kmeans.fit(X_train,Y_train)
    labels=kmeans.labels_

Is there a way I can improve the prediction?"
"Weekly Status Check Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",3,3,False,False,False,learnmachinelearning,1509779110,True,"Let's have a  meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
Looking for a study partner to learn machine learning,25,3,False,False,False,learnmachinelearning,1509794729,True,"Hey guys, I'm looking for someone who wants to learn machine learning concepts and implement them on mini-projects/kaggle competitions. Studying alone can be hard and it's easy to lose motivation so I would love to have an accountability partner that I can exchange ideas/work on projects with. The ideal partner would: 1- Have some background in either mathematics/computer science or analytics. 2. Be serious and committed to learning ML over the next few months/year. 3. Able or willing to spend a minimum of 5 hours per week studying material and/or working on projects. 
Please let me know if you're interested so we can discuss this further."
Total beginner looking to use a text-based neural network that's easy to set up.,3,11,False,False,False,learnmachinelearning,1509809545,True,"I'm looking to dive into a text-based (inputs plain text training data and outputs plain text) neural network. Not to hack it, just use it. I've set my eyes on [torch-rnn](https://github.com/jcjohnson/torch-rnn) since [CarryKH](https://www.youtube.com/user/carykh) uses it (he calls it CBLSTM for some reason). However, the setup process is... daunting to say the least.

Is there an easy to set up (preferably through `apt-get`) neural network out there that I can use? I'm on an Ubuntu machine (obviously), and I know some Bash, Java, and C++.

EDIT: Clarified what a ""text-based"" NN is (/u/karn1948)"
Help needed in normalized layer and training NN,0,1,False,False,False,learnmachinelearning,1509814946,True,"I am implementing this paper: https://arxiv.org/abs/1702.00832
In, this paper author has used normalized layer and I tried to implement this layer in my code but NN is unable to train due to some reason.I'm confused where i made mistake.Please someone can help me to figure this out.

my code link: https://github.com/immortal3/Machine-Learning/blob/master/autoencoder_2_2.ipynb"
Question about data structure,2,1,False,False,False,learnmachinelearning,1509817516,True,"Hi everyone, quick question here about structuring data. 

I appreciate you all taking the time to answer this. I've been immersing myself in all that I can about ML, but still have a few questions that I have not had answered, this being one of them. 

Suppose I am trying to predict the number of posts that a certain subreddit will have each day. Originally I thought that having the growth rate of the subreddit (both in terms of raw numbers e.g. +10, and percentage e.g. +1.25%) would be beneficial.

With that being said, is it redundant to also include the growth rate of the growth rate? As in, if a subreddit is on average growing 5% each day, and then starts growing on average 10% each day. Should I include that +5% growth rate of the growth rate in my stats? Would that be redundant? Basically I guess what I'm asking is, is it redundant to include what is essentially the second derivative of a stat or will a neural network discover that connection given enough training?

tl;dr. Are raw numbers enough for a neural network to discover other indicators such as acceleration of growth, or should those be broken down and included as well?

Thanks!"
"Is ML all about trying to different algorithms, with different parameters, and seeing what works best on a dataset?",0,1,False,False,False,learnmachinelearning,1509823476,True,[deleted]
"Is ML all about trying out different algorithms, with different parameters, and seeing what works best on the given dataset?",3,2,False,False,False,learnmachinelearning,1509823583,True,"EDIT: After a bit of googling, I've come to the conclusion that answer is ""No"", but I'm looking for a concrete example that would differentiate an expert vs non-expert.

Let's say they're both given a dataset. After a bit of data exploration, how would their approaches differ?

[Let's assume that the non-expert is mildly competent at using libraries and has a superficial idea of when to use what algorithm (eg: if you're doing binary classification, you can't use linear regression - let's try plugging in sklearn's logistic regression or knn instead)]"
Discrete distributions in R: Part I,0,1,False,False,False,learnmachinelearning,1509848543,False, 
"Image Classifier with 78,000 100x100 images",8,11,False,False,False,learnmachinelearning,1509855597,True,"I've got 78,000 100x100 images of apartments that I'd like to build an image classifier with. The problem is that I only have access to my laptop and would prefer not to use it for training because I don't want to completely destroy my CPU. 

I'm considering renting cloud GPUs like the ones [Paperspace](http://www.paperspace.com) offer. I see they have a ML in a box that starts at around $200 per month. Does anyone have experience with Paperspace and image classification in general? Is this do-able on my laptop? How long (ballpark estimate) might I have to wait if I run this on a CPU vs GPU?"
Is there any AMD GPU solution for ml/neural nets that makes not upgrading from an RX 480 to a GTX 1070 possible?,9,4,False,False,False,learnmachinelearning,1509867328,True,"Would prefer to keep existing hardware over buying a new card and selling off the RX 480 to help cover the expenses but beggars can't be choosers, can they? Plus, then there's a portal to TensorFlow.

R is my background but willing to migrate over to where a solution would call home."
Analytical VS. Numerical Intuition?,2,1,False,False,False,learnmachinelearning,1509873734,True,"I am a chemical engineer who's searching for a phd. I contacted a professor who works on process optimization through machine learning algorithms, which is new to me.

I am exceptionally good in math, especially the analytical theoretical-proof type of problems,,, My intuition is rock-solid. However, I never felt excited about algorithms and numerical methods. 
Two possible reasons: 1) I have good intuition in analytical math, but my mind does not do well with numerics.
2) I had bad luck with professors when it came to numerical methods, and computer algorithms. It is true they were bad, but I also tried learning for myself, it just seems like it never sticks with me.

I am not sure if this should stop me from pursuing the phd in algorithms, or I should just build my intuition and I'll be good to go.

Did anyone have a similar experience? Any thoughts?"
Is there a list of gotchas for rigorous data analysis / ML? I've learned a few accidentally and feel like I'm missing a large part of the critical thinking skills for this.,10,15,False,False,False,learnmachinelearning,1509888269,True,"For example, thanks to Géron's Hands-On book, I just realized that when you're continuously training and re-evaluating a model, you should be careful that it never sees too much of your data.  Otherwise over time it'll get too smart and overfit to your dataset.  Another thing I learned was that your training data should be representative of your problem space to avoid under-fitting (I think this is the correct term?).  However, in his book, topics like this are not discussed very deeply (so far).

So my question is where I can learn more about this sort of thing.  And also what might this topic be called? Data.... fidelity?  I'm not even sure how I would know if my model was under- or over-fitting my data.  This is probably more in the statistics area, and less ML."
Help! Perceptron algorithm convergence math proof.,1,3,False,False,False,learnmachinelearning,1509895936,True,"Hi ML-Reddit people.

I am about to make a school assignment about the Perceptron ML-algorithm, and I am looking for a mathematical convergence proof for the algorithm.
Unfortunately, I have not been blessed by the math gods, so all of the convergence proof of the math behind the perceptron algorithm seems a bit too complicated or at least a bit too discursive. I was wondering if anyone had an easy and intuitive link to a source which explains the math behind the algorithm.

- Thanks a lot! ;)

Best regards,
Frederik, Denmark."
"If I normalized my training set, doesn't that mean I have to normalize the validation and test sets, otherwise the training would have been performed on different type of data?",7,2,False,False,False,learnmachinelearning,1509902501,True,"basically the title, jw, I couldn't find any definitive resource on this point of confusion, so any help is appreciated"
Guide please,4,1,False,False,False,learnmachinelearning,1509903825,True,"Hi I know python and Java(not an expert but I am familiar with them)...I want to learn Machine learning..I saw this course by Andrew Ng on Coursera... Should I start doing that course straightaway? I need a guide to learn Machine learning..
P.S. I have interest in programming, computers, games and Mathematics."
Understanding Michael Nielsen's backpropagation code,6,6,False,False,False,learnmachinelearning,1509913738,True,"I'm trying to understand/run the code in Michael Neilsen's Neural Networks and Deep Learning chapter 2, on backpropagation: http://neuralnetworksanddeeplearning.com/chap2.html#the_code_for_backpropagation. 

At the start of the backward pass, it has:

    delta = self.cost_derivative(activations[-1], y) * \
        sigmoid_prime(zs[-1])
    nabla_b[-1] = delta
    nabla_w[-1] = np.dot(delta, activations[-2].transpose())

The forward pass creates the `activations` list, where `activations[i]` contains a vector of the activations of the neurons in layer i. So `activations[-1]` is the last layer. y is the desired output.

`cost_derivative` is defined as:

    def cost_derivative(self, output_activations, y):
    """"""Return the vector of partial derivatives \partial C_x /
    \partial a for the output activations.""""""
    return (output_activations-y)

So that first line outputs a vector with the same shape as our output layer. So my question is how is that `np.dot` on the 4th line supposed to work? My understanding is that `activations[-2]` is a vector of the activations of the neurons in the 2nd-to-last layer, which can have any number of neurons, so I'm not sure how we can dot product it (or its transpose) with the delta, which has the shape of the output layer. 

I ran the code (https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/network.py) with some added debug lines to try to understand this, and it doesn't seem to work:

    &gt;&gt;&gt; from network import *; net = Network([2,1,2])
    &gt;&gt;&gt; net.backprop([1,2], [3,4])

    Activations[0]
    [1, 2]
    
    Activations[1]
    [[ 0.33579893]]
    
    Activations[2]
    [[ 0.37944698]
     [ 0.45005939]]
    
    Traceback (most recent call last):
      File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
      File ""&lt;snip&gt;/neural-networks-and-deep-learning/src/network.py"", line 117, in backprop
        nabla_w[-1] = np.dot(delta, activations[-2].transpose())
    ValueError: shapes (2,2) and (1,1) not aligned: 2 (dim 1) != 1 (dim 0)

`activations` looks exactly as I'd expect - 2 activations, then 1, then 2. The failure is on the line I'm unclear about, and fails as I'd expect. But, presumably the code in this book is tested (the book is excellent) and I must be doing something wrong. I was writing an independent implementation and hit the same issue, so I was expecting to be able to take this code apart to figure it out - but I can't figure out how this is supposed to work, or why it works for the author.

I'd appreciate any insight on what I'm missing here. Thanks! :)"
Why do so many people use Python when C or C++ is much faster?,12,0,False,False,False,learnmachinelearning,1509916549,True, 
TensorBoard:TPU Compatibility,1,1,False,False,False,learnmachinelearning,1509918702,True,"Looking the TensorBoard graph: TPU Compatibility

I see that  a number of steps in my model are partially red. I can't find any documentation to explain this.  Any one got some guidance. Thanks."
Reinforcement Learning Clarification,0,1,False,False,False,learnmachinelearning,1509920118,True,"I've been watching the ""RL Course by David Silver"" and I'm on the 3rd lecture and I just wanted some clarification about Reinforcement Learning 

My first question is regards to Partially Observable Markov Decision Processes and how it applies to Reinforcement Learning.  

For example if I were to train a network to learn to play a trading card game such as Yu-gi-oh or Hearthstone, the decision process would have to be partially observable as the agent does not know all the cards the opponent is using.  Where as chess and such are regular MDP as the entire board state is known at all times.

My second question is about the reward function and how it is defined in some scenarios.  As mentioned in the lectures, for environments with defined rewards such as score and such, it is easy to map an action to a reward, but for games like chess or even more complicated games, how would such reward be defined?

Thanks!"
Which situations should you use a regular ReLu activation function or a 'Leaky' ReLu activation function ?,9,13,False,False,False,learnmachinelearning,1509920124,True, 
[Project] A PyTorch implementation of Paragraph Vectors (doc2vec),0,2,False,False,False,learnmachinelearning,1509920857,True,"I'm implementing a library for training paragraph vector models as proposed by Q. V. Le et al. (Distributed Representations of Sentences and Documents). The code is available on GitHub: https://github.com/inejc/paragraph-vectors

Feedback would be much appreciated. Contributions in any form are also more than welcome (see opened issues on GitHub)."
Why were sigmoid and tanh used as activation functions in the first place?,3,6,False,False,False,learnmachinelearning,1509922216,True,There seem to be many disadvantages to them for deep learning. But I'm guessing there was a reason for them to be used in the first place?
Keras Val_loss,14,1,False,False,False,learnmachinelearning,1509922960,True,"Is Val_loss the loss across the entire training set, batch or the expected loss on one item?

An example for clarity (hopefully), I have 10 images and a value loss of 10. Does this mean I should expect the loss of one per image or 10 per image?


"
"Where can I download a free copy of Introduction to machine learning with Python, by Andres Müller",0,0,False,False,False,learnmachinelearning,1509928741,True, 
Proving PAC Learnability,0,2,False,False,False,learnmachinelearning,1509933705,True,"I'm trying to prove that a hypotheses space is PAC learnable from an example in class and can't figure it out.

We have X which is out discrete instance space.

H is our set of hypotheses over X, which contains all singleton functions and an all negative function.

How can I show that H is PAC learnable while providing a upper bound on complexity?"
looking for a ML intro digital textbook that includes videos to read/listen to,0,3,False,False,False,learnmachinelearning,1509935183,True,"1) need to be able to search within the textbook. 

2) also need it to have the highest rating out of the options. highest rating from many reviews 

does anyone know?"
What is data augmentation?,0,1,False,False,False,learnmachinelearning,1509942207,False,[deleted]
Writing Tips: How To Write Better Charcaters,2,0,False,False,False,learnmachinelearning,1509945716,False, 
GAN Playground - Experiment with Generative Adversarial Nets in your browser. A good way to get started with GANs.,1,25,False,False,False,learnmachinelearning,1509958655,False, 
"Good visual resources for SVM, random forests, and other bagging methods?",0,3,False,False,False,learnmachinelearning,1509959637,True,"Hi, im working on a project involving SVM and various bagging methods, and i was wondering if there were any good resources (text or video) that gave a good visual intuition for SVM and bagging methods (random forest especially).

I have Intro to Statistical Learning and other ML texts, but I was wondering if there were any good video resources that describe these algorithms, especially through a visual context since it seems like SVM has a rich geometric intuition behind it. For context, I have mathematical background with linear algebra and probability, and programming background in Python, along with knowledge of Naive Bayes and logistic regression, I just lack knowledge of other ML algorithms."
Ruuh: AI bot from Microsoft is Savage,0,0,False,False,False,learnmachinelearning,1509971070,False, 
Best solution for classifying large texts?,3,1,False,False,False,learnmachinelearning,1509977830,True,"I am trying to build a Neural Network to classify movie genres based on the movies subtitles/dialogue. However I have trouble finding the right model to base my network on. Most of the models I have found that can deal with text are built for words/phrases, not for large sequences of text like in this case. 

The requirements for the model are:

* Needs to be able to deal with variable input size. No subtitle sequence is the same length.

* Needs to work on about 5000 samples.

* Ideally provide information about key phrases/words that are most decisive on picking the genre.

* Ideally work with 'context' in the text. I would imagine there is lots of information lost if I were to use a bag of words approach. Although I am not fully able to argue why one or the other is better. 


I considered Convolutional Neural Networks(**CNNs**) but I don't think it would be a fit in this application.

I have used CNNs before and at the time I was absolutely amazed by them and so they were my first thought. The application I used was classifying action based on a number of game frames. For those interested I followed [the Python plays GTA V tutorial](https://pythonprogramming.net/game-frames-open-cv-python-plays-gta-v/) on PythonProgramming.net. 
Why would this not work? CNNs work well with image sequences, which is pretty much the opposite of what I'm trying to deal with now. Static text. Unless however we would try to incorporate the timing of the subtitles which would make it a bit less static.


Unfortunately I am not very familiar with language models so a big part of this question is about learning more about that as well. I've got some keywords that were suggested to me but I don't know what way to implement them. (bag-of-words, one-hot, n-grams)


If anyone has any experience with this or has useful suggestions I would love to know! "
Resources for architecting a simple Neural Network or other AI concepts that may be better for my application?,1,1,False,False,False,learnmachinelearning,1509982123,True,"I'm trying to build a candy sorter, and my strategy is to measure a photoresistor's value when different colors of light are shined on a candy. 

I'm thinking I'd shine some combination of Red/Green/Blue/White lights, so my input would be between one and four photoresistor measurements (integers between 0 and 1023). 

My output would be 3 bits that would map to 8 outputs possibilities. I'm thinking this makes for a very simple neural network that would be a good learning experience to architect my own.

My question is: what are some good resources (maybe a tutorial to follow that I can adapt) for architecting a very simple NN, OR what other types of AI (maybe a clustering algorithm) would be a good application for my problem above? Thanks!"
Math Curriculum/Textbooks?,2,3,False,False,False,learnmachinelearning,1509993756,True,"I am a self learner and I would like the math background required in order to understand Murphy's Machine Learning book.  As of now I am a Machine Learning engineer so I'm not too focused with applied courses, but would like to be able to delve into modern research/papers. I've gone through or am going through the following books:

* How to Prove It, Velleman
* Vector Calculus, Linear Algebra, and Differential Forms: A Unified Approach, Hubbard
* Introduction to Statistical Learning
* Statistical Inference, Casella

Assuming I can get through these books are there any others you'd recommend (especially statistics as I feel that is my weakest area) before tackling Murphy? Also does anyone have any engineering focused books they'd recommend? I recently read Data-Intensive Applications and found it very useful.
"
How do we count the number of cars in a video?,3,3,False,False,False,learnmachinelearning,1509994210,True,"I have a video and i want to count the number of cars in it, so how can i do this, should i crop the car images in the video or is there another way, i will be using python"
Is there a Reason to use a CNN on a 4x4 grid? Would there be no benefit?,9,6,False,False,False,learnmachinelearning,1510005428,True,"For making a 2048 solver, I was thinking that it might be natural to use a CNN because it takes adjacency into account and can identify significant features/patterns. However, since it's only a 4x4 grid, I'm not sure a CNN would give any benefits over a totally connected Neural Network. Any thoughts?"
Best services for running neural networks on?,3,4,False,False,False,learnmachinelearning,1510005931,True,I'm currently trying to train an lstm network will 188 input neurons and my computer just isn't cutting it. What's the best cloud computing service to run my code on? I'm mostly using VB.Net.
[D] Has there been any studies done on the trade off when using piecewise-linear activation functions (ReLu) vs traditional non-linear activation functions (logistical/circular) for modeling high curvature non-linear activity?,2,2,False,False,False,learnmachinelearning,1510008983,True,"As I understand, combinations of piece-wise linear functions can be used to approximate curative, as explained here 

https://stats.stackexchange.com/questions/299915/how-does-the-rectified-linear-unit-relu-activation-function-produce-non-linear

How, you need a lot of combinations to approximate curvature. Where as you would need significantly less when using a combination of curved function. At least that's my assumption. 

Thoughts? "
At tensorflow they say you only need to know python and arrays to learn how to get started. Is it really that newbie-friendly? (I do understand it might get complicated later though),12,21,False,False,False,learnmachinelearning,1510010350,False, 
A gist for anyone having trouble connecting and accessing Jupyter from AWS (P2)instances,0,2,False,False,False,learnmachinelearning,1510022195,False, 
[P] I implemented a Q Learning agent to solve Lunar Lander in 1 Hour on CPU. You can reuse the agent easily to solve other challenges.,3,22,False,False,False,learnmachinelearning,1510027928,False, 
How to structure model to give 1 output per row for an image?,8,1,False,False,False,learnmachinelearning,1510041785,True,"Hi All,

I'm trying to use machine learning to find a path from the top of an image to the bottom.  The image itself contains a noisy line from top to bottom and i'd like the model to predict which column in each row of the image is closest to the line.  I have lots of sample data to train on where each sample consists of the image and then an array of columns of length number of rows.  

I could create a ""category"" for each column and have it try to predict which category fits best but is this the correct way?

Here is sample image - https://imgur.com/CDGA5hx

Thanks"
How do I go about implementing this recommender system?,1,3,False,False,False,learnmachinelearning,1510060253,True,"There are numerous paths I have in my data set (that others have taken). Each path has some steps. Given some steps (let's say these exist in the training data too), can I get the next step to be taken based on the data set? Say, I have these paths - 
1. eat -&gt; sleep -&gt; anime 
2. sleep -&gt; anime -&gt; eat -&gt; bath 
3. sleep
If I have done ""eat -&gt; anime"", what should I do next? Will it be better if some sort of ""satisfaction value"" is associated with each step/path? I am kinda new, so please be gentle :3."
Reasons why an LSTM network does not improve,17,2,False,False,False,learnmachinelearning,1510072220,True,"I'm currently in the process of testing my LSTM neural network based on Siraj's lstm network seen [here](https://github.com/llSourcell/LSTM_Networks) but my version is created in vb.net and I am using my LSTM to generate Midi. My code seems pretty much identical to the one in the link but after 54 training files (roughly 200k+ timesteps) the loss seems to have only decreased by about 0.01 on average. I'm fairly certain the code is the same after checking many times so is there any other reasons a network would fail to train. 

Some other details are the network has 188 input neurons and 188 output neurons with a single lstm cell. It used RMSProp to update the weights.

Thanks for any help :)"
Keras: Zero Padding Pre-Trained Model,5,5,False,False,False,learnmachinelearning,1510085672,True,"I want to zero pad my images before they are passed to the  pre-trained model ResNet50.  (Easier than modifying a large numpy array)

There is an example how to append layers to the ResNet50 model but not how to append the ResNet50 to existing layers.   Any Hints?

Thanks for the direction."
"Convolutional-Deconvolutional Regressor network is getting stuck in a local minima, can't get it out",2,6,False,False,False,learnmachinelearning,1510087225,True,"I'm working on a toy project to identify topography from satellite image date. The main purpose of the project is just to get my hands dirty with ML, so it might not be solvable, but I'm running into a strange issue and wondering if I could get the community's help.

My network seems to be getting stuck at a point at which the error not only fails to decrease, but it fails to change entirely.
I've tried:

* Changing the learning rate and other optimizer parameters
* Trying a different optimizer (I have tried Adam and RMSProp)
* Clearing my saved weights and restarting the training
* Thoroughly investigating the data I'm passing into the net to make sure it's not all corrupt or something
* Getting more data
* Increasing the size of the convolutional filters, since I've read that larger networks are less likely to get stuck, since they have more paths to try
* Hopping on one leg while patting my head and praying to the gods of ML
* Restarting my computer

What I find really strange is that even when I restart the training from scratch, it gets down to the same region of error.

Also, an earlier version of my network was able to perform better. The only major thing I changed from that earlier version was that it was originally set up to take a fixed size input, and I modified it to take variable size input, since that seemed like something I should have done initially. Another thing I've tried is forcing the input to this to be fixed size, thinking maybe the net was getting confused with all the different sizes. It's still set up to take a variable size, but I've modified the incoming training data so that it's all the same size. Same issue.

**Code:** https://github.com/nbelakovski/topography_neural_net/blob/master/neural_network.py

**Page showing the input image/label/sample output:** nbelakovski.github.io/topography_neural_net/index.html

I apologize for throwing my entire code at you guys, I certainly don't expect anyone to go through it and figure out my problem for me, but obviously I couldn't post this question without linking to it. I'm more than happy to do more work to try to present my problem more clearly.

I'd appreciate any help or suggestions you guys could provide! Really want to get past this issue!

**Update** I had some interesting discussions with users on this subreddit's Discord server. The suggestion was that maybe my network was hitting a global maximum for its design, and that the earlier network that performed ""better"" was actually just learning the data rather than anything generalized (which could make sense since I added significantly more data since training that one). There was a suggestion to look at training error as compared to validation error (I was looking at the latter), which I didn't get a chance to implement because I tried other suggestions to just make the network a lot bigger (in this case I dramatically increased the number of feature maps), and this got me unstuck. Thanks all!"
Is this Udacity course paid only?,16,2,False,False,False,learnmachinelearning,1510092771,True,"Hi,

I came upon this upcoming course today: https://www.udacity.com/course/deep-learning-nanodegree-foundation--nd101

I can't seem to be able to find a way to enroll freely to it, though. Is this course paid only?

Thanks!"
Representing error rates as confidence levels of different models.,1,2,False,False,False,learnmachinelearning,1510119247,True,"Hello.
So i'm trying out different feed forward models (wide, deep) on my data set, which returns mean error and a +/- std. deviation upon training (this is obtained using cross validation).
I want to be able to represent the results of these models graphically. Something which can best represent which model is better among the others.

Currently plotting errorbars, but looking for other options.

Thanks!"
TWIL (This Week I Learned) - Share something new that you have learned this week!,1,2,False,False,False,learnmachinelearning,1510124714,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
Policy Gradient Theorem: Why is the reward treated as if it does not depend on Theta?,5,2,False,False,False,learnmachinelearning,1510136538,True,"In all derivations of the Policy Gradient Theorem I saw so far e.g. 

* http://karpathy.github.io/2016/05/31/rl/
* David Silver Lecture 7: https://youtu.be/KHZVXao4qXs?t=48m34s
* ...

The reward is treated as if it does not depend on \Theta (the parametrization of the policy). However, in my understanding the reward depends on the trajectory taken, with itself depends on the parameterization \Theta. Therefore, the reward should depend on \Theta. 

In more details with

* p(x) probability that a given path/trajectory is taken. 
* f(x)  Reward collected by taking the path/trajectory   

in the calculation of gradient of the expected value of

E[p(x)*f(x)] 

wtr to \Theta f(x) is treated as if it does not depend on \Theta, yielding (with a few standard tricks) to:

E[f(x)\grad log(p(x))]

What is my mistake? Any help is very well appreciated.
"
Question | Basic Chain Rule Implementation | Python,6,2,False,False,False,learnmachinelearning,1510142078,True,"Hi there! 

The task of this assignment is to calculate the partial derivative of the loss with respect to the input of the layer. You must implement the Chain Rule. 

I am having a difficult time understanding conceptually how to set up the function. Any advice or tips would be appreciated! 

The example data for the function variables are at the bottom. 

    def dense_grad_input(x_input, grad_output, W, b):
        """"""Calculate the partial derivative of 
            the loss with respect to the input of the layer
        # Arguments
            x_input: input of a dense layer - np.array of size `(n_objects, n_in)`
            grad_output: partial derivative of the loss functions with 
                respect to the ouput of the dense layer 
                np.array of size `(n_objects, n_out)`
            W: np.array of size `(n_in, n_out)`
            b: np.array of size `(n_out,)`
        # Output
            the partial derivative of the loss with 
            respect to the input of the layer
            np.array of size `(n_objects, n_in)`
        """"""

        #################
        ### YOUR CODE ###
        #################
        return grad_input        
________________________________________________________________________

    #x_input
    
    [[ 0.29682018  0.02620921  0.03910291  0.31660917  0.6809823   0.67731154
       0.85846755  0.96218481  0.90590621  0.72424189  0.33797153  0.68878736
       0.78965605  0.23509894  0.7241181   0.28966239  0.31927664  0.85477801]
     [ 0.9960161   0.4369152   0.89877488  0.78452364  0.22198744  0.04382131
       0.4169376   0.69122887  0.25566736  0.44901459  0.50918353  0.8193029
       0.29340534  0.46017931  0.64337706  0.63181193  0.81610792  0.45420877]
     [ 0.24633573  0.1358581   0.07556498  0.85105726  0.99732196  0.00668041
       0.61558841  0.22549151  0.20417495  0.90856472  0.43778948  0.5179694
       0.77824586  0.98535274  0.37334145  0.77306608  0.84054839  0.59580074]
     [ 0.68575595  0.48426868  0.17377837  0.5779052   0.7824412   0.14172426
       0.93237195  0.71980057  0.04890449  0.35121393  0.67403124  0.71114348
       0.32314314  0.84770232  0.10081962  0.27920494  0.52890886  0.64462433]
     [ 0.35874758  0.96694283  0.374106    0.40640907  0.59441666  0.04155628
       0.57434682  0.43011294  0.55868019  0.59398029  0.22563919  0.39157997
       0.31804255  0.63898075  0.32462043  0.95516196  0.40595824  0.24739606]]
    
    #grad_output
    
    [[ 0.30650667  0.66195042  0.32518952  0.68266843  0.16748198]
     [ 0.87112224  0.66131922  0.03093839  0.61508666  0.21811778]
     [ 0.95191614  0.70929627  0.42584023  0.59418774  0.75341628]
     [ 0.32523626  0.90275084  0.3625107   0.52354435  0.23991962]
     [ 0.89248732  0.55744782  0.02718998  0.82430586  0.73937504]]
    
    #W
    
     [[ 0.8584596   0.28496554  0.6743653   0.81776177  0.28957213]
     [ 0.96371309  0.19263171  0.78160551  0.07797744  0.21341943]
     [ 0.5191679   0.02631223  0.37672431  0.7439749   0.53042904]
     [ 0.1472284   0.46261313  0.18701797  0.17023813  0.63925535]
     [ 0.6169004   0.43381192  0.93162705  0.62511267  0.45877614]
     [ 0.30612274  0.39457724  0.26087929  0.34826782  0.71235394]
     [ 0.66890267  0.70557853  0.48098531  0.76937604  0.10892615]
     [ 0.17080091  0.57693496  0.19482135  0.07942299  0.7505965 ]
     [ 0.61697062  0.1725569   0.21757211  0.64178749  0.41287085]
     [ 0.96790726  0.22636129  0.38378524  0.02240361  0.08083711]
     [ 0.67933     0.34274892  0.55247312  0.06602492  0.75212193]
     [ 0.00522951  0.49808998  0.83214543  0.46631055  0.48400103]
     [ 0.56771735  0.70766078  0.27010417  0.73044053  0.80382   ]
     [ 0.12586939  0.18685427  0.66328521  0.84542463  0.7792    ]
     [ 0.21744701  0.90146876  0.67373118  0.88915982  0.5605676 ]
     [ 0.71208837  0.89978603  0.34720491  0.79784756  0.73914921]
     [ 0.48384807  0.10921725  0.81603026  0.82053322  0.45465871]
     [ 0.56148353  0.31003923  0.39570321  0.7816182   0.23360955]]
    
    #b
    
    [ 0.10006862  0.36418521  0.56036054  0.32046732  0.57004243]"
Common diagrams,0,1,False,False,False,learnmachinelearning,1510149196,True,"Hello everybody,
I am looking for a collection of common diagrams used in machine learning and how to interpret them. An example could be a diagram where the trainings and validation loss are plotted over the epochs. The interpretation could be overfitting or so.
Thanks in advance
Fettpet"
Hero of Deep Learning's an advice for college students,6,25,False,False,False,learnmachinelearning,1510151735,False, 
Neural network for predicting an arbitrary curve?,4,1,False,False,False,learnmachinelearning,1510152711,True,"I want to fit an arbitrary one-dimensional curve (which is the output of an analytical/numerical function) which can be quite complex, so it can't be easily parameterized as a Taylor series, Fourier transform, etc. Is there a standard way of doing this, particularly with neural networks? Or perhaps with other machine learning methods? Right now I am discretizing the curve and essentially doing multi-variate regression using a fully-connected neural network. It works fine, but it just seems a bit awkward."
Looking for some friendly advice?,12,2,False,False,False,learnmachinelearning,1510159656,True,"Hi, wondering if some of you could clarify something for me. I'm trying to apply a neural network to a problem that involves multiple inputs and multiple outputs. 

This isn't my scenario but it is similar: lets say we have a switch under every seat in a lecture theatre. We also have a square grid of LEDs. When someone sits on a seat, a corresponding LED lights up on our display grid. So as the cinema fills up, the lights gradually all light up.

Say I want to try to predict the probability that a particular seat is about to be sat in, based on which seats are occupied in the cinema right now. 

I've got lots of data which consist of snapshots of the grid taken at 2-minute intervals, on lots of occasions.

I want a list of probabilities for each seat, so I could say ""the most likely seat that will be sat in, given the current state of the seats, is x"".

Although it's 'time-series' prediction in a way, I feel that LSTM would not be suitable but I could be wrong?

Do I treat the grid as a picture and use a convolutional neural net on it? 

I feel like this problem is conceptually trivial and I should easily understand the best approach but I haven't found similar examples and I could just do with some constructive advice!

Thanks!


"
AWS: Graphics Instance vs GPU Instances,0,1,False,False,False,learnmachinelearning,1510170718,True,I can run TensorFlow and Keras on a Graphics Instance instead of a GPU instance. Is there a performance reason why I can't use them?  The Graphics Instance spot price is cheaper and more stable.
Machine Learning Glossary - Organized like Documentation,7,40,False,False,False,learnmachinelearning,1510171291,False, 
Which metric to use to evaluate a model used for ranking?,0,1,False,False,False,learnmachinelearning,1510171810,True,"Hi all,

I'm working on a model which will be used to estimate the priority ranking of a backlog of work. E.g. ""given these jobs, which one is best to do first?"".

I have data which includes a measurement of how ""good"" each job was, so I can train the model to predict that goodness score.

However, in the end (for details I'll omit for brevity) I care less about accuracy of this goodness prediction, and a lot more about accuracy of the overall ordering of _all_ the jobs.

I don't believe I could use this overall ranking accuracy metric as the loss function for training (but if I'm wrong, do tell!). However, I could evaluate the ordering as a separate step after training.

It seems there should be an accepted metric for how well a list is sorted. Does anyone have a suggestion for a good statistic for similarity between two lists—one sorted perfectly, one sorted imperfectly?"
How do kernels in SVMs give rise to decision boundaries?,0,2,False,False,False,learnmachinelearning,1510177030,True,"Hello, I trying to figure out how the kernel trick gives rise to a decision boundary. In my particular case I'm looking at string kernels where strings are classified. I get that kernelization helps to make decision boundaries for nonlinearly seperably data but whenever they're explaining they usually only seem to show how the dot product give you a similarity score between two data points not how it partitions a set of data into 
two categories.

https://www.quora.com/What-are-kernels-in-machine-learning-and-SVM-and-why-do-we-need-them

 For example in this above link the Lili commentator simply gives an example of what looks like two datapoints in 3d space (x and y) and calculates the dot product between them. But I don't see an explanation about how this product can be used to determine similarity between the two points or how it can be extended into a decision boundary between two groups of points. 

Does someone have some insight in regards to this? "
Seeking peer review/discussion on an assignment I'm completing for job application.,0,1,False,False,False,learnmachinelearning,1510187550,True,"Hello, this is a classification problem with limited opportunity for feature engineering.  I'm using a random RandomForestClassifier, and GridsearchCV to tune the hyper parameters.  I have two questions 1. Have I implemented the random forest in the best possible way (will share my notebook) 2. Where should I focus the rest of my efforts, try more classifiers, or do more with the random forest.

Down to chat wherever."
Intel portal to learn Machine Learning,4,13,False,False,False,learnmachinelearning,1510189111,False, 
Machine Learning and the Internet of Things – Bolt IoT,0,1,False,False,False,learnmachinelearning,1510198930,False, 
"The linear algebra in linear regression is so weird, can someone help me with this particular trick?",15,3,False,False,False,learnmachinelearning,1510206644,True,"I have the following algebra to decipher:

https://imgur.com/a/664OY

related to solving for the coefficients via the residuals equation

where X is the feature vectors stacked on top of each other, and B is the coefficients, and y is the actual value (not the predicted value)

Please help me decipher this alien language :D

(also if you know any tutorial of sorts related specifically to least squares / linear regression, I would greatly appreciate the extra guidance!)"
"who were the first few ppl that personally (with intention) invented the technologies directly leading into the existence of ML, as ML is understood currently?",1,0,False,False,False,learnmachinelearning,1510210204,True,"who were the first few ppl that personally (with intention) invented the technologies directly leading into the existence of ML, as ML is understood currently?"
Looking for a Mentor/Buddy to learn machine learning with.,26,26,False,False,False,learnmachinelearning,1510231911,True,I've trying learning on my own but I've failed miserably. I've been trying for the past 1.5 years but I haven't got anywhere with myself. I'm too lazy and procrastinate whenever I feel deviating from the right path. I would be happy if someone could help me on this journey. 
Nvidia Deep Learning Institute Workshops to be held in 6 cities in India,0,1,False,False,False,learnmachinelearning,1510236885,False, 
More dimensions vs larger data type?,3,1,False,False,False,learnmachinelearning,1510242810,True,"In neural networks, why does ""one hot encoding"" work better when doing classification  (e.g. [0, 0, 1, 0] instead of [3])? Similarly, when training a siamese network to do metric learning, I suppose that picking an N dimensional float32 vector works better than a float64 vector with half the dimensions.

From an information theoretic perspective, both representations take up the same amount of bits so it's a bit weird to me that using more dimensions tends to work better.

If anyone can help me gain an intuition about this, I would be immensely grateful!"
Image classification / detection - Objects being used in real life vs. stock photo images?,1,1,False,False,False,learnmachinelearning,1510248493,True,"When training detection models, are images that are used in real life better (i.e. higher accuracy / mAP) than images of the same object but in the form of stock photo? i.e. https://i.stack.imgur.com/Mh9Lo.png"
Is there an efficient way to do online learning (w/ adaptive optimizer) with LSTMs? Maybe with PyTorch?,1,2,False,False,False,learnmachinelearning,1510255076,True,"Currently, I have a tuned LSTM model that is being used in ""production"". I get new data every day which I have to re-train my model on. Ideally, I'd just load my model and then train it on that new data. But unfortunately, you cannot do that with Keras if you are using an adaptive optimizer because the learning rate gets reset every time you begin training ([at least that is my understanding](https://github.com/fchollet/keras/issues/1868)).

So two questions:

 -- am I correct in my understanding that as long as I am using an adaptive optimizer, say Adam, I will not be able to use Keras for online learning?

 -- are there frameworks out there that can handle this type of situation? I know PyTorch is supposed to be a little more flexible so I was considering that, but I don't want to be spinning my wheels if it doesn't.

Thanks in advance for any insight!"
How do I approach my ML-data-scraping problem?,4,1,False,False,False,learnmachinelearning,1510258459,True,"I want to build a data-scraping / machine learning tool that will look at several hundred competitor domains and return the price and other details about their products on a frequent basis. This data would go A) into a spreadsheet for further analysis, and B) onto a comparison website for the world to see.

I understand Python is popular for some data-scraping use cases but (I think) I'd require more comprehensive ML tools to get good quality, clean data - perhaps using computer vision on screenshots of the websites?.. I believe this is essentially what [DiffBot](https://www.diffbot.com/) and [Import.io](https://www.import.io/) do.

I'm a complete beginner having recently started (Andrew Ng's ML Coursera course)[https://www.coursera.org/learn/machine-learning?utm_source=gg&amp;utm_medium=sem&amp;campaignid=693373197&amp;adgroupid=36745103675&amp;device=c&amp;keyword=andrew%20ng%20coursera&amp;matchtype=e&amp;network=g&amp;devicemodel=&amp;adpostion=1t1&amp;creativeid=156061453600&amp;hide_mobile_promo&amp;gclid=Cj0KCQiAlpDQBRDmARIsAAW6-DPjxetkJURJzbHI1nr1DS_6HFoRGcK9SYWInhVSaMb3JYzL8GeoU_0aAjP7EALw_wcB]. Does anyone have any ideas for next steps and how to piece together a solution? Many thanks"
Active Learning for (Multivariate) Regression?,1,1,False,False,False,learnmachinelearning,1510262802,True,"There's a lot of literature on using active learning for classification, but does anyone know any seminal work on active learning for regression? How does the query strategies change for regression, and in particular, for multivariate regression?"
Machine Learning for Cyber Security,1,31,False,False,False,learnmachinelearning,1510264987,False, 
Little shortcut for learning new APIs,2,4,False,False,False,learnmachinelearning,1510284550,True,"Hi everyone, I'm a little new to the community, but I thought I'd offer up a little tool that's been helping me, maybe it'll help someone else as well. 

I've had language learning as a hobby for the last 15 years or so, so I've spent a lot of time experimenting and exploring different ways to learn and retain a lot of information. One of the more useful tools for that is [Anki](https://apps.ankiweb.net/). It almost feels silly mentioning this tool here, but I figure maybe not every community is so familiar with SRS. . It's just a simple little tool for making flash cards and reviewing them at appropriate time intervals, but it's a great way to make certain kinds of notes and make sure you don't forget them over time. 

It's NOT good for trying to just rote memorize abstract concepts you don't fully understand, so I'd hesitate to recommend it for any underlying theory, but it's an amazingly helpful little tool when getting comfortable with simple, discrete mappings between intention and syntax. It's free, syncs up with the phone for review on the go, and works with LaTeX (with a little work) if you did decide to use it for some equation memorizing too. 

Course, nothing like getting into this field to start imagining more powerful possibilities, but... for now, we use the tools we have I guess. "
A nice Jupyter-based tutorial for 'Deep Learning For NLP in Pytorch',0,4,False,False,False,learnmachinelearning,1510292675,False, 
Anyone know of some good regression problems on kaggle for beginners (outside of the 'getting started' category) post them here!,0,7,False,False,False,learnmachinelearning,1510293025,True,"My friends and I are looking to get started from the basics, so we just want some solid foundational competitions to try out as we learn, since the text book were using didn't post their solution manual, and the author didnt respond =D"
About to finish the 2011 Andrew Ng machine learning course. What course should I do next? Coursera? Udacity? Other?,11,10,False,False,False,learnmachinelearning,1510294146,True,"I've already been working on ML projects and have a good math background. 

Someone a while back recommended the 2011 Andrew Ng course a while back to tie together my back and hobbiest ML background and it was the perfect recommendation. 

I would love to continue this course format to get a deeper understanding of theory and most prominent techniques. 

The two most prominent options that I know of are Coursera and Uadacity? And even among those two companies, they both offer several courses. 

Are there any good recommendations? This is a guy who has done a few ML projects already and will continue to do so, and already has a good math background (linear algebra, stats, optimization, numerical methods, etc). "
Weekly Show-off!,1,2,False,False,False,learnmachinelearning,1510297519,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
Modified Actor Critic Agent Achieves Super Human Level in Open AI Lunar Lander Test. Code in description...,0,3,False,False,False,learnmachinelearning,1510301427,False, 
Biologically Relevant Datasets on Kaggle,0,1,False,False,False,learnmachinelearning,1510305509,True,[removed]
More evidence that humans and machines are better when they team up,0,3,False,False,False,learnmachinelearning,1510318262,False, 
FPGA Engineer looking to join/ start group learning/ implementing ML,12,14,False,False,False,learnmachinelearning,1510327316,True,"Experienced FPGA engineer with 30 years experience developing high performance applications looking to join or start a group learning or currently working on ML problems. 

I've worked at SpaceX and companies developing Cognative Radios for DARPA. Also early graphics and networking companies.

I'm really good at fast and efficient implementations, but I'm just getting started in ML. Currently I'm working at a trading company, so NLP seems the most applicable for me, but I'd be willing to work on any projects that help me get started.

I have started the Andrew Ng course, but it's slow going for me.

I'm physically located in Naperville/ Chicago Il, but working together remotely is an option too."
Looking for books/papers about Kernel Methods from a functional analysis point of view,2,2,False,False,False,learnmachinelearning,1510348123,True,"Hello everyone,

first of all I hope this is the right ML subreddit to post this in as this is my first post in any of them! 

I'm currently finishing up my Bachelor in math with a focus on functional analysis and recently got interested in the whole machine learning topic. This way I just got introduced to Kernel methods (via Mercer's Theorem). Because I think that this topic is really interesting I would like to ask, if you guys have any recommendation about books/papers, that take a close look at this topic from a mathematical/functional analysis point of view.  "
How can I use a set of 100x100 to 64x64 image mappings to convert the rest of my 100x100 images?,3,1,False,False,False,learnmachinelearning,1510358555,False, 
What do I need to know about concurrency/parallelism/map reduce in machine learning?,1,1,False,False,False,learnmachinelearning,1510367990,True,"Andrew Ng mentioned this in his 2011 course. I looked it up on youtube and there's not much on there. 

Is this important for me to learn? Do all ML careers need to know this? If so, where can I learn the required skills? "
web developer to machine learning,6,6,False,False,False,learnmachinelearning,1510383637,True,"I've been a full stack web developer for about 5 years now and am starting to dislike that 60% of my time is spent creating mechanisms that prevent the user from breaking forms or features on a site and I'm getting bored of it. At work we are implementing some machine learning but are looking to hire for it and I figured maybe I could do it. I am entirely self taught and learning machine learning would be fun especially since I think the subject is incredibly interesting.

My only concern however is that I really enjoy creating and so far my machine learning studies have shown it's more of a finding answers in data kind of paradigm. With the constant reminder of statistics, linear algebra and data science I feel like I might not think machine learning is what I thought it would be. I am a code monkey and it seems like a lot of ML is research and prep work then only a few lines of code in Python or R.

Anyone experienced this when first learning? The fact that ML seems to have very little with coding makes me feel like I won't enjoy it since I like to spend hours just writing code."
"Weekly Status Check Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",6,2,False,False,False,learnmachinelearning,1510383909,True,"Let's have a  meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
[Coursera] How to download all the assignments jupyter notebooks and files,1,3,False,False,False,learnmachinelearning,1510393778,True,"I am wondering if there is a way to download all the assignments jupyter notebooks and files from https://hub.coursera-notebooks.org.

I am already using `coursera-dl` to download the videos and it works great, but I am missing an analogous tool for the assignments.

Otherwise, I could download them manually one by one, but it is annoying !"
Is it worth me adding features to my data or would a machine learning algorithm find these itself?,4,10,False,False,False,learnmachinelearning,1510398770,True,"I'm just getting into machine learning and I think the dots are starting to connect but I have a high level question to try and help my understanding.

I've heard deep learning algorithms described as an ""infinitely flexible function"".

I have a regression data set of financial data - dates with open, high, low, close number values.

When I'm preparing my data, is it helpful to add extra column features to my data, things like a moving average, or MACD indicators, or would the training algorithm find these patterns itself and therefore it's not helpful? (or potentially even misleading).

Does that makes sense?

Thanks."
Simple Deep Learning Model for Stock Price Prediction Using Tensorflow,2,53,False,False,False,learnmachinelearning,1510410881,False, 
How to start DL4J(Deep Learning for Jave) for Windows,0,1,False,False,False,learnmachinelearning,1510411116,False, 
How do you know whether a dataset is useful for creating a classifier?,13,1,False,False,False,learnmachinelearning,1510418134,True,"I recently found the national math student's performance survey dataset. It has a lot of variables and the final result of whether the student is approved or not. Based on it, I'd like to be able to classify/predict the result.

I tried with sklearn's SVC and a Keras CNN without any success (literally, 0% of accuracy). Am I doing it wrong or is the data not enough to do what I want?

Edit: as suggested in comments, I was doing something wrong. I changed my code and now it's at 57%. However, is there a way to know if I can get a better result using the same dataset.?"
Popular machine learning algorithms,1,9,False,False,False,learnmachinelearning,1510420191,False, 
Visualization of different types of neural network,3,4,False,False,False,learnmachinelearning,1510425301,True,"https://drive.google.com/file/d/1DfRkU-TG2ethiidHPX9abF5JUc2gXfRf/view?usp=sharing

I'm just trying to get into neural network. I think, the best way for me to learn things is to summarize my learning in my own way. To that end, I made this visualizations. Please tell me if I got anything wrong, so I can learn. Thank you.

edit: I'm representing neural network as a [directed graph](https://en.wikipedia.org/wiki/Directed_graph) which is visualized through [Adjacency matrix](https://en.wikipedia.org/wiki/Adjacency_matrix#Directed_graphs). In this representation, the row and the columns are the nodes (neurons), while each cell is a synapse and the value is the weight of the synapse. For each synapse (cell), it connect the node (neuron) from the corresponding column, to the node (neuron) of the corresponding row. This, to find the weight of the synapse connection from a1 to b1, find the cell in the column a1 and row b1.

The weights are just random numbers. Cells without numbers shows that there's no connection/synapse between the corresponding nodes.

The nodes (neurons) are labeled in L_N (letter _ number) manner. The letter represent the layer, and the number represent the xth node in that particular layer. All the nodes starting with the letter 'a' (a1, a2, a3, ...) are the input nodes, thus 'a' is the input layer. All the nodes starting with the letter 'z' (z1, z2, z3, ...) are the output nodes, thus 'z' is the output layer. e.g.

* The node 'b1' is the first node of the second layer (first hidden layer).

* The node 'b2' is the second node of the second layer (first hidden layer).

* The node 'c1' is the first node of the third layer (second hidden layer).

* The node 'c2' is the second node of the third layer (second hidden layer).

The boxes in the middle shows the synapse between nodes in the same layer. This doesn't exist in MLP (multilayered perceptron). 











"
"Learn R coding for Geometric, Negative Binomial and Poisson distributions.",0,3,False,False,False,learnmachinelearning,1510430218,False, 
"Cross Entropy and softmax were really confusing to take the derivative of, so I made the following brain dead pdf guide, if any pros would like to review it, ill update it",1,12,False,False,False,learnmachinelearning,1510434832,True,"I'm not great with derivatives. In fact, I'm horrible with most math, but I get the concepts behind cross entropy and softmax, or at least I think I do. Cross entropy is telling us how much information we lose between two distributions. Softmax is turning a vector of scores into a distribution. Therefore, we can find out how much information we lost between the distribution of the target one hot encoded vector, and our distribution created by taking the softmax of some vector of scores (it could be the final output of a neural network for instance).

So here's my guide that tries to get through the gradient math in the dumbest way possible by avoiding index algebra as much as possible:

https://www.overleaf.com/read/hykntfmvchgg"
Monthly ELI5 (Explain Like I am Five) Thread,2,5,False,False,False,learnmachinelearning,1510442410,True,"Top comments need to be in the format of: `ELI5 $CONCEPT_NAME` and the replies should provide a clear explanation in a layman's term.
Here are the relevant rules from /r/explainlikeimfive breaking down the meaning of ""ELI5"":

- E is for Explain - merely answering a question is not enough.

- LI5 means friendly, simplified and layman-accessible explanations - not responses aimed at literal five-year-olds.
"
Issue with convergence with Stochastic Gradient Descent when approximating a sin curve with a polyonomial is not close to least squares solution,0,1,False,False,False,learnmachinelearning,1510453856,False, 
Issues with learning meaningful masks with unet segmentation networks,5,2,False,False,False,learnmachinelearning,1510455799,True,"Here's what encountered. Would appreciate if anyone has ideas to solve this problem. I'm training a rudimentary U-net to do semantic segmentation on small images 64X64. I have tried several different depth, initialization schemes, optimizers etc. All of the configurations learn basically all zeros or ones (the ground truth is a binary mask image). 
Two examples of the data (left), ground truth mask (middle) and prediction by the model (right) is given.
The weights of the trained model are all quite small. I have tried to train it for a long time (&gt; 200 epochs). The model usually quickly learns to map all pixels to zeros and gets stuck there.

https://groups.google.com/forum/#!topic/keras-users/0m7UBD_5cjw

Any suggestions are welcome!

edit: The image was not uploaded somehow. But it's in the link."
Why is the bias term in neural networks in the shape of the number of weights as opposed to just one bias term? (a*W + b),12,5,False,False,False,learnmachinelearning,1510464845,True,"in linear models, you have a single bias term like so:

w_1 * x_1 + w_2 * x_2 + , ... , + b_1

but it seems like in neural network implementations what is happening is

w_1 * x_1 + b_1 + w_2 * x_2 + b_2 + , .... , w_d * x_d + b_d

that doesn't really make sense to me. Shouldn't there only be a single bias parameter? Isn't the bias term just serving as a y-intercept essentially? Why does there need to be so many

As a concrete example, let's look at the beginning of a neural network with an input X

input X has dimensions Nxd

weights, W, has dimensions dxH

bias, b, has dimension 1xd

We do X dot W + b

which means that the (1,1) cell, IE the first cell, in the resulting NxH matrix is

x_1 * w_1 + b_1 + x_2 * w_2 + b_2 + , .... , x_d * w_d + b_d

Please anyone who understands this, I would seriously appreciate the help!"
val_loss: 1.1921e-07 - val_acc: 0.0715 How is that possible?,2,1,False,False,False,learnmachinelearning,1510479123,True,"I am currently training this model: https://pastebin.com/F7dQvmZP. When i trained it with only 1 feature (raw data) per timestep i got a loss of ~1.3 and an accuracy of ~57%. After adding the direction of change (1 if increased 0 if same -1 if decreased) as a second feature to each timestep my loss went down to ~0.8 and my accuracy increased to ~70%. Then i added a differently scaled version of the raw data as a third feature. This data is basically scaled such that the maximum reading during that timeseries is 1.0. Training this quickly results in a loss of ~1e-7 but the accuracy stays at ~7%. The input is composed like this

    np.dstack((measurements, change, scaled))        

I dont really know how that is possible since my outputs are one hot encoded and I only have 22 classes. The training data includes 291300 training and 97100 validation samples. It trains normal until I add the third feature. Any help would be appreciated.    "
Learning Machine Learning 0.1 - Machine Learning seen by a beginner: the basic key concepts,3,24,False,False,False,learnmachinelearning,1510481290,False, 
Any guides on how to tune a keras/tensorflow network using tensorboard?,1,3,False,False,False,learnmachinelearning,1510501564,True,"I can run code that outputs details to tensorboard (e.g. [iris](https://github.com/jacobmanning/ml-iris). How can I use this information: particularly scalars, distributions and histograms?

Is there a guide which has useful stuff like, if the graph looks like this then you should probably try to ....?"
Adding weight decay terms in ConvNets,0,2,False,False,False,learnmachinelearning,1510502416,True,"I have noticed that Tensorflow implementations of several popular ConvNets like ResNet or Squeeze and Excitation Net all use this kind of loss function:

    l2_loss = tf.add_n([tf.nn.l2_loss(var) for var in tf.trainable_variables()])
    optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, 
    momentum=momentum, use_nesterov=True)
    train = optimizer.minimize(cost + l2_loss * weight_decay)

This implementation adds up regularization terms for all ConvNet layers. Shouldn't we average the terms instead?"
Deconstructing Data Science,2,27,False,False,False,learnmachinelearning,1510503965,True,"Hey everyone! 👋

Yesterday I launched the second post of a new Data Science blog, where I’m open-sourcing every resource I find and insight I come across in pursuit of becoming a world-class (top 5%) Data Scientist in &lt; 6 months.

The purpose of this post is to empower others to start accelerating their own learning by:

1) deconstructing the complex craft of Data Science into it’s simple micro-skills

2) identifying the 20% of skills that contribute to 80% of outcomes

I'm writing this with learners like you and I in mind, so if you're also interested in accelerating your learning, check it out &amp; feel free to share around:

https://ajgoldstein.com/2017/11/12/deconstructing-data-science/"
How does Q-learning Neural net Chooses the best possible actions? Specially in a continuous action space case,1,2,False,False,False,learnmachinelearning,1510505081,True,"The Q learning neural net learns a reward function in terms of the current state and action, but how it picks the best action possible when using a neural net? Does it use some optimization algorithm? In a table it's obvious as it just use a max function, but a NN is more complex. "
Would like some direction on how I should focus my learning,2,1,False,False,False,learnmachinelearning,1510507040,True,"I'm currently a Masters student in Statistics. I've taken ML classes before (both supervised and unsupervised learning), and will be doing research in machine learning.

I would like to focus on developing my proficiency in machine learning on my own time, with the goal of going into data science or a role that involves machine learning . I would like some directions as to how I should prioritize my own education. I would personally want to improve my research skills, but I'm not sure how relevant that would be. Here are some things I am thinking about.

1. Focus on modelling/applications through things like kaggle competitions. I feel this might give me good practical experience, but I might be missing out on some research experience (although I'm not sure just how much research experience I would need. 

2. Focus on implementing ideas from research papers. This would definitely give me the research experience I would want, but one thing going against me on this path would be that for neural networks, I have little familiarity with TensorFlow, as I mostly focused on application using Keras in my projects. In order to follow this path I would most likely have to learn how to write custom code using tensorflow.

As an extra question, if I wish to write custom code, do I have to learn tensorflow, or is writing custom layers in keras sufficient?"
Getting word embeddings to work with optimizer?,0,1,False,False,False,learnmachinelearning,1510511504,True,[deleted]
Dropout Regularization with CNNs,3,0,False,False,False,learnmachinelearning,1510520716,True,"I've been following [this](https://elitedatascience.com/keras-tutorial-deep-learning-in-python) tutorial here on implementing CNNs in Keras. 

I have a couple questions about using dropout regularization in their code (scroll all the way to the bottom of the article if you want to see their code)

The CNN architecture used in the article is Conv2D --&gt; Conv2D --&gt; MaxPool --&gt; Dropout --&gt; Flatten --&gt; Dense --&gt; Dropout --&gt; Dense

I get the second dropout layer is randomly removing nodes from a fully connected neural network, but I don't understand what the first dropout layer is doing before we flatten images into a 1D array. Is it randomly removing a percentage of our training samples? What exactly is being dropped in that layer? "
How important is Linear Algebra?,7,19,False,False,False,learnmachinelearning,1510521083,True,"I haven't looked at this stuff since 1995. It's nice to flex my math skills, but I'm the proverbial old guy in the gym rapping along to Wu Tang on his iPod.  
  

My professor said it was vital for a deeper understanding of data science.  
Do you guys find it useful?"
Easy to use A2C agent that performs very well in various environments.,0,3,False,False,False,learnmachinelearning,1510536931,False, 
Summary of Deep Learning Architectures,1,2,False,False,False,learnmachinelearning,1510543315,True,"Hi all, I'm somewhat new to the deep learning area and while I've been able to find wonderful resources about the different kinds of layers out there (LSTM, CNN), I haven't been able to find a good summary or overview that describes what state of the art architectures look like. Could someone point me to one?

I'm particularly interested in a resource that goes over common problems and lays out what the state of the art architecture for that problem looks like. For example: ""Question answering is best solved by a neural net with 4 layers of X followed by 3 layers of Y..."""
What prerequisites are important for machine learning?,10,22,False,False,False,learnmachinelearning,1510543929,True,"I'm 15 and want to get into Ml. I'm wondering what i need to know before starting, obviously linear algebra, calculus, and some programming knowledge. Anything else? Is there any way to start learning ML without these? For example I have completed the [""Tensorflow for Poets""](https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#0) tutorial without any knowledge of Calculus or linear algebra. Are there other ways to learn ML without learning all the prerequisites? Basically the question I'm asking is **what, if anything, must i do before learning ML**"
How hard is it to build own PC,7,0,False,False,False,learnmachinelearning,1510549654,True,"Hi, I would like to build my own Deep learning PC. I am familiar with the Linux command line at a basic level. How hard is it to build something like this? https://pcpartpicker.com/user/latency/saved/G6fwP6 
Is there any step by step guide that is foolproof? "
Deep Learning for NLP,2,1,False,False,False,learnmachinelearning,1510554015,True,I'm looking to get started with applying deep learning for NLP and I was wondering if anyone had strong recommended books/blogs/other resources for efficient learning. 
What are the requirements for ML job. And how it's going on this career?,0,1,False,False,False,learnmachinelearning,1510561041,True,[deleted]
How to use neural networks to find parameters of a distribution?,1,6,False,False,False,learnmachinelearning,1510575306,True,"I'm trying to implement a model from a paper (https://arxiv.org/pdf/1704.04110.pdf), where they are modeling count data of product sales in order to do forecasting. The idea is that they use a negative binomial loss function. However what i'm sure about is how you would train a network to predict parameters of a probability distribution ( in this case a negative binomial). I feel like there is something fundamental I'm missing but my understanding is that in a neural network you would pass in training data, it gets passed through a bunch of hidden layers with weights and biases, then in the output layer the last hidden layer is transformed by an activation function to have the prediction be in a certain form (e.g. linear would just return h*W + b, softmax would return a probability), and then you would calculate the difference between your prediction and the real answer, then use back prop to update weights and slowly minimize the loss. Now for standard linear regression this makes sense to me, you return a y_pred value and you compare it to a y_true value and try to minimize the loss. 

Now in this paper, they state: ""a. In our approach, the network directly predicts all parameters θ (e.g. mean
and variance) of the probability distribution for the next time point.""
&lt;p/&gt;
So i'm not exactly sure how this works, but feel like there is something fundamental that hasn't clicked. Does anyone have any resources that might help clarify my confusion? Perhaps an example of doing regression on count data? Thanks!


"
I don't understand OpenAI's gym environment step function.,2,6,False,False,False,learnmachinelearning,1510575627,True,"I am playing with the FrozenLake scenario which has 4 possible actions. At first I just wanted to force it to step through the world so did this: 

    environment = gym.make('FrozenLake-v0')
    environment.reset()
    for i in range(0, 5):
        environment.render()
        environment.step(2)

Which produces output like this (bold is where it's moving): 

**S**FFF

FHFH

FFFH

HFFG

  (Right)

S**F**FF

FHFH

FFFH

HFFG

  (Right)

SF**F**F

FHFH

FFFH

HFFG

  (Right)

SFFF

FH**F**H

FFFH

HFFG


Why does it move down? I've tried a bunch of different things, but all the steps I make seem to be down in rather arbitrary directions. I'm hoping someone can explain this because it's confusing."
A question about how to improve RL.,0,1,False,False,False,learnmachinelearning,1510585985,True,"This is my homework. My professor asked me to improve the catmouse game performance.

http://www.cse.unsw.edu.au/~cs9417ml/RL1/applet.html

When mouse gets cheese, mouse gets 1 score. When cat catches mouse, cat gets 1 score.

The performance is mouse score / ( mouse score + cat score ).

I has tried two ways to do. But it doesn't work.

https://github.com/KunyiLockeLin/catmouse

The first way is every steps minus one reward.  It makes the mouse wants to move to illegal direction, like walls and trash cans, because in illegal direction, it doesn't have penalty record. But in fact, the mouse can't move to illegal place. As a result, it causes the mouse stops moving until the cat catches it.

The second way is to avoid illegal action. But it doesn't help.

So I have no idea how to do that."
Can I tell how long it will take to fit a model?,7,6,False,False,False,learnmachinelearning,1510607001,True,"I've recently started teaching myself machine learning using Python and usually in Jupyter notebooks. I'd like to know if it's possible to see how long it will take to fit a model to data, or if I can see the progress that is being made whilst the fitting process is taking place.

Currently, if I try and fit a model and it takes longer than 30 seconds or so, I have no idea if it's going to be seconds, minutes, or hours before it completes. Obviously, I have some idea based on the size of the dataset, but I have no empirical understanding of this and some algorithms fit much quicker/slower than others (and I don't have much knowledge of this either).

What I'd really like is to be able to see an 'estimated time remaining'. Does such a thing exist?"
Help define a ML problem - x features(categorical) and y outputs(numerical),0,1,False,False,False,learnmachinelearning,1510607535,True,"I have an executable that takes 5 input flags and returns 3 numeric values. It can have x number of parameters(flags) to start it and y number of outputs after execution. Then for a given set of y values, can i predict what are the x best parameters to use? I have a subset of the search space for training data. I am thinking, I could reverse the problem- The outputs(y) are numerical inputs to an ML algorithm(logistic or something else) and inputs become outputs of the ML algorithm. Are there any ideas if this can be done in this way? Is it a classification problem?
I am also exploring the neural network option but i think the amount of data i have is very limited(couple 1000 samples). This will probably need more research on my part, but if i can predict the flags with some accuracy using traditional approaches, it will be a good start."
How to classify objects and count them at the same time,6,2,False,False,False,learnmachinelearning,1510621900,True,"Hi, I followed a few tutorials about classification which uses 1 hot vectors to represent the outputs. Those kind of networks use a softmax activation function in the last layer.
But now, I would like to add 1 more dimension to the output. For exemple, instead of a 1 hot vector [0, 0, 0, 0, 1, 0, 0] I'd like a uint8 hot vector [0, 0, 0, 0, 128, 0, 0] which tells the network the number of objects in that specific class or its brightness or its relative size.. You get the picture.
Do I still need to use a softmax activation function? How can I do that? (framework exemples are ok, I'm learning)
Thanks!"
Machine power.,2,1,False,False,False,learnmachinelearning,1510625745,True,"In simple AI. 

Do i understand correctly that we need all power to calculate weights when we learning.
Once weights are figured out we can use less powerful machine to produce results. 

Thanks"
"Analyzing and Predicting Songs w/ k-Nearest, Logistic Regression &amp; Random Forest",4,31,False,False,False,learnmachinelearning,1510643577,False, 
Top-N recommendation methods for cart-based systems?,1,4,False,False,False,learnmachinelearning,1510650786,True,"I'm typically seeing rating-based recommendation systems, but I don't see too many that work with top-n cart-based systems.

My main problem is figuring out HOW to model the carts/user interactions.  Modeling user/single-item interactions is obvious, but not multiple items.

Currently, I'm using an word2vec type model, where I'm training co-occurence neural embeddings based on a target item and context items (the other items in the cart).  This works really well with negative sampling + subsampling.

But I'm interested in using factorization machines, and whatnot.

How can I model the user/cart/item interactions (with side features)?  Like, what are the inputs, the dimensions, etc. to the matrix factorization methods?  If anyone has a basic explanation, or a pointer in the direction of some papers?  Ideally, I want to recommend an item based on what's in the current cart + the user's history."
"Wasserstein distance as a measure in Improved WGAN, BEGAN?",0,3,False,False,False,learnmachinelearning,1510656177,True,"Does it still make sense to look at the Wasserstein distance (approximated loss function of the WGAN) in the improved WGAN with gradient penalty, or other architectures that don't use weight clipping?
Can I even use it to measure convergence of my Improved WGAN?"
What to feed the machine? (And other questions),3,4,False,False,False,learnmachinelearning,1510672632,True,"I'm getting a certification in machine learning and we're using AzureML for software and I have a couple questions:

What other ML platforms are there out there?

How much data (or how many different variables) should you feed it when trying to build something to get a high accuracy? Can you know what variables are more effective in getting your results? (Or is it a trial-and-error deal?)

And the biggest question is: What is the process for the data (I know you don't do this to every problem, but these are questions to ask while getting to a nice model)?

Join data, dedupe, clear blank rows, math, transform, normalize, split, train, score, eval, select column (for web applications), output

(and I know I'm in the right sub cause I saw the first post in making a reddit bot and I love it!)"
Place to find Pytorch consultants?,0,3,False,False,False,learnmachinelearning,1510672648,True,"Hi there friends in ML,

I'm looking to further optimize a Pytorch LSTM RNN trained on newspaper text. Does anyone know of resources that could help me hire someone to consult on Pytorch? 


Thanks in advance."
Please dont let this get buried - I need advice on the right book.,12,0,False,False,False,learnmachinelearning,1510684600,True,"Ive been wanting to do machine learning for oh, five years now. Five years ago I didnt know algebra. Now I know algebra, trigonometry, calc1, calc2, linear algebra, and statistics. Ive got 100 pages left in my vector calculus book before the section on gradients is covered. Then Bayesian statistics. My point is I have never worked this hard or made this much progress on anything. Im not a futurology dude. Im legit.

My degree is in programming and I am a professional software developer so I am not worried about that side of things.

I did the Andrew NG intro to machine learning course. I started reading ahead in the book that I thought I was going to use as my machine learning book ([the physical copy of this](http://www.deeplearningbook.org)) and it turned out to be useless as a teaching tool, at least for me.

So, you know where I am coming from. My plan is to do a basic book on machine learning. Then do something on cnn's for image recognition...and then who knows.

What I want right now is a solid book on elementary machine learning. What book would you suggest?"
Hey there! How do i get into ML. I have basic skills of python c &amp; c++.Can someone point me in the right direction?,4,3,False,False,False,learnmachinelearning,1510684698,True, 
I'm looking for a GAN tutorial which uses images as inputs for the generator,2,2,False,False,False,learnmachinelearning,1510685328,True, 
Which DNN architecture is currently the state of art for facial detection?,4,1,False,False,False,learnmachinelearning,1510685357,True,"I've been MTCNN based facenet. YOLOv2 and Tiny Face seem to be pretty comparable as well.

As of today, what is the most accurate (highest mAP) architecture? Is there a blog / stats page that share &amp; updates this?"
"scikit-plot - ""library to add plotting functionality to scikit-learn objects""",4,31,False,False,False,learnmachinelearning,1510705650,False, 
How much time do you spend implementing/training?,0,2,False,False,False,learnmachinelearning,1510707059,True,"How much time do you spend implementing models, versus training/testing/validating, versus coming up with a model idea?

My times are roughly 20%, 70%, 10%; is this typical? What tools do you use to help speed up the process?"
How do I implement grid LSTM in tensorflow?,6,2,False,False,False,learnmachinelearning,1510708682,True,"Hello,

I have been trying to figure out how to implement a multidimensional RNN in tensorflow. After some quick googling, it seems like [tf.contrib.rnn.GridLSTMCell](https://www.tensorflow.org/versions/r1.1/api_docs/python/tf/contrib/rnn/GridLSTMCell) is the way to go.

However, I'm not exactly sure how to implement this. The most I have ever done in Tensorflow is a few [BasicLSTMCells](https://www.tensorflow.org/versions/r1.1/api_docs/python/tf/contrib/rnn/BasicLSTMCell) combined through a MultiRNNCell. 

I'm mainly stuck on what to use for the ""num_frequency_blocks"" argument. 

My inputs are in the shape [batch size, time steps, number of features]. Specifically, in my case, my input comes in the shape [32, 50, 10]. Any idea how to implement gridLSTM? 

Thanks!"
Does GPU Acceleration in TensorFlow require CUDA GPUs?,0,1,False,False,False,learnmachinelearning,1510712497,True,[deleted]
Are there any blogs that focus on explaining arxiv papers for mid-advanced learners in ML,0,1,False,False,False,learnmachinelearning,1510713451,True,"Reading research papers is a good thing. But for self-learners, getting stuck in a paper is a common thing. Your Coursera courses never get you to that level is a known thing.
So, is there a blog or any resource that walks-you-through some important papers in Machine Learning? So that once we get used to reading some, we can be on our own. It need not be a line-to-line explanation, but a decent overview of what the paper is talking about and how to interpret the results.
Thank you!"
How do you load resume training on models (load a model and resume) in Tensorflow?,0,2,False,False,False,learnmachinelearning,1510720497,True,"I'm having trouble resuming training on a model that I saved with tf. saver(). I wrote a long post on SO just for formatting purposes, (easier to read the code) as my questions on tensorflow don't seem to get answered on SO. 

Here is the link:

https://stackoverflow.com/questions/47299378/correcly-loading-a-model-to-resume-training-meta-graph-ckpts


I can't seem to load a model properly to resume training --
I'm either getting errors, or it's training from scratch. "
Can I use two different GPUs with Tensorflow?,1,1,False,False,False,learnmachinelearning,1510724181,True,"I have a machine with 980 Ti and I am planning on buying a 1080 Ti as well. Will Tensorflow be able to hand the use of both GPUs?

If yes, could you please provide a source?"
TWIL (This Week I Learned) - Share something new that you have learned this week!,3,2,False,False,False,learnmachinelearning,1510729515,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
"Training a Keras model for classification, classifying groups that were not in training data",3,2,False,False,False,learnmachinelearning,1510730762,True,"so I have Keras model that was trained on 5 classes of data.

If I were to test the trained Keras model on a data that do not belong to the 5 classes of data it was trained on but rather a new class ""6"". So how can model tell that it does not belong to either of the 5 classes it was trained on?

Is is just a simple as adding a neuron at the output layer?

I am puzzled about this as it do not really make much sense that the model can give an output that it has not trained on."
What part of ML have you found most difficult to grasp?,0,1,False,False,False,learnmachinelearning,1510736421,True,Just trying to survey opinions.
LSTM Problems for small Time Series Sample,5,2,False,False,False,learnmachinelearning,1510742416,True,"Hey ML crowd :)

I'm experimenting on a (stateful) LSTM RNN in Keras to forecast monthly financial time series. It's very basic so far, but performing worse than I expected. The output variable is a binary classifier if Y went up or down. The input is a set of up to 12 predictors transformed into supervised learning format X according to whether I want to look back 48 or 24 timesteps. I'm using Nadam optimizer, a dropout of 20%, batches of 5 and inbetween 300-1000 epochs (it starts to clearly overfit after around 500 epochs).

I'd love to learn the views of more educated people. I'm feeling like a rookie because I'm not sure if the model can't get above the benchmark (prediction for next month is what the price did today (say it will go up if it went up this month and vice versa)), if there's not enough data to train on or if there simply is nothing to learn on this scale. 

* Is it possible to train&amp;validate on a set of 500 vectors or are that to few?

* How many LSTM blocks are at least required to make sense? How many are overkill (I'm not sure if all the single gate weights also contribute fully to the overfit/to many parameters thing)

* Would I be better off with a simple RNN because I can make it bigger with the same amount of weights? Because the #parameters limit makes the #LSTM cells not worthwhile? 

* How important is a PCA for the input?

* Decreasing the model size to prevent quick overfitting leaves it at always guessing up or always guessing down. Thoughts?



Thanks in advance and let me know if I disregarded any etiquette or forgot some info.
Ghosty"
Understanding LSTM and Its Diagrams,2,29,False,False,False,learnmachinelearning,1510745519,False, 
Machine Learning: The High Interest Credit Card of Technical Debt,2,18,False,False,False,learnmachinelearning,1510746856,False, 
L1 Norm Regularization and Sparsity Explained for Dummies,2,4,False,False,False,learnmachinelearning,1510765640,False, 
Gluon nn implementation question,1,2,False,False,False,learnmachinelearning,1510770107,True,"Hi!
I'm trying to implement the neural network described [here](https://hackernoon.com/latest-deep-learning-ocr-with-keras-and-supervisely-in-15-minutes-34aecd630ed8), which is a method for reading text (license plates in this case). They provided the [source](https://github.com/DeepSystems/supervisely-tutorials/blob/master/anpr_ocr/src/image_ocr.ipynb) for their network and as such, I'm trying to go through that and convert it over to gluon (as an exercise to better understand gluon). My input data is slightly different (only lowercase alphabetical, so 27 outputs on the last dense layer).

My network is defined as follows:

    class ReshapeLayer(gluon.Block):
        def __init__(self, **kwargs):
            super(ReshapeLayer, self).__init__(**kwargs)
        def forward(self, x):
            #Not familiar with reshape, -1 for the batch index, 32x256 for the target, am I really stacking the depth slices on top of each other with this command?
            x = x.reshape((-1,32,256))
            return x
    
    net = nn.Sequential()
    with net.name_scope():
            net.add(nn.Conv2D(channels=16, kernel_size=3, activation='relu', padding=1))
            net.add(nn.MaxPool2D(pool_size=2, strides=2))
            net.add(nn.Conv2D(channels=16, kernel_size=3, activation='relu', padding=1))
            net.add(nn.MaxPool2D(pool_size=2, strides=2))
            net.add(ReshapeLayer())
            net.add(nn.Dense(32, flatten=False))
            #Two layer bidirectional, is this all thats needed for that complex diagram?
            net.add(gluon.rnn.GRU(512, num_layers=2, bidirectional=True,layout='NTC'))
            net.add(nn.Dense(27, flatten=False))

Which seems to mimic the keras implementation; however, I'm finding that the loss quickly stagnates and never reaches a happy state. 

So my biggest differences end up being the reshape layer, the gru layer, and the CTCLoss function input. I guess my questions are, to do the equivalent reshape, is this correct?  Is this also the correct way to implement the described GRU layer? And lastly, they do a softmax activation layer before feeding it into the CTCLoss function; however, gluon [says](https://mxnet.incubator.apache.org/api/python/gluon/loss.html#mxnet.gluon.loss.CTCLoss) not do add the softmax, am I interpreting that correctly and that it is okay to leave off the softmax activation layer? Right now the input for predictions (on CTCLoss) looks like an array of random small numbers (|x| &lt; .1) both negative and positive, which eventually move towards the hidden character having the highest value. 

Thanks!

Edit: Here's an example of my labels for the word hello, incase I'm screwing up the CTCLoss stuff:
[7, 4, 11, 11, 14, -1, -1,  ... , -1, -1, -1, -1]   # length 32"
Question about long cross-validation times,0,3,False,False,False,learnmachinelearning,1510781027,True,"Hi there, I need to publish my results for a project this coming week. I am using LSTMs for binary sentiment classification. 

It takes 3 hours to run 10 epochs of my training data. I am using a GTX 1060 6gb for reference. I would like to validate my models, so I am using GridSearch cross-validation with a Sklearn wrapper for Keras. 

Assuming I want to tune the hyperparameters: Dropout rate, batch size and hidden layer sizes, if I was to pick two variables for each hyperparameter, e.g. batch sizes of 64 and 128, I would need to run 6 different variations of the model on my training data. So assuming it takes 3 hours to run the model on training data, it would take me 18 hours to validate one model. I am using  4 model variations (different embedding weights) on 4 datasets (16 models) so that will take me 768 hours to validate all my models and that's only validating a small number of hyperparameters!

So my question is, how should I approach this task? I can't do it in full as that would take 768 hours. What I'm thinking of doing is just using cross-validation once per each model so only doing this 4 times out of 16 by just picking one dataset to validate. 

In any case, even doing this seems lazy - but I realistically can't spend 4 weeks validating models. I'm just wondering how you guys approach problems such as this? I am thinking of using GPU instances to cut down my workload too, but still, even if it only took 500 hours to run on the cloud it would still nearly be $500 which seems quite absurd. 

 "
Issue trying to implement stacked LSTM layers with Keras,5,2,False,False,False,learnmachinelearning,1510782573,True,"I'm trying to add more LSTM layers to my neural net, but I keep getting the following error:

    ValueError: Error when checking target: expected dense_4 to have 2 dimensions, but got array with shape (385, 128, 1) 

The code for my model is as follows:


    model = Sequential()

    model.add(LSTM(60, return_sequences=True, input_shape=(128, 14)))

    model.add(LSTM(60, return_sequences=False))

    model.add(Dense(1))

    model.compile(loss='mean_squared_error', optimizer='adam')

    model.fit(data_train, RUL_train, epochs=number_epochs, batch_size=batch_size, verbose=1)



It works fine when I remove the second LSTM layer. Or if I add more dense layers. Just not when I add the LSTM layer. RUL_train has shape (385, 128, 1).

The output of model.summary is as follows:

    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    lstm_15 (LSTM)               (None, 128, 60)           18000     
    _________________________________________________________________
    lstm_16 (LSTM)               (None, 60)                29040     
    _________________________________________________________________
    dense_7 (Dense)              (None, 1)                 61        
    =================================================================
    Total params: 47,101
    Trainable params: 47,101
    Non-trainable params: 0
    _________________________________________________________________



Any help appreciated."
What path would an absolute beginner coder/programmer take in programming(python) with the end goal of creating neural networks/AI machine learning?,8,7,False,False,False,learnmachinelearning,1510783532,True,"I ask this question because the past two weeks I have gotten a bit confused. I am an absolute beginner and am using Youtube tutorials to get the basics of code and python and khan academy for revising math. (I'm not too good at the math part and have a  way to go and could use help on that as well.)

But for the python Youtube tutorials I have felt a bit confused as i'm not sure if I am learning the things for the end goal that I wish to accomplish (Neural networks/AI) as some of it is marketed for people with different goals (website developer, etc)

I was wondering is there a clear cut path for someone who is an absolute beginner in code (python) and revising math for machine learning  with the end goal of knowing neural networks/AI and creating them? What should I download for machine learning modules?
(I heard somewhere that there's modules that people use for neural networks/AI in python but i'm not sure what it is.) 

What should I watch/read/practice so I can get to my  main goal? 

Thank you for reading, advice really welcome!"
Beginning machine learning by a software engineer in a hurry,2,56,False,False,False,learnmachinelearning,1510783705,False, 
Basic Keras Seq2Seq on Twitter Customer Support Data,0,1,False,False,False,learnmachinelearning,1510791681,False,[deleted]
Seq2Seq: Kaggle Notebook of Basic Conversational Model - Trained on Twitter Customer Support Data,0,1,False,False,False,learnmachinelearning,1510798472,False,[deleted]
Laptop recommendations?,7,1,False,False,False,learnmachinelearning,1510831185,True,Budget 1000. Looking to buy a laptop that won't need replacement in a long run. I've just started learning machine learning but I want a setup that would work for fairly bigger data projects.
Simple Explanation of Baum Welch and Viterbi,1,2,False,False,False,learnmachinelearning,1510831720,True,Hello does anybody know of a simple explanation/example of baum welch and viterbi? The stuff I find seems to be mostly &gt;30min vids or degenerate into an orgy of symbols without providing a concrete example. The closest I found to a simple example is in wikipedia but with a note above it saying it was wrong. 
"Introducing BOLT, Fully integrated IoT platform, made for Machine Learning - Would love to know your thoughts!!",0,2,False,False,False,learnmachinelearning,1510833224,False, 
Neural networks for beginners: popular types and applications in real life,0,54,False,False,False,learnmachinelearning,1510842100,False, 
What is wrong with my gradient descent algorithm?,3,2,False,False,False,learnmachinelearning,1510849149,True,"I've gone through only the first week of Andrew Ng's course, where he explains univariate linear regression, and univariate gradient descent. I understood the logic and the math behind the concepts quite well (I think so anyway) so before proceeding I decided I'd try implementing the algorithms on my own.

The dataset I have considered is the working population of the US versus the total population of the US. [It comes out to be roughly a straight line, as shown in this image](https://i.imgur.com/ENGHtCG.png). So, I implemented a gradient descent algorithm to see if it could come up with a good fit for the data. Just for reference, I checked the points, and came up with an approximate line myself, which is:

-13907.62 + 0.7194*x

[This image shows it.](https://i.imgur.com/2to1t2r.png) Then, I put my gradient descent algorithm to work.

 [Here is the code.](https://gist.github.com/anonymous/3cdec0c8272fe6318418f1d753353153)

Lines 1 - 20 generate the dataset from an excel sheet, and then print the data. totalpop stores the feature (x-variable), and is the total population, while workingpop stores the output (y-variable) and is the working population. [Here is the exact data - the first list is totalpop, second is workingpop.](https://gist.github.com/anonymous/abb8c973232ecf5be946052d8b88d3ac)

Lines 23 and 24 generate initial random parameters. 

Lines 27-32 evaluate the hypothesis h(x), which is calculate as the product of the row vector [t0, t1] and the column vector [1, x], giving t0 + t1*x.

Lines 34-45 is the actual gradient descent algorithm which should be self explanatory. alpha is the learning rate.

Lines 50-61: Then, I print the initial hypothesis and run my gradient descent 1000 times. Every tenth time, I pause and print out the hypothesis. Then, I print out the final hypothesis.

Lines 63-68: I generate the line modeled by the algorithm and plot it along with the actual data to see how well it fits.

Here is my output, with learning rate 0.5:

    &lt;totalpop and workingpop are printed&gt;
    
    Current hypothesis:
    
    2772.388550573294 + 2.886337291205133x
    
    Loop: 0
    
    Hypothesis:
    
    -189745.445199 + -35091344869.6x
    
    Loop: 1
    
    Loop: 2
    
    Loop: 3
    
    Loop: 4
    
    Loop: 5
    
    Loop: 6
    
    Loop: 7
    
    Loop: 8
    
    Loop: 9
    
    Loop: 10
    
    Hypothesis:
    
    -1.55826566141e+107 + -2.84876161599e+112x
    
    Loop: 11
    
    Loop: 12
    
    Loop: 13
    
    Loop: 14
    
    Loop: 15
    
    Loop: 16
    
    Loop: 17
    
    Loop: 18
    
    Loop: 19
    
    Loop: 20
    
    Hypothesis:
    
    -1.26502059701e+209 + -2.31266221763e+214x
    
    
    Loop: 21
    
    Loop: 22
    
    Loop: 23
    
    Loop: 24
    
    Loop: 25
    
    Loop: 26
    
    Loop: 27
    
    Loop: 28
    
    Loop: 29
    
    Loop: 30
    
    Hypothesis:
    
    -inf + -infx

So the initial (random) hypothesis is fine, but then you see, right at the first loop, parameters skyrocket - they should be far lower, as my approximate equation (-13907.62 + 0.7194*x) indicate. In later loops, it grows even faster and by loop 30, we reach infinity. What am I doing wrong? Is there something wrong with my logic, or is there a silly error somewhere?"
Can I stop l stop learning Vector Calculus after gradients?,2,3,False,False,False,learnmachinelearning,1510850534,True,"The subject is fascinating and I wish I could read the whole book but ML is my goal.

Ive heard you really only need calculus up to gradients. Am I done with calculus now that I can do gradients?

Please advise."
Building my own deep learning machine - any suggestion is helpful!,3,3,False,False,False,learnmachinelearning,1510850728,True,"I'm building my own deep learning machine to really delve into studying deep learning with the hopes of landing a job. I've built a list on pcpartpicker: [link](https://pcpartpicker.com/list/66vN3F)


Any suggestion on particular parts will be helpful!"
Using RNNs to generate an ICO white paper,0,1,False,False,False,learnmachinelearning,1510856509,False,[deleted]
Building a Deep Learning Rig. Had a question.,4,1,False,False,False,learnmachinelearning,1510862697,True,"My friend is selling me his computer. 

i7-4770K, 16GB, 980Ti - appropriate power supply, etc. 

I'm buying this, and going to add a 1080 Ti also and 16GB more to the PC. (motherboard has 3 PCI 3.0 ports and supports max 32GB ram, and power supply is plenty). 

Is this enough for self projects?"
Source-to-Source Debuggable Derivatives in Pure Python,0,1,False,False,False,learnmachinelearning,1510867537,False, 
Help with python implementation of backpropagation,2,3,False,False,False,learnmachinelearning,1510890250,True,"[My code](https://pastebin.com/bVGrQLNV)

Gives 1 as output when I pass in the AND operations,

Gives 0 as output when I pass in the OR operations.

I understand the backpropagation algorithm in general but I might have messed up some finer details, so any help would be appreciated. Also, I am not quite sure whether what I am doing with the bias node is correct.

Also this is my first time posting here, not very sure what kind of information I should be giving / formatting / etc. Any guidance is appreicated.
"
Weekly Show-off!,2,2,False,False,False,learnmachinelearning,1510902328,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
What are some good resources for Deep Learning Math?,3,8,False,False,False,learnmachinelearning,1510904923,True,"I am able to follow recent deep learning (vision) papers fairly well. However, I am not able to understand anything /u/fhuszar writes, like [this](http://www.inference.vc/design-patterns/) nor am I able to think of improvements based on first principles [like he does](http://www.inference.vc/unsupervised-learning-by-predicting-noise-an-information-maximization-view-2/).

Can someone point me to a book/course that can help me get a hold of that kind of maths?

Thanks in advance :)"
Data Tagging in Medical Imaging - Diving Deep into the Processes,0,1,False,False,False,learnmachinelearning,1510905488,False, 
"After going through the first week of Andrew Ng's course, I thought I'd take a shot at implementing my first ever ML algorithm. I made it into a tutorial-esque jupyter notebook to try and help others on the same path. I hope it's of use.",4,47,False,False,False,learnmachinelearning,1510907733,False, 
"[CNN Classification Question] Adding an extra class of random noise to benchmark ""goodness of fit"" and getting around adversarial samples?",1,2,False,False,False,learnmachinelearning,1510941009,True,"Hi all,

Lets say you have a binary classification task, maybe cats vs dogs. If we fully train this network then put an image of a bird through, it will either classify cat or dog with probably close to 50/50 class probabilities.

Say I had a third class that was randomly generated noise and the network now has three classes: cat, dog, noise. 

1. If I were to input the image of the bird, would noise be the highest class probability? Not necessarily right? There might be more features in common in either the cat or the dog case then the noise case.

2. If I look at the average value for the class probability of noise when evaluating the test set of classes cat and dog, could this be a metric for model confidence? IE. lets say that the test set images of cat and dog only ever score below 0.05 in the noise category. If I am evaluating some unknown image like the bird, if it is above 0.05 noise I know I can throw it out and not trust the classification?

Are there any references anyone has stumbled upon along this line of reasoning?

Cheers"
Long Training Times with Cloud-based GPU compared to Local GTX 1060,8,13,False,False,False,learnmachinelearning,1510955067,True,"Hi there, I need to train a lot of models for a project submission. With the tight deadline impending, I've decided to launch a purpose-built Machine Learning (with pre-installed ML packages, including Tensorflow GPU etc.) instance with a cloud provider. 

It was my assumption that the cloud-based instance would run much faster than my local hardware but I'm not finding that to be the case. In fact, I'm finding it to be rather underwhelming, particularly given the fact that I am paying hourly. 

 Is this the norm? Is there really any reason why my 1060 is nearly 2x faster than a SoTA cloud offering?

Below are the relative runtimes (same size dataset, same model etc.)

Local: GTX 1060 6GB (1280 CUDA Cores, 4.4TFLOPs)

Epoch 1/10
2177s - loss: 0.2912 - acc: 0.8809

Cloud Provider: NVIDIA Quadro P5000 (2560 CUDA cores 9.0 TFLOPs)

Epoch 1/10
4192s - loss: 0.3828 - acc: 0.8267

EDIT: The differing accuracies are due to one dataset being sampled evenly (equal number of positive and negative classes) and the other follows the original distribution. The data is very similar just different label distributions. 


"
"Question about data, and how much of it you need",7,8,False,False,False,learnmachinelearning,1510957693,True,"I have a CNN that I'm training to try to identify topography from images. After seeing just a couple hundred images, it can pick out things like roads and other features in the evaluation set and knows that they're lower than surrounding features, however, as it continues to train, I'm not seeing much improvement.

I have a training set of about 10k images. I haven't gotten through all of them, but I was wondering what my expectations should/shouldn't be.

As I train the net on more data, should I expect it to slowly get better, or get stuck for a while and then make some dramatic leaps, or something else?

One particular aspect of the problem I'm trying to solve is that I don't know if it's even possible, so another question I'm asking myself as I'm looking at my error rates is whether or not the net has gotten as close to solving the problem as is physically possible. Any thoughts (even guesses) as to what might indicate whether or not this is the case?"
How do I create manual segmentations for an image segmentation task (tensorflow)?,7,4,False,False,False,learnmachinelearning,1510973026,True,"Hello all; I have a dataset consisting of MRI images with tumors. I need to generate ground truth segmentations of the images but don't know what tool I should use or what format the results should be in in order to use the dataset in tensorflow.

Please help!"
[Gradient Descent] Why do we subtract the *Y Value*?,11,8,False,False,False,learnmachinelearning,1510977766,True,"theta := theta − a  ∂ f(theta)/ ∂theta

It makes intuitive sense to update xi by subtraction (to move away from the direction of the gradient).

However, what does not make sense to me is the value we yield from **a * ∂ f(thea)/ ∂theta**. The gradient yields us the magnitude of change in yi, and we subtract theta - yi? Should we not subtract a theta value from theta, instead of y?

edit:

For brevity, we are essentially subtracting alpha * slope. But alpha * slope gives us a Y. Why do we theta - Y to get a new theta value?

edit2: finally found [this resource](https://timvieira.github.io/blog/post/2016/05/27/dimensional-analysis-of-gradient-ascent/). *digesting*

edit3: Please throw in your two cents :). New perspectives always help!"
"Weekly Status Check Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",0,2,False,False,False,learnmachinelearning,1510988710,True,"Let's have a  meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
How to Implement Siamese Manhattan for Kaggle’s Quora Question Pairs Competition,0,1,False,False,False,learnmachinelearning,1511004679,False,[deleted]
How to Implement Siamese MaLSTM for Kaggle’s Quora Question Pairs Competition,0,5,False,False,False,learnmachinelearning,1511004779,False, 
Training and Prediction with Google Cloud Platform services - Quick overview,0,4,False,False,False,learnmachinelearning,1511005086,False, 
"[noob question]In Neural Network, why would setting up several units in a layer using the same activation function helps?",2,1,False,False,False,learnmachinelearning,1511010889,True,"Hi, newbie here. So, so far my bet is that because the weights starts with random different number, therefore each units will reach different local optima in the same dataset? But what if there is only 1 local optima? Would Neural Network with several hidden layers and units help? I don’t really know. "
The basics of continuous probability distributions,1,14,False,False,False,learnmachinelearning,1511037680,False, 
Previous works on MIAS mammogram dataset,0,1,False,False,False,learnmachinelearning,1511087670,True,"I'm trying to classify the mammograms from MIAS using image processing and machine learning techniques. Currently doing a research on previous works, are there any good ones for my reference? Thanks."
Getting started with TensorFlow: A Brief Introduction,0,1,False,False,False,learnmachinelearning,1511098141,False, 
"Cross validation for ridge regression, 7 million observations, 100 features.",0,0,False,False,False,learnmachinelearning,1511118772,True,"Hey guys 

I've had to write my own function to estimate a ridge model for fixed lambda using biglm (my data is stored in an ffdf object). 

Is there any way I can incorporate cross validation into my function to return an optimal value for lambda?

Or should I just resort to information criterion for determining lambda?

Thanks? "
Boltzmann Machines in TensorFlow with examples,0,16,False,False,False,learnmachinelearning,1511129788,False, 
Training Char-RNNs for Transferring Name Styles,2,3,False,False,False,learnmachinelearning,1511130568,False, 
"What is the ""Hello, World!"" equivalent of machine learning?",24,23,False,False,False,learnmachinelearning,1511151052,True,"Lets assume the person knows a little bit of Python. What would the ""Hello, World!"" of machine learning look like for a complete beginner who has a general high level understanding of some of the concepts of machine learning but lacks technical/application/implementation experience/knowledge."
Which of these two books do you suggest reading?,5,2,False,False,False,learnmachinelearning,1511164188,True,"Hi everyone.
Given that I am not a complete beginner but would like to understand better some implementations of machine learning/deep learning, which book do you suggest? I can't decide between [Hands-On Machine Learning with Scikit-Learn and TensorFlow by Aurélien Géron](https://www.amazon.com/dp/1491962291/sr=8-1/qid=1511163140/ref=olp_product_details?_encoding=UTF8&amp;me=&amp;qid=1511163140&amp;sr=8-1) and [Python Machine Learning by Raschka and Mirjalili](https://www.amazon.com/Python-Machine-Learning-scikit-learn-TensorFlow/dp/1787125939/ref=sr_1_7?ie=UTF8&amp;qid=1511163140&amp;sr=8-7&amp;keywords=machine+learning). Has anyone read them before?"
Free Webinar on Machine Learning,0,2,False,False,False,learnmachinelearning,1511174965,False, 
Announcing Excel Add-in for ParallelDots AI APIs,0,1,False,False,False,learnmachinelearning,1511177251,False, 
Setting Keras on GPU,4,2,False,False,False,learnmachinelearning,1511194917,True,"Hello,

I've installed Keras with Theano backend and I'm trying to get it to run on GPU, by following these instructions : https://keras.io/getting-started/faq/#how-can-i-run-keras-on-gpu

I created a .theanorc file containing these instructions :

[gcc]
cxxflags = -D_hypot=hypot

[global]
floatX = float32
device = gpu*

[nvcc]
fastmath = True

but it still doesn't work. I tested a program that I found that checks if GPU is used but it's not the case. 

FYI I'm on Windows and I have an AMD graphics card so no CUDA unfortunately.

Can anyone help? Thanks in advance"
How to interpret pattern in this scatter plot,5,2,False,False,False,learnmachinelearning,1511197234,True,"How could you interpret the clear pattern that appears in each plot, in which it seems the points are very well aligned?

The dataset is `Olives`, from `extracat` package.

Hope don't be asking a silly question, but I am not able to came with a explanation.

[![Image1][1]][1]
[![Image2][2]][2]


  [1]: https://i.stack.imgur.com/XvBuh.png
  [2]: https://i.stack.imgur.com/vvIBS.png"
Question about randomly initializing weights when building a neural network.[syntax][python],7,11,False,False,False,learnmachinelearning,1511198578,True,"I'm a a newbie to both ML and Python. I decided to follow [this](https://www.youtube.com/watch?v=h3l4qz76JhQ&amp;list=PL2-dafEMk2A5BoX3KyKu6ti5_Pytp91sk) tutorial by Siraj Raval to build a Neural Network.


On line 24 and 25, Siraj uses the following code to initialize the weights of the synapses between the three layers:

**syn0 = 2* np.random.random((3,4)) - 1**

**syn1 = 2* np.random.random((4,1)) - 1**


I'm not sure I fully understand the syntax here. According to an example in the [documentation for random.random](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.random.random.html), 

**5 * np.random.random_sample((3, 2)) - 5**

gives you a ""three-by-two array of random numbers from [-5, 0)""

So does this mean that **syn0** gives you a 3x4 matrix of random numbers from -1 to 1, and **syn1** gives you a 4x1 matrix of random numbers from -1 to 1? If so, why did he choose this range? Does it have anything to do with the sigmoid function?
"
Starting deep learning hands-on: image classification on CIFAR-10,0,2,False,False,False,learnmachinelearning,1511210871,False, 
first steps to building a predictive model?,6,2,False,False,False,learnmachinelearning,1511212878,True,"hi all! I'm a super novice in programming (I've been doing a fair amount of R recently, but not more than very basic cleaning and analysis). I'm looking for a in-depth step by step instruction to build my first predictive model (I'd eventually want to optimize my model, too). 

I've been doing some reading on caret, but am not sure where else to start. I'm most familiar with the dplyr, stringr, zoo, and lubridate packages, but not much beyond those. 

Anyone have any idea on where to start? I'm looking to predict how buildings use energy with mostly quantitative variables (outdoor air temperature, temperature of other spaces, etc.) and a couple categorical variables (status of compressors i.e. on or off) - anyone have a good starting place, or an idea of the general outline of predictive modeling with a combination of categorical and numerical variables? 

Cheers!"
Reinforcement Learning Approach to 2048,5,7,False,False,False,learnmachinelearning,1511214079,True,"I've been trying to use the AlphaGo Zero paper as a blueprint for a 2048 solver. However, a very big difference between Go and 2048 is that Go is easy to turn into a simple classification problem (win or loss for the current player), whereas 2048 is fundamentally different. A way of turning 2048 into a classification problem would be to train a neural network to predict the likelihood of the current board reaching 2048. However, I don't really like this approach because it won't ever reach 2048 unless it makes incremental progress on the way there and more importantly I would like it to maximize the score as an end goal (see how far it can go). I could train it to reach 256, then 512, then 1024, then 2048 incrementally by reusing the previous network as a starting point, but that seems to be way too vulgar and not encapsulating what I want it to learn. The other approach would be to avoid classification to begin with and simply predict the final score. Instead of a {-1,1} value, it would be anywhere on the interval [0,~2^20]. My question is whether using the neural network to approximate the score in this way is something that is normally done or if there are inherent problems with it.     
The other approach I was thinking about was training the neural network to take in two games and predict which one will score higher. This would be the sort of classic classification problem neural networks are known for, but it seems a bit less natural. For example, if one game loses, then the other game would just say ""I won"" and terminate. And if you wanted it to play normally (single player), there might not really be a good way to do it. (You could always have the other board be the same board, that might do the trick). Any thoughts?"
My Keras CNN model implementation is resulting in no change to accuracy or loss,9,1,False,False,False,learnmachinelearning,1511223176,True,"I have this up on stackoverflow but still can't figure if I'm not implementing something correctly:

https://stackoverflow.com/questions/47401556/no-change-in-loss-or-accuracy?noredirect=1#comment81756737_47401556"
Artificial Intelligence with Python by Prateek Joshi - Free eBook (for 21 hours as of now) on PacktPub,0,1,False,False,False,learnmachinelearning,1511230849,False, 
Help with the PAN Intrinsic Plagiarism Dataset?,0,1,False,False,False,learnmachinelearning,1511233400,True,I'm having trouble working with this data (http://pan.webis.de/clef11/pan11-web/plagiarism-detection.html). Has anyone used this before? Do they know where I can find some guidance/a starter bot?
Trying to break a remote sensing classification problem down into bitsize chunks. Remote sensing with 10k+ instances of bounding boxes specific to an item,0,1,False,False,False,learnmachinelearning,1511234782,True,"Hey guys,

I was wondering if someone could give me some guidance for a remote sensing project I'm trying to crack.

I have a dataset comprising of bounding box polygons with the following characteristics:
*polygon id
*centroid latitude/longitude
*centroid latitude pixels
*centroid longitude pixels
*area pixels
*area meters
*nw corner of image lat/long
*se corner of image lat/long
*polygon_vertices_lat_lon
*polygon_vertices_pixels

With this data, I would plan on downloading imagery from I can get a base image, and a bounding box with the target training data. What I'd like to be able to do is to train a NN that will be able to look at a satellite image, determine whether the object is present, and if so, return the coordinates of it.

So I'm familiar with transfer learning in basic image classification (eg Dogs/Cats/etc), but my target outputs here are a little bit different: I'd like to be able to determine the real-world coordinates of the target object, if the object is present in the picture.

How do I need to approach altering the basic VGG/Resnet/CNN etc neural network model to incorporate a) the bounding box data, and b) to output the coordinates rather than a classification?

This is a bit of a step up from some of the basic stuff, but if anyone could help break down the process, it would be a huge help.

Thanks!"
How to deal with NaN data of a dataset in python (pandas),7,4,False,False,False,learnmachinelearning,1511241826,True, 
Detecting Automated scans using AI,7,1,False,False,False,learnmachinelearning,1511257394,True,"From application and access logs, which have request details like the number of requests, request status and request params etc.. I am trying to find whether it is an automated scanning tool (or) not... 

Using unsupervised k-means can solve this, but I am wondering is there any other ways like multivariate Gaussian distribution can also work fine... Whom to choose.?"
How to decide thresholds for each class in multilabel classification problems ?,1,1,False,False,False,learnmachinelearning,1511259691,True,"I am working on project which has multilabel classification in it. I am using neural networks with sigmoid as last layer. But now I am not able to decide out of all those sigmoid outputs which ones are to be selected ? My dataset is completely skewed so I thought to use different threshold for every class, but again I don't even know if this is correct or not.

Any suggestion will be appreciated.
Thanks for reading."
How to create text classifiers with Machine Learning,0,10,False,False,False,learnmachinelearning,1511261135,False, 
"More than 1 Sensitivity Values, when Changing Labels",2,1,False,False,False,learnmachinelearning,1511262286,True,"In order to deal with the mixture of continuous and binary values, in the data, using R caret package Random Forest, I changed the label of classes from 0, 1 to -1, 1. This resulted in sensitivity values bigger than 1, which is not possible. Why?"
Free Live Webinar on Introduction to Machine Learning,0,2,False,False,False,learnmachinelearning,1511268030,False, 
3d data over time and want to do interpolation but have some questions (also using scipy.interpolate),0,1,False,False,False,learnmachinelearning,1511268526,True,"Hey all,

So I have some x,y,z data over time and I'm trying to interpolate it then re-sample to smooth it out. From googling around and reading some papers one of them mentioned that piece-wise cubic spline interpolation is a promising direction and then I found [Scipy grid data](https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.interpolate.griddata.html) and I think my data is unstructured (it's just movement data)

1) Do you think that griddata is what I want? I'm pretty new to this area

2) From the documentation of the function:

points : ndarray of floats, shape (n, D)
Data point coordinates. Can either be an array of shape (n, D), or a tuple of ndim arrays.

values : ndarray of float or complex, shape (n,)
Data values.

I don't really understand where values come from in this case? What is it for? "
Implementation of Neural Tensor Network for Knowledge-base completion in Python using Keras.,0,10,False,False,False,learnmachinelearning,1511277139,False, 
Deep neural network running keyword spotting on a tiny microcontroller.,0,6,False,False,False,learnmachinelearning,1511279951,False, 
Is there a (legal) way to access Udacity's courses for free?,9,7,False,False,False,learnmachinelearning,1511282481,True,"For instance, Coursera bundles up its courses and you need to pay to access the entire collection. But you can access each course individually, for free.

Does Udacity allow for something like that with its nanodegree courses? Is it possible to  access each sub-course of a nanodegree for free?"
⚔️ Big challenge in Deep Learning: training data – Hacker Noon,0,5,False,False,False,learnmachinelearning,1511283878,False, 
how to handle sgf files?,0,4,False,False,False,learnmachinelearning,1511284244,True,"I want to try making a neural network that plays 9x9 go. I found a dabase of 9x9 games in sgf format and I have no idea how to make them into something that can be imported into a python script and worked with.

Any suggestions?"
Short Text Topic Modeling,2,3,False,False,False,learnmachinelearning,1511298919,True,"Hello,

I'm fairly new to ML and I was wondering what topic modeling methods are proven to be useful with shorter text (conversational length preferably), especially if it's non-parametric. If anyone could point me to some useful papers or other information I would greatly appreciate it. 

Thanks "
[TensorFlow]Saving/restoring problem,0,2,False,False,False,learnmachinelearning,1511299300,True,"I'm trying to save trained model for further use in application.
The model itself works, but when i run several iterations of training, then save it using tf.train.Saver() and load with import_meta_graph(), loaded weights are the initial weights containing random values, not updated(trained) weights.

What could cause this problem?

"
How to use AWS for ML?,2,1,False,False,False,learnmachinelearning,1511309565,True,"Are there any good resources on how to use AWS (or maybe Azure or other platforms; I'd try GCP, but unfortunately it's only available to companies in my country) for machine learning/data science? I tried the Amazon ML thing, but I don't really like the idea of just uploading the data and letting the server run everything on its own.

What I want is, basically, a way to run jupyter notebooks and scripts in the cloud. Any tips/links?"
Could you please evaluate this build for a Deep Learning Rig?,8,2,False,False,False,learnmachinelearning,1511316871,True,"I'm buying this build off of my friend for $900 - https://pcpartpicker.com/list/6hz8nn

My plan is to add a 1080 Ti and 16GB more RAM as well. 

Do you think this will be a good deep learning workstation?

I think I might have to increase the power supply as well. 

Would love your help! "
initializing a simple conv net from the ground up,2,1,False,False,False,learnmachinelearning,1511317719,True,"How would one initialize a simple conv net from the ground up? I am working to understand what really goes on inside of conv nets so I'm trying to not use tf, just numpy. I always thought I knew it, but I think I am kidding myself by just calling a conv function from tensorflow. I am going over to post in stack exchange as well, but let me know.  

[this is some starter code for creating the feature maps.](https://gist.github.com/lhubbard01/68f1559f1c54f44f684d0ab99fd1e42f)  I mightve read my source incorrectly, so I'm open to improvements.  I will also update the code in a new gist down the line"
Algorithm or some method for data categorization for support tickets,1,1,False,False,False,learnmachinelearning,1511321623,True,"I'm UX designer with basic javascript skills and I have this problem:

I am going to redesign a user management portal/admin panel for my company to solve user problems. Apparently, according to the tech support manager gut feeling (the company has no culture of measurement), 60% of tickets are related to some issues in that portal that relates to user authorization to use a desktop software. I need to find a way to measure KPIS/OKR on how this portal is going to reduce tech support tickets related to these problems. The company is using a very basic system to log support tickets which doesn't provide tags until we move to Zendesk. Data is not uniform on a description and neither titles.


What I need to do: get CSV data from the current system, and find a way to tag different support tickets based on title and description, example: user password reset, software authorization, etc. 

Data quantity: 12.000 support tickets, with an average of 6 word title and description of 40 to 80 words ONLY* (we have no exchange of emails)


Is there a method or algorithm that I can use to automatically tag / categorize these support tickets instead of me going manually tagging in google sheets /excel? at least I know I can do some sort of filter. "
"Just learned to use tensorflow a theoretical deep learning, where do I learn the maths and what are the requirements?",2,12,False,False,False,learnmachinelearning,1511326518,True, 
TWIL (This Week I Learned) - Share something new that you have learned this week!,3,1,False,False,False,learnmachinelearning,1511334314,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
[dumb question]Is a neuron’s status consist of only “activated” or not?,7,1,False,False,False,learnmachinelearning,1511340578,True,"Hi, newbie here. I am still trying to grasp the idea pf what a neuron is and came up with the ReLU function, which output either a 0 if the weighted sum of input is negative and the value of weight sum of inputs for the opposite. In this case, isn’t the neuron just has two status? My question is, can’t it has an negative effect to the outputs connected to it?"
Deep Learning GPUs: Buyer's Guide,3,34,False,False,False,learnmachinelearning,1511346197,False, 
[Coursera] Downloading all the assignments jupyter notebooks and files,14,5,False,False,False,learnmachinelearning,1511359616,True,"*Context*: I am already using `coursera-dl` to download the videos and it works great, but I missed an analogous tool for the assignments.

GREAT NEWS!

I have just found a way to download all the assignment files from the coursera-notebook hub.

This saved me hours of painful single file downloading: 

(adapted from [here](https://stackoverflow.com/a/47355754) )

1. Go to the home of the coursera-notebook hub

2. Create a new python notebook

3. Execute `!tar cvfz allfiles.tar.gz *` in a cell

4. Download the archive !

Enjoy! 

**If the resulting archive is too big and you can't download it**

Open the python notebook where you executed last command and execute the following in a cell:

    !split -b 200m allfiles.tar.gz allfiles.tar.gz.part.

This will split the archive into 200Mb blocks that you can download without a problem (if there is still a problem reduce the size by changing 200m to a lower value)

Then when you have downloaded all the split files reunite them on your system using the following command line (in a linux environment, or use cmder if you are on Windows):

    cat allfiles.tar.gz.part.* &gt; allfiles.tar.gz

PS: This is in fact valid in any Jupyter-notebook hub"
Cant access the inception-2015-12-05.tgz' needed for recognizing images in tensorflow,2,2,False,False,False,learnmachinelearning,1511365374,True,"Im currently trying to make an application that lets users upload a file and then use Inception-v3 to recognize what it is. I've been using the tutorial repository as a guide: https://github.com/tensorflow/models/blob/master/tutorials/image/imagenet/classify_image.py

    @app.route('/uploader', methods = ['GET', 'POST'])
    def upload_file():
       if request.method == 'POST':
          f = request.files['file']
          f.save(f.filename)
          image_handler(f.filename)
    
    def image_handler(fname):
        maybe_download_and_extract()
        image = (FLAGS.image_file if FLAGS.image_file else
          os.path.join(FLAGS.model_dir, fname))
        predictions = dict(run_inference_on_image(image))
        print(predictions)
        return jsonify(predictions=predictions)
    
    def main(_):
        app.run()
        
    if __name__ == ""__main__"":
        parser = argparse.ArgumentParser()
        # classify_image_graph_def.pb:
        #   Binary representation of the GraphDef protocol buffer.
        # imagenet_synset_to_human_label_map.txt:
        #   Map from synset ID to a human readable string.
        # imagenet_2012_challenge_label_map_proto.pbtxt:
        #   Text representation of a protocol buffer mapping a label to synset ID.
        parser.add_argument(
          '--model_dir',
          type=str,
          default='/',
          help=""""""\
          Path to classify_image_graph_def.pb,
          imagenet_synset_to_human_label_map.txt, and
          imagenet_2012_challenge_label_map_proto.pbtxt.\
          """"""
        )
        parser.add_argument(
          '--image_file',
          type=str,
          default='',
          help='Absolute path to image file.'
        )
        parser.add_argument(
          '--num_top_predictions',
          type=int,
          default=5,
          help='Display this many predictions.'
        )
        FLAGS, unparsed = parser.parse_known_args()
        tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)

The file is taken from a html button and saved to the current directory, then tensorflow should access that save file and perform image recognition on it. When I pass the file to tensorflow I get the following error:

    Traceback (most recent call last):
      File ""C:\Users\Conor\Anaconda3\lib\site-packages\flask\app.py"", line 1982, in wsgi_app
        response = self.full_dispatch_request()
      File ""C:\Users\Conor\Anaconda3\lib\site-packages\flask\app.py"", line 1614, in full_dispatch_request
        rv = self.handle_user_exception(e)
      File ""C:\Users\Conor\Anaconda3\lib\site-packages\flask\app.py"", line 1517, in handle_user_exception
        reraise(exc_type, exc_value, tb)
      File ""C:\Users\Conor\Anaconda3\lib\site-packages\flask\_compat.py"", line 33, in reraise
        raise value
      File ""C:\Users\Conor\Anaconda3\lib\site-packages\flask\app.py"", line 1612, in full_dispatch_request
        rv = self.dispatch_request()
      File ""C:\Users\Conor\Anaconda3\lib\site-packages\flask\app.py"", line 1598, in dispatch_request
        return self.view_functions[rule.endpoint](**req.view_args)
      File ""app.py"", line 167, in upload_file
        image_handler(f.filename)
      File ""app.py"", line 170, in image_handler
        maybe_download_and_extract()
      File ""app.py"", line 152, in maybe_download_and_extract
        filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)
      File ""C:\Users\Conor\Anaconda3\lib\urllib\request.py"", line 258, in urlretrieve
        tfp = open(filename, 'wb')
    PermissionError: [Errno 13] Permission denied: '/inception-2015-12-05.tgz'"
Best way to structure my neural network,3,3,False,False,False,learnmachinelearning,1511366642,True,"Hello, I am quite new to ML but find it fascinating so now I am looking to build a Four In A Row bot for fun.

Here's what I was planning on doing:

* First of all, simulate a bejillion games at random
* Within a game, each state in a game can be represented as a two dimensional array with elements which can have three states: 0(empty), 1(yellow), 2(red)

Example of a game state:

    0000000
    0000000
    0000000
    0010000
    0010000
    0010222

Question 1:

I want to create a classifier that classifies a state to an output (range [0,6]). For the above example, the output would be 2 so player 1 gets four in a row.

I think a neural network makes sense to use but I am unsure how to structure the network. I've heard about flattening things like this is normal but I have some conserns.

My problem seems similar to image recognition problem only that here there is no third dimension and only 3 values instead of 255?

If I flatten the state, will it be able to generalise vertical and diagonal wins? Or do I have to use convolutional network or perhaps there is something even more apropriate?

Question 2:

After I have simulated a game I am left with all the states of that game.
Half the states, the winner's moves, will be labeled, but the looser's won't be. Can I make use of these moves also somehow with semi-supervised learning? If so how would I go about doing that?"
Any sample projects using Sloth for computer vision?,0,1,False,False,False,learnmachinelearning,1511368968,True,"I'd like to take advantage of this Thanksgiving break and learn about computer vision. I would like to utilize Sloth on my Linux machine, but I don't know where to get started once I get it up and running. Anyone have suggestions?"
A gentle dive into the anatomy of a Convolution layer,0,14,False,False,False,learnmachinelearning,1511371268,False, 
Derivative with respect to a weight vector,2,4,False,False,False,learnmachinelearning,1511372057,True,"If I have a function:

`f(x) = log(1 + exp(−y_iw^T x_i))`

How can I find the derivative with respect to weight vector?"
Pickling Keras Models,0,4,False,False,False,learnmachinelearning,1511381129,False, 
Educational Artificial Intelligence Blog,0,2,False,False,False,learnmachinelearning,1511384112,False, 
"Newbie to programming, should i just dive in?",4,5,False,False,False,learnmachinelearning,1511396140,True,"I am currenly studying Civil Engineering, but i want to learn ML because it fascinates me. As a third year eng student, the maths doesnt bother me to much. I've just started working through Automate the Boring Stuff, to learn python. But should i finish this book, or should i just sign up to something like Dataquest and learn as i go? My concern is that it isn't really aimed at people who want to get into ML so how much of the knowledge is relevant.

I also plan on doing Andrew Ng's course in the future, but just want to get some opinions on the best path to learn and how much conventional programming knowledge is required.
EDIT: Also what are your thoughts on the MIT 6.001 and 6.002 courses for someone who's  new to programming and interested in machine learning
Thanks guys"
Update to Deep Learning YouTube Playlists,2,31,False,False,False,learnmachinelearning,1511403094,True,"Hi everyone,

I made two posts here a few weeks ago sharing deep learning playlists from my YouTube channel. I received messages from many users on this subreddit stating that they were subscribed and following the videos. I just wanted to give a quick update to share that my deep learning/ai content has moved and is no longer available on the previous YouTube channel. 

I updated my previous posts on this subreddit with the new links. I hope to see you on the new channel! I'll be continuing to produce new deep learning content there.

- [Post for Deep Learning Fundamentals Playlist](https://www.reddit.com/r/learnmachinelearning/comments/7740tc/deep_learning_fundamentals_youtube_playlist/)
- [Post for Keras Playlist](https://www.reddit.com/r/learnmachinelearning/comments/735ez9/deep_learning_with_keras_youtube_playlist/)

- [Direct link to Deep Learning Fundamentals YouTube Playlist](https://www.youtube.com/playlist?list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU)
- [Direct link to Keras YouTube Playlist](https://www.youtube.com/playlist?list=PLZbbT5o_s2xrwRnXk_yCPtnqqo4_u2YGL)"
Looking for study partner,9,3,False,False,False,learnmachinelearning,1511412621,True,"I enjoy math and programming so when I first started getting in touch with the idea of AI and ML it was immediately obvious to me that this is something that I want to do, and I would even go so far as to think that this is something that I want to do for a living.

I have been trying to study things on my own with Coursera and Datacamp and stuff, but am having some motivation issue. I am a high school senior, so it's true that at the moment I am kind of bogged down by college application, but even then I definitely see a lot of time that I could be using to study ML that I am just wasting. I think that if I had a study partner then it might become easier for me. I don't really know how study partner works and what kind of stuff makes people compatible to be study partner, so I guess for now I am just looking for someone that I can talk to about my progress in study so we can supervise each other.

I am ok with most modes of contact. I use discord really often so that's ok with me, or we can text, email, slack, skype, etc."
Reading features from a csv file,0,2,False,False,False,learnmachinelearning,1511421170,True,I have a csv file with first column as labels from 0-9(1000 labels) and column 1-1023 with pixel values of 32*32 image sets. There are around 1000 images in training example. How do I read my train_data and train_data_labels?
Whats the python equivalent of the tutorial below,0,3,False,False,False,learnmachinelearning,1511435182,True,"Im currently retraining the model to recognize hand drawn images on top of the 1000 classes already trained for. Is there a python way of doing what they do with bazel? I already started dividing my photos into folders for retraining.

Tutorial:
https://www.tensorflow.org/tutorials/image_retraining"
Algorithms for sparse and imperfect information environments such as card games,0,6,False,False,False,learnmachinelearning,1511438327,True,"Go is an example of a sparse but perfect information game but from my point of view it is not that different from Hearts. Simple QLearning is out of the question because the model gets too big since every state has to be stored so it makes it unpractical. 

I read a little about [POMDPs](https://en.wikipedia.org/wiki/Partially_observable_Markov_decision_process) and that seems to fit card games of this kind.

What are my chances trying  (Double?) DQNs? Should I be looking elsewhere?

Would love to hear what you guys think, I’m kinda stuck."
Issue with shuffling image to a hdf5 file,0,5,False,False,False,learnmachinelearning,1511439391,True,"I want to shuffle my image before putting it into the hdf5 file, but got an error in the computation.

if shuffle_data:
    c = list(zip(address, labels))
    shuffle(c)
    addrs, labels = zip(*c)

ValueError: not enough values to unpack (expected 2, got 0)

Reference: http://machinelearninguru.com/deep_learning/data_preparation/hdf5/hdf5.html#list"
Why do Neural Networks 'love noise'?,5,10,False,False,False,learnmachinelearning,1511441806,True,"I was watching this lecture

https://youtu.be/ERibwqs9p38?t=1h17m34s

and the professor says Neural Networks 'love noise'. Why is that?"
"Neural network applications outside images, speech, and similar?",14,8,False,False,False,learnmachinelearning,1511449787,True,"I'm really interested in neural networks, both deep and shallow, and potentially using them to do interesting things in my work. However, it seems that most of the applications involve things like images, speech recognition, captioning, etc. Is this pretty much where they are being used, or are they useful for other problems as well? 

Is there a list somewhere where you can see a bunch of novel neural network approaches on things outside images and speech? "
Probabilistic graphical models: parameter estimation and inference algorithms,0,16,False,False,False,learnmachinelearning,1511454077,False, 
Learn to create Machine Learning Algorithms in Python and R from two Data Science experts. Code templates included.,1,21,False,False,False,learnmachinelearning,1511456266,False, 
Resources for learning the required math for ML.,4,26,False,False,False,learnmachinelearning,1511466584,True,I would love courses and resources on math refreshers and to learn the math to succeed in learning ML. 
Resources for learning the required math for ML.,0,1,False,False,False,learnmachinelearning,1511467735,True,[deleted]
Koh Kodes - Author Check: a tool for analyzing documents for stylistic similarity,0,2,False,False,False,learnmachinelearning,1511478201,False, 
"Docker Quick Guide (macOS, Ubuntu, Windows)",0,12,False,False,False,learnmachinelearning,1511480661,False, 
Weekly Show-off!,1,2,False,False,False,learnmachinelearning,1511507118,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
Visual Analytics of Instagram’s #gopro hashtag with AI,0,1,False,False,False,learnmachinelearning,1511507653,False, 
xLearn - High-Performance and Scalable Machine Learning Software for Large-Scale Sparse Data,0,7,False,False,False,learnmachinelearning,1511531729,True,"How to solve large-scale sparse machine learning problem efficiently is a very important topic. The ML algorithms like Sparse LR, FM, and FFM have been widely used in both industry and machine learning competitions recently. Existing open source ML software like lib linear, libfm, and libffm are designed to solve one specific algorithm and lacks scalability, flexibility, and ease-of-use. Motivated by this, we designed a new ML software called xLearn, which has been shown in NIPS 2017. After that, we polish our software carefully and now we are excited to announce that we open-sourced this software today ! https://github.com/aksnzhy/xlearn . Our vision is that we can push our project forward and become the package that has the most impact for solve large-scale machine learning. 

Compared to exiting software, xLearn has the following advantages: (1) Generality. We use a uniform framework to handle a set of powerful machine learning algorithms, and users do not need to change their tools between different package. (2) High-performance. xLearn has been built on high-performance C++ with careful design and optimizations. Our system is designed to maximize the CPU and memory utilizations, provide cache-aware computation, and support lock-free learning. By combining these insights, xLearn 13x faster that libfm, and 5x faster than libffm and lib linear on a MacBook pro (based on the Criteo CTR benchmark).  (3) Ease-of-use and Flexibility. xLearn does not rely on any third-party library, and hence users can just clone the code and compile it by using cmake. Also, xLearn supports very simple python API for users. Apart from this, xLearn supports many useful features that has been widely used in the machine learning competitions like cross-validation, early-stop, etc. Also, users can also specify the optimization method (SGD, AdaGrad, FTRL) they want. (4) Scalability. xLearn can be used for solving large-scale machine learning problems. First, xLearn supports out-of-core training, which can handle very large data (TB) by just leveraging the disk of a single machine. Also, xLearn can support distributed training, which scales beyond billions of example across many machines.

We are hope that more developers can join us to push this project forward !"
[D] Choosing Components for Personal Deep Learning Machine,1,8,False,False,False,learnmachinelearning,1511544682,False, 
Getting started with machine learning in R,2,12,False,False,False,learnmachinelearning,1511545349,False, 
"How to overcome the Daunting, daunting math machine learning has as a mathemathically lacking highschooler, And generally everything else?",15,11,False,False,False,learnmachinelearning,1511561750,True,"So: Here's the situation.

I have a fascination for machine learning. Before I knew anything about this it just was in fascination for robots and cheesy robot movies, but now that I have a slight knowledge about what machine learning is, I would like to try and overcome my mental barriers surrounding stuff like programming and machine learning and achieve my AI/Neural network creator dreams, if that makes sense.

Heres where i'm at now, to give you an idea of where I am: 

I am in highschool(freshman), but I am quite behind in math, could be considered stuck in 7th grade math for that field(I still forget fractions). My learning process is both slow and forgetful, so I could take days to 'understand' a math concept and then forget it the  next day.

 I've been trying to take notes for myself but i'm terrible at explaining things (even to myself) especially when I write them in a hurry so the knowledge just goes one ear out the other unfortunately. I often need to explain the things step by step and not forget any small but important details, and I usually forget that in my notes so i'll have an arrow here or an unexplained step there and i'll have to revise the whole thing all over again. And even then when I take the perfect notes and practice, I still flunk on those zero-note tests.

An important part, I'm a beginner to coding in general and am floating around with python. I'm not sure if that's what I'm actually supposed to be using and how i'll get to the machine learning part, Particularly because I can't find any courses of general places that talk about beginners in code with the end goal of doing AI/Neural networks/machine learning, I mostly hear about web development etc...

 I heard somewhere that they're are certain 'pre-packaged' python distributions that are focused for machine learning/AI/Neural  networks, but I'm not sure whether that's what i'm using or what i'm doing because currently i'm learning about print(), random.int(), etc. But I have no clue, so a little bit of explanation would help me a lot.

Now, when I hear about machine learning math credentials and hear concepts like 'Linear algebra, differential calculus(got that wrong probably) and probability, I nearly flinch. 

I'm not sure if i'm entirely terrified by math, or i'm terrified of all the small, little concepts and how my slow, forgetful brain's going to remember and string them all together. At this point it may not matter-matter as my math grades are always on thin ice of becoming C's or F's- which is why I ask this question:


How do I overcome the Daunting, daunting math machine learning has as a mathemathically lacking highschooler, And generally- everything else that comes with being a beginner coder/programmer and machine learning?

Thank you for reading, input appreciated.


"
Multiple labels for classification in large dimensional space,5,2,False,False,False,learnmachinelearning,1511563905,True,"I have a large database where I'm trying to classify every single entry for a subset of my data (i.e. approximately 10 000 out of 1 000 000 000) with two separate classification types. Each entry has 10 associated measurements with quite large errors (up to 20%). Thus the data exists in 10-dimensional space, although based on the operational space for the measurements, it might be very sparse.

Now the two separate types of classification are essentially colour and age: the colour of an entry can be labelled as 10 different colours (strings), and the age of an entry can take on a set of real values from 0.00 - 100.00 (floats up to at least 2 decimal places).

I am planning to manually assign the age and colour of about 10 000 entries in my subset and train my algorithm, which would then be used to further classify my larger database of entries into a particular colour and a particular age. Although I am wondering what type of algorithm is optimal in this situation. I was considering Random Forests or k-means clustering, but am open to any advice/thoughts on either these methods or others for the above situation."
Boosting and Bagging: How To Develop A Robust Machine Learning Algorithm,0,14,False,False,False,learnmachinelearning,1511565476,False, 
Need to learn how to install and use Tensorflow's Language Model on One Billion Word Benchmark,0,2,False,False,False,learnmachinelearning,1511573403,True,"I am admittedly very new at machine learning programming and programming in general, so all I have been able to do is download all the necessary files from https://github.com/tensorflow/models/tree/master/research/lm_1b but I simply don't know how to proceed and the I do not understand how to do some of the instructions from the read me (for example, I don't know how to ""create an empty WORKSPACE file in my workspace.""

Any and all help would be greatly appreciated. "
Learn Machine Learning Using Azure ML,0,1,False,False,False,learnmachinelearning,1511589159,False, 
Why is the ID3 algorithm 'slow'?,1,2,False,False,False,learnmachinelearning,1511589718,True,"I am trying to build a decision tree with a depth of 200 using ID3. I found that this takes a really long time. The dimensionality of this dataset is very large, and I also have quite a bit of data training points."
InceptionV3 transfer learning,7,5,False,False,False,learnmachinelearning,1511592409,True,"I recently used InceptionV3 model to classify dog breeds. While training the model I found a few quirks.
1.) using an epsilion of 1e-8 for an adam optimizer slowed my learning compared to an epsilion of 0.1. Ideally epsilion is used so that we don't geta divide by zero error. But how is it affecting my learning speed?
2.) My training loss was 3.x while my validation loss was 0.x? I've used data augmentation techniques for training data set and not for validation data set. Can someone explain this effect to me?
3.) It took me 2 days to train my models last layer on AWS with 8 core CPU. Is this valid time period or did I screw up somewhere in my code. (i used 256 dense layer and 120 softmax layer)

Thanks in advance. "
"Weekly Status Check Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",0,1,False,False,False,learnmachinelearning,1511593510,True,"Let's have a  meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
Loss rate at convergence : Gradient Descent,2,2,False,False,False,learnmachinelearning,1511603871,True,"Hello guys, I'm implementing the gradient descent. I'm looking for the definition of **loss rate at convergence** and how to compute it. I don't have luck with google so far.
Thanks."
Any good books for Beginners in ML to suggest?,9,6,False,False,False,learnmachinelearning,1511610693,True,"I have about 10 yrs professional experience in programming (mostly Ruby, a little Python and less C/C++). I am watching some ""courses"" in Youtube but I want to buy a book or two as a guide. So I don't have any experience in Machine Learning or A.I.

Those of you who have already done a few steps on this area, which books did you find helpful and well written? I am looking mostly into prediction e.g. replacing lots of ifs and manual conditional blocks with an ML implementation and what I've already read are about Tensorflow which I find the most popular and supported framework so far. "
How are higher order markov chains fitted?,0,1,False,False,False,learnmachinelearning,1511616483,True,I haven't been able to find any concise material on it.
How to deal with datasets of varying formats?,3,0,False,False,False,learnmachinelearning,1511620963,True,"I'm currently trying to create an application in Python that analyzes telephone call records to try and extract various relevant data from them. The intended use-case is for finding potential criminals and detecting fraud. Currently I'm using a sample data-set as an example to design the various functionalities of the application. But the obvious problem with my current solution is that it only works for the dataset I'm working with, not all datasets. Suppose a telecom company would like to use my software, but their call records use a different format (I mean column ordering, column names etc, not file extensions). How would I be able to make an application work with practically any type of call record, given that all call records follow a similar (though not identical) format?"
AI in production.,2,5,False,False,False,learnmachinelearning,1511625678,True,"I am a beginner in AI but have been programming for all my life. 
And got to admit that Python is not my first language to go to when i want to develop production system. 

So i am developing a system that will take a picture of the package and recognize the shipping address from the picture and put it in a system with tracking #. Shipping labels are all generated with computer so it should not be hard to get AI working perfectly.

So the plan is to write AI level in Python with TensorFlow, train my model and then dump the model into C# written program that will already work in production. 

Again, i am very new to this, it's my first project with the goal to learn AI.
Please let me know you thoughts about this.

thanks.
"
Spiking RBMs trained using Contrastive Divergence based on STDP rule,0,1,False,False,False,learnmachinelearning,1511630531,False, 
I don't get a core component of LSTMs,4,6,False,False,False,learnmachinelearning,1511634634,True,"I have begun to read up on LSTMs and just don't get something very basic: what are the gates trained on? They are trained using conventional supervised learning, right? Does that mean that for each input in your training set you need to prepare a set of target vectors for the different gates?"
The basics of Beta distribution explained using a simple example and animation.,2,14,False,False,False,learnmachinelearning,1511641807,False, 
Feature selection and input into neural network,9,2,False,False,False,learnmachinelearning,1511647782,True,"I'm currently in the middle of a university assignment where we have been tasked with applying an AI implementation to a problem area. I've chosen spam detection as my choice of area, and I'm planning on using a neural network for the AI.

At the moment I have written a program that analyses a folder full of spam/ham emails and counts the occurrence of every word and whether it appeared in a spam email or a real email. I'll keep the technical details short but the word occurences are stored in a custom class within two separate arrays, corresponding to ham email words and spam email words. 

My problem now however is figuring out what I need to provide to the NN in order to train it. I'm not sure if I should take the most common words in both emails and apply that to the NN or do something different in order to train it. My university lecturer mentioned that I should compare the difference in occurrences of  words between the spam and ham emails and then apply that to the NN to train it, but I'm not sure how exactly this works.

Just hoping someone would be able to give me some advice here with what exactly needs to be input to the NN in order to train it to detect whether a test email is spam or not."
"Question about scaling and normalizing some input data (some are labels with a linear relationship, some are descriptive)",3,1,False,False,False,learnmachinelearning,1511655885,True,"I have some data where some of the attributes are a quality scale (i.e. the values are 'poor', 'below average', 'average', 'above average', and 'excellent') and other attributes are just text values without any such relationship. So what i've done is changed the quality-type attributes such that the text values are replaced with 1, 2, 3, 4, 5 and the other descriptive attributes I've one-hot encoded.

So my question is: Should I scale the quality attributes? some of the attributes have a range 0-5, others 1-5, and the one-hot encoded attributes of course are either 0 or 1.  So I'm wondering if any scaling or normalizing should be done.

Bonus question: if some of my attributes are ""descriptive"" (i.e. an attribute has values 'green', 'blue', 'red') and some of my other attributes convey some kind of relative quality like poor, average, excellent - what would you call these different types of attributes?"
Would you donate your data for the collective good?,0,1,False,False,False,learnmachinelearning,1511662317,False, 
Need minimal linux VM image,5,1,False,False,False,learnmachinelearning,1511674238,True,I need vm image which can be used to train Or code Neural network.Vm image needs to be as minimal as possible( no gui) and can be used for 512 mb or 1 gb ram.basically i will be using ssh to connect and then code into it.
Comprehensive practice problem-heavy statistics book recommendations,7,2,False,False,False,learnmachinelearning,1511675465,True,"I know this is a question that comes up somewhat often, please forgive yet another permutation. 

I have a fairly strong math background considering I majored in CS and only have a math minor. I'm fairly comfortable with calc up through vector calculus, my linear algebra is rock solid, but I never learned stats. I intend to change that in the next two months. I found a good looking biostats course from John Hopkins on Coursera I just started, there's MIT's stats 101, and [think stats](http://www.greenteapress.com/thinkstats/) that I'm skipping through, plus Kahn's Academy of course for specifics... but I'm looking for a very specific kind of companion piece. Here's what I want:

I find I learn best by doing. I get a much better sense of where the holes are in my understanding when I run into roadblocks in practical problems. I want as much fodder to wade through as I feel I need for any given concept. When I was learning Calc and Linear Algebra, the books always had a ton of problems at the end of each section, you could wade through until you knew what you needed, and then move on. I want that. Any suggestions? "
"Hi everyone, I have a question about continuous conditional random fields.. I think",0,5,False,False,False,learnmachinelearning,1511705998,True,"So, I have a problem in which I have a time series of grids (2d arrays of information).  So, I have say, 200x200 grid squares.  Each grid square has ~35 samples.  Each grid square sample has ~20 to ~40 features.  I have been modeling each square's time series individually, and by predicting for each square I am able to predict an entire grid in the future.  The grid is representative of something in the real world, and so for features of each square I have been using neighbors in time and space.  I use various methods to reduce the dimensionality of my features to something reasonable, to improve effectiveness.  My results have been good.

My question is if this sounds like an appropriate problem to use continuous conditional random fields (something I know almost nothing about).  One of my main concerns would be lack of sample size.

Furthermore, it's my understanding that conditional random fields try to solve the probability of a target given each feature.  So in this case, I would be solving the conditional probability of each target, given supplied features over each grid square.  ~35 samples sure does not sound like enough to do this.

In my mind I can envision something more effective for this scenario.  What if I had a model that mapped the conditional probability not only of y given each x for each grid square, but also of y given the probability of every other y for every other square.  So, a model that could use *both* each grid square time series as samples (~40 per square), but also use the entire grid for that year as relevant information as well.  Essentially, training for each individual square would end up being based on *all* previous information, and determination of relevancy (hey, is this square on the other side of the grid actually relevant?), would be up to the model to determine.  I have to wonder, is this actually what the *big picture* implementation of a conditional random field actually is?

Is there anything like this?  Am I making sense?  Thank you for your patience."
Meet the High Schooler Shaking Up Artificial Intelligence,0,0,False,False,False,learnmachinelearning,1511707392,False, 
"A-Z courses related to ML,AI,DS and DL",0,22,False,False,False,learnmachinelearning,1511707734,False, 
Question about Max Margin Loss equation (from Stanford's deep learning NLP course),0,3,False,False,False,learnmachinelearning,1511709068,True,"Here's the specific equation in question

https://youtu.be/uc2_iwVqrRI?t=50m6s

This is where some of those terms are defined

https://youtu.be/uc2_iwVqrRI?t=49m10s

My question, is how is there 2 s's in the loss equation? Do you only take one sample at a time, so that one of the s's is always 0? Or is it summed over several sentences?"
Write a text using machine learning,5,2,False,False,False,learnmachinelearning,1511717270,True,"Hi,

For a schoolproject I have to write a speech, and I've chosen to do it about AI. I thought starting the speech with text generated by AI was kinda cool, and I found this perfect article on how to do it (How to write with artificial intelligence, medium.com), but it only works on Mac. Does anyone have an idea on how to achieve this?"
Making AI Art with Style Transfer using Keras,0,12,False,False,False,learnmachinelearning,1511717656,False, 
Can ML reverse engineer a formula from pricing data? [Shipping Costs],2,2,False,False,False,learnmachinelearning,1511727719,True,"Hello, 

I was wondering if there's an algorithm that can figure out a price formula from sample shipping data. Essentially the price of shipping items varies on factors such as mileage, region, etc. The shipping company I use will charge a base fee and a mileage fee based on information on my shipping request. 

What would my best approach be for figuring out how Company R calculates the cost of shipping my items, using an algorithm? Very simple dummy data below: 

ITEM|MILES|TIER (BASED ON MILES)|ORIGINATING STATE|REGION|BASE|MILEAGE RATE|PRICE TO SHIP|
:--|--:|--:|:--|:--|:--|:--|:--|
Shoes|12|1|TX|Southeast|x1|y1|x1 + y1|
Socks|27|1|TX|Southeast|x2|y2|x2 + y2|
Laces|31|2|OK|Southeast|x3|y3|x3 + y3|


I can see how an algorithm can make a prediction on 'price to ship' given features. But can it give me the finite formula the company uses, assuming it's consistent? 

Thanks in advance!  
"
Classes/exercises/projects to build intuition on practical ML strategies after taking a beginner MOOC?,3,2,False,False,False,learnmachinelearning,1511736990,True,"I did Andrew Ng's machine learning class on Coursera, and I'm now working my way through his deep learning specialization. It's been fascinating so far. But as I've started to play around with the tools in a less ""guided"" way, it's also become clear to me just how far I have to go to until I can apply any of this knowledge.

In light of that: what would be a good next step after I finish the specialization? Are there other classes that are more project-based, maybe? Should I try a few Kaggle competitions? Just go build stuff?"
Using checkpoint saving with train_on_batch in Keras?,0,2,False,False,False,learnmachinelearning,1511738416,True,"I'm training my data in batches using train_on_batch, but it seems train_on_batch doesn't have an option to use callbacks- which seems to be a requirement to use checkpoints. 

I can't use model.fit as that seems to require I load all of my data into memory. 

model.fit_generator is giving me strange problems( like hanging at end of an epoch).

Here is the  Keras API docs showing the use of  checkpoint:

Example: model checkpoints

`from keras.callbacks import ModelCheckpoint

model = Sequential()
model.add(Dense(10, input_dim=784, kernel_initializer='uniform'))
model.add(Activation('softmax'))
model.compile(loss='categorical_crossentropy', optimizer='rmsprop')

'''
saves the model weights after each epoch if the validation loss decreased
'''
checkpointer = ModelCheckpoint(filepath='/tmp/weights.hdf5', verbose=1, save_best_only=True)
model.fit(x_train, y_train, batch_size=128, epochs=20, verbose=0, validation_data=(X_test, Y_test), callbacks=[checkpointer])`
"
How valuable is the certificate from completing Andrew Ng’s Coursera ML course?,4,4,False,False,False,learnmachinelearning,1511748215,True,Does anyone value the certificate and is it worth $79?
What is the correct way to train a sparse multi-label classifier in keras?,1,8,False,False,False,learnmachinelearning,1511779300,True,"My target output is a 1000 dimensional binary vector which each represent an attribute of the input. Only few attribution return 1 and most of the output is 0.

I tried to train with cross entropy but the classifier just want to output a 0 vector"
Visualizing ConvNN layers in RGB,3,4,False,False,False,learnmachinelearning,1511794525,True,"Hi all, I've been reading through some CNN visualization articles, and a lot of the visualizations show RGB representations of the models inner layers. How are these layer activations visualized as RGB images when the layer activations have way more than 3 filters [channels]?

In say, VGG16, the model takes an image input from 3 filters(RGB) to 64, 256 or 512 filters in subsequent layers.

In one of Andrej Karpathy's earlier posts, his images and his reference to Deepvis show these activations in color. 

karpathy.github.io/2015/10/25/selfie/

I also see full color representations (i.e DeepDream) of these inner layers that supposedly have very many filters.

say for an image with a shape 300, 300, 3; how would one visualize in color a layer output that produces 300, 300, 64?"
Introduction to generating image data for convolutional neural networks using Keras.,0,13,False,False,False,learnmachinelearning,1511816013,False, 
Tensorflow Regression Help,3,3,False,False,False,learnmachinelearning,1511817878,True,I was wondering if anyone knows any good resources/tutorials for understanding how to do nonlinear regression with Tensorflow? Currently working on a school project where I need to create such a design in order to predict response variables in a dataset and I am a bit lost on how to go about it. Thanks for the help!
"1080 Ti combined with 980 Ti, good enough for ML + Kaggle?",2,3,False,False,False,learnmachinelearning,1511827388,True,"Title says it all. I have 32GB RAM and i7 processor.

Can't buy anything else for the time being. Just wanted to know if it this is a good place to start from. 

Any help would be appreciated! "
Tensorflow Race Condition,4,3,False,False,False,learnmachinelearning,1511834277,True,"How do you deal with the race condition when using tf.assign()?

For example, if my code is the following:


    y = tf.Variable(6,trainable=False,name='y');
    
    x = tf.Variable(0,trainable=False,name='x');

    assign_op = tf.assign( x, 2 );
    
    divide_op = y/assign_op;
    
    answer = sess.run([divide_op]);
My answer is either 3 or 0inf.. 
The only thing that I can think of is splitting up the sess.run into this:

    _ = sess.run([assign_op]);
    
    answer = sess.run([divide_op]); 


I thought that creating a operation dependency like I did above would solve the issue of there being a race condition but it doesn't. Does anyone know what to do about this?"
Starting with ML: Learn theory or jump into learning libraries,12,15,False,False,False,learnmachinelearning,1511844815,True,"I've been dabbling with Python libraries such as pandas and numpy and want to move into more machine learning. However I wonder if I have to start by learning the statistical theories or are there resources that can both teach the necessary theory and the Python libraries involved? 

Does anyone have suggestions for books (I prefer books over videos) that can teach both?"
Translating English to Yoda English using Sequence-to-Sequence with Tensorflow.,4,10,False,False,False,learnmachinelearning,1511846536,False, 
The non-techie’s guide to machine learning,0,4,False,False,False,learnmachinelearning,1511849086,False, 
Machine Learning in simple words: Azure Machine Learning part I,0,2,False,False,False,learnmachinelearning,1511853884,False, 
Step-by-step modeling a neural network for classification (in-browser experiment),0,3,False,False,False,learnmachinelearning,1511869731,False, 
I am lost and I need help.,7,12,False,False,False,learnmachinelearning,1511875349,True,"I'm at the point where I am proficient enough with python and the common concepts of machine learning that I should start experimenting. Except I still feel there is this major missing connect between understanding the concepts and putting my newfound skill in use? 

Anyways I have this personal project I really really want to do to help my parents. They want to build a house to retire and my mom is really a visual person and I would like to create something to automatically generate 3d model of houses base on blueprints. My idea is to train a CNN to automatically recognize blue print of a house so Blender3D can automatically generate the 3D models. I know this has been done before but I really want to make my own. I took andrew ng's course and I have learned how convolution neural networks work but I still have no idea where to start. I would like to get some directions on where I should proceed. 

My background: I took andrew ng's course and I stopped on week 4 because I was struggling with octave. I am almost done with Udacity's ML course. I will finish andrew ng's course and I might also take up berkely's ML course just to review everything again. I like to learn from different sources. However most of the stuff really doesn't interest me, like text learn to predict email authors, regressions to find body weight ratio or housing prices. I am a very artistic person so I would love to master CNNs. I know the concept and math behind it from Andew's course now I need to look for more information about CNNs to make my project come true. Any idea on which course and book I can read about CNNs would be greatly appreciated. 

I am currently taking udacity's intro to ML because of python and their computer vision course aswell. "
Machine Learning A-Z™: Hands-On Python &amp; R In Data Science,0,1,False,False,False,learnmachinelearning,1511889905,False, 
Predicting Cryptocurrency Prices With Deep Learning,10,31,False,False,False,learnmachinelearning,1511891838,False, 
Predicting popular tweets with Python and Neural Networks on a Raspberry Pi,0,1,False,False,False,learnmachinelearning,1511901613,False, 
Data Preprocessing,1,1,False,False,False,learnmachinelearning,1511919614,True,"I'm preprocessing data on Weka and was wondering if anyone has a suggestion for managing missing values? They are coded as 0 in this dataset, but it's troublesome because some of these instances could very well have an actual measured value of 0. How should I manage this?"
Using Caffe2 (ONNX) Models in Java.,0,1,False,False,False,learnmachinelearning,1511920881,True,"Does anyone have a link or any information about using converted ONNX models in Java? I have successfully converted a PyTorch model to ONNX. Now I would like to use this model in a Java application. I know Caffe2 has been used before for this purpose but I haven't been able to find any real documentation. 

Basically, I'm looking to use the model in an Java streaming application that was written in Apache Flink. Preferably I'd like to incorporate it directly into DataStream as a map from incoming data to prediction. "
Can coursera courses be completed once the course is finished?,3,1,False,False,False,learnmachinelearning,1511925356,True,I'm enrolled in Andrew Ngs coursera course. I want to work through the MIT 6.00.1x and 2x first. And the Machine Learning course ends before I will finish them. But I want to know if I can still do the course once it's ended. I don't care for certificates or grading. I just want to work through the content. 
TWIL (This Week I Learned) - Share something new that you have learned this week!,4,12,False,False,False,learnmachinelearning,1511939115,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
First look of Azure Machine Learning : Azure Machine Learning part II,0,6,False,False,False,learnmachinelearning,1511945408,False, 
Is it possible to skip for normal machine learning and learn deep learning?,9,6,False,False,False,learnmachinelearning,1511947740,True,"As per title. I want to learn deep learning in python. Provided I have a large data and a very good gpu, can i just skip the normal machine learning steps (skip learning pandas, sklearn, etc..) and straight away deep learning (tensorflow)? I've watched the youtube intro video for deep learning and from what I understand the algorithm used is different anyway. Or does deep learning also requires knowledge in pandas and sklearn before using tensorflow?"
Text Analysis in Excel: Real world use-cases,0,1,False,False,False,learnmachinelearning,1511954194,False, 
Natural Language Processing Library for Apache Spark,0,10,False,False,False,learnmachinelearning,1511959830,False, 
Layman's Guide to Overfitting in Machine Learning Models,5,18,False,False,False,learnmachinelearning,1511965666,False, 
"""Hello World"" equivalent to get into NLP?",8,9,False,False,False,learnmachinelearning,1511966735,True,"Hey guys,

I've been doing general machine learning and deep learning for computer vision tasks for quite some time now and would love to get into NLP.

In your opinion, what's the ""Hello World"" equivalent for NLP? For computer vision it's basicly MNIST with Keras, is there something similar for NLP?

Thanks in advance!"
Home Automation System,1,7,False,False,False,learnmachinelearning,1511973257,True,"I started Internship at a company as a Python developer, and manager assigned a Home Automation System project to me which takes voice as input and used to control appliances, using Raspberry Pi 3.
So in the first phase of project i have to convert speech into text and text into speech. I know it will need to implement ML but i don't have much knowledge of ML.
So Where should i start? And he asked if i can train it to understand Hindi(language used in India).
Any help or suggestions would be appreciated."
Learn how to use Google's Deep Learning Framework - TensorFlow with Python! Solve problems with cutting edge techniques!,0,3,False,False,False,learnmachinelearning,1511978301,False, 
Image comparison library in python?,0,1,False,False,False,learnmachinelearning,1511982080,True,[removed]
"What could I study to learn the ""building blocks"" of ML algorithms themselves?",8,12,False,False,False,learnmachinelearning,1512000625,True,"Sorry if the title's not exactly clear, I'm not sure of a short way to put this?

So, when I was learning CS the biggest ""a ha"" moments for me came in my data structures class. Once I knew about pointers, graphs, arrays, recursion, big-O analysis etc., I was able to reason about algorithms somewhat: I could decide what performance characteristics were most important for a problem, look for an algorithm that fit, and then tweak or build one to suit my specific needs.

I'm very early in my machine learning studies -- I've done Andrew Ng's ML class on Coursera, and I'm working through his deep learning specialization right now. I can usually follow the explanations of the algorithms and understand what they do. This feels analogous to my early days programming: I could maybe understand how a program works with enough context, but I didn't know enough to deeply analyze them or to build my own.

I get the impression that experienced practitioners -- the people writing papers, say -- have some ML intuition similar to what I started to experience with CS in data structures. A sense of how effective ML algorithms come together that helps them know what to try. Am I right? And if so, is there some area of study that would help me grasp it myself? Particular branches of mathematics, perhaps?

For context: my math studies in school were only up to single-variable calculus and discrete math. I've learned a *tiny* bit of multivariable calculus in the process of working through the ML/DL classes."
What is the difference between soft and hard labels?,1,6,False,False,False,learnmachinelearning,1512000906,True,What does it mean to train a model against soft labels rather than hard labels?
Got a silver medal in my first kaggle competition!,4,51,False,False,False,learnmachinelearning,1512031343,True,"In the Porto Seguro competition that just ended. Really fun experience if you haven't tried it before. I learned a lot from my submissions, but I learned even from the public kernels and discussion posts by top kagglers. Overall my model was pretty simple, a stack with a couple of xgboost models with an LR on top. Turns out that was good enough for a top 200 finish. I was trying to make a neural net to ensemble with but ran out of time sadly.

I honestly got kinda lucky with the submission though. I had some very good submissions, 1 that even would've gotten me top 50 but most of them would've been bronze medals so I got lucky that I submitted the ""right one"" so I could land that silver.

Great experience and whilst I know kaggle doesn't translate to real life machine learning it feels good to atleast have some sort of validation for the time I've put in the last couple of months in learning ML. Hopefully it gives my CV a nice little boost too :)

edit: I started my master's degree in comp sci with a focus on data analysis 3 months ago. Taking courses and learning all the basics whilst reading as much as I can about neural net research on /r/machinelearning and also reading a lot on kaggle. Learned A LOT in the span of the competition just from reading and learning from others."
"I adapted the TF ""deep mnist for experts"" to my data and it seems to work, what now?",4,5,False,False,False,learnmachinelearning,1512047595,True,"Hi all,    
     
I'm a bioinformatician, trying to get into all this ML goodness.    
    
Last week I managed to adapt the TF tutorial to my data, but thanks to my
general ignorance on the topic I am now stuck. My model seems to be working, but I don't
understand how well and have almost zero clue as to how I could improve it from here.    
so I'm hoping for some advice/direction!     
    
To introduce my problem:
My data come from sequencing assays and consist of a collection of about 
200.000 genomic sites ""of interest"", and a crap load (1.600.000) of ""control"" sites 
(shuffled on the genome more or less).  So it's a binary classification problem, right? 
I gave my good sites label 1 and the ""control"" ones label 0.
(what ratio of 'bad/control' sites should I feed with my good ones? Does that influence the system? )    
    
Each site is a 200x80 matrix where the x axis is the genomic position and y is 
the fragment size of the sequencing reads (the distance between the pair of reads). 
I split the signal in 2 channels, one for the + strand mapping reads and one for the - mapping ones.     
       
Unfortunately each individual site doesn't have too much info, they look like this:     
https://i.imgur.com/9Wbzbjp.png    
     
But if you combine plenty together, you can see the underlying pattern:
[+ channel](https://i.imgur.com/yBzKntV.png) , [- channel](https://i.imgur.com/witGOCi.png)     
      

So I copied the TF tutorial like a monkey, only changing the size of the matrices,
adapting to 2 channel input and nothing else... and miraculously it actually seems to work:    
    
https://i.imgur.com/qDjXNMm.png    
(sorry for the lack of legend)    
     
This ROC is from running my resulting CNN on a different dataset, blue is the CNN,  
orange is my previous best attempt at this problem, green and red other things.. doesnt matter...    

So moving on to questions:
     
It seems important to monitor the loss (?) of the model, so in my last run I output accuracy and loss every few steps:    

Epoch | Accuracy | Loss
---|---|----
100	|	0.94	|	0.271744
200	|	0.91	|	0.290175
300	|	0.9	|	0.293357
400	|	0.91	|	0.201807
500	|	0.92	|	0.233421
600	|	0.92	|	0.191467
700	|	0.89	|	0.329137
800	|	0.9	|	0.273969
900	|	0.93	|	0.195474
1000	|	0.96	|	0.148833
1100	|	0.9	|	0.308429
1200	|	0.97	|	0.125979
1300	|	0.94	|	0.164453
1400	|	0.97	|	0.107192
1500	|	0.96	|	0.167179
1600	|	0.91	|	0.244394
1700	|	0.88	|	0.288442
1800	|	0.92	|	0.215035
1900	|	0.95	|	0.191149
2000	|	0.92	|	0.2513
2100	|	0.92	|	0.257605
2200	|	0.93	|	0.226356
2300	|	0.92	|	0.22736
2400	|	0.92	|	0.23665
2500	|	0.97	|	0.133527
2600	|	0.93	|	0.219137
2700	|	0.93	|	0.206086
2800	|	0.9	|	0.26439
2900	|	0.93	|	0.210805


Does this look stuck ? I'm not sure what I should be expecting... 



And that's it, I have no clue where to go from now...       
Should I slap on more layers?    
Play with the number of channels on the layers?     
Look for different activation functions? different loss?        
     
Should I try to make this an LSTM network? That makes sense since the whole core of my problem is
a sequence...    
        
     
Thanks a lot in advance !     
     
I don't have cats or puppies to finish the post with a cute picture so here's a pretty plot I made with the same data:    
https://i.imgur.com/MBm1nEZ.png
"
Universities and Professors that focus on Feature Learning?,0,1,False,False,False,learnmachinelearning,1512055916,True,"I am in the process of applying for a Masters and trying to lock down a topic of research interest. I'll naively describe my goal problem as follows: 

I want to be able to take all the files that a student acquires and generates over a semester of school (PDFs, text, audio recording, etc) and cluster the files into courses. 

More academically, I believe this falls into *feature learning or representation learning*. Is that correct? From what I have read, deep learning is all the hype for this. But, the focus is on learning features for one data type: audio, video, etc. I am interested in taking a data dump of any arbitrary type of data, and then being able to cluster related items. Is there a good ""academic"" way of phrasing this? Any terminology I should be using or look into? 

My main question:

**What universities, professors, labs, and conferences would this topic belong to**? I found ICLR. Toronto might do a bit?"
Bad multi-gpu scalling on Tesla K80s,0,1,False,False,False,learnmachinelearning,1512056843,True,"Hello.

I got access to cluster with 2x Tesla K80 (4 gpus total).
I've tried so far tensorflow and mxnet (benchmarks showed increased performance comparing to tf) with both 1 gpu and all 4 gpus.

With this code:
https://gist.github.com/szymko1995/1af3150961086dd7e6c3dd1ce4cd52af
(mostly borrowed from keras-mxnet git) here's what I got:
- single gpu: ~85 sec/epoch,
- 4 gpus: 30-35 min/epoch.

Tensorflow benchmark seemd to be simillar (big slowdown using all gpus)

I'm using keras-mxnet with latest mxnet-cu80 0.12 on Windows Server and Python 3.5.
Channel is set to first (as recommended).

Is this caused because slow connection betweend gpus (pci-e) and can't be fixed or there is some kind of solution for this problem?

Edit:
If you encounter same problem as me here is fix - just change some flags:
os.environ[""MXNET_CUDNN_AUTOTUNE_DEFAULT""]=""1""
os.environ[""MXNET_ENABLE_GPU_P2P""]=""0""

1 K80, batch size=4096: 35 sec;
4 K80, batch size=4*4096: 10 sec

87,5% scalling seems good enough for me. :D

Here is code:
https://gist.github.com/szymko1995/c5b50e7087dd561793c73dceadb626e9

If you have any other ideas for improving scalling with multiple gpus please share.
"
Need some help in knowing which machine learning solution fits my problem.,6,2,False,False,False,learnmachinelearning,1512067580,True,"Hello, its my first time posting to this subreddit and I'm definitely not even at the level of an amateur in machine learning. However I'm keen to learn.

My question is related to my work in geotechnical engineering, we have official standards as to the description of soil and rocks. I would like to attempt to use machine learning to train a model (?) to be able to determine if a particular soil description sentence is correct. Eventually, I'd like it to indicate where it is incorrect and maybe even recommend where it could be improved.

My problem is there are so many tools and things out there I really don't know what is right for me? I am fairly proficient with python and know of many excellent packages available. 

If someone could recommend a probable first step or even just what is the right tool for the job it would be much appreciated.

Thanks"
"If data is the new oil, Google wants to sell you the drilling tools",5,27,False,False,False,learnmachinelearning,1512088673,False, 
Text Classification with Naive Bayes,0,15,False,False,False,learnmachinelearning,1512092831,False, 
How to get started with a clothes classifier?,4,2,False,False,False,learnmachinelearning,1512106038,True,"Hi all, my friends and I want to build a program that can take an image of a person and give some attributes to the clothes they are wearing (shirt, blue, jeans fabric, etc.) So far I've taken an undergraduate ML class and implemented some very  basic programs, such as the Viola-Jones face classifier and an artificial neural network to recognize digits. In the class I've also studied the theory behind a lot of these things, but since the technology for what we want to do already exists (like in this paper [here](http://ieeexplore.ieee.org/document/7780493/?section=abstract&amp;part=1)), I'm approaching this project with the mindset that we just need to find the tools online and then code the program and train it. Given my knowledge, how far-fetched would our idea actually be? And if it's realistic, where should I start? More specifically, I'm looking for 

* material to read on implementing an algorithm

* how to find/compile clothing data to train on

* perhaps a language suggestion? I'm using python but I heard it's inefficient.

Thanks in advance!"
Why is all-pairs faster than one-vs-all for multi-class classification?,0,1,False,False,False,learnmachinelearning,1512109327,True,"Hi all,

I was reading on multi-class classification and read somewhere that all-pairs is faster than one-vs-all, but there was no explanation for that logic. 

As I see it, if you have `n` classes:

+ with one-vs-all you have `n` operations (each class vs all the other classes).
+ with all-pairs you have `n choose 2` operations, which is &gt;n for n &gt; 3.


Can anyone please shed some light on this?

TIA :)"
Writing your first program in TensorFlow,0,1,False,False,False,learnmachinelearning,1512109464,False, 
Weekly Show-off!,3,5,False,False,False,learnmachinelearning,1512111920,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
Can code that uses CUDA (like deep-image-prior or pytorch) run on a computer without an Nvidia GPU (like a macbook)? I am new to this.,4,6,False,False,False,learnmachinelearning,1512112548,True, 
Regularization and variable selection via the elastic net,0,3,False,False,False,learnmachinelearning,1512118956,False, 
Short guide to running regressions in Python. Thoughts?,0,6,False,False,False,learnmachinelearning,1512135593,True,"Hello everyone!

I've been looking to get into the ML blogging game, and I'm interested in knowing what people think of what I've written so far.

The best I have now is [a short guide on regressions in Python, mostly in scikit-learn](https://github.com/amianthoidal/ml_guides/blob/master/Statistical%20Learning/1_Regressions.ipynb). The target audience are statisticians already familiar with regressions, but I hope it's useful for anyone looking to get into statistical Python.

If I get good at writing these things, I want to start releasing neural network guides as well. But these are tough for me to write! With practice and your feedback I hope I'll someday have something good.

Thanks!"
"What is a ""derived variable""?",1,2,False,False,False,learnmachinelearning,1512136696,True,"I was asked to ""build a derived variable for a taxi trip tip as a percentage of the total fare."" 

I learned about binning and discretizing a continuous valued variable, but I never learned about 'derived' variables. Any help would be appreciated!"
"This Week in Machine Learning &amp; AI talks to key members of the OpenAI Community, including Founder and CTO Greg Brockman, to talk AGI, Safety &amp; Robotics! You don't want to miss it!",2,16,False,False,False,learnmachinelearning,1512144813,False, 
Internship recruitment task,2,5,False,False,False,learnmachinelearning,1512160718,True,"Basically, I applied for a deep learning internship at a London-based startup and they asked me to do a task involving implementing an algorithm from a recent paper, testing it and exploring the results. They said it's generally expected that it'll be done in 3 weeks and I'm just... not sure if they're trying to make me do work for free?

It seems like quite a bit of work, especially since they claim publishing my work could be grounds for rejection, so potentially I won't even be able to put it on my GitHub.

Does anyone have experiences like this? For my last internship I just had to do a stupid coding test and the most important thing was an actual interview, so I'm really uncertain whether it's worth it jumping through these hoops."
Naive Bayes classification Text (no package) tutorial,2,1,False,False,False,learnmachinelearning,1512166326,True,"Does anyone know where I can find a tutorial of writing a naive Bayes classification from scratch. In the sense, I don't want to import a classifier package like NLTK or Scikit learn. I have seen a few online but I was hoping for an example that is built to deal with text instead of numerical values only."
Question about what I think is hashing?,5,1,False,False,False,learnmachinelearning,1512169461,True,"I'm working on a project using Keras (reading in a CSV file using Pandas) and one of my feature columns is a customer number. Since that customer number is not involved in any computation, do I need to hash that column so that its not being used in any kind of computation? Sorry this part is a bit fuzzy for me. It's not necessarily a defined list so I don't think that a one_hot is correct here right?

If it matters I am trying to observe a customer's past payment history (how many days it takes them to pay invoices of different types to predict how long outstanding invoices will take to be paid)."
Thoughts on Coursera's Deep Learning Specialization?,2,13,False,False,False,learnmachinelearning,1512172022,True,"To those of you who are doing the course or have tried it, how is it? Is it worth the money and do you think it will improve your chances of getting interviews/hired."
Improving classifier performance by synthesizing data.,0,8,False,False,False,learnmachinelearning,1512180368,True,"I'm dealing with a set of data that has a relatively small N and I find that my learning curves aren't converging, even with some regularization.  f scores are decent, but what I gather from the learning curves is that more samples could improve performance quite a bit further.  So, just messing around with my data, I used SMOTE to oversample both minority and majority to varying, but equal numbers.  Using a nested cross-validation I found that I eeked out another 4-5% out of the classifier.

This seems like a valid technique, but I was wondering if I'm overcomplicating this.  SMOTE is essentially synthesizing a lot of noisy data around each class.  I'm assuming that this 'fake' data is improving my robustness and helping with a few of the borderline cases.  Why aren't techniques like these used more often, or are they?  SMOTE might not be the best algorithm here, but even just creating new samples based off of the distributions in your data could be used.  I know this is explored in deep learning, but I'm finding it somewhat useful in more simple models as well, such as ensembles of trees.

As an aside, any other techniques to try when you've seemed to reach the limit of your classifiers on the data you have, to try and eek out a few more %?  Training a number of classifiers and having them vote can help a bit here and I'm looking to go there next, but anything else you typically try, assuming you can't engineer new features?"
"Weekly Status Check Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",0,3,False,False,False,learnmachinelearning,1512198310,True,"Let's have a  meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
Understanding data shape in Keras,2,3,False,False,False,learnmachinelearning,1512202919,True,"Hi! I've been playing with neural networks in [Keras](https://keras.io/) for a few weeks, but I really struggle to understand the shape in which my data is expected and how it is transformed by each neural layer. Because of this, my results are completely off sometimes, and I often blindly reshape the data until it works. Things like `batch_size`, `return_sequences`, etc remain very vague to me.

Most tutorials read the data from huge CSV files, transform it, run through a NN and just plot the output, which doesn't really help.

I know this is explained in the docs, but what I really need is some examples of small arrays that go through a neural network and are explicitly shown after each transformation that happens to them.

Is such thing available anywhere?

Thanks!"
I really need help on implementing this Twitter Sentiment Analysis system using Linear SVN,13,2,False,False,False,learnmachinelearning,1512207723,True,"I am trying to implement a system of twitter sentiment analysis as a personal project (https://aclanthology.info/pdf/S/S17/S17-2132.pdf). This uses a linear SVM classifier with many different features. I was wondering how I should start implementing those featuers. 

Some of the features are just mentioned as 

- ""Three values were added to the feature vector
for musicians: a binary value representing musician’s
mention in a tweet, number of musician’s
albums, and musician’s rating.""

And I am not really sure how to apply these kinds of feature vectors to the SVM since I am quite new to this area. Please give me a comment or a helpful link how to implement this kind of SVM with numerous features. Thanks"
HELP? CNN explaining the feature detection in a high level architectural design.,5,12,False,False,False,learnmachinelearning,1512214866,False, 
"Efficient Reinforcement Learning from pixels without CNNs on CPU, that achieves 90% in one day! (Code in description)",0,1,False,False,False,learnmachinelearning,1512216865,False,[deleted]
"Efficient Reinforcement Learning that learns to win Atari Pong from pixels without CNNs on CPU, that achieves 90% in one day! (Code in description)",5,27,False,False,False,learnmachinelearning,1512217144,False, 
Bagging for linear estimates,0,4,False,False,False,learnmachinelearning,1512238266,True,"Hey all,

This is probably a dumb question, but I haven't been able to find a rigorous answer to this, and my attempts at providing one myself have failed, so here I am. 

Suppose we have some data [; Z = (x_1,y_1),...,(x_N,y_N) ;], both [; x ;] and [; y ;] just real numbers. Let [; f ;] be the linear function obtained by running the usual linear regression on [; x ;] ,i.e. 

[;f(x) = ax + b;]

where a and b are given by minimizing least squares. 

Now, we form [; K ;] bootstrap samples [; Z_1, ... , Z_K ;] by sampling with replacement from [; Z ;], and let's say they all have the same size as [; Z ;]. For each bootstrample, we can perform a linear regression and form an estimate [; f_k(x) ;] in the same way we made [; f ;]. 

My main question comes in trying to understand the relation between the average of the [; f_k ;], i.e.

[; \frac{1}{K} \sum_{k} f_k (x)  ;]

Now, most sources claim that this should be equal to [; f(x) ;]. Clearly, this cannot be correct, right? After all, I could just end up by accident picking the same entry N*K times, and form an extremely stupid estimate. 

I've seen some say that this should be equal to in the limit as K goes to infinity. This seems more palatable since intuitively if we form enough data sets we should be able to wash out the 'stupid ones' i.e. picking the same entry N*K times. By the law of large numbers, this is really just saying we put the uniform distribution over Z and, make a linear regression, then take the average of the coefficients a and b with this distribution. In this particularly simple case, we even have explicit formulas for a and b. However, I'm getting stuck in the computation, especially since the a is a nonlinear combination of the data. I'm not seeing a clear way to obtain the desired result. Is there a usual  trick one employs for this? How does one rigourously compute that expectation? Or am I misunderstanding the claim entirely?

Thanks for your help!"
To people who bought a copy of Neural Networks by Michael Taylor,4,0,False,False,False,learnmachinelearning,1512242975,True,"I've found an error at the page where the partial derivative of E with respect to Z is calculated: the answer is not z minus t but 2 times z minus t. Because the derivative of a square with respect to what is squared is two times what is squared.

Edit 2: All of this is located at the first pages of Chapter 11."
Training a multi-class image classifier,4,3,False,False,False,learnmachinelearning,1512248484,True,"Hi. Let's me illustrate my problem. Images only contain one of four classes: Husky, Shephard, Cat, Rabbit. My goal is to detect only ""Husky"" images. Of course, the testing images include one among four classes. There is no none-above-class image. How to train my classifier? 1. Training a binary classifier: Husky (positive) and the others (negative). 2. Training a 4-way multi-class classifier: The classifier gives us one among four classes. It is positive if it is Husky, the others are negative. 3. Training two classifiers: Dog vs others and Husky vs Shephard. Since visual appearance of Husky and Shephard compared to others is similar, I'm not sure the first option produces the best result, which is a common way of training. Could someone answer this question or suggest me relevant papers? I can easily check out the result using experiment. However, I would want to know the answer having theoretical grounds or qualitative insight. I posted a similar question few month ago but, the answer was not satisfactory. https://www.reddit.com/r/computervision/comments/6jtz3h/how_do_i_train_the_classifiers_for_image/ 

I originally posted this text in Machine learning and move this text to here. 

The first reply is ""
Next time post at r/learnmachinelearning
If you want to detect only Husky just use 1 for H and 0 for others. On last layer you should have single neuron with sigmoid function. If you have unbalanced dataset (eg. 20% Husky) just use class weights: 

http://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_class_weight.html 

This task should be rather easy (to get nice accuracy). Consider using image augmentation even if you have +1k images. "" 

However, this answer does not include why the first is better. 

The above one is an illustrative example and the actual problem has more classes including many classes in ""dog"". 


Chul Min"
Every day examples of exponential distribution. Understanding how to derive the pdf of exponential.,0,1,False,False,False,learnmachinelearning,1512249300,False,[deleted]
Every day examples of Exponential distribution and deriving its pdf.,0,5,False,False,False,learnmachinelearning,1512251267,False, 
When not to use deep learning,1,0,False,False,False,learnmachinelearning,1512262353,False, 
Essential Guide to keep up with AI/ML/CV,0,1,False,False,False,learnmachinelearning,1512272244,False,[deleted]
Essential Guide to keep up with AI/ML/CV,0,39,False,False,False,learnmachinelearning,1512272330,False, 
Trying to get into doc2vec,0,1,False,False,False,learnmachinelearning,1512290446,True,"Hello, 

I'm doing a programming internship, where I need a unique vector representation for each sentence in a document and I'm using gensim doc2vec for this task. 

Code seems to work but I have 2 questions and I can't seem to find the answers. 
In doc2vec you can label each sentence withe a unique label but I don't understand their exact purpose. The only thing I found is that they can identify a sentence. 

Also if the same sentences have different labels will this influence the learning process in a negative way or better said how does doc2vec handle duplicate sentences in the learning process?

Sorry If these are questions I could easily answer if I took a look at the paper/documentation but this is just a small part of my project and I'm very short on time. 

Thank you. "
Predicting availability on a bike station,0,2,False,False,False,learnmachinelearning,1512294039,True,"I finally decided to start learning ML, to do so I am trying to predict the availability of bikes of my city's public bike sharing system.

* [Dataset](https://www.dropbox.com/s/mkwp79nqbfjsx62/Zunzunegi.txt?dl=1) (1MB) for one bike station. Columns: date, weekday, id, station, free_bikes, free_docks

I've been following Machine Learning Mistery's [tutorials](https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/) with Keras, in this case one for multivariate time series forecasting LSTM, which I think is adequate for my problem.

Currently, I am training the NN feeding it with: weekday(t-1), free_bikes(t-1) and free_bikes(t).

The loss and val_loss [graph](https://imgur.com/a/H0Qsj) I think looks good(ish). If I am not mistaken a RMSE of 0.9 is that I'll probably have an error or 1 bike when making predictions.

If all that is correct I'll also like to give the NN the date the sample was taken but I run into some problems I don't know I can solve. Adding an extra column I get this kind of error:

```
ValueError: operands could not be broadcast together with shapes (5949,2) (3,) (5949,2)
```

To add the date into the problem I'll just delete the part on line 63 that says `index_col = 0` when reading the file.

Is it correct to add the date to improve the prediction and how should it be done?

* [script](https://www.dropbox.com/s/u859ws5wopk5jpk/script.py?dl=1)
"
R. RecommenderLab. Evaluating ALS_implicit model.,0,3,False,False,False,learnmachinelearning,1512295641,False,[deleted]
"Basic Tutorial of Naive Bayes in python, Upvote the kaggle notebook if you find it useful",0,7,False,False,False,learnmachinelearning,1512302492,True,"I made this kernel, This is my first kernel or you can say first tutorial, Fellow redditers please review it or give advises, or if you find it useful then you are requested to upvote it on kaggle :)
https://www.kaggle.com/ibadia/easy-python-tutorial-basic-for-beginner/notebook"
How to start with image/video recognition app?,2,7,False,False,False,learnmachinelearning,1512305704,True,"Hi guys!
I know basics of ML (from school and Andrew Ng's Coursera course) and I would like to create a mobile app which would detect for example if someone has touched a table.
Unfortunately I have no idea where to begin with. I've heard that Tensorflow would be good for me but still, I have no idea how to start.
Could you give me some links/hints how to make it happen?"
"Learning Machine Learning as a start in my PhD career, which resource to follow?",3,14,False,False,False,learnmachinelearning,1512307836,True,"Hello everyone,
I can not say I am new to the machine learning domain. In my Masters I did a small project using Random Forests i.e. I know how to use sci-kit learn to train classifiers. I know concepts like overfitting, cross-validation, etc.

Now, I want to move into research in this domain. I want to know the math behind the algorithms and want to gain a stronghold of probability theory which governs a huge part of machine learning algorithms. Finally, I want to venture into deep learning. 

The main motto of this question is that I don't want to be an ML practitioner who just can code up an algorithm given a framework or language of choice. I know that is a must. But I want to do the math as well and modify algorithms as a part of my research. 

After my coursework, I am free for the winter and I want to utilise the time to my best. The problem with me is that I get distracted by too many MOOCs and resources (books) available on the internet.

I have a few listings:

Books on ML:
1. PRML by Bishop
2. Machine Learning: Probabilistic Perspective by Murphy

MOOCs:
There are several (Andrew Ng, Nando de Freitas, Tom Mitchell, etc). I am not listing them individually.

Books and MOOCs on DL:
1. Deep Learning book by Goodfellow et. al
2. CS231N by Fei Fei Li

Now you see why I am confused. I start with something and keep jumping resources. I feel like the other one is more suitable. 

Should I do Individual courses to learn Linear Algebra and Probability Statistics (if so which one? books or MOOCs), then move on to implementing stuff and learn concepts whenever needed?

Folks who have already been through this journey please help me out. I am looking for a somewhat like a track or path whose ultimate destination is deep learning practitioner with good grasp in the theory for further research.

Thanks in advance.
"
"When training a NN with cross entropy, is there a way to train on samples that do not have a corresponding network output?",8,5,False,False,False,learnmachinelearning,1512315339,True,"I have samples that do not have a target that corresponds to those of my network. I would like to train on this sample so that the network learns to not predict any of its labels when this sample is input.

The problem is if I provide a one-hot encoding that is all zeros, then it seems to me there will be no gradient flow as the derivative of my cross entropy cost function for that sample would be zero (because `p_i(x) = 0` in `-p_i(x) log(q_i(x))` for all `i`). 

Does anyone know a way around this? I do not think just creating an extra network output into which I can bin these samples is a good idea for my use case."
What do you use to read papers?,3,1,False,False,False,learnmachinelearning,1512327262,True,"I've had to read dozens of papers over the past few months, and I'm just curious what others are using to read the literature. Usually, I would read them on a computer, because that's where arxiv is. Sometimes, I'll print them out.


So my question is: What do you use to read papers?"
Confused about the Bellman Equation,0,2,False,False,False,learnmachinelearning,1512348622,True,"I am learning reinforcement learning and I am kind of confused about Bellman Equation.

Basically how can I guess the maximum possible reward for the next state? Isn't this a recursive problem which would require me to reach to the lowest depth? At the same time, unless I'm playing a game with a fixed-set space like chess, isn't it impossible to really reach ""the end""? Take the cart and pole problem. There's an infinite number of games since there are infinitely many possible variations in the cart direction and speed.

Is it a matter of guessing which actions led to a good score or low score directly and then using that to assign values? I am reading this article on it, it's the best one I've found yet, but I'm still confused after getting about halfway through:

https://www.intelnervana.com/demystifying-deep-reinforcement-learning/"
Getting a sequence prediction for a LSTM model in keras on live data/not test data.,2,1,False,False,False,learnmachinelearning,1512351060,True,So I've been following some tutorials on machinelearningmastery (my model is based off this [ tutorial](https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/) )and I've created a LSTM model. I can train and test it fine on my data. The problem I am now facing is that I want to get the prediction for future sequences for the pollution field in his dataset. It currently uses model.predict(x) where x is my test data. How do I run it on steps in the future? Any help is greatly appreciated!
What is NLP? Get started!,0,37,False,False,False,learnmachinelearning,1512351822,False, 
How does one use Hermite polynomials with Stochastic Gradient Descent (SGD)?,0,1,False,False,False,learnmachinelearning,1512354784,False, 
Trying to decide if learning ML is worth it when it's not career-related.,13,7,False,False,False,learnmachinelearning,1512363537,True,"I have a MS in Computer Science from forever ago and while my focus was on Unix system administration, which is what I've done for 20 years now, I did study a few ML-related topics in their relative infancy like Artificial Intelligence (very dated top-down approaches), Genetic Algorithms, Neural Networks, and Cellular Automata. I've also been learning Python lately (having been Perl guy most of my career). Unfortunately I don't have the mathematical background that seems necessary for a study of modern ML tools (i.e. linear algebra, statistics), nor do I have any personal or business real applications for ML programming, but I find them utterly fascinating regardless, so I'm torn between trying to self-study all of the math and Python libraries for playing around as a purely intellectual pursuit, and dropping the entire notion and focusing my career-related hours on updating my Unix engineering skillset (e.g. Docker, modern security technologies, etc.)

Any thoughts from the ML experts here on whether the self-study for purely intellectual curiosity is worth it, given the time-investment required?

"
Automated Caries Detection on Bitewing Radiographs Using Deep CNNs,0,1,False,False,False,learnmachinelearning,1512378469,False, 
Question about working with categorical data,7,2,False,False,False,learnmachinelearning,1512380780,True,"Hi, I'm a complete beginner who is just trying to do some (basic) machine learning for a project for school. This is not a class that teaches machine learning, but it is worth marks if we're able to incorporate it.

I've been working with a modified version of [this video game dataset](https://www.kaggle.com/rush4ratio/video-game-sales-with-ratings) including month released and some more genres and I am trying to predict sales of a game based on what I can learn beforehand, i.e. genres, rating, platform and month and year of release. 

I have tried using some standard regressors from scikit-learn with some basic cross validation, but I have found so far that my predictions are very centered around the middle of the data, and thus not much use. I am worried this is because the data is mainly categorical, and I was wondering if there were any special techniques or any good tutorials for working with this sort of data. At the moment I have just use the pandas get_dummies() method to encode the data.

Any help is much appreciated,
thank you."
How do I get started with machine learning?,7,5,False,False,False,learnmachinelearning,1512395528,True,"I want to try learning machine learning, but I'm not sure where to start. 

I came across a book called 'collective intelligence' (https://www.amazon.com/Programming-Collective-Intelligence-Building-Applications/dp/0596529325) which I considered buying but I see that the same publisher also has something like 10-20 other books on the subject so I have no idea which one I should buy, if any. "
Apache Spark with Python Course- The next generation of Big Data [FREE],0,1,False,False,False,learnmachinelearning,1512396782,False, 
A deep dive on Linear Regression,1,15,False,False,False,learnmachinelearning,1512397452,False, 
Finding the log of 0 in logistic regression cost function?,0,2,False,False,False,learnmachinelearning,1512400327,True,"I was implementing the logistic regression algorithm in Python (from the Ng course), but it seems that scipy.optimize.minimize is trying to find the log of 0. Here's the code:

https://gist.github.com/anonymous/2e505284ab6d736c3b4c78a68b39d1fc

Here's the output, in images: 

https://i.imgur.com/bx7UyWV.png

https://i.imgur.com/ilbsla6.png

https://i.imgur.com/x64J8en.png

As you can see, it's trying to find the log of 0 - why is that happening? The sigmoid function can never equal zero."
When to Run Bandit Tests Instead of A/B/n Tests,0,3,False,False,False,learnmachinelearning,1512402662,False, 
How do you decide how many layers to put in a deep neural network?,11,18,False,False,False,learnmachinelearning,1512403475,True,"I've been watching sentdex's excellent series and I'm confused about the layers. He will use 1, 2, etc. hidden layers with no explanation of why. 

Does adding layers serve to abstractify the data so you can back propagate more efficiently by reducing the data field per layer? In the famous breakout game for example, they had a roughly 120 X 84 grid in the first layer, and then several layers which were each 1/4 of the size, which makes sense to me because then the layers serve as abstraction points, which should help reduce computational requirements.

But why would you have numerous hidden layers all with the same number of neurons? Is it to account for the possibility that there are some strange unknown connections between variables? 

For example if we have inputs 1, 2, 3, and 4, our first layer would basically assume the inputs are independent, but maybe our second layer would reveal that inputs 2 and 4 are linked, and then a third layer would reveal that that combined input is somehow linked with input 1? But even then how would you decide how many levels to use? "
a use case i'm trying to solve but i have no idea where to begin. Is ML the right choice?,1,3,False,False,False,learnmachinelearning,1512403548,True,"I have customers who have hardware/software on premise that I support. These machines run jobs with arbitrary number of subjobs and each subjob has an arbitrary amount of data. 

My thought was that if I fed the data around a job, subjob, amount of data, durations of jobs and subjobs, to an algorithm, would I be able to potentially teach it to identify anomalies? 

example: 

for 30 days, this one job with 10 subjobs runs consistently within 10-15 minutes and captures X amount of data.

Yesterday, the job ran for 45 minutes because it had 30 subjobs instead of 10.

So my algorithm should tell me that the job ran longer because of the change in subjobs.

or, if the amount of data increases drastically but the number of subjobs is the same, then the time will still go up.

Is this a good candidate for ML?

I was thinking about this because each customers jobs will be different for many reasons. So having one set of guidelines for all customers may not be ideal.

Am i going about this the wrong way? 

My apologies if this is the wrong place to ask this question.

How else would you solve this problem? And how would someone who prefers to write in golang begin tackling this problem?

thank you."
Selective Attention ep 001 - Noise As Targets,0,2,False,False,False,learnmachinelearning,1512405210,False, 
What type of orthogonal polynomials does R use?,0,2,False,False,False,learnmachinelearning,1512410346,False, 
The beauty of Bayesian Learning,1,22,False,False,False,learnmachinelearning,1512414471,False, 
Java Othello,5,3,False,False,False,learnmachinelearning,1512416021,True,"In my AP Computer Science class, my teacher is having us create an Othello AI. I, being ahead of the class, decided to take this opportunity to try to figure out Machine Learning. Unfortunately, I'm not really sure how to get this going. I'm able to get a list of possible moves, and I can add things that I need, but I'd like a push in the right direction as to what kind of learning algorithm I should use, and how to put in data.

Thanks in advance!"
Error locating python.exe on PATH of msys2 shell,0,2,False,False,False,learnmachinelearning,1512417996,True,"Trying to compile bazel-0.8.0 from its source, I ran into the error cannot locate python.exe; check your PATH. when inputting the command $ ./compile.sh on the msys2 shell.

When I try to run the command export PATH=/c/Python36:$PATH, it's giving me an error that the export is not a valid identifier.
Furthermore, my version of Python (Python 3.6) is already in the System32 folder, which I double checked that it is in the path for my PC."
Error locating GNU coreutils on MSYS2 shell to compile Bazel,0,2,False,False,False,learnmachinelearning,1512420248,True,"Trying to run ./compile.sh to compile Bazel from its source, I run into the following error:
cannot locate GNU coreutils; check your PATH.
(You may need to run 'export PATH=/bin:/usr/bin:$PATH)'

Even when the suggested command is run, the following error pops up:
-bash: export: `/bin:/usr/bin:': not a valid identifier

I would really appreciate any help"
How to handle data when low on memory?,4,3,False,False,False,learnmachinelearning,1512424475,True,"I tried to prepare data (images) before I start training on an NN.
My problem is that I have only 8GB memory on my laptop. On idle only 4 GB is free from this memory.

The raw data before I do anything is 1.6 GB.

This is how I preprocess it:

    X = []
    y = []

    i = 0
    for class_folder_name in os.listdir(constants.TRAIN_DATA_FOLDER):
        class_folder_path = os.path.join(constants.TRAIN_DATA_FOLDER, class_folder_name)
        class_label = class_folder_name
        for image_path in glob(os.path.join(class_folder_path, ""*.png"")):
            image = cv2.imread(image_path, cv2.IMREAD_COLOR)
            image = cv2.resize(image, (244, 244))
            image = image / 255.0
            X.append(image)
            y.append(class_label)

            i += 1
            if i % 100 == 0:
                print(""Done with: {0}"".format(i))

    print(""Done with preparing data"")

    X = np.array(X)
    y = np.array(y)

My problem is that my laptop freezes at this point after a while (it uses 100% memory).

How could I resolve this problem? Is there any way?"
Input Layer Help,3,2,False,False,False,learnmachinelearning,1512425050,True,"Was just curious if anyone has any pointers/advice when setting up an input layer for data points. I worked through the MNIST example, but I want to know how to set it up for a set of data points, say 10 factors with 100 values each. Thanks for the help!"
Binary classification with dependence on cumulative statistics?,0,2,False,False,False,learnmachinelearning,1512427900,True,"I am trying to predict a series of binary outcomes, but the statistics of the set of outcomes matters. For example, in twenty outcomes, it is very unlikely that less than 2 outcomes will be false, or that more than 5 outcomes will be false, irrespective of input data.  I'm at a loss at to how to formulate the question so as to best google the theory that must be out there..."
Saving/loading tensorflow GAN model progressively slower,0,1,False,False,False,learnmachinelearning,1512443530,True,"I have a toy GAN I am training on my desktop PC with an intel i7-4790, 16gb ram and geforce GTX 750 Ti. I feed it small batches of images (200, 60, 80, 1) scraped from the web. Even so I'm nudging the boundaries of capability, but all seems to work OK. I save the model every 3000 training iterations, dump the old images and scrape 200 more. As training progresses the saving process takes loner and longer. After 8 training cycles (=21,000 iterations) it's 3.5 hours to save. I have been looking for some (ELI5) explanation of this. Given that the number and shape of the elements of the graph remains the same, the only changes are the weights and biases. Yet the increase in time to save (and load) the model suggests that there are elements being added? Or not - I really have no idea. Can someone shed some light on this phenomenon?"
Why is KNN considered machine learning?,9,19,False,False,False,learnmachinelearning,1512447220,True,"I'm a complete noob at ML, but this question popped into my head when reading about the K Nearest Neighbors Algorithm. It doesn't really ""learn"" from the training data, it just compares predictors to the nearby training data. So why is it still considered machine learning?"
Machine learning for non-MS job seekers?,8,5,False,False,False,learnmachinelearning,1512448236,True,"I know most people studying ML pursue Masters Degree. However, I also know that many people regardless of their degrees, study ML for many reasons. I was wondering if having like a fair understanding (but not super) of ML will help people without MS or MS with no relevance to ML help to get a computer science job?

In other words, does ML knowledge help me to get a job in CS and does it actually get applied to real work settings? I am asking because it seems like ML related topics are mostly for research studies and not really used in actual work environment."
Questions with implementing (or adding?) features in a support vector machine.,0,1,False,False,False,learnmachinelearning,1512451442,True,"https://aclanthology.info/pdf/S/S17/S17-2132.pdf

I am new to machine learning and trying to implement the SVN system described above. It is a linear kernel SVM with bunch of features (such as word embeddings, sentiment polarity, ratings of the topic mentioned, etc..). 

However, I am not really sure how these features have to be added. In what formula do we have to plug these feature vectors? Is there like a good tutorial for this?

My second question is that, are these features need to numericalize the data (tweets in this case) determine the location of the data in the plot? I am not sure if this is the why I am supposed to ask, but this is some question that I have in mind."
(Tutorial) Principal Component Analysis using Python,0,16,False,False,False,learnmachinelearning,1512455461,False, 
Tutorial codes for training RNN and Bidirection RNN model with IMDB movie review to analyze sentiment.,1,4,False,False,False,learnmachinelearning,1512462588,False, 
Using training data and testing data in a shared task,3,3,False,False,False,learnmachinelearning,1512469552,True,"I am working on this shared task http://alt.qcri.org/semeval2017/task4/index.php?id=data-and-tools

which is just a twitter sentiment analysis. Since i am pretty new to machine learning, I am not quite sure how to use both training data and testing data.

So the shared task provides two same sets of twitter tweets one without the result (train) and one with the result. 

I current understandings of using these kinds of data in machine learning are as follows:

- training set: we are supposed to split this into training and testing portions (90% training and 10% testing maybe?)

But the existing of a separate test data kind of confuses. 

Are we supposed to use the result that we got in the test using the 10% portion of the 'training set' and compare that to the actual result 'testing set' ?

Can someone correct my understanding?"
10 Ways You can succeed in Machine Learning Career,0,1,False,False,False,learnmachinelearning,1512472723,False, 
Word vector example please,2,8,False,False,False,learnmachinelearning,1512479662,True,"New to this. Learning about neural nets, NLP, and word matrices. I'm getting the concept of the matrix, but Id like an example of how to create a word vector from scratch.

Is The word vector the string of numbers in its matrix column?

Who is that represented on a graph? Is it always relative to another word vec?
Thx"
GPU process doesn't clear in Jupyter Notebook,10,11,False,False,False,learnmachinelearning,1512483768,True,"I'm using jupyter notebook with Python3, TF, Keras 2 and Pytorch.  I've noticed, particularly in Keras, that when I execute a training algorithm, the process on my GPU doesn't clear at the end of the run.  

For example, when I train, I will still have a process using 10GB of memory on my GPU, which I then have to kill with a kill -9 #PID.  Otherwise if I run the trainer again, I will get an out of memory error on my GPU.

Best way to avoid this?  Not use Jupyter?"
"How to use ML to identify characters from an image using pattern recognition, then measure the widths of those characters?",2,4,False,False,False,learnmachinelearning,1512499128,True,"Hey all,

I'm a total beginner to machine learning, but I'm interested in learning how to use machine learning to get a computer to pick out (recognise) characters from an image (similar to OCR) and then measure the widths of those characters (so I can then determine the average width of an 'a', the average width of a 'b', etc)

I've seen a lot of programs online for converting text in images into a text file, but I'm not interested in what the text actually says, more in the widths of the characters as they are on the page - as in, if I transfer the text into a text file, the font will change and therefore I won't be able to measure the widths of each character)

Thanks,

S14"
What are vectors in ML? What is the correct way to think about them in a Cartesian plane?,24,8,False,False,False,learnmachinelearning,1512538568,True,"I'm struggling to understand what a vector is in the context of ML.
I have always though of vectors as an arrow or line of magnitude and direction, but the deep learning book has mentioned they are effectively points in space.
Now I'm not sure if I should think of them as an arrow or a single point, and when I consider the dot product between two vectors I'm trying to think about the angle between them.
But what happens if you have a vector that has high dimensionality?
How do you take the dot product?
What the calculations I need to know for them?"
Outliers by running DBScan and k-means,0,2,False,False,False,learnmachinelearning,1512542467,True,"I am using dbscan in scikit-learn and k-means in combination to detect outliers. 
But I dono how to optimize its parameters (epsilon and min points and k), such that I will get top 100 outliers.

Is it advisable to rerun algorithm with various values of epsilon/min-points/k and stop after reaching my result of getting top 100 outliers or stop after some particular reruns?

PS: My dataset is very small say some 60k rows"
TWIL (This Week I Learned) - Share something new that you have learned this week!,6,5,False,False,False,learnmachinelearning,1512543914,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
Getting the right dataset for a shared task,0,2,False,False,False,learnmachinelearning,1512552776,True,"http://alt.qcri.org/semeval2017/task4/index.php?id=data-and-tools

This is a Twitter Sentiment Analysis shared task from SemEval2017. The link above provides a data for it. But I am totally confused which data to use. Since I am doing the Subtask B, I am assuming I first need to get the training data and test data for subtask B which are included in this link

- All training data can be found here. (http://alt.qcri.org/semeval2017/task4/index.php?id=download-the-full-training-data-for-semeval-2017-task-4)
- The test data can be found here.(http://alt.qcri.org/semeval2017/task4/data/uploads/semeval2017-task4-test.zip)

But on the top, it also has a training data for codelab which I don't really know what it is, but seems like an official data used for the competition.

My question is, if I am trying this task personally for self-studying issue, I am not sure which data to use. Some of the data do not even have actual tweets and just have the tweet ID and labels (positive / negative).

Which data do I have to use for training, and how am I supposed to test it?

It is just too confusing for a beginner.."
How to set up a model if you know predictor will be higher than a feature?,7,3,False,False,False,learnmachinelearning,1512554553,True,"edit: `predictor` should've been `target` in the title sorry.  
  
So I am trying to predict the sales in a month, given only the first week (plus some extra features).   
  
When I use standard models like random forest, neural network or GLMs, I can get **predictions for monthly sales that are lower than the first week's sales**. Obviously, this is impossible. I know that, but the models don't.  
  
My question is, how should I set up the model to incorporate the fact that my target will always be higher than one of my features (i.e. monthly sales will be higher than the first week of the month's sales).  
  
My current practice is to take *monthly_prediction = max(monthly_prediction, 1_week_sales)*. But I hope there would be a better way to go about it."
Questions about feature vector of a tweet in a Twitter Sentiment Analysis Task.,1,5,False,False,False,learnmachinelearning,1512560173,True,"https://aclanthology.info/pdf/S/S17/S17-2132.pdf

In this paper that describes one of the systems used in the shared task of SemEval2017, it explains how an SVM Classifier was implemented for a twitter sentiment analysis task.

I am trying to imitate this system, but there are some parts that are not understandable as a beginner.

- It lists bunch of features that describe a single tweet. To implement a feature vector X (where a single row represents a single tweet and the column contains all values of the features listed in the paper) am I supposed to compute vectors for each features and concatenate it at the end?

- One of the features is the Tf-Idf vectorizer. As far as I know, Tf-Idf gives us the weight of the word per document. But in this case, what would be the document? Wouldn't using Tf-idf as one of the features cause the final X to have rows with different numbers of columns? I just want to know how Tf-idf would work here as one of the feature vectors.

- What does the 2.8 Topic and Hashtag feature indicate? I don't quite what kind of value it is describing.

Any kind of advice would be great! Please help!

"
Tutorial for Sentiment analysis in a subreddit?,2,1,False,False,False,learnmachinelearning,1512564966,True,"Hi,

recently I started playing and reading about ML and I am searching for an easy(or not so easy) getting started tutorial into sentiment analysis. A good and funny use case would be something like analyze the posts of specific subreddits for word analytics. Do you have anything available? priority on Python tutorials :) "
Examples of machine learning tasks in which a program is presented with data and forms a hypothesis about the mechanisms generating that data sought!,4,2,False,False,False,learnmachinelearning,1512566844,True,"For example, a computer is presented with a simulated environment and has to formulate a theory of the laws of physics in that simulated environment.

Or an avatar explores an environment and has to formulate an understanding of the structure of that environment and how its parts interact.

Or a bunch of data generated by hidden variables is given and the AI must abductively reason from the data to the underlying variables.

My hunch is that such problems are very close to the 'essence' of what true general intelligence is , and are potentially tractable with contemporary methods, meaning any such research might have broad application."
How much is data analytics related to AI?,4,6,False,False,False,learnmachinelearning,1512572602,True,"I've been trying to learn Machine Learning for AI for a while right now and the more I read, the more I see myself getting closer to data analytics than AI. Is it a necessity to know a good part of Data Analytics to work in AI or am I going in the wrong direction?"
Neural network predictions are not lining up with the data I provided,12,9,False,False,False,learnmachinelearning,1512574108,True,"I am pretty new to machine learning and neural networks and I have followed some tutorials around the web and I thought that it was time to embark on my own data and try it out. I have this data which is the components of a color spectrum  known as the [Lab color space](https://en.wikipedia.org/wiki/Lab_color_space). I have a separate program that I would take pictures of white, purple, green, red, blue and yellow squares I have in different lightings. I set my data in a way that the machine should predict 0 as white, purple as 0.2, green 0.4, red as 0.6, blue of 0.8 and yellow as 1. For inputs to my data I would supply 3 different weights for each component of Lab color and include a bias. for example 

`               L,                             A,                                 B,                  Pred`

`[70.88009995843976, 3.3187934385111584, 6.952836399188267,    0]`

I train my data using partial derivative cost and and compare the prediction to what it should be. I am not sure why after several thousands of iterations the predictions aren't very accurate. I am very new to this stuff and a lot of the math I haven't developed a strong grab on because I haven't learned this math in school yet. If there is something wrong about my approach please let me know I am trying to get this to be pretty accurate so that I can plug in a lab color and get an accurate prediction according to the data I am training on. Here is my [code](https://pastebin.com/9p2Q5ZvX). Thanks in advance!

"
Wondering if this is an incorrect way of viewing Machine Learning,3,1,False,False,False,learnmachinelearning,1512580901,True,"Hi there, I'm new to machine learning and I'm coming at it as a software developer.

I'm curious if it's incorrect to view ML as a way to ""brute force"" an approximation of how much of an impact each feature has on the end result? I'm specifically looking at the linear models and neural networks that work on updating the weights of each of the dependent variables/features as it is trained.

If that is a decent way of viewing it, are there other long form ways methods of achieving the same thing? I know linear models have been around for a very long time and I just assume people would calculate them by hand. I'm just trying to understand the general domain and how it relates to other existing subjects."
Volatile Train Accuracy,3,1,False,False,False,learnmachinelearning,1512581035,True,"I'm training a basic LSTM with TensorFlow and the training-set's accuracy is [very volatile](https://imgur.com/a/ZUkX1). While I understand why the test-set's accuracy might zick-zack I thought that shouldn't be the case for the training data.

So is that something that is considered as normal, e.g. because of more complex data, or is it a symptom for some kind of mistake or problem?

My graph looks like this

    LSTM_SIZE = 100

    lstm_predictions, state = tf.nn.dynamic_rnn(
        tf.nn.rnn_cell.LSTMCell(LSTM_SIZE),
        normalized_input_data,
        dtype=tf.float32
    )

    lstm_prediction = last_relevant(lstm_predictions, length(scaled_data))

    weight = tf.Variable(tf.truncated_normal([LSTM_SIZE, OUTPUT_SIZE], stddev=0.1, mean=0))
    bias = tf.Variable(tf.constant(0.1, shape=[1]))

    prediction = tf.nn.softmax(tf.matmul(lstm_prediction, weight) + bias)"
"Identical, parallel training in Keras/TF?",3,4,False,False,False,learnmachinelearning,1512584273,True,"I want to train my GAN 5 times with the same parameters, same dataset, all identical except for the random seed. What is the best way to multithread train them?

Since TF takes up the entire GPU the multithreading will have to be able to utilise the same GPUs. My neural nets are small so the GPUs should be able to handle multiple training in parallel."
Is it possible to train a neural network with only 20 input values?,4,7,False,False,False,learnmachinelearning,1512585311,True,"I have a program that I've written to analyse a collection of emails and store the frequency of word occurences in both spam and ham emails. So for example if the word 'money' appears in this collection of emails, the program determines the amount of times the word appears in spam emails for every 1 occurence in a ham email. 

At the moment I have an output file that the program creates that is in this particular format;

    statements 31.25
    search 28.666666
    life 26.666666
    spain 22.5
    online 21.833334

With each word and its ratio of occurences appearing next to it in a x:1 ratio of spam:ham occurences. This output text file has a large number of these pairings, and the number of inputs could vary anywhere from 20-100.

Would it be possible to train a neural network to classify emails as spam/ham using the data in this text file? If not, what would I need to change to make a neural network work with this data. Are there also any alternative ML methods such as Naive Bayes I could use with this input data instead?"
"Hopefully useful collection of resources (summaries, talks, posts, papers)",4,13,False,False,False,learnmachinelearning,1512597664,False, 
Confusion with argmax notation,1,2,False,False,False,learnmachinelearning,1512603762,True,"https://imgur.com/a/Gc4QN

The image shows the formula of getting the best alignment between e and f. But I am confused how to read the a_j notation for argmax in the final formula.

I am assuming the final formula is saying that to find the best alignment (a_j with a hat) get the a_j that maximizes the probability of fj when inputting e_aj.

I can read it, but I dont quite understand what it means..

"
"Supervised, Unsupervised, and Semi-supervised learning explained",0,12,False,False,False,learnmachinelearning,1512613369,True,"The three latest videos from my [Machine Learning &amp; Deep Learning YouTube playlist](https://www.youtube.com/playlist?list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU) explain the general ideas behind supervised, unsupervised, and semi-supervised learning techniques and discuss the differences between them.

- [Supervised Learning explained](https://youtu.be/Quh6x4kG6VY)
- [Unsupervised Learning explained](https://youtu.be/lEfrr0Yr684)
- [Semi-supervised Learning explained](https://youtu.be/b-yhKUINb7o)"
Neural Information Processing Systems - Videos,0,1,False,False,False,learnmachinelearning,1512630085,False, 
"When data scientists talk about ""noise"" in their data what do they mean?",21,9,False,False,False,learnmachinelearning,1512634376,True,I am currently confused over this terminology in machine learning. My educated guess would be when they talk about noise they mean data points that doesn't really affect the direction and the flow of your entire distribution? Its not just outliers but other non-relevant deviations as well?
[Q] InceptionV3 input shape (channel last) Keras Question,2,1,False,False,False,learnmachinelearning,1512635429,True,"Hi,

I would like to fine-tune InceptionV3. This is how I ""define"" the base model:

    base_model = InceptionV3(weights='imagenet',include_top=False, input_shape=(150, 150, 3))

Than I get this error: 
    Error when checking input: expected input_4 to have shape (None, 3, None, None) but got array with shape (32, 150, 150, 3)

I know this happens because my images are not `channel_first` images but how can I use the channel last ordering?"
What sort of ML projects can I do which won't require to much GPU power/time,11,13,False,False,False,learnmachinelearning,1512665814,True,"I can't afford to buy a PC for ML or buy too much time on a GPU cloud. So I was wondering what sorts of areas I can look into, which don't require too much computing power. 

I think anything to do with images is out of the question. Images contain relative a lot of memory. I think text analysis might be more feasible to me. 

Thoughts?"
Word embeddings: how to transform text into numbers,0,1,False,False,False,learnmachinelearning,1512670802,False, 
Google's AlphaZero Destroys Stockfish In 100-Game Match,3,19,False,False,False,learnmachinelearning,1512680728,False, 
Weekly Show-off!,1,1,False,False,False,learnmachinelearning,1512716718,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
How do I make it big in AI when everyone else is trying to do the same thing?,12,0,False,False,False,learnmachinelearning,1512721157,True,"I mean AI is cool and all, but it just seems like everybody and their baby brother is studying machine learning these days. How am I supposed to make the big bucks and get all the glory when I'm competing against all the smartest people in the world?

Should I just give up and go back to playing Phoenix Wright?
"
Transfer Learning for Classifying dog breeds using Keras and Tensorflow backend?,14,9,False,False,False,learnmachinelearning,1512730625,True,"I've been using inception-v3 pre-trained weights to classify the dog breeds and I'm trying to implement a transfer learning procedure. My question is: Do we need to do data augmentation procedure if we are transfer learning? because the weights of the base_model have been trained on 15 million data points and I'm just training the final classifier of the model! 

Thanks in advance."
Can't find this pdf of random forest (or decision tree),0,1,False,False,False,learnmachinelearning,1512750300,True,[deleted]
Tips on applying ML on invoices,3,2,False,False,False,learnmachinelearning,1512759881,True,"I have access to a dataset that consists of invoices from a company. So one row is a specific invoice and the columns are 
- invoice ID
- Amount
- Payment date
- Supplier
- Which department that the invoice was sent to
- Account

The total count of rows are 2 000 000.
I was wondering if it would be possible to do some kind of machine learning on this dataset, with hopes of learning how it can be applied on a business case."
Making Sentiment Analysis Easy With Scikit-Learn,2,27,False,False,False,learnmachinelearning,1512767859,False, 
"Classification of Radar Targets - lots of data, but unclear about next steps.",3,2,False,False,False,learnmachinelearning,1512772653,True,"(crossposted to /r/MLQuestions)

I have over 100 GB of data from long range surveillance radars. Hours and hours of data with location (in 3D), time of observation, and a number of other variables. These are essentially huge point clouds, where each point in 3D space also has associated time and other dimensional values and characteristics. I've spent quite some time developing tools in Python to extract this data from its original binary format, reduce it to the dimensions I'm interested in, and clean it up using a variety of spatial filters.

I've done research on Machine Learning, but I'm still very new to it myself. Ideally I'd like to be able to work with a data file OR real-time data and have a system that classifies each resulting target as noise, bird/flock of birds, UAS/drone, missile, or aircraft. I think Kernel Ridge Regression/Kernel Approximation might be the direction to go for this, or maybe I should treat it as a CV problem and use a 3D-CNN, but at this point I don't have any real labeled data, and I'm curious what next steps might be best to generate this. Many of these targets are difficult to manually classify unless you view the plots in at least 4 dimensions (x, y, z, and time), because there tends to be a lot of noise and it's often difficult to see that one point in space is related to another unless you can see a history of trailing points sequentially in time. How would you go about this problem of labeling data to create a training set, and am I going the right direction overall?

Here's an example of only a tiny portion of data. This is 50 rows from a file with 160,000 rows of data, and it's only one of hundreds of data files with recordings from different days.

| Timestamp  | Azimuth_deg | Range_nmi   | x            | y            | Height_Kft | ELAngle_From_Radar |
|------------|-------------|-------------|--------------|--------------|------------|--------------------|
| 1342182046 | 236.585083  | 12.70696562 | -6.997701498 | -10.6065616  | 5250       | 3.774822712        |
| 1342182047 | 237.1179199 | 15.81499857 | -8.586149694 | -13.28127302 | 7250       | 4.252370358        |
| 1342182047 | 237.7331543 | 18.01656208 | -9.618378547 | -15.23428054 | 8625       | 4.426027775        |
| 1342182047 | 238.1286621 | 26.25627277 | -13.86366837 | -22.29777027 | 12000      | 4.132731438        |
| 1342182048 | 238.3648682 | 28.18252031 | -14.78195899 | -23.99475233 | 10875      | 3.449725151        |
| 1342182048 | 237.9089355 | 32.13241263 | -17.07087312 | -27.22273374 | 13000      | 3.618355751        |
| 1342182048 | 237.590332  | 33.13579715 | -17.75976859 | -27.97448252 | 13875      | 3.751922369        |
| 1342182296 | 236.8927002 | 99.6340088  | -54.42096109 | -83.45834112 | 11625      | 0.492897689        |
| 1342182297 | 236.9696045 | 100.9291029 | -55.01482645 | -84.61709449 | 7125       | 0.056097049        |
| 1342182297 | 239.0899658 | 112.131715  | -57.60111073 | -96.20620327 | 14875      | 0.555176675        |
| 1342182297 | 237.7990723 | 127.8811392 | -68.14657738 | -108.2110426 | 10750      | 0.017806327        |
| 1342182544 | 237.9968262 | 18.05127794 | -9.566567894 | -15.30782198 | 10875      | 5.519592762        |
| 1342182669 | 239.2987061 | 20.2345192  | -10.3309834  | -17.39846399 | 11375      | 5.20694828         |
| 1342182669 | 240.2325439 | 27.72928559 | -13.76706319 | -24.07033965 | 15250      | 5.029750347        |
| 1342182795 | 239.5019531 | 18.50210183 | -9.389983031 | -15.94227056 | 11250      | 5.616712093        |
| 1342182796 | 240.6170654 | 23.19645628 | -11.38120772 | -20.21246385 | 14250      | 5.617844105        |
| 1342183407 | 238.8372803 | 16.47893921 | -8.527362363 | -14.10104707 | 4250       | 2.31631875         |
| 1342183407 | 239.4580078 | 18.11395933 | -9.204965574 | -15.60077343 | 4500       | 2.198268175        |
| 1342183407 | 238.6395264 | 24.23262798 | -12.61116056 | -20.69248386 | 4875       | 1.763411999        |
| 1342183408 | 239.0570068 | 25.02578874 | -12.86788457 | -21.46410139 | 3250       | 1.048457146        |
| 1342183408 | 240.8312988 | 26.46649653 | -12.89931353 | -23.11023906 | 5625       | 1.836069107        |
| 1342183408 | 239.5953369 | 28.44144269 | -14.39432675 | -24.52996168 | 4875       | 1.429123044        |
| 1342183409 | 241.6223145 | 30.06006922 | -14.28699733 | -26.44786322 | 8625       | 2.518773556        |
| 1342183409 | 239.0240479 | 30.7399213  | -15.82116934 | -26.35589805 | 8000       | 2.254117489        |
| 1342183409 | 239.8205566 | 50.86113182 | -25.56839087 | -43.96717091 | 12500      | 2.002401352        |
| 1342183410 | 240.5291748 | 58.03236577 | -28.55078155 | -50.5233446  | 11750      | 1.545037985        |
| 1342183410 | 240.3588867 | 67.90661442 | -33.58427931 | -59.02037331 | 14875      | 1.642581463        |
| 1342183410 | 241.0455322 | 21.8208407  | -10.5637836  | -19.09333824 | 15000      | 6.349717617        |
| 1342183411 | 240.9851074 | 36.48684105 | -17.6974657  | -31.90751131 | 11250      | 2.674653053        |
| 1342183411 | 240.9466553 | 17.85503695 | -8.670829408 | -15.60830105 | 15625      | 8.146371841        |
| 1342183411 | 241.7596436 | 29.97906557 | -14.18523631 | -26.41066912 | 8500       | 2.503671408        |
| 1342183412 | 240.5511475 | 31.74378797 | -15.60671923 | -27.64232967 | 10625      | 2.950431824        |
| 1342183412 | 240.9631348 | 39.67539549 | -19.25733667 | -34.68849941 | 13250      | 2.906309605        |
| 1342183412 | 239.9359131 | 41.14840831 | -20.61405064 | -35.61253182 | 15000      | 3.176202297        |
| 1342183413 | 241.6607666 | 44.32153348 | -21.03903334 | -39.00970913 | 14250      | 2.760872841        |
| 1342183413 | 239.7491455 | 29.4776144  | -14.8504348  | -25.46358845 | 2000       | 0.474312395        |
| 1342183413 | 241.1004639 | 28.94337603 | -13.9876186  | -25.33901225 | 11875      | 3.697468281        |
| 1342183414 | 241.171875  | 12.23781947 | -5.900877954 | -10.72118765 | 15500      | 11.905797          |
| 1342183414 | 241.809082  | 25.50891766 | -12.05069489 | -22.48300764 | 10875      | 3.846702099        |
| 1342183414 | 241.2487793 | 10.6674094  | -5.131103368 | -9.352293916 | 18375      | 16.40489197        |
| 1342183415 | 241.4025879 | 36.19513147 | -17.32487936 | -31.77949177 | 17000      | 4.207995892        |
| 1342183415 | 242.243042  | 7.672685127 | -3.573338185 | -6.789797587 | 5375       | 6.48469305         |
| 1342183415 | 241.9793701 | 34.39858621 | -16.16009275 | -30.36633227 | 12250      | 3.138323784        |
| 1342183415 | 243.2922363 | 33.10349212 | -14.87803508 | -29.57169699 | 15000      | 4.051062584        |
| 1342183416 | 241.9958496 | 33.84795425 | -15.89281681 | -29.88481856 | 14750      | 3.894590378        |
| 1342185070 | 242.5726318 | 111.3698949 | -51.29962535 | -98.85141342 | 12375      | 0.358596236        |
| 1342185070 | 242.2155762 | 118.7354412 | -55.34806818 | -105.0461629 | 15375      | 0.488656789        |
| 1342185071 | 242.6660156 | 121.0826184 | -55.5982987  | -107.5631427 | 10250      | 0.066518605        |
| 1342185071 | 244.1766357 | 11.18332551 | -4.87143644  | -10.06657223 | 5250       | 4.326072693        |

[Here's an example](https://i.imgur.com/ZG9wwxx.jpg) of a file which was processed in python with matplotlib to show only the 2D portion of a data file. It has been reduced to show only plots out to about 30 miles from the radar (which would be at the center of the image). The plots are colored by time, which helps to visually distinguish valid targets/tracks from surrounding noise. [Here's the same data, zoomed in even closer on the lower-right quadrant.](https://i.imgur.com/aulXWVA.png) I haven't reduced the noise from these files, though I can do that to some extent by filtering out points that are distant from other points in all three physical dimensions as well as time.

A large portion of what you'll see are birds/flocks of birds moving slowly in time through space. But you'll also see a few potential drone/UAVs, and some fast-moving aircraft.

I know this is traditionally the realm of things like Kalman Filters, but I'd really like to take a crack at this with ML. Any recommendations for where to go next with this will be much appreciated!"
Help with project needed,0,2,False,False,False,learnmachinelearning,1512782328,True,"I am starting with a project for drawing to some kind of canvas using hand motion. I am planning on using Python with openCV + Tensorflow. I have a basic idea on how to train the model and how to feed inputs to it for classification. It would get an image of n*n pixels and i would use openCV to just take the hand part from the image.

I am not sure how or where to get a data set for that, or if it even exists? I would probably have 3-4 different gestures. Draw, clear canvas, and possibly switch some modes for the app, which is not that important for now.

Do you have any ideas how to generate or where to get the data set?

I am thinking of making a video of my hand and extracting frames of images for each class. How many images per class should i need?"
What does it mean when you want to stratify your data?,6,2,False,False,False,learnmachinelearning,1512802988,True,I am a newbie and I'm confused on the phrase stratify your data.
"Weekly Status Check Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",1,5,False,False,False,learnmachinelearning,1512803110,True,"Let's have a  meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
Detecting Diseases in Chest X-ray Using Deep Learning,0,1,False,False,False,learnmachinelearning,1512813382,True,[removed]
what is the best route to Machine learning?,3,3,False,False,False,learnmachinelearning,1512819394,True,"I just know basics of Machine learning, I know linear algebra and calculus. "
Naive Bayes in sentiment analysis: Machine Learning Questions &amp; Answers Part – IV,0,4,False,False,False,learnmachinelearning,1512826924,False, 
The loss function of multiple not-probabilistic outputs in reinforcement learning,1,2,False,False,False,learnmachinelearning,1512829210,True,"I am trying to make a car navigate a track from a top down perspective in a 2d environment. So far I've been successful following this tutorial, but my current car can only choose between steering a fixed amount right and left, and is always accelerating. I want to improve my network by making it able to gas, brake and choose the steering angle at the same time. I plan on achieving this by having an action layer with 3 nodes, using a tanh activation function. The first will be for steering left and right (the value being the steering angle, negative for left and positive for right), the second gas and the third brake.

My main question is, and what I've been stuck on for many days, is how do I compute the loss function of such model? What I used so far was the negative log likelihood of the chosen action's probability. But I don't understand how I could possibly scale this to multiple outputs, where sometimes the right chose is not 0 or 1 but somewhere in between?

From the research I've done the solution seems to be an actor critic network, but from the information I've found online I can't wrap my head around this. I have a few questions about this where I can't find the answers on: 1) Should the actor and critic network share the same hidden layers, or be entirely independent? 2) Do I calculate the loss of the actor network by putting in the current state and next state into the critic network and squaring the difference? Isn't it bad that this does not take the inputs into account? 3) Why use the critic anyways instead of just the discounted reward?"
When to use what 'kind' of Support Vector Machine (SVM) on non-lineair data?,7,8,False,False,False,learnmachinelearning,1512829515,True,"I know some basics of machine learning, but overal im still fairly new to it. For a project I'll be using a SVM on a non-lineair dataset. As far as I know there are two methods to do deal with the non-linair data:

1. First transform the data to a new feature space using a kernel.
2. Using a soft margin SVM.

But when should what method be used? And are there possibly more methods to do this?"
How to chose a loss function?,5,1,False,False,False,learnmachinelearning,1512843355,True,"Hi,

I've been given a machine learning case study to analyse and give a 20 minuet presentation on and frankly I'm a little bit lost. I come from a general mathematics background with little exposure to ML before. The general gist of the problem is that an insurance company has a huge set of data (mixture of continuous, integer and categorical data) and want to predict the average cost of insurance claims. Most of the costs are 0 (no claim) but where there is a cost it can become very large (10^6). I'm supposed to chose an algorithm to use, compare its features to the standard GLMs in use and describe how to go about desiging a pipeline for it, but I'm sort of lost.

From looking at various sources, and wikipedia, it seems that random trees or gradient boosting machines are good options, the later specifically. I need to find a loss function in order to use the GBM, but how do i go about chosing that? Is just using mean squared error ok?

As for the pipeline part, from what I can gather the pipeline refers to going from data through training into outputs with several steps in the way, but what design features do we need to be considering here? How commonly your model needs retraining, how often the data gets updated, how much data and which fields to be using etc?

Many Thanks."
[Classification] Rescaling or standardisation?,1,5,False,False,False,learnmachinelearning,1512851598,True,"Suppose I have a dataset where there are multiple features but some of them have a different type. For example, let's say the features are x, y &amp; d - where x, y are coordinates (doubles), and d is depth (centimetres). As you can see, since d is of a different type (compared to x &amp; y), I want to change it so it can be of the same type as x &amp; y, but that's not possible I think, so I was thinking to change all the features to a different type so the type is the same for all the features.

Would it be better to rescale the features so the values lie between 0 and 1? Or would it be better to standardise the features?"
Memoryless property of exponential distribution explained in detail.,0,6,False,False,False,learnmachinelearning,1512856637,False, 
Convolutional Neural Networks (CNNs) explained,0,47,False,False,False,learnmachinelearning,1512860527,False, 
[Regression] Coffee Shop Neural Network,1,2,False,False,False,learnmachinelearning,1512871756,True,"Hello, I am extremely new to the world of machine learning. 
My machine learning class had us run through a few basic models before we arrived at neural networks. As a final project, I was given the opportunity to write a neural network to predict something based off a dataset I was interested in. I chose our school's coffee shop sales data. My goal is to build a network that can tell its user how much of each type of item will be sold during a given day. 

 The biggest roadblock I faced so far was the horrific format of the coffee shop's sales data. I spent a good week or two working in python to get the data into a usable CSV file. Long story short, I have the data in what I believe is the best possible format but I have no idea how to begin building the network. 

Our professor had us watch the [4 part series](https://www.youtube.com/watch?v=aircAruvnKk&amp;list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) from 3blue1brown which helped me to understand the architecture of a neural network. Additionally, she described the mathematics behind back-propagation. Finally, she gave us some examples of how to create an image classification network in matlab. Unfortunately, her examples do not appear to cross over to a shallow regression network. 

The best launching point I could find was the ""Neural network getting started GUI"", so I fiddled with the parameters available to me, but all I managed to do was overfit my data a lot. I began trying to write my own custom network, but most of the code I have is just me playing with parameters. Does anybody have any advice? How should I go about beginning this project?

(I did not see any rules in the sidebar. I hope posts like this are OK.) "
a little help with Keras,3,3,False,False,False,learnmachinelearning,1512876702,True,"I am trying to learn Keras and struggling a bit. Want to run by someone my understanding of things to confirm  i am correct (might struggle a bit with terminology).

    model = Sequential()
    model.add(Dense(35, activation='relu', input_dim=50))
    model.add(Dense(1, activation='sigmoid'))
    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])

    import numpy as np
    data = np.random.random((300, 50))
    labels = np.random.randint(2, size=(300, 1))

    model.fit(x=data, y=labels, epochs=10, batch_size=32)

**Understanding:**

We have input data of 50 data points. Trying to build a neutral network that has 1 output (Yes/No scenario). 

We build 2 layers. 

1st layer has 'relu' activation and has 35 neurons.

2nd layer has 'sigmoid' activation (hence yes/no) and has 1 neuron.

Training data has 300 samples (of 50 points each, examples and results are generated randomly for example sake).
We train our model with epoch=10 (go through training 10 times).

**Questions:**

* Not sure what the batch_size is. Documentation says ""Number of samples per gradient update."" 
I thought weights are updated after each data pass. 

* Is my general understanding of this sample correct?


Thanks."
MNIST vanishing gradient (C++ neural network from scratch),5,3,False,False,False,learnmachinelearning,1512895021,True,"I'm writing a neural network from scratch in C++ to classify the MNIST digits. I initialized the weights to be between -1 and 1, scaled the pixel inputs to be between -1 and 1, and I'm using the tanh(x) activation function. The problem is that after training, my outputs for all 10 neurons are either -0.9999 or 0.9999.

How do I avoid this? I'm currently using incremental learning (mini-batch with size 1). Will increasing the batch size solve this? Thank you. :)


"
Question about minibatch optimization in recurrent neural nets,2,2,False,False,False,learnmachinelearning,1512895945,True,"Initially posted this in r/machinelearning, but this may be a better place for it.

I'm trying to wrap my head around the finer points of backpropagation through time and was hoping to get some clarification on something. For the most part, I understand the general idea of BPTT: we feed inputs forward through the RNN to estimate output, send the errors backwards along the network to calculate gradients of the loss function w.r.t. the various parameters, and iterate this process until convergence. Then there's the minibatch/stocastic version of gradient descent, in which we repeatedly use random subsets of the training data (as opposed to all of the data at once) to get our updates.

I get that, but most of the resources I can find present the equations assuming a single training sequence. In general, the training data for an RNN can be 3-dimensional: [number of sequences, time steps, number of features]. When we talk about minibatches, are we sampling time steps (i.e. sampling along the second dimension), or sequences (sampling along the first dimension)?

Also, how does the math behind BPTT change with multiple training sequences? Is it simply a matter of double-summing loss contributions over both time-steps and sequences? Again, most resources I can find assume a single sequence, so only time is considered.

Thanks in advance!"
Dealing with multiple objects in object detection,0,2,False,False,False,learnmachinelearning,1512896977,True,"hi people, does anyone have experience in object detection here? I had a couple of doubts.

Suppose my 1st image has 20 objects to be detected(all rectangular), and my second image has 25 objects to be detected.

How do I manage this variable number of objects in the model(keras or tensorflow)? [ Since dynamic graphs are not possible because of my lack of skill, I thought that I could fix the number of outputs(predictions for boxes) the model would make for a single image. But then what should be the number? Minimum number of boxes or maximum number? If I go with minimum, I am not using useful data. So what should I do with the rest? If I go with maximum, how I do manage images with lesser boxes ]

How would the loss know which predicted box corresponds to which ground truth? Or would the model need to learn the order in which to predict as well?"
LSTM with Keras: unprecise regression of a sinusoid,6,5,False,False,False,learnmachinelearning,1512905764,True,"Hi, I originally posted in [stats.stackoverflow](https://stats.stackexchange.com/questions/317865/lstm-with-keras-unprecise-regression-of-a-sinusoid) but it appears that nobody sees it there. I hope you can help me!

I trained a **LSTM network with Keras** in order to predict the simple `sin()` function, but the amplitude of the sinusoid decrease over predictions: 
[The result graph][1]

In the above image, we can see that the second maximum of this curve do not reach **0.5** like the first one (the blue one). Also, the minimum is supposed to be at **-0.5** but never reach it. Each point of the predictions is predicted using the **30 precedent ones**: and that's why the result is ""drifting"".

My training set contains **6000 sin() points** with **sequences of 30**. I have a two LSTM layers and 2 Dense layers with linear activation. If I increase the number of neurons on the two dense layers, it can be better but never reach the 0.5 or -0.5. 


    model = Sequential()
    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)

    model.add(LSTM(
        units=dim[1],
        input_shape=(6000, 30),
        activation=None,
        return_sequences=True,
        implementation=1))
    model.add(Dropout(0.2))

    model.add(LSTM(
        units=dim[2],
        activation=None,
        return_sequences=False,
        implementation=1))
    model.add(Dropout(0.2))

    model.add(Dense(
        units=128,
        activation=""linear""))

    model.add(Dense(
        units=64, 
        activation=""linear""))
    model.add(Activation(""linear""))

    model.compile(loss=""mse"", optimizer=sgd)


I also tried to train through a lot of epochs (at least 100) but it wasn't either successful:

[Losses from tensorbard][2]

This is the Tensorboard graph for a few tests for different configurations. The **100 epochs** test appears in blue.

So, the loss is very low and seems hard to improve, but still I don't get the desired result (which is the proper sin() function). 

My problem is that I don't know how to improve my model, because the loss is very low (because each predict is pretty good regarding the 30 precedent one, finally!) but after a few points, it drifts. How can I also correct points if they are too far away from their real position ?
Or maybe I have to change my loss function (but I don't see how to do with LSTM) ?

*Note: I basically tried to do the same as Jakob Aungiers did in his blog post : http://www.jakob-aungiers.com/articles/a/LSTM-Neural-Network-for-Time-Series-Prediction, but it is not working anymore on this version or keras (I guess)*

Thank you.

  [1]: https://i.stack.imgur.com/AI2IC.png
  [2]: https://i.stack.imgur.com/mYFx6.png"
Binary-class Support Vector Machine (SVM) vs Multi-class SVM,7,6,False,False,False,learnmachinelearning,1512910250,True,"For a project I'll be learning a SVM to recognize seizures in epileptic patients. Mainly the SVM should recognize the two classes:

1. Sound alarm (when recognizing a heavy seizure)
2. Don't sound alarm (when recognizing a mild seizure or no seizure).

Ideally though, it would also split the second class in seperate classes, but this would require a multi-class SVM. I don't have any experience with multi-class SVM's (and little with normal SVM's) and am wondering if using a multi-class SVM could have a negative impact on the original problem.  By either getting a worse classification for sound alarm vs don't sound alarm or by taking more time to classify a new point (I can't have it take minutes to recognize a seizure). Is someone able to tell me if this could be the case or if there is another reason this could be negative for the original problem?"
Pandas running out of memory on unstack; a priori for large datasets,2,7,False,False,False,learnmachinelearning,1512928787,True,I’m trying to pivot a large DataFrame out to use a priori algorithm on it. The problem is there are like 20k skus and a couple hundred thousand orders. So when I try to unstack I am getting errors that seem to be memory related for such a large DataFrame. I could batch it but I don’t know how I’d reconcile the results through multiple batches. Or maybe I’m thinking about this completely wrong lol. 
What does a Hamiltonian have to do with machine learning?,13,11,False,False,False,learnmachinelearning,1512935572,True,"Has anyone ever come across the term Hamiltonian in a machine learning context? Can anyone explain what this may be referring to?

Thx!"
Face verification: what's the advantage of the triplet loss function?,3,4,False,False,False,learnmachinelearning,1512941697,True,"Working through the deeplearning.ai specialization on Coursera right now. In the module on ConvNets, the professor introduces face verification by talking about siamese networks and the triplet loss function (in the context of creating a system that can learn to verify faces by comparing to a single ""anchor photo"").

I *think* I get why you'd want to use a siamese network architecture for this problem, though I'd have trouble putting it into words at this point. The triplet loss is a bit more confusing to me, though. It seems like triplet loss just forces the network to do two separate binary classification problems at the same time: checking for a match between the anchor photo and the positive example, and then checking for a match between the anchor and the negative example. If that's the case, it should fit the format of a standard binary classification pretty well, right? What am I missing here? Does it have something to do with training efficiency...?"
Policy vs Value?,6,1,False,False,False,learnmachinelearning,1512948794,True,"In RL, is policy at a state conceptually the same as the softmax of the values of all the child states?

Also for a deterministic game/environment, all the policies in the ideal solution have 0 everywhere except for the optimal action which is 1 right?"
Multiple fully-connected layers,5,7,False,False,False,learnmachinelearning,1512967021,True,"I'm reading [this series of articles](https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/) and it's great; highly recommend it to anyone on this sub who hasn't already seen it.

Anyway my understanding of a fully-connected AKA complete bipartite AKA 1-dim convolution is that it can represent a multiplication by any general matrix, full rank or anything. Or in other words it spans the complete space of all possible linear functionals, so from a purely mathematical standpoint you might as well compose multiple fully-connected/linear layers into one. (Unlike when you have alternating linear and non-linear layers, although you can swap adjacent max pool and relu)

So what are the benefits of having two or more fully-connected layers in a row? I assume it helps gradient descent converge faster if you have a complex feature space or something, but my intuition is kinda shaky here."
"Is ReLU ""free""?",5,8,False,False,False,learnmachinelearning,1512971298,True,"I always see ReLu being used after every convolution. Is it because it's ""free"" in the sense that it's computationally efficient (simple branch both forwards and backwards) and doesn't introduce any parameters so it can't possibly hurt your model?"
DBScan find top 10 outliers: Parameter tuning,0,1,False,False,False,learnmachinelearning,1512986230,True,"How to tune min points and epsilon in such a way that i will get only top 10 outliers.

I came across this paper http://roar.uel.ac.uk/5674/1/Choosing%20DBSCAN%20Parameters.pdf Where differential evolution is used(kinda heuristic). 

But I want to do that very simply.

My current algorithm:

     itr = 0, eps = 900, minpts = 5, inc_step = 100
     while number of outliers &lt; 10  and itr &lt; 10:
          eps = eps + step
          itr = itr + 1
          dbscan(eps,minpts)


Also, I don't want to loop dbscan more than 10 times."
Simplifying the Machine learning workflow with Optimus and Apache Spark,0,2,False,False,False,learnmachinelearning,1512998922,False, 
What do I have to change for a neural network to solve a regression problem instead of a classification problem?,5,3,False,False,False,learnmachinelearning,1513003386,True,"I created my first neural network from scratch in python classifying the minst letter data set. I got to an accuracy of 96%. I now want to tackle a regression problem(predicting house prices) but I'm confused what to change about my neural network for it to be able to solve a regression problem.


Am I correct when I say that I Will only Need one output node, that I will need a different activation function instead of a sigmoid function. 

And how would I test for 'accuracy' as I think the neural network will rarely give the exact price?

"
"Yann LeCun - My take on Ali Rahimi's ""Test of Time"" award...",1,13,False,False,False,learnmachinelearning,1513006772,False, 
"How do you update the weights of a network when you don't know the ""target""?",4,9,False,False,False,learnmachinelearning,1513022685,True,"I'm trying to make a neural network that plays tic tac toe, but I don't know how to update the weights. "
"""Most common"" vs ""Most indicative"" vs Predictive Model",7,3,False,False,False,learnmachinelearning,1513023505,True,"When given a dataset about a number of patients, the conditions they've been diagnosed with, and the medications they're taking, how would you interpret the following questions in an exercise for a class on statistical methods in medicine?

1. Which are the most *common* medications for each disease?
2. Which medications are most *indicative* of each disease?

There's a separate question asking to *model* diseases based on medications (which I know how to do and have done), so question 2. seems to ask for something else, likely something simpler. Note that the most common medications aren't necessarily the most indicative for a disease because e.g., many diabetics take aspirin or high blood pressure medications for reasons other than diabetes. The way I'm interpreting ""indicative"" is as elevation of a medication over other medications compared to the general population, but it's not clear. Btw, I'm not asking for solutions or even pointers, just want to make sure I understand the questions correctly. Thanks. "
Why does ML need so much memory?,3,5,False,False,False,learnmachinelearning,1513026333,True,"I understand that having a lot of memory makes solving problems a lot faster, but why for example, can neural-style not split the problem up into multiple parts and complete the problem one piece at a time. All of the tiling examples I've seen haven't worked well with the algorithm, it seems like instead of transferring the style across the entire photo, it tiles the style along with the photo.

Could it be possible to generate a file of what needs to be done and then fill up the gpu with as much as can fit and keep doing that until everything is done? Are there just initial calculations that take up a lot of memory at once? Is there any way to program around memory restraints? I'm finding that I'm unable to test a lot of projects because of memory. I have a 4GB 960 and an 8GB amd r9 390 that I can't use much because of a general lack of opencl support in most projects."
Intuition behind deviation from 0 = overfitting,3,5,False,False,False,learnmachinelearning,1513033255,True,"Adding L2 regularization is weird for me to conceptualize, because I don't see why lines of higher slope are inherently more prone to overfitting than lines of lower slope.

Is it correct to think of the regularization term as a measure of the ""discontinuity"" of the function output by the network? Is there some analogy to line integral or surface tension which shows why L2 or L1 is a good measure of discontinuity?"
Monthly ELI5 (Explain Like I am Five) Thread,10,17,False,False,False,learnmachinelearning,1513034411,True,"Top comments need to be in the format of: `ELI5 $CONCEPT_NAME` and the replies should provide a clear explanation in a layman's term.
Here are the relevant rules from /r/explainlikeimfive breaking down the meaning of ""ELI5"":

- E is for Explain - merely answering a question is not enough.

- LI5 means friendly, simplified and layman-accessible explanations - not responses aimed at literal five-year-olds.
"
"Data augmentation and speed, which data workflow",0,3,False,False,False,learnmachinelearning,1513041279,True,"Hi!

I am using data augmentation using OpenCV where I randomly rotate my images, but this operation is costly and impacts my training time especially because I use a sequence of images as an input.
My operation is a little more complex than a rotation, it involves finding the bounding box of the rotated object so that the output images have similar margins. 

I tried generating a LMDB database with only a subset of rotated images (10 degrees, my database is 90Gb) and the bottleneck is now searching the key and parsing the binary data to an image.

Which efficient data flow do you use if you want to apply a image processing pipeline for your training set? Any tip?

Thank you!

"
"Deploying a simple machine learning model as an API with Python, Falcon, Gunicorn, and Datmo",0,19,False,False,False,learnmachinelearning,1513041665,False, 
Tic-tac-toe classifier,2,1,False,False,False,learnmachinelearning,1513062250,True,"I'm trying (and failing) to make a simple network that classifies tic-tac-toe boards as winning,losing, or neither.

My input is 3x3x2 (one binary layer each for X's and O's) and output is 3 logits.

My intuition tells me it should be doable with only a 3x3 convolution of depth 8 with ""same"" padding (for the 4 ""winning lines"" x 2 players) followed by a fully-connected layer of 3 units. In fact I think I know what all the weights in the 100% network should be (-2 bias after conv then relu should do the trick) but no matter how much I train it I can't get above 57 % accuracy.

Is this a math error or implementation error?

Edit: I finally fixed it. I didn't initialize numpy arrays properly"
[video] Machine Learning with TensorFlow and Google Cloud with Vijay Reddy,0,1,False,False,False,learnmachinelearning,1513085880,False, 
"Tomorrow we are holding our final online meetup of the year. We'll discuss the paper ""Understanding Deep Learning Requires Rethinking Generalization"" by Chiyuan Zhang et al, which will be presented by Bruno Gonçalves. We start at 3pm PT! Don't be late!",0,17,False,False,False,learnmachinelearning,1513103766,False, 
"How to load a trained keras model, pop(remove) the last two layers, and then save it again?",1,2,False,False,False,learnmachinelearning,1513108591,True,"So I'm working (in keras :P) with this architecture for a facial point network:

    n_kpts = 68 # number of keypoints

    input_shape = (1,100,100)

    input_1 = Input(shape=input_shape)

    conv_1 = Conv2D(34, kernel_size=(9,9),
				activation='tanh',
				input_shape=input_shape,
				padding='same',
				data_format='channels_first')(input_1)

    conv_2 = Conv2D(34, kernel_size=(9,9),
				activation='tanh',
				padding='same',
				data_format='channels_first')(conv_1)

    conv_3 = Conv2D(34, kernel_size=(9,9),
				activation='tanh',
				padding='same',
				data_format='channels_first')(conv_2)

    conv_4 = Conv2D(34, kernel_size=(9,9),
				activation='tanh',
				padding='same',
				data_format='channels_first')(conv_3)

    conv_5 = Conv2D(34, kernel_size=(9,9),
				activation='tanh',
				padding='same',
				data_format='channels_first')(conv_4)

    softargmax = spatial_softArgmax(68)(conv_4)

    reshape = Reshape((68,2))(softargmax)

    model = Model(inputs=input_1, outputs=reshape)


I need to get rid of the reshape and softargmax (it's a custom layer) - and just save the model as the input and conv_1 - conv_5; I want the output to just be the output of that last convolutional layer. I have a model that's trained as an h5 with all of these layers, but i run into some trouble when trying to pop and resave - here's the script I wrote for that:


    def get_weights_without_softargmax(fname):
        	model = load_model(fname, custom_objects={'spatial_softArgmax':spatial_softArgmax})
	
	    model.summary()
	    model.layers.pop() # reshape layer
	    model.layers.pop() # spatial softargmax

	    model.summary()
	
	    model.save(""no_softargmax_"" + str(fname))

The first model.summary returns a summary of the whole network;

    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    input_1 (InputLayer)         (None, 1, 100, 100)       0         
    _________________________________________________________________
    conv2d_1 (Conv2D)            (None, 34, 100, 100)      2788      
    _________________________________________________________________
    conv2d_2 (Conv2D)            (None, 34, 100, 100)      93670     
    _________________________________________________________________
    conv2d_3 (Conv2D)            (None, 34, 100, 100)      93670     
    _________________________________________________________________
    conv2d_4 (Conv2D)            (None, 34, 100, 100)      93670     
    _________________________________________________________________
    spatial_soft_argmax_1 (spati (None, 68)                0         
    _________________________________________________________________
    reshape_1 (Reshape)          (None, 34, 2)             0         
    =================================================================
    Total params: 283,798
    Trainable params: 283,798
    Non-trainable params: 0


and the second one returns the now popped network


    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    input_1 (InputLayer)         (None, 1, 100, 100)       0         
    _________________________________________________________________
    conv2d_1 (Conv2D)            (None, 34, 100, 100)      2788      
    _________________________________________________________________
    conv2d_2 (Conv2D)            (None, 34, 100, 100)      93670     
    _________________________________________________________________
    conv2d_3 (Conv2D)            (None, 34, 100, 100)      93670     
    _________________________________________________________________
    conv2d_4 (Conv2D)            (None, 34, 100, 100)      93670     
    =================================================================
    Total params: 283,798
    Trainable params: 283,798
    Non-trainable params: 0


but when I try to do `model.save()` - i get this error:


    Traceback (most recent call last):
      File ""weight_chopper.py"", line 18, in &lt;module&gt;
        get_weights_without_softargmax(""34pts_94percent.h5"")
      File ""weight_chopper.py"", line 16, in get_weights_without_softargmax
        model.save(""no_softargmax_"" + str(fname))
      File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 2553, in save
        save_model(self, filepath, overwrite, include_optimizer)
      File ""/usr/local/lib/python2.7/dist-packages/keras/models.py"", line 107, in save_model
        'config': model.get_config()
      File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 2390, in get_config
        new_node_index = node_conversion_map[node_key]
    KeyError: u'reshape_1_ib-0'


Note how it's referencing the old reshape layer? When I defined the model; I said `model = Model(inputs=input_1, outputs=reshape)` - so does it still think that the model has that reshape output? How can I convince it otherwise? I've tried doing another `Model(inputs=..., outputs=...)` type command; but there aren't any appropriate values to plug in for the inputs and outputs! 

How can I get the model to save (preferably as a compiled model) with just the convolutional layers?

edit: formatting"
Must Read Books for ML!,0,1,False,False,False,learnmachinelearning,1513113992,True,[deleted]
Are there any big machine learning forum besides the ones on reddit?,1,2,False,False,False,learnmachinelearning,1513122463,True, 
Where can I find the derivation of the cross entropy function?,2,7,False,False,False,learnmachinelearning,1513130274,True,"I've been looking everywhere, I'm very curious about why it works as a machine learning loss function."
MxNet version of Keras MLP doesn't learn,2,3,False,False,False,learnmachinelearning,1513142867,True,"I'm working with the Pima Indians dataset. The problem is binary classification. Using an MLP in Keras, I can get an accuracy of ~85%. Doing the same MLP in MxNet gets me a model that predicts constant or pretty much constant probabilities regardless of input feature values.

Any ideas on what's going wrong? I've tried different batch sizes, epochs, optimisation algorithms, activation functions, normalisation, scaling and altering the numbers of neurons, but I can't get the MxNet MLP to do anything useful.

Here's the Python code for Keras MLP:

    model = Sequential()
    model.add(Dense(12, input_dim=8, activation='relu'))
    model.add(Dense(8, activation='relu'))
    model.add(Dense(1, activation='sigmoid'))

    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

Here's the MxNet code:

    batch_size=10
    train_iter=mx.io.NDArrayIter(mx.nd.array(df_train), mx.nd.array(y_train), batch_size, shuffle=True)
    val_iter=mx.io.NDArrayIter(mx.nd.array(df_test), mx.nd.array(y_test), batch_size)

    data=mx.sym.var('data')

    fc1 = mx.sym.FullyConnected(data=data, num_hidden=12)
    act1 = mx.sym.Activation(data=fc1, act_type='relu')

    fc2 = mx.sym.FullyConnected(data=act1, num_hidden=8)
    act2 = mx.sym.Activation(data=fc2, act_type='relu')

    fcfinal = mx.sym.FullyConnected(data=act2, num_hidden=2)
    mlp = mx.sym.SoftmaxOutput(data=fcfinal, name='softmax')

    mlp_model = mx.mod.Module(symbol=mlp, context=mx.cpu())
    mlp_model.fit(train_iter,
              eval_data=val_iter,
              optimizer='rmsprop',
              eval_metric='ce',
              num_epoch=150)"
TWIL (This Week I Learned) - Share something new that you have learned this week!,1,7,False,False,False,learnmachinelearning,1513148715,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
How to organize different research contents to form a Phd thesis?,0,2,False,False,False,learnmachinelearning,1513155926,True,"The research content includes a proposed algorithm for image/object matching and two proposed algorithms for multiple object detection.
The algorithms for image/object matching and multiple object detection are not related. 

My question is how to organize them to form a Phd thesis? How to unify them into a big problem to present? What title is appropriate? 
"
Collaborative learning group over winter break/into the spring semester?,13,12,False,False,False,learnmachinelearning,1513160547,True,"Hi /r/learnmachinelearning,

I'm a 3rd year undergrad, and I'll be self-studying ML over the winter break (12/15-1/15) to prepare for my ML class next spring. Does anybody want to learn with me, and potentially keep working together into the spring? I'm thinking of setting up something like a Twitch stream where I'm reading and thinking through stuff out loud, and we can all talk together on discord or through chat to work through problems together, code together, etc. 

Just for some context, I'm a super average CS student at Berkeley and starting mostly from scratch - I know some basics of regression, SVD, PCA, and k-means. 

Let me know if you're interested! I'd be videotaping this stuff regardless because I find I learn better out loud, but I learn even better with groups so I wanted to ask around and see if anyone would want to join me.

Thanks : )"
DDPG and Batch Normalization in TensorFlow,6,6,False,False,False,learnmachinelearning,1513161683,True,"Hello everyone, 

I am currently writing a DDPG agent in TensorFlow and want to try to apply batch normalization to the hidden layers. As I have several people claim that this improves the training, I too wanted to try this. Luckily tensorflow gives a nice function to create a batch normalization layer `tf.layers.batch_normalization()`.

However I have some question regarding the correct implementation of the batch normalization when used with slow updated target networks as is the case with DDPG. My understanding of the batch norm layer is that it uses a scale, an offset and moving averages of the mean and variance of the input to that layer. The scale and offset variables of the target networks can easily be updated as they are part of the `tf.trainable_variables()` collection. 

However the moving averages of the mean and variance of the batch norm layer are not, as it is only used internally. The batch norm layers are designed such that the moving average is actually only updated when it is told it is in training mode. With DDPG the only part of the algorithm which is considered 'training' is the optimizer run of the normal network and the slow target network update based on the normal network thereafter. This would therefore result in the moving averages of the target network to keep constant at the initial values.

My question then is, is this reasoning correct and furthermore what will the impact be as these internal moving averages are not the same?

I have looked at some implementations I found online. However all I could find are either incorrectly implemented, or just ignored that these internal values are not the same. "
What do you think about this Machine Learning Computer Build?,8,7,False,False,False,learnmachinelearning,1513165497,True,"**Purpose:**
As I've out grown the processing power of my laptop and have started working on more intensive Machine Learning models, I thought of building a computer to handle that workload in a more efficient manner.

**Problems I'll be working on**
Speech Synthesis, Natural Language Processing, Generative Models and Computer Vision.

**Budget**: ₹80K ($1250)

If you have any suggestions to improve the build, then comment.

[PCPartPicker part list](https://in.pcpartpicker.com/list/dvkLvV) / [Price breakdown by merchant](https://in.pcpartpicker.com/list/dvkLvV/by_merchant/)

Type|Item|Price
:----|:----|:----
**CPU** | [AMD - Ryzen 5 1400 3.2GHz Quad-Core Processor](https://in.pcpartpicker.com/product/72wqqs/amd-ryzen-5-1400-32ghz-quad-core-processor-yd1400bbaebox) | ₹12975.00 @ Amazon India 
**Motherboard** | [Asus - PRIME B350-PLUS ATX AM4 Motherboard](https://in.pcpartpicker.com/product/fPDzK8/asus-prime-b350-plus-atx-am4-motherboard-prime-b350-plus) | ₹8694.00 @ Amazon India 
**Memory** | [Crucial - 8GB (1 x 8GB) DDR4-2133 Memory](https://in.pcpartpicker.com/product/TTnG3C/crucial-memory-ct8g4dfs8213) | ₹4099.00 @ Amazon India 
**Storage** | [Western Digital - Caviar Blue 1TB 3.5"" 7200RPM Internal Hard Drive](https://in.pcpartpicker.com/product/MwW9TW/western-digital-internal-hard-drive-wd10ezex) | ₹3454.00 @ Amazon India 
**Video Card** | [Zotac - GeForce GTX 1080 8GB AMP! Extreme Video Card](https://in.pcpartpicker.com/product/qKp323/zotac-geforce-gtx-1080-8gb-amp-extreme-video-card-zt-p10800b-10p) | ₹37934.81 @ Amazon India 
**Case** | [Corsair - Carbide SPEC-04 (Black/Red) ATX Mid Tower Case](https://in.pcpartpicker.com/product/2tTrxr/corsair-spec-04-blackred-atx-mid-tower-case-cc-9011107-ww) | ₹3898.00 @ Amazon India 
**Power Supply** | [\*SeaSonic - 650W 80+ Gold Certified Semi-Modular ATX Power Supply](https://in.pcpartpicker.com/product/R7V48d/seasonic-power-supply-ssr650rm) | ₹6918.48 @ Amazon India 
 | *Prices include shipping, taxes, rebates, and discounts* |
 | **Total** | **₹77973.29**
 | \*Lowest price parts chosen from parametric criteria |

Thank you for your valuable time."
How to set up your free website with Github,0,1,False,False,False,learnmachinelearning,1513168298,False, 
Classifying handwritten digits with Machine Learning,0,1,False,False,False,learnmachinelearning,1513169125,False, 
Javascript estimate next number in series?,4,2,False,False,False,learnmachinelearning,1513170062,True,"Hii there,

I'm trying to get started with machine learning.  
The language I want to use for this is Javascript (as that's the language I'm most familiar with outside PHP).  
I have tried to do some reading, but I can't make anything of it.  
Now, before you start scolding at me that I should learn to crawl before I can learn to run, please bear in mind that I tried to do so, but it didn't work for me.  
I'm willing to learn, but be patient with me, not everybody has the same way and speed of learning something.  

So I wanted to do something that is more like something I can use, so I am able to connect the dots more easily.  
Therefore, I have collected some data in the form of pseudo-random numbers between 100 and 300.  
for example:

    var gameData = [198, 297, 100, 300, 300, 275, 102];

This array gets longer over time, so don't worry about the fact that ""it might be too little data to go of"".  
Now my goal is to predict (or rather estimate) what might be the next number in the series.  
So my question is: how would I go on doing that?  

I hope somebody can help me :D "
How to Create your own Virtual Assistent,0,1,False,False,False,learnmachinelearning,1513186340,False, 
Final Year Project: Reinforcement Learning in Texas Hold'em,7,9,False,False,False,learnmachinelearning,1513186404,True,"I am a final year Games Programming (BSc) student currently beginning my final year project which is will take place over the next 5 months. 

I have already submit my proposal, stating that I will be developing an agent to play Texas Hold'em poker using neural networks. It's now time to start narrowing that down and to decide on the specifics of the project, so I've decided to post here for some advice.

The first and most important thing that needs to be taken into account is the amount of time that I have. In these 5 months I need to design, develop and test with program, then write a 10,000 dissertation regarding this.

What type of Texas Hold'em could be possible for this project? whether it's heads-up or not, limit or no limit? 

I have decided that I think reinforcement learning would be the best approach for this as there are databases full of poker hands online that can be used for training.

I'm starting to worry that I won't have enough time to complete this project so any advice would be greatly appreciated."
What kind of NN should I use for 3D tensor classification?,2,1,False,False,False,learnmachinelearning,1513202964,True,"Hello,

As my first student project I have to classify 3D volumes into three different classes, let's call them A, B, C. 
The volumes are MxNxP tensors where every element/voxel holds a 32-bit float that is the gray-level of said voxel.
Every file has a corresponding .xml file that contains useful data (features of interest of the imaged sample) and the label regarding the class to which it pertains (it was assigned by human experts).

Now, I can use keras with tensorflow backend or scikit-learn, and I can load the 3d image as a numpy 3d array.

What kind of NN would you recommend? I am absolutely stuck at the endless possibilities that came to my mind:
- use every 3d volume as such and try to send it into a CNN?
- slice it over a direction, perform a CNN based classification over the different samples for every slice and a second NN decides which slices are actually more accurate for prediction
- should I slice every volume, perform segmentation over the histogram, send the GL counts to a MLP? Maybe iterating to improve segmentation?

I am really lost at what I could do and thus I don't do anything.

I know the theory behind and I don't have any practical experience"
Would machine learning be suitable to analyse this health trial dataset?,18,13,False,False,False,learnmachinelearning,1513209627,True,"I'm a doctor involved with a health trial that has ~450 participants that we have followed for 5 years. At the start they received a thorough assessment looking at a range of both quantitative data (about 30 things - weight, age, ethnicity, blood pressure, etc...) and also qualitative data (level of support, level of motivation, family etc..). Our trial participants also had additional tests including blood tests, sleep studies, glucose monitoring... These additional tests were looking for undiagnosed comorbidites (hypertension, diabetes, sleep aponea etc..)

Because we don't want to perform these tests on every child going forward, we are trying to establish if we can use the data collected on the initial assessment to risk stratify the likelihood of the undiagnosed coomorbidities. I.e. If they are overweight and have a certain ethnic background what would their risk of diabetes be? This is about generalising outside of our trial dataset - i.e. new kids that come along. 

Our current analysis is using pivot tables to do it manually based on the ~450 participants that we have. My question is - is there a way that machine learning could help us out? I.e. We feed it all the data we have, tell them which of the participants were diagnosed with diabetes then have the algarithm try to establish what is different about them based on that initial data. 

I imagine we would train it with 300 people then test it on the extra 150 or something like that?

My background is web development and playing with python/arduino/rasp pi so I'm not afraid of coding but I have never looked at machine learning - just know that it exists as a thing. So before I took a deep dive into it I just wanted to make sure that it's something that would actually be useful for this problem. Would appreciate any help and advice."
Advice to start Data Analytics/Machine Learning Projects,3,2,False,False,False,learnmachinelearning,1513216670,True,"Hi, 

I have been interested in the field of Data Analytics and Machine Learning for a while now, and have been looking into grad school and nanodegrees to gain knowledge of the field. HOWEVER, nothing beats real practice but I am a little unsure of how to start. 

To make things easier for those willing to give me advice, I'm really interested in applying data analytics and ML to sports, ie I wanna make insights and predictions about games and players using data available online and/or data I collect myself. 

I am wondering what is the best way to start a project like this, what resources to look at, etc.

Thank you!"
Dataset augmentation vs. lossless dimensionality reduction,0,5,False,False,False,learnmachinelearning,1513222185,True,"In image processing convnets, it's often useful to augment the training data by distortion, rotation, reflection, etc. The AlphaGo/Zero teams also applied this to augment their training data, since Go is invariant under rotation and reflection (but not color inversion because komi)

However, this is only helpful because of inherent redundancies in the dataset. In every case where data augmentation works, you can instead map every element to a canonical form (the quotient of the input space over the transformation group), and maybe multiply your learning rate by the order of the transformation group to get (I think) roughly the same result.

So my question is: When is it appropriate (if ever) to apply ""lossless"" dimensionality reduction like this?

Possible pros:

* Reduced training time per original input
* Reduced input size in some cases
* Super duper application specific as always, but if you get lucky you might save a layer that would have extracted the invariance (idk)

Possible cons:

* Gradient &amp; backprop are kinda cheap compared to data collection anyway
* You won't save many weights because most of them are in the FC layers
* Maybe the first layer will try to extract the feature you eliminated! (unlikely unless you did it carelessly and tried to gzip compress the input or something)
* Your weights could get unstable if the transformation isn't continuous (eg. if you mapped 8 images to 1 based on the corner pixels)
* Easier to overfit (?)
* Perhaps it defeats the ""black box"" purpose of using NNs; you'll probably end up testing it both ways just to make sure it's not hurting your model

Just from brainstorming this list, I think it's usually not worth it but I think I might have a legitimate use case.

There's an open-source AlphaZero-like chess program, where the input is (12 8x8 binary feature planes (one per chess piece type)) x 9 history states, one 8x8 constant plane to keep track of the 50-move rule, and an 8x8 constant for side to move.

*However, the rules of chess are such that you can always flip the board and invert the colors to get the side to move on the bottom.*

I could suggest using this to augment their data (which would surely be better than nothing), but since chess rules are non-continuous and have non-local correlations (compared to, say, images or even Go), I think it might be strictly better to keep the side to move always on the bottom.

Are there any pitfalls to this approach that I missed, or is it actually applicable and common? I'm still very new to ML, so anyone who can offer some intuition as to when/why this does/doesn't work is very helpful!"
Research papers on reinforcement learning,2,6,False,False,False,learnmachinelearning,1513231676,True,I'm starting my masters project and I'm looking for papers on reinforcement learning in general to use as research and reference. Does anyone have any recommendations? 
"Besides linear algebra, which math subject should I have a firm grasp of to understand ch1-4 of Elements of Statistical Learning?",7,6,False,False,False,learnmachinelearning,1513234231,True,"Currently going through some of Axler's Linear Algebra Done Right. Looked like there was some calc in ESL (Haven't taken calc since an ""advanced calc"" course in first year of college... 10+ years ago). Wondering if it's just general calc or if there's a more specific branch someone could point me to. 

Also, I wasn't familiar with the the term conditional expectation. Wondering if that's founded in another branch of mathematics. 

Thanks!!"
Web series explaining Machine learning techniques for the mathematically impaired?,8,11,False,False,False,learnmachinelearning,1513242822,True,"I am a student who has taken a machine learning course and I'm very interested in utilizing this knowledge for some personal projects. My issue though is that my math background is quite horrendous (working on it though). As a result, I find myself flustered by all the various algorithms out there. I was wondering if there were any web series where a good, in-depth analyses of the technique is given, but at a beginner understanding. I feel this would help me when it comes to choosing an appropriate algorithm. 

thanks!"
Introduction to Word Embeddings - word2vec,0,5,False,False,False,learnmachinelearning,1513243596,False, 
100 Years of Solitary Typing,0,0,False,False,False,learnmachinelearning,1513245592,True,"[reference: 100 Years of Solitude]

Wondering how far I'll need to go to replicate my trolling abilities with a net:

=== My uncle's estate &lt; philo565 &gt; 2017-12-13 06:42

The family gave me negatives from my uncle's estate. I have been scanning for two days now. Some go back to the 30's and evidently were actually my unlce's father.

Many are 4 x 5's and medium format 2 1/4...

=== post a sample? &lt; phobrain &gt; 2017-12-13 21:03

For example, my uncle's estate was a rambling plantation in the Philippines that grateful locals had given to a Japanese soldier who had helped repair their fishing nets during WW2. Long story short, the property came to a grand niece of the original soldier, but since she had changed her name, it was disputed for many years, then finally out of the blue they settled when my uncle offered to share a jug of tequila with each of them, and after one died the heirs were so grateful that they gifted the property to my uncle.

My uncle never fully appreciated the gift, but grudgingly lived there because they gave him palm wine. One day he was trying to figure out a camera phone, his first electronic device ever, when drinking the palm wine, and he stepped on maybe a sharp twig and staggered over the edge before he had even taken the first photo in his life.

Edit: e.g. the training data would have to include an encyclopedia I think, so I suspect a full-on version would be beyond a 1080 ti. FYI downvoters: I don't just want to troll; rather like Jesus I want to be a fisher of people for higher purpose, and leave a living sort of Bible behind.
"
"I am about to finish intro to ML from udacity, I would really like to study ML for animation/art but I don't know where to start?",5,1,False,False,False,learnmachinelearning,1513253044,True,"I am about to finish Udacity's intro to ML course and I currently taking their computer vision course as well. I was wondering what is the next advanced course to tie computer vision, machine learning and animations together? The only thing I found from a quick google search is Edx.org's robotics branch, but I really want to learn computer vision / machine learning for art. Art as in animation(2D, 3D), drawings, compositions, modeling and simulations. Where can I find something like this? If there is no Moocs I can accept course in book form as well.

"
Clarification needed when using Tf-Idf vectorizer as a feature for Text Sentiment Classification task.,7,2,False,False,False,learnmachinelearning,1513254369,True,"I am using a Support Vector Machine to classify a twitter sentiment (neutral, positive, negative). The feature that I am trying to use Tf-Idf as a text representation. 

I know that Tf-Idf takes a list of all documents and use that to produce vectors in which each vector contains the value of each word in the document. 

I am assuming that document is a single tweet in this case. What I am not sure about is, do I have to use the pre-processed Twitter text as each document, or do I just use the original raw twitter text as a document?

I need a clarification."
Scopes of Machine Learning and Artificial Intelligence in Banking and Financial Services,0,1,False,False,False,learnmachinelearning,1513256274,False, 
"Top Masters Programs in Europe for Data Science, Machine Learning, Artificial &amp; Big Data Analytics",6,0,False,False,False,learnmachinelearning,1513257483,False, 
Question regarding imbalanced dataset,21,6,False,False,False,learnmachinelearning,1513258737,True,"Hey all, 
First of all, I'm new to this reddit. Hopefully I'll learn a lot here. A bit about myself: I'm student in business engineering, data analytics, and for my master's dissertation I got the topic predicting gaming behaviour. For this, i got a dataset with 5.8k records. In this, there's a column regarding likes to a certain page with theme games. So this will be my predictive variable. If a person like one or more pages, he's labeled 1, if not, he's 0. In total I have 799 1's, and more than 4000 0's. Now I finished building my random forest model, with an accuracy of 86%. I was super happy, until I made my classification report and saw my model only predicted 0's and never 1's. 
Does anyone of you have experience with this, and if so, how can I solve this?

Thanks in advance!"
Transfer Learning for Classifying dog breeds using Keras and Tensorflow backend?,0,1,False,False,False,learnmachinelearning,1513259994,True,[deleted]
Question Regarding Deep Reinforcement Learning,3,2,False,False,False,learnmachinelearning,1513262999,True,"I'm pretty new to machine learning and am currently trying to solve a self imposed problem, but I'm having quite a few difficulties.
I'm having some trouble with environments and more specifically - how do I define rules for possible actions to be taken, as well as how they impact the state.

Specifically I have a system with items in a hierarchy, each with a corresponding value. The actions taken could be adding a new item in any position, pushing the ones below him down, removing an item, pulling the ones below up, switching existing items and changing the values. 
How should I approach this?"
How can I increase the accuracy of my neural network?,18,7,False,False,False,learnmachinelearning,1513264945,True,"I have a neural network that classifies emails as being either spam or ham. It does this by taking the 20 most common words of a feature set that appear in both spam and ham emails. It then uses these feature words to classify unseen training emails in order to train the network.

I have tried changing the amounts of features I use and the number of training emails used, but my NN always hits around the high 60%s, it has never yet managed to break 70% correct classification. I've tried training the network with between 1000 and 12000 emails. 

I think the problem may be to do with my input matrix. Below is an example of what the matrix looks like. Bear in mind that the matrix below is pre-standardisation for clarity. When the input is passed to the network all input numbers are standardised between 0 and 1. The boolean at the end of each row indicates if the training email is spam or ham. 

What I believe the problem to be is the amount of zeros that is present within the input matrix. Each number represents the amount of times a particular feature word appears in this specific email, and as you can see from the matrix in a lot of cases this number is 0. I believe this is throwing off the NN and messing with the results. The feature words used to train the network are the most common words present in both spam and ham emails, so this means that they are the words most likely to appear in a set of unseen training emails, however there are still a lot of zeros. I can't simply increase the amount of feature words used as this will not decrease the amount of zeros present in the input.

Is there anything I can do about the amount of zeros that are present in the input matrix?

    Email 44: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 true 
    Email 45: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 true 
    Email 46: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 true 
    Email 47: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 true 
    Email 48: 0 0 0 0 0 0 0 0 37 2 0 1 0 0 0 0 0 0 0 1 true 
    Email 49: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 true 
    Email 50: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 false 
    Email 51: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 false 
    Email 52: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 false 
    Email 53: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 false "
What is the best way to handle hundreds (221) feature columns,3,10,False,False,False,learnmachinelearning,1513270652,True,"I'm using Tensorflow 1.4 to create an estimator. I recently encountered many more columns that could be a predictor for the label, but it balloons to 212 columns quickly. I am currently using the dataset loader but I do not know how to define that many columns except one by one. Any suggestions? Thanks!"
How to read Loss in Tensorflow MNIST example?,0,5,False,False,False,learnmachinelearning,1513274750,True,"The Tensorflow tutorials have three different examples for classifying MNIST digits, one using a [basic softmax regression](https://www.tensorflow.org/get_started/mnist/beginners), one using [a simple CNN](https://www.tensorflow.org/tutorials/layers), and one using [an optimized CNN](https://www.tensorflow.org/get_started/mnist/pros). I've only been working with TF for a few days, and I can't figure this out, how can we get a numerical output for Loss from the third example?

We have

    with tf.name_scope('loss'):
        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv)
        cross_entropy = tf.reduce_mean(cross_entropy)

and of course when I add in

    print('{}'.format(cross_entropy))

or

    print('{}'.format(cross_entropy.eval()))

or

    print('{}'.format(tf.estimator.EstimatorSpec(loss=cross_entropy)))

or

    print('{}'.format(tf.Print(cross_entropy, [cross_entropy], message='Loss = ')))

I get

    Tensor(""Mean_4:0"", shape=(), dtype=float32)

How can I turn *cross_entropy* into a numerical value?

The Simple CNN example uses

    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)
    loss = tf.losses.softmax_cross_entropy(onehot_labels=onehot_labels, logits=logits)
    ...
    train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())
    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)

and that outputs

    {'loss': 2.3116555, 'global_step': 11, 'accuracy': 0.097199999}"
What does the average of a vector mean?,5,5,False,False,False,learnmachinelearning,1513274899,True,"The paper that I am reading says,

""tweet is represented by the average of the
word embedding vectors of the words that compose
the tweet. ""

Does this mean each word in the tweet (sentence) has to be represented as the average of its word vector (still having the same length), 

or does it mean the sentence itself has to be the average of all values computed above (average of word vectors of the word that the sentence contains)?

I am confused "
Gradient Boosting and parameter tuning in R,0,3,False,False,False,learnmachinelearning,1513275016,False, 
Difference between error function and cost function?,5,3,False,False,False,learnmachinelearning,1513280880,True,I'm going through a textbook where E_in (the in-sample error) is mentioned a lot. I understand this as being the difference between the predictions of the trained model and the real values of the training set. For linear regression least squares is used. Least squares also happens to be the cost function. It makes sense when you consider that we want to minimize both. Are there any cases where the cost function doesn't measure the error directly? Can the two terms be used synonymously?  
I'm getting a ValueError in my Actor Critic Network and I have no idea why,3,3,False,False,False,learnmachinelearning,1513289713,True,"Hey there, I'm making a little car learn how to drive. For this I want to use an Actor Critic Network. After a lot of research I have put together the following code for the networks:

    import tensorflow as tf
    import tensorflow.contrib.slim as slim


    Class Actor:

    def __init__(self, lr, s_size, a_size, h_size):
    
        with tf.variable_scope('Actor'):
            self.state_in = tf.placeholder(shape=[None, s_size + a_size], dtype=tf.float32)
            self.hidden = slim.fully_connected(self.state_in, h_size, biases_initializer=tf.random_uniform_initializer(), activation_fn=tf.nn.relu)
            self.hidden2 = slim.fully_connected(self.hidden, h_size, biases_initializer=tf.random_uniform_initializer(), activation_fn=tf.nn.relu)
            self.output = slim.fully_connected(self.hidden2, a_size, biases_initializer=tf.random_uniform_initializer(), activation_fn=tf.sigmoid)
    
        self.actorvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='Actor')
        self.lr = lr
    
        self.agradients = tf.gradients(Q, A)[0]
        self.policy_grads = tf.gradients(ys=A, xs=self.actorvars, grad_ys=self.agradients)
        self.optimizer = tf.train.RMSPropOptimizer(-self.lr)  # (- learning rate) for ascent policy
    
        print(self.agradients, self.policy_grads, self.actorvars)
    
        self.train_actor = self.optimizer.apply_gradients(zip(self.policy_grads,self.actorvars))

    class Critic:
    
        def __init__(self, lr, s_size, a_size, h_size):
    
            with tf.variable_scope('Critic'):
                self.state_in = tf.placeholder(shape=[None, s_size + a_size], dtype=tf.float32)
                self.hidden = slim.fully_connected(self.state_in, h_size, biases_initializer=tf.random_uniform_initializer(), activation_fn=tf.nn.relu)
                self.hidden2 = slim.fully_connected(self.hidden, h_size, biases_initializer=tf.random_uniform_initializer(), activation_fn=tf.nn.relu)
                self.output = slim.fully_connected(self.hidden2, 1, activation_fn=tf.sigmoid, biases_initializer=tf.random_uniform_initializer())
    
            self.criticvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='Critic')
            self.lr = lr
    
            self.target_Q = R + GAMMA * Q_
            self.loss = tf.reduce_mean(tf.squared_difference(self.target_Q, Q))
            self.train_critic = tf.train.RMSPropOptimizer(self.lr).minimize(self.loss)

but it isn't working. I'm getting the following error:

    ValueError: No gradients provided for any variable: ['&lt;tensorflow.python.training.optimizer._RefVariableProcessor object at 0x000002695B692588&gt;', '&lt;tensorflow.python.training.optimizer._RefVariableProcessor object at 0x000002695B10A438&gt;', '&lt;tensorflow.python.training.optimizer._RefVariableProcessor object at 0x000002695B10AC88&gt;', '&lt;tensorflow.python.training.optimizer._RefVariableProcessor object at 0x000002695B10A208&gt;', '&lt;tensorflow.python.training.optimizer._RefVariableProcessor object at 0x000002695B10A0F0&gt;', '&lt;tensorflow.python.training.optimizer._RefVariableProcessor object at 0x000002695B11B710&gt;'].

about the line
        

        self.train_actor = self.optimizer.apply_gradients(zip(self.policy_grads,self.actorvars))
    in the Actor Network.

I have been doing a lot of googling but I can't find the issue. Does anyone maybe see what the problem is? Help is very much appreciated.

The one print in the code is printing the following by the way, if that helps:

    None [None, None, None, None, None, None] [&lt;tf.Variable 'Actor/fully_connected/weights:0' shape=(8, 10) dtype=float32_ref&gt;, &lt;tf.Variable 'Actor/fully_connected/biases:0' shape=(10,) dtype=float32_ref&gt;, &lt;tf.Variable 'Actor/fully_connected_1/weights:0' shape=(10, 10) dtype=float32_ref&gt;, &lt;tf.Variable 'Actor/fully_connected_1/biases:0' shape=(10,) dtype=float32_ref&gt;, &lt;tf.Variable 'Actor/fully_connected_2/weights:0' shape=(10, 3) dtype=float32_ref&gt;, &lt;tf.Variable 'Actor/fully_connected_2/biases:0' shape=(3,) dtype=float32_ref&gt;]
"
Clear Gradient Boosting tutorial,1,4,False,False,False,learnmachinelearning,1513290376,False, 
What does external knowledge mean in the context of natural language processing?,1,2,False,False,False,learnmachinelearning,1513304287,True,"For example, in the paper ""Named Entity Recognition with Bidirectional LSTM-CNNs"" by Jason P.C Chiu and Eric Nichols, on page 11 second column, it is mentioned ""[...] employed large-scale unlabelled data to perform feature reduction and achieved an F1 score of 91.02 on CoNLL-2003, which is the current state of the art for systems without external knowledge."". I would greatly appreciate if someone could explain what external knowledge means in this case. Thanks!"
GPU suggestion for machine learning,8,3,False,False,False,learnmachinelearning,1513312037,True,"Hi, I want to explore some deep learning concepts. I am planning to buy GPU for that.
As I don't have good knowledge over GPU, I tried to get help from google but results perplexed me.
Can anyone suggest me some good GPU specs.

I am going to use GPU mainly for text related features.So, mostly I will run LSTM and RNN."
Poor performance for RBF network forecasting stock series data,2,7,False,False,False,learnmachinelearning,1513319170,True,"I'm using RBF network to predict stock series data, using (close price + open price + highest price + lowest price + trade amount) to predict next day's closing stock price.

During the training process, I do:

Give 100 iterations, in every iteration input 180 samples. Every time a single sample input to the network, use gradient descent to update the weight and the RBF center. In the output, use denormalization on the output of network(I do normalization before input the data), then print the result. I've found that the performance are worse.

For checking my network, I calculate mean square error in every iteration, and I found that MSE rise during the training. 
I've check the training algorithm, but can't find out the problem. 

When I input only one sample, train with 100 iterations, I can see the MSE oscillates and finally converged.I can get the right value when only one sample input to network. However, when I input the whole training sample dataset in 100 iterations, I can't get the right value in the output. 

Is there any mistake in my training process? Thanks for helping!"
Weekly Show-off!,3,8,False,False,False,learnmachinelearning,1513321519,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
Gaussian process regression: Kernel hyperparameters and model complexity,2,3,False,False,False,learnmachinelearning,1513322668,True,"I am currently designing a (non-stationary) kernel for Gaussian process regression that takes into account some expert knowledge. My particular kernel has many hyperparameters and linear combinations of sub-kernels, and so may be prone to overfitting during maximum likelihood optimisation. As a result, I would like to formulate the degree to which each hyperparameter contributes to model complexity -- i.e. the determinant of the covariance matrix -- with the end goal of factoring out one or two 'complexity' hyperparameters from the kernel. The resulting 'complexity-normalised' hyperparameters could be tuned straight after training, while the 'complexity' hyperparameters could be more carefully selected e.g., manually or by cross-validation, to avoid overfitting.

A simple example of this notion is the linear combination of two kernels: k3 = a*k1 + b*k2. Since the 'scale' of k3 determines the complexity of the model in this case, I could rewrite the kernel as k3 = c * (a'*k1 + b'*k2), where a'=a/c and b'=b/c. This way, c controls model complexity while a' and b' are more about configuration (assuming k1 and k2 both equally contribute to model complexity).

Now, I'm having some trouble figuring out exactly how a kernel's hyperparameters impact complexity -- at least relatively. For example, in an RBF kernel the complexity increases with 'output scale' and decreases with 'length scale'. This makes sense qualitatively: high 'output scale' means high function variance, and low 'length scale' means more squiggles. But how can I quantify their relative contribution to complexity?

My only guess is that the area of the kernel is relevant, in which case the complexity is square in the scale and linear in the length. This is based purely on the hunch that the area of the kernel is strongly related to the determinant of its computed covariance matrix. If anyone knows about this relationship, I would love to hear about it!
"
Do I have to manually reshape my X_train after using train_test_split from sklearn?,3,8,False,False,False,learnmachinelearning,1513328590,True,"If I don't reshape the value my linear regression breaks. I need to go from (97,) to (97,1) for my training data so my code doesn't break. I google searched this problem and most people just use .values.reshape() but is there a better way? Can I just get (97,1) straight from train_test_split? I'm looking at the docs right now and I don't see any example of this being possible. 

Lazy move on my part and a stupid question but I gotta ask."
How to train a stacked autoencoder,5,5,False,False,False,learnmachinelearning,1513343701,True,"I posed this question on stats stack exchange: https://stats.stackexchange.com/questions/318952/training-autoencoder-with-softmax-layer

I basically don't know how to train a trained encoding layer with a new softmax layer for classification purposes."
Sentiment analysis with machine learning,0,1,False,False,False,learnmachinelearning,1513344103,True,[removed]
Random search,1,3,False,False,False,learnmachinelearning,1513352716,True,I'm struggling to understand how to implement random search. [Wikipedia](https://en.wikipedia.org/wiki/Random_search) says that the algorithm starts from a point of the hyper-parameter space and then follows a descending path for N iterations or until it reaches a desired minimum value. From other sources ([this](https://machinelearningmastery.com/how-to-tune-algorithm-parameters-with-scikit-learn/) for instance) I understood that I should randomly sample N models from the hyper-parameter space. Which implementation is correct?
Support vector regression in python,9,10,False,False,False,learnmachinelearning,1513363394,True,"Looking for basic implementation/tutorial or anything of the sort of how SVR is used in python. I've looked at the documentation.

My problem in more detail: have a dataset (csv file) of hourly energy readings for 365 days. Trying to train it on 9 months of data( just the energy values in kW) and then test it on the remaining 3 months. "
Understanding and interpreting dataset characteristics and model predictions,0,2,False,False,False,learnmachinelearning,1513389890,True,"I'm looking for books and other resources for learning how to understand and discover the important characteristics of datasets and their effects on how you should interpret the results of different types of classifiers. 

Learning of Simpson's paradox makes me think that I am often misinterpreting or incorrectly analyzing the results of basic statistical tests. 

Similarly, I often feel that I incorrectly assess the prediction of a model because I am not considering important features of the dataset that was used in training. For instance, I am unsure how training a model on an imbalanced training set (e.g., 80% of samples are class A, 20% are class B) would affect the ""meaning"" of different predictions. "
"Weekly Status Check Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",3,6,False,False,False,learnmachinelearning,1513407911,True,"Let's have a  meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
Important Algorithms in Machine Learning,0,1,False,False,False,learnmachinelearning,1513420971,False, 
Yolo and yolo9000 class predictions [xpost r/MachineLearning],2,6,False,False,False,learnmachinelearning,1513424750,True,"I am trying to understand yolo (https://arxiv.org/abs/1506.02640) and have some confusion over the final class predictions. The original paper and presentation by the author (https://www.youtube.com/watch?v=NM6lrxy0bxs) says ""We only predict one set of class probabilities per grid cell, regardless of the number of boxes B."" However Andrew Ng's CNN course (https://www.coursera.org/learn/convolutional-neural-networks/lecture/fF3O0/yolo-algorithm) and Siraj Raval's video (https://www.youtube.com/watch?v=4eIBisqx9_g) say we predict a set of class probabilities for each bounding box. Has anyone come across this? Why the disparity? Which approach is actually used/which is better? "
A Quick Guide to Identify Twitterbots Using AI,0,1,False,False,False,learnmachinelearning,1513425634,False, 
A3C and A2C in Reinforcement Learning,0,4,False,False,False,learnmachinelearning,1513456713,True,"Is it correct that in A3C, you have several agents running in parallel, and at the end of an episode you average across the gradients returned by these agents, update your master agent, and then set each small agent to the same parameters of the master net? In A2C, is it just that we have a single agent? How do these two algorithms work?"
Steps in PCA,2,3,False,False,False,learnmachinelearning,1513458295,True,"I am struggling  with the 3rd and 4th step in PCA. I think I get it but can someone confirm this is correct:

  1. Standardize data matrix: Y=HX
  2. Calculate covariance matrix: S=(1/(n-1)) * Y^T Y
  3. Eigenvalue Decomposition: S = Z * Lambda * Z^(-1)
  4. Find PC Scores of original data: T=YZ

Where lambda is a diagonal matrix whose elements are the eigenvalues of S in decreasing order. And Z is a matrix whose columns are the eigenvectors of S."
What do you do with your trained ML model after you finish?,18,5,False,False,False,learnmachinelearning,1513464537,True,Do you then start writing a flask app to deploy it to the web? Write up a power point report with the results? Do you leave it as a Jupyter notebook for other data scientists to use?
Map of (un)supervised learning techniques,5,12,False,False,False,learnmachinelearning,1513472574,True,Is there a resource which shows all of the techniques available just as a visual guide for beginners. For me I would find that very useful
Andrew Ng Coursera or ISLR lecture course?,4,2,False,False,False,learnmachinelearning,1513473886,True,"Hey, Im currently deciding between these two courses as an introduction into ML. I've heard that the ISLR course + book are more mathematically rigorous than Andrew's coursera course. 

Is there a benefit to taking Andrew's course over ISLR?"
The Master Algorithm,2,27,False,False,False,learnmachinelearning,1513479355,True,"I really enjoyed reading Pedro Domingos' book, 'The Master Algorithm"" a while back. A link to [this project](https://alchemy.cs.washington.edu/) was at the end of the book. I've never heard anything about it in the wider ML community though. How is Pedro Domingos' work viewed?"
Python/Keras question,8,9,False,False,False,learnmachinelearning,1513484505,True,"When looking at examples in Keras i came across following code.

    inputs = keras.layers.Input(shape=(2,3,3))
    output = Flatten()(inputs)
    output = Dense(100, activation='relu')(output)
    
I am not sure about syntaxis. 
    output = Flatten()(inputs)

If the __init__ function of Flatten class were to return some other function then i would get it. But i looked at source code and __init__ does not return anything.

So how does this code work?

"
Machine Learning Cheatsheet,0,1,False,False,False,learnmachinelearning,1513516729,False, 
Python module from docker image to use with NLP project?,0,1,False,False,False,learnmachinelearning,1513519005,True,[deleted]
Python module from docker image to use with NLP project?,0,1,False,False,False,learnmachinelearning,1513519811,True,[deleted]
"ANN for non image, text, language data",0,8,False,False,False,learnmachinelearning,1513526471,True,"I'm trying to figure out which ANN to try in order to aid me in analyzing some non-image data.

I realize I will have to try a few approaches to see which performs the best.  

I guess my first question is would an ANN help?

My data is hierarchical in design and I currently use a Nested ANOVA for statistical analysis.

I have about a 100 sets of ""a"".
In each ""a"", I have 3 sets of ""r"".
In each ""r"", I have 5-7 sets of ""i"".
In each ""i"", I have 30-100 sets of ""m"".
In each ""m"", I have ""n"" measures.
Each of the ""n"" measures are different traits of a single object.
n is currently 3, but might increase to a dozen or so.

I use PCA to reduce the dimensionality of the n measures (PCA12, PCA23, PCA13, PCA123).  I also compute the correlation coefficients between n12, n23, and n13.  This expands my ""data"" from n=3 to n=10.

One idea I've had is to train a Sparse Autoencoder Network (using Unsupervised training with all my data) to expand the dimensionality of the 3 ""m"" measures into, say, 10 traits. I would use trial and error to find how many encoder nodes are most useful.

For each ""i"", I would then have 30-100 of these new traits.  I could build a histogram which essentially describes the ""i"" structure in terms of the relative abundance of these 10 traits.  So each ""i"" groups would have 10 measures instead of the 30 to 50 ""m"" measures.

This would allow me to directly compare the ""i"" groups even though they had different counts of ""m"" measures.

I could keep going up the tree like this until ultimately I would have a profile at each level of my data.

I don't think a convolution or deconvolution network is appropriate since there is no spatial relationship with the order of the sets in ""m"".

Anyone want to help point me in the right direction as to where to begin?  Or care to discuss this?
"
Which degree would help the most for AI research?,7,1,False,False,False,learnmachinelearning,1513541737,True,"I am trying to pick between these 3 very similar degrees: CS(engineering), CS+Statistics, CS+Math.

Course selections: https://cs.illinois.edu/academics/degree-program-options

I'm very lost. Any help would be greatly appreciated!"
What concepts have you had the most trouble with incorporating into your intuition ?,0,8,False,False,False,learnmachinelearning,1513547664,True, 
Why are sigmoid and tanh activation functions most commonly used in RNNs?,2,13,False,False,False,learnmachinelearning,1513557306,True,Wouldn't ReLU make it converge faster and prevent saturation?
"Help, Is this a valid thing to do with Latent Dirichlet allocation?",0,1,False,False,False,learnmachinelearning,1513560037,True,"So let's say I have two sets of documents: 
 
set_1 = [doc_1, doc_2,  doc_3, doc_4]  
set_2 = [doc_5, doc_6, doc_7, doc_8]

I apply LDA to figure out the themes(topics) in set_1

now can I use the model which was fit on set_1 and predict the themes(topics) of set_2? (the set_1 and set_2 could be totally different)

I ask this because from my understanding LDA allows me to capture the latent themes in a set of documents, and you can't use this to do some prediction on some other random corpus.(if you do something like this, it's like trying to fit the new documents into the latent structure of some other set of documents.)

Note: I'm not talking about document clustering/ classification: sure if document classification was the goal maybe you could do something like 
1. first, do an LDA, figure out the topics of the documents.
2. use some clustering algorithm to cluster similar topics
3. predict on new documents."
Speech Recognition with CTCs,1,1,False,False,False,learnmachinelearning,1513574344,True,"My understanding of CTCs in speech recognition are that they are trained to recognise phonemes, upon which it infers the words based on a learned probability distribution. However, this would then not work for ""nonsensical"" words.

Would it be possible to create an extra ""character"" to denote the end of each word, such that it then pieces the phonemes into a word regardless of whether it actually is a word or not?

"
What technique for supervised learning to get subjective output,8,2,False,False,False,learnmachinelearning,1513576902,True,"I'm interested in getting into machine learning, however after some research I'm not sure of the best place to start. I understand the concept of neural nets (have nodes, weighting them etc.) but i am unsure of which method or if tutorial exists for a similar project.

I'm planing on doing something similar to making music (probably not the easiest I know). Some thing along the lines of taking videos of lighting and making the visuals from the sound. I know I'll probably have supervised learning with a recurrent neural network possibly using tensorflow? (just because I know python). But that's kind of my extent of knowledge of machine learning, not to sure of the next step or if my first is even right

TLDR Where to start with making the visuals from an associated sound "
"Policy Gradient method starting with policy learned from a baseline, stupid idea?",2,3,False,False,False,learnmachinelearning,1513585073,True,"We are developing an agent for a game using reinforcement learning. However, it takes quite some time until the agent first (randomly) discovers a good solution. On the other hand, we have a strong baseline policy based on a behavioural tree. 

The idea would be that, we first learn the policy in a supervised fashion from the baseline and then start the policy gradient or actor-critic algorithm using the learned policy. 

I am not sure if this obvious idea is also a good idea. E.g. we might start in a local minima and never escape it. Has somebody done this before, is there literature? "
Overfeat and yolo [xpost r/MachineLearning],0,1,False,False,False,learnmachinelearning,1513592806,True,"Here is my current understanding. Overfeat is sliding window classification+localization implemented convolutionally. Yolo (object detection) divides image into say 19x19 grid and predicts (class, bounding box) for all anchor boxes per grid cell.

If stride of overfeat = length of sliding window (so that sliding windows don't overlap), and in Yolo number of anchor boxes=1, can we say Overfeat and Yolo are similar thing here?
"
How to balance training data within classes. Satellite imagery pixel classification using sklearn random forest.,5,15,False,False,False,learnmachinelearning,1513598156,True,"I'm using python sklearn Random Forest Classifier to classify pixels in very high resolution satellite imagery and I think that I am having some data balancing issues.
It is a binary classification problem, with the 2 classes essentially being 'above ground vegetation' (let's call this trees) and 'not above ground vegetation' (let's call this land).
The training data is created by digitizing polygon's on the imagery using GIS software.
The features are created using derivatives of the imagery bands and the elevation model such as band ratios and the min/max/mean for 3 and 5 pixel windows. I'm currently using 35 features.

The first balancing issue is that it is a lot easier to digitise land then it is trees, so the technician may digitise 50,000 tree pixels, but 1.5 million land pixels.
I attempt to solve this by 'under-sampling' the land training data by only using a random 50,000 pixels.
A second solution I have tried is by creating multiple 'not above ground vegetation' classes (bare earth, grass, somewhere between bare soil and grass, water, buildings etc.) and then undersampling if required. I'm not sure if having more
classes helps the final binary classification, or only complicates it. This is also a lot more work when creating the training data.

The problem is that there is not a clear definition between the extra classes so it is hard to digitize. It is also time consuming and I don't know how many different classes would be required.


The other balancing problem is for the data in the land class. If, for example, 70% of the pixels in the 'not above ground vegetation' class are bare earth, 20% are water and only 10% are the hard to digitize grassy patches between trees,
is there a way to balance this? Do I even need to balance this when using random forests?

I think sklearn variance scaling may help here? For example I guess most water pixels and their 35 features will have a low variance, so some can be culled. Same with the bare earth pixels.

I'm sure you can tell I'm new to this, so even just suggestions of terms that I can google will be greatly appreciated.

Thanks"
"As a freshman, how do I maximally increase my chances of landing a data-science/ML internship?",4,10,False,False,False,learnmachinelearning,1513621349,True,"
Context about me:

 I've done Andrew Ng's ML course (now I'm currently doing the Deep Learning specialization), and I've got several projects up on github, some of which I've made web apps out of. Recently I've been adopting more of a bottom-up approach to learning algorithms, where I code up an algorithm from scratch, experiment with different parameters, then apply it to a real-world dataset. 

As for internships, I did apply to a few companies, but haven't heard back...
Admittedly I haven't been super aggressive in applying for internships but most data science postings I've looked at require you to be pursuing a PhD/Masters, and I've got a long while to go before that. 

It's not always easy striking a balance between coursework and projects, but I love what I'm doing. It's a lot of fun when a custom kmeans algorithm you coded up from scratch accurately clusters an unlabelled collection of trump vs hillary tweets.

 But, in terms of internship prospects, seeing as I'm not a Master's/ PhD (yet), I'm beginning to think if I'd be better off delving more into software engineering projects. I mean, ML is fun, but I really *do* want work experience. 

"
Poor Accuracy in Time Series Classification using LSTM network in TFLearn,10,9,False,False,False,learnmachinelearning,1513624189,True,"Hello,

I am trying to build a network which will take a financial time series and classify the last timestep into one of two classes. My data is structured so that each input consists of N timesteps which each have 66 features. The first input consists of timesteps 0 to N-1, the second has timesteps 1 to N, etc. I have about 15,000 samples.

Below is the network I have built in TFLearn.

    net = tf.input_data(shape=[None, 12, 66])
    net = tf.batch_normalization(net)
    net = tf.lstm(net, 64, dropout=[.9,.9], return_seq=True)
    net = tf.lstm(net, 64, dropout=[.9,.9], return_seq=False)
    net = tf.fully_connected(net, 2, activation='softmax')
    net = tf.regression(net, optimizer='adam', learning_rate=0.001, loss='categorical_crossentropy')

    model = tf.DNN(net, tensorboard_verbose=0, best_checkpoint_path= 'models/')
    model.fit(trainX, trainY, validation_set=.1, n_epoch=100, show_metric=True, batch_size=32)  

It all works and trains, but the accuracy never gets above 54%.

 I believe I must be missing an important layer or perhaps I need to use a different optimizer. However, my knowledge of neural network theory is quite weak.

 I have played around with number of layers, lstm size, batch size, dropout, the number of timesteps I include in each input, but nothing has helped. Can anyone offer a suggestion as to how to improve my accuracy?

*EDIT*

My data set consists of 15 minute candlestick data for three cryptocurrency trading pairs from Poloniex.com: BTC_ETH, BTC_USDT, ETH_USDT.

In particular I use [weighed average, open, close, high, low, native volume, quote volume]. In addition, I have taken the weighted average, high, and low values and calculated a 50 period simple moving average, and four exponential moving averages of widths 3, 6, 12, and 28."
"Brand new, how feasible is it to make an AI that can detect angles?",4,1,False,False,False,learnmachinelearning,1513626550,True,"Hey, basically I was thinking about trying to study machine learning on my own time because it's incredibly interesting. I have an idea of a program where a user draws a single angle, and machine learning would detect if the angle is either ""round"" or ""sharp"" (just one of those two, not how sharp it is or anything). So basically the user would end up drawing a ""spike"" or a ""hill"" which are the most extreme cases of the angle being sharp or round.


Is machine learning using drawings/images an unrealistic goal for a beginner? I wouldn't make it for the end goal, just for the learning I do while making it. I want to break into this and start being able to research and study on my own, is this a decent beginner goal?


Be harsh, I want to learn. I'm a first year cs student, I took a course which included a basic overview of AI/machine learning and it's incredibly interesting. So I mostly learned what it is, why it's used, and concepts around how it is used (first year course though, so we didn't specifically learn how to create anything on our own because of the skill required). "
Adversarial examples - regularization method.,1,7,False,False,False,learnmachinelearning,1513629790,True,"In Intriguing properties of neural networks (https://arxiv.org/pdf/1312.6199.pdf) they show (4.3), that the existance of adversarial examples is closely connected to the upper Lipschitz constant, namely that if the constant is small enough then it's not possible to find adversarial examples. As it turns out these Lipschitz constants are bounded by respective norms of weight matrices (in case of fully connected network). Has anyone tried to regularize network with respect to these Lipschitz constants or matrix norms, so that the network is fully resistant to adversarial examples? If not, then why? Is it too complex when it comes to computations, not very efficient, or something else?"
Increasing epochs vs increasing learning rate?,4,1,False,False,False,learnmachinelearning,1513631888,True,What's the motivation for using n epochs and 1 learning rate instead of 1 epoch and n learning rate? Is the latter more susceptible to overfitting?
Setting loss to zero as a hack to train one output,0,1,False,False,False,learnmachinelearning,1513632012,True,"I have a Keras model with two outputs, but would like to train them separately. Can I just set the loss weight of one of them to zero?"
Implemented with code: Mixture of gaussians model for image pixel classification,0,1,False,False,False,learnmachinelearning,1513632804,True,"https://github.com/KeirSimmons/computer_vision/tree/master/gaussians

Not state-of-the-art obviously, but I've been taking a class on classical computer vision and implemented a mixture of gaussians model for pixel-by-pixel classification. I've included a write up with an example implementation so it runs out of the box. It basically allows you to classify each pixel as 'class' or 'not class', with the given implementation training on 'apple' and 'not apple'. 

I'm new to world of vision, but this stuff is awesome, hence why I wanted to implement it. Feel free to take a look and play around with it, I'd love to see what results you get :) . "
Is it possible to limit GPU/CPU usage during training?,2,6,False,False,False,learnmachinelearning,1513641102,True,[deleted]
Help understand these Keras gradient Tensorboard histograms,0,2,False,False,False,learnmachinelearning,1513642204,True,"I'm using Keras and I think I'm having my gradients explode. Therefore I would like to sanity check them.

I am using Keras's Tensorboard callback passing `histogram_freq=1` and `write_grads=True`.

When I check these grad histograms, I get something like this:

https://i.imgur.com/7c3nXl6.png

Each one of the 10 ""levels"" is related to one epoch, I know that much.

What I don't understand is what does the Y axis represent? 

That can't be the gradients, since I also trained the Keras example mnist_cnn, it converged well and had these grad histograms also quite high.

What does the X axis represent?
"
Writing Stories with AI,6,7,False,False,False,learnmachinelearning,1513647614,True,"I've seen a few examples of where people use AI to write chapters/scenes to existing works (like this one that's a scrub monologue: https://www.instagram.com/p/Bc2Xys1gzqq/ or this harry potter chapter:http://www.iflscience.com/technology/ai-attempts-to-write-harry-potter-and-it-goes-hilariously-wrong/ ). 

How exactly is this done? Obviously, you train against a bunch of writings by the author but what algorithms would be best? A neural network maybe? Any explanation would be appreciated or even just something to use as a jumping off point like what to google. Thank!    "
Can someone explain how backpropagation works for the hidden layer?,2,6,False,False,False,learnmachinelearning,1513665995,True,I'm trying to create a backpropagation program for a multi layer neural network. Thanks in advance
CountVectorizer reading t-shirt as shirt.,5,5,False,False,False,learnmachinelearning,1513678415,True,"Any quick fix for this?

Example:

from sklearn.feature_extraction.text import CountVectorizer

CountVectorizer().build_analyzer()(u't-shirt')

['shirt']"
Tensorflow: Concatenate two subgraphs in a big graph and finetune it,1,4,False,False,False,learnmachinelearning,1513685224,True,"I want to implement [this paper](https://arxiv.org/abs/1708.03474) in tensorflow. It's approach is to create two separate CNNs at first, and then concatenate them for finetuning (as you can see in figure 1a)). 

My current situation is: I have two pre-trained and saved models, each of them fed with a data queue input (so, no feed_dict and no Dataset API), and now i am off for finetuning. I want to restore them from disk and somehow concatenate them, so that i can define an optimizer which optimizes both networks. 

This is my current approach:


    # Build data input
        aug_img, is_img, it_img = finetuning_read_training_images(trainset_size=num_steps,
                                                                  batch_size=batch_size,
                                                                  cropped=cropped,
                                                                  base_folder=base_folder)
    
        # Load the graphs
        tf.reset_default_graph()
        print(""Loading ECNN graph..."")
        ecnn_graph = tf.train.import_meta_graph(os.path.join(ecnn_path, ""ecnn.meta""), clear_devices=True)
        trained_target = tf.get_default_graph().get_tensor_by_name(""E-CNN/ecnn_output/ecnn_output_convolution/BiasAdd:0"")
        augmented_icnn_input = tf.concat([is_img, trained_target], axis=2)
        icnn_graph = tf.train.import_meta_graph(os.path.join(icnn_path, ""icnn.meta""), clear_devices=True, input_map={""aug_img"": augmented_icnn_input, ""it_img"": it_img, ""is_img"": is_img})

The data input function reads 3 batches. `aug_img` is the source image, which has reflections, e.g. when photographed through a glass panel, augmented with its edge map as a 4th color channel. The ECNN graph should predict the reflection-free edge map. Tensorflow should augment the plain source image, which is stored in the `is_img` variable with the predicted reflection-free edge map, which should happen in the lines beginning with `trained_target` and `augmented_icnn_input`. The augmented image is then fed to the ICNN graph which should create a reflection-free image then, so it is given the `it_img` which is the target image. It is fed the not-augmented source image again, only for tensorboard visualization. 

But now i am unable to further proceed. I cannot concat the both tensors for creating the `augmented_icnn_input` because i get a `ValueError: Tensor(""E-CNN/ecnn_output/ecnn_output_convolution/BiasAdd:0"", shape=(?, 224, 224, 1), dtype=float32) must be from the same graph as Tensor(""batch:1"", shape=(?, 224, 224, 3), dtype=float32).`

Also i seem not to understand the input_map in combination with the data input queue correctly, since although i have had definied the  `aug_img`and other variables in the ICNN, and see them in tensorboard, i do not see them in the `variables` collection and therefore cannot map them. 

So i would like to know: Is this the correct approach to combine two subgraphs in a bigger graph? How can i solve the problem that i am unable to concat the two tensors in `augmented_icnn_input`? And why is my `input_map` not working?"
Improving Keras accuracy,2,3,False,False,False,learnmachinelearning,1513692087,True,"I am predicting an integer value (bike availability in a public station), during the data pre processing step I transform every value to float and normalize it.

In the process of training the NN Keras outputs the [results](https://imgur.com/GqBZN51) for every epoch and it says that the accuracy is 33%. When I plot the data overplayed with the predicted data I get an accurate [prediction](https://imgur.com/a/D413W).

How important is the accuracy value that I get from Keras? As I see in the prediction is not important because the predictions are great. The problem is that if the real value is 9 bikes and it predicts 9.3 bikes it's considered as an error. If a human saw this value it won't be considered as an error.

How should I approach this?"
Face Detection,6,4,False,False,False,learnmachinelearning,1513694299,True,"Hey, I've been building a simple face detection application using dlib on videos. I would like to know how to differentiate between a photo and live image of the same person"
Useful techniques for analysing genomic data (where p &gt; n)?,2,5,False,False,False,learnmachinelearning,1513704489,True,"I have a data set of mutation information for ~900 genes across ~600 people with a given disease, where for each mutation there are a number of properties available (such as role of the mutation).

I'm trying to a) see if there are implicit sub-groups of this disease, and b) see if a patient's outcome (survival, treatment type etc...) can be predicted solely from their mutation profile.

For a) I've used HDBSCAN and Bayesian Networks for b), since they form nice causal diagrams rather than just a black box. However, it's challenging that even when looking at a dichotomous mutation occurred/not, p &gt; n, yet alone when wanting to investigate the different types of mutations (which would lead to at least p = 4n). 

Would deep learning offer any advantages here, owing to the way it performs inherent dimensionality reduction? If so, would a standard MLP be useful, or would a more complex structure be more appropriate? I've seen that auto-encoders and RBMs are suitable for dimensionality reduction."
Reading List for Tensor Decomposition/Spectral Learning,4,4,False,False,False,learnmachinelearning,1513709614,True,"Hi everyone! I'm participating in a research project next semester involving tensor decomposition. I was hoping I could get a reading list for topics that might be helpful to understand before going into the project, rather than just take a grab-bag approach and learn as I go. For reference, I've taken the typical undergraduate cs courses (algorithms, data structures), and some relevant math courses (linear algebra, multivariable calculus, basic stats and probability), and have a cursory understanding of basic ML concepts. Things that build from that background would be great. Thanks so much."
Which Tensorflow batch normalization implementation to use?,1,5,False,False,False,learnmachinelearning,1513709698,False, 
Is a validation dataset needed when training neural networks?,9,2,False,False,False,learnmachinelearning,1513713562,True,"I have a neural network that I have developed which classifies emails into either spam or ham emails, and at the moment I have two datasets. These two datasets are used for training the neural network and testing the neural network's accuracy. 

I've just been reading up on validation sets, but I'm wondering if this is even needed since my neural network seems to be able to be trained simply using the testing set.

At the moment my neural network has around 80% accuracy and is adjusted through the use of back propagating an error and adjusting the weights of the inputs based on the error. Do I need to provide a validation set for my network? If I do, how do I even provide validation? I don't get the concept of a validation set at all."
Input processing in Python,2,3,False,False,False,learnmachinelearning,1513723027,True,"I'm trying to process large datasets and I'm finding that Python uses too much memory with its float64 (which is a waste since Keras uses float32). Would it be a good idea to rewrite all of my list processing to use numpy with dtype=float32 instead, or would it be very easy to end up copying tons of arrays if I'm not careful?"
A couple questions on RNNs,1,0,False,False,False,learnmachinelearning,1513728932,True,"Hello, I recently read Andrej Karpathy's post about RNNs on his blog (http://karpathy.github.io/2015/05/21/rnn-effectiveness/), and it left me with a couple questions:
What would the affect be of sharing parameters between the hidden layers that simply 'feed-forward' (the W_hy's/W_hx's) and those that send/receive information from the previous timestep (the W_hh's) ?
Could you step in to the training by directly training the RNN's W_hh weights by specifying what the 'correct' value of the hidden state should be? I've been starting to read a little about reinforcement learning (your post on the subject made me interested!). What if a recurrent network represented the agent, and we trained it so that the information it passes on to the next timestep represented the Value function?
Thanks for any input!"
How to test performance of a fitted probability distribution?,0,1,False,False,False,learnmachinelearning,1513740709,True,"I am using R to fit a poisson distribution (distfitplus package) to count data. After funning the ""fit"" , I have the model parameter, the estimated lambda, but how can I go about testing its performance?

I have test data, i.e. observations that were not used in the fitting but I am unsure how to test a probability distribution with the new data."
"When designing events for a ML data pipeline, would you opt for lots of specific events or a few more general ones?",6,7,False,False,False,learnmachinelearning,1513741188,True,"As the title says.

I'm not entirely sure which route to go down, what are peoples opinions and why? Which was more convenient down the line? Is creating lots of specific events unneeded work and complexity?

For example - item updated vs. item price changed, item paid for, etc...

Please and thank you!"
Would machine learning be suitable to analyze this dissertation data set regarding adversity and recovery?,3,2,False,False,False,learnmachinelearning,1513743143,True,"I'm a PhD candidate in psychology and have completed most of my dissertation research that regards approximately 22 variables comprising a theoretical model proposed to describe the experience of adversity, variables involved in the resiliency/recovery process, and a few outcomes.  The sample size is about 2000 participants (all measures) assessed at baseline (either during or shortly after experiencing an adverse experience) and again a few months after experiencing the adverse event. 

I'm considering a machine learning approach as I'm genuinely interested in learning this skill and prior attempts at theoretically grounded structural equation modeling have not really been incredibly productive.  It would be good to be able to know who will likely have good short-term and long-term outcomes after experiencing trauma for a number of reasons.  

My question is - is there a way that machine learning could assist in providing a reliable and valid means of evaluating an individual's resiliency given traumatic exposure? I.e. We feed it all the data that I have and try to produce an algorithm that essentially predicts the level of depression symptoms (for example) that an individual is likely to have if given specific test scores?

I have no experience with machine learning, very limited coding and technology development experience, but my statistical math is fairly strong and I'm not afraid of getting my hands dirty.  I didn't want to waste my time doing a bunch of research if none of this was possible so I thought I'd ask.  Any help and advice would be greatly appreciated."
How could I preprocess an dataset with corrupt values?,2,4,False,False,False,learnmachinelearning,1513750315,True,"I'm using python to preprocess a dataset which is a measurement of environment pollutants. Due to the real world sensor problem, not all the values detected are valid. Error values distribute in the dataset and showed as string like: '17x', which should be a number for normal expression.

I use read_csv to read the file, and found that all values in the dataframe are viewed as string. I've looked for methods of data processing, but only found how to fill missing values.

My dataset is veiwed as string now, so I think I need to convert it to number and then fill the error value just like missing values.

How could I do with this kind of dataset?

Thanks for helping!
"
TWIL (This Week I Learned) - Share something new that you have learned this week!,13,10,False,False,False,learnmachinelearning,1513753515,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
Question answer system question,0,1,False,False,False,learnmachinelearning,1513791920,True,[deleted]
Inputing Time Series data for Convolutional vs LSTM layers,4,5,False,False,False,learnmachinelearning,1513806090,True,"So I have been reading [this](https://arxiv.org/pdf/1709.05206.pdf) paper and I don't understand the following passage about shaping input data.

&gt;The fully convolutional block and LSTM block perceive
the same time series input in two different views. The fully
convolutional block views the time series as a univariate time
series with multiple time steps. ***If there is a time series of
length N, the fully convolutional block will receive the data
in N time steps.***

&gt;Contrarily, the LSTM block in the proposed architecture
receives the input time series as a multivariate time series with
a single time step. This is accomplished by the dimension
shuffle layer, which transposes the temporal dimension of
the time series. ***A univariate time series of length N, after
transformation, will be viewed as a multivariate time series
(having N variables) with a single time step.***

Can anyone elucidate this?"
Anyone have advice on comparing image segmentation methods in R / caret?,9,3,False,False,False,learnmachinelearning,1513808956,True,"Disclaimer: I am fairly new to machine learning, in that I have successfully stumbled through using a random forest classifier to accurately segment medical images...

I have gray scale images that I am attempting to segment using caret. They are 3D medical images showing lesions that appear slightly darker in brain tissue. The images (volumes) are pretty large, so I am manually segmenting smaller portions (about 500 - 1000 voxels) of the image, and using that as training/testing data. Then using a random forest classifier to predict the rest of the image based on the value of the voxel (3d pixel), and the value of its neighbors.

The random forest classifier works fairly well in most cases, but I would like to compare it to some other models. Which other models should I try? What are the performance metrics I should be looking at, and which R functions provide the ability to compare different classifiers? I would also like to try a ""baseline"" model, one you might try naively, so I can get an idea of how much better any of these other models is. Would that be a simple linear model?"
General guidelines for regularization loss,3,3,False,False,False,learnmachinelearning,1513815877,True,"Let's say you have two loss terms, 1.0 MSE + 1e-4 L2. In general, the longer you train the lower MSE is, but I *think* L2 tends to stay the same or increase. The final ratio L2/MSE is a function of the input distribution and the weight priors (Gaussian with variance 1e-4 in this case), which is probably a good estimate of the degree of overfitting (lower = underfit, higher = overfit)

What's a ""usually good"" value for this ratio to be? Is it 0.1-1, 1-10, etc or completely application specific? "
Similar model like VGG/ResNet/... but for 1-dimensional time series classification,1,5,False,False,False,learnmachinelearning,1513835477,True,There is extensive literatures on time series classification but I am wondering is there a state of the art model that people always refer to for time series classification like visual recognition problem in ImageNet.
[video] One does not simply put Machine Learning into Production with Henrik Brink,0,1,False,False,False,learnmachinelearning,1513861219,False, 
Motivating sigmoid output units in neural networks starting with unnormalized log probabilities linear in z=wTh+bz=wTh+b and ϕ(z),0,3,False,False,False,learnmachinelearning,1513864043,True,"I reuse the title from [this](https://stats.stackexchange.com/questions/269575/motivating-sigmoid-output-units-in-neural-networks-starting-with-unnormalized-lo/269640?newreg=2d387c171c9148c8b820aeb9cc5859a8) question on stackexchange because it's very clear. I have the same question. When I read the answer it confused me more, specially the first part of the answer: 

&gt; There are two possible outcomes for y∈{0,1}y∈{0,1}. It's very important, because this property changes meaning of the multiplication. There are two possible cases:

&gt;     logP~(y=1)=z
&gt;     logP~(y=0)=0

could someone enlighten me or have a ELI5 version for this question? 
 
"
Prerequisites to scikit- learn,2,3,False,False,False,learnmachinelearning,1513865559,True,"Im just wondering, aside from being familiar with python, are there any other packages/libraries etc such as NumPy that i should be familiar with to get a good grasp on scikit- learn?"
A friendly introduction to Recurrent Neural Networks - simple and intuitive,3,14,False,False,False,learnmachinelearning,1513868178,False, 
Great Deep Learning Achievements Over the Past Year,0,30,False,False,False,learnmachinelearning,1513869035,False, 
How to print out validation accuracy in addition to training accuracy after every batch/epoch in keras?,6,1,False,False,False,learnmachinelearning,1513880932,True,"I'm using model.fit_generator and there doesn't seem to be an option to print validation accuracies as well. I posted this question on stackoverflow with the code snippet. 

I wrote out the question here:
https://stackoverflow.com/questions/47930176/printing-out-the-validation-accuracy-to-the-console-for-every-batch-or-epoch-ke"
keras doubt in yolo implementation,2,1,False,False,False,learnmachinelearning,1513885612,True,"code in question: https://github.com/experiencor/basic-yolo-keras/blob/master/frontend.py#L295

    netout[..., 4] = self.sigmoid(netout[..., 4])

in this line, ... signifies what? I am not able to find anything on google, so I thought to ask here."
"Help with Keras, python 3 Convolution network visualization. Result different from expected. Current code in comment.",5,7,False,False,False,learnmachinelearning,1513893866,False, 
Question about spatial awareness in Convolutional Neural Networks,11,4,False,False,False,learnmachinelearning,1513895495,True,"I was reading an article while learning a bit more about machine learning, CNNs in particular and it mentioned that they still don't have spatial awareness. 

Eg. A picture may contain a nose in the top right corner, two eyes in the bottom middle and a mouth in the top left and the network would still classify it as a face

I was thinking about this and from my understanding the convolutional kernels create feature maps that basically find certain features in the original picture (Speaking only about the first convolutions, I know they get more abstract the more convolutions). Well I thought why can't the feature maps be used to deduce the spatial features as well ie. A feature map detects what it might recognise to be eyes, another feature map detects what it recognises to be a mouth and another detects what it recognises as a nose and the network uses the geometry to deduce if the mouth and nose are in the correct place based on the eyes and vice versa. 

Is this a possiblity? Is it already being taken into account? Do I even understand conv nets?

I hope the answer to all 3 is not a resounding ""No""."
"Using sklearn, giving same data to both fit() and score() and getting poor accuracy (around .55). Is this normal or am I doing something wrong?",4,8,False,False,False,learnmachinelearning,1513897776,True,"Here's the code: 
  
    clf = LogisticRegression()
    
    clf.fit(x_train, y_train)
    
    accuracy = clf.score(x_train, y_train)
    
    print(accuracy)

I expected accuracy to be pretty close to 1, since I'm feeding it the exact data it's been trained on, but instead accuracy is closer to .55. 

Is this normal or did I something wrong here?"
Need help with a clarification on this sentence from the main batch normalization paper.,2,3,False,False,False,learnmachinelearning,1513909389,True,"https://www.arxiv-vanity.com/papers/1502.03167/

This passage:

&gt;Fixed distribution of inputs to a sub-network would have positive consequences for the layers outside the sub-network, as well. Consider a layer with a sigmoid activation function and the parameters of all the layers below, changes to those parameters during training will likely move many dimensions of 
 into the saturated regime of the nonlinearity and slow down the convergence. This effect is amplified as the network depth increases. In practice, the saturation problem and the resulting vanishing gradients are usually addressed by using Rectified Linear Units (Nair &amp; Hinton, 2010)  careful initialization (Bengio &amp; Glorot, 2010; Saxe et al., 2013), and small learning rates. **If, however, we could ensure that the distribution of nonlinearity inputs remains more stable as the network trains, then the optimizer would be less likely to get stuck in the saturated regime, and the training would accelerate**.

Specifically the bolded part

As far as I know, ReLu doesn't have a saturated regime. Perhaps what they mean was when x&lt;0 ?"
Weekly Show-off!,3,6,False,False,False,learnmachinelearning,1513926318,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
15 Machine Learning Online Courses and Tutorials,0,31,False,False,False,learnmachinelearning,1513936666,False, 
Recommended itinerary builder; both sequence AND fill-in-the-blank,0,1,False,False,False,learnmachinelearning,1513950159,True,"I am trying to devise a recommender system that takes into account user schedules.  This presents itself sometimes as a sequence-to-sequence problem, but also sometimes like a fill-in-the-blank problem.  

That is, if a user has a roughly continuous set of observed actions and no plans in the future, I will be making recommendations that continue the sequence at and beyond recommendation time.  
e.g., at time=t3, Observed action A at t0 then B at t1 then C at t2; recommend actions D at t3, then E at t4, then F at t5.
I can build this using a RNN (or a MDP or probably something else), and get decent results.

However, if the user has future plans beyond the recommendation time, I may need to ""fill in"" the itinerary.
e.g., at time=t3, Observed action A at t0 then B at t1 then C at t2 and action D *planned at t4*; recommend action E at t3, nothing at t4 (it's already planned), then F at t5.
I'm not sure how to build this, although I think an RNN *could* be used; maybe a skip-gram?

I'd like a *single* model that recognizes sequences vs blanks and completes the problem accordingly.  I can't seem to find any literature that fits the problem, as I'm mentally devising it.

To make matters more complex, these actions- both observed and recommended- have a wide range of durations, so the time isn't actually discrete.  I may be able to coerce it into discrete, so I'll tackle that version first before introducing continuity.  

Any pointers or experience with this type of problem would be greatly appreciated!"
Question on backpropagation algorithm,9,1,False,False,False,learnmachinelearning,1513961490,False, 
PyData - YouTube,1,1,False,False,False,learnmachinelearning,1513964204,False, 
Gabby Shklovsky - Random Forests Best Practices for the Business World,0,11,False,False,False,learnmachinelearning,1513964685,False, 
What are the advantages of 5x5 over two 3x3 convolutions?,0,2,False,False,False,learnmachinelearning,1513972275,True,"For a concrete example, to represent a knight's move in chess using two 3x3 layers, you would need 4 filters in the first layer and one in the second layer. However it would only require one layer of one filter using 5x5s. If you compare the number of weights that's 72 for conv3 vs 25 for conv5.

In general, does this kind of ""intuition"" have good predictive power, or is the black box ""test and see"" the best way forward?"
Keith Myers-Crum - sklearn Compatible Model Stacking,0,1,False,False,False,learnmachinelearning,1513977107,False, 
A Zero-Math Introduction to Markov Chain Monte Carlo Methods,5,43,False,False,False,learnmachinelearning,1513977375,False, 
Problems with installing Theano,1,1,False,False,False,learnmachinelearning,1513986634,True,"A few weeks back I came across the fast.ai course, for which I'm trying to install Keras, for which I need Theano (or tensorflow, but that does not seem to work with my current version of cuda). When I try to import Theano I get an error message. 


Some information about how I installed it:

- I've installed Theano with pip 

- I'm using python 3.6 and have NumPy and SciPy

- I've installed libgpuarray with CMake

- I've installed MKL

- I've installed the MinGW GNU C++ and C compiler

- I have CUDA 9.1


Here is the error:

  File ""C:\Program Files\Python36\lib\site-packages\theano\gof\lazylinker_c.py"", line 92, in &lt;module&gt;
    raise ImportError()
ImportError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
  File ""C:\Program Files\Python36\lib\site-packages\theano\__init__.py"", line 110, in &lt;module&gt;
    from theano.compile import (
  File ""C:\Program Files\Python36\lib\site-packages\theano\compile\__init__.py"", line 12, in &lt;module&gt;
    from theano.compile.mode import *
  File ""C:\Program Files\Python36\lib\site-packages\theano\compile\mode.py"", line 11, in &lt;module&gt;
    import theano.gof.vm
  File ""C:\Program Files\Python36\lib\site-packages\theano\gof\vm.py"", line 673, in &lt;module&gt;
    from . import lazylinker_c
  File ""C:\Program Files\Python36\lib\site-packages\theano\gof\lazylinker_c.py"", line 127, in &lt;module&gt;
    preargs=args)
  File ""C:\Program Files\Python36\lib\site-packages\theano\gof\cmodule.py"", line 2359, in compile_str
    (status, compile_stderr.replace('\n', '. ')))
Exception: Compilation failed (return status=1): C:\Users\Fabian\AppData\Local\Theano\compiledir_Windows-10-10.0.16299-SP0-Intel64_Family_6_Model_158_Stepping_9_GenuineIntel-3.6.2-64\lazylinker_ext\mod.cpp:1:0: sorry, unimplemented: 64-bit .  #include &lt;Python.h&gt;
"
Is it reasonable for this SVM to take 53 seconds on prediction phase?,0,0,False,False,False,learnmachinelearning,1513989631,True,[deleted]
How to calculate the derivative of the loss function for logistic regression?,0,1,True,False,False,learnmachinelearning,1513994941,True,[deleted]
Creating a machine-learning python bot for a flash game.,2,1,False,False,False,learnmachinelearning,1513999320,True,"I want to develop a deep-learning, Python-programmed bot that could capture the screen, identify it as a source of input, and learn from its mistakes and environment, specifically for a web-browser game that isn't part of the 'OpenUniverse/Gym'. 

But attempting to understand Sentdex's Gta5 driving algorithm - which I thought was a similar project to the one I wish to begin - to no avail made me realize that I was missing a whole lot of concepts, so much that I don't even know where to start.

What lectures would you recommend me? - someone who knows only the basics of Python, but want to apply machine learning to a particular 'Kongregate' game.

Thank you in advance. ;)
"
Good tips and tricks for Jupyter Notebooks,0,48,False,False,False,learnmachinelearning,1514000012,False, 
How exactly does Policy Gradient use rewards to determine the gradient?,6,12,False,False,False,learnmachinelearning,1514006343,True,"I am currently trying to build an AI, using Neural Networks in TensorFlow, to play a game named ""Brawlhalla"". I started looking into reinforcement learning and I landed on Policy Gradient. I want to use Policy Gradient to teach the AI how to play the game, but I am confused about what to do with the rewards that I am receiving: How exactly do I use them to train the network?

&amp;nbsp;

I am working with a discrete action space that has 512 different actions, and I am receiving rewards that are very sparse and can be any of the values +10, +1, 0, -1, -10. Now my question is, how exactly do I turn these values into ""fake labels"" such that they encourage and discourage appropriate actions?"
Is there a proof that a sufficiently small learning rate in gradient descent will always lead to a decrease in cost function in every iteration?,5,11,False,False,False,learnmachinelearning,1514008025,True,"On his Coursera MOOC, Andrew Ng says that mathematicians have proved this. Could someone please point me in the direction of papers/proofs that discuss this?"
"Weekly Status Check Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",1,1,False,False,False,learnmachinelearning,1514012710,True,"Let's have a  meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
Machine learning concepts explained for non-techies,1,28,False,False,False,learnmachinelearning,1514048340,False, 
tensorflow: trouble capturing output from tf.logging.info in terminal output,2,2,False,False,False,learnmachinelearning,1514055026,True,"i ve been building a python command line app to explore google's tensorflow image classification -- make it easy to download loads of images, auto-sort them, use them to retrain a classifier, which in turn makes for better sorting, retraining, etc.
one huge issue, for which i have an ugly workaround, is trouble capturing, specifically, the final test accuracy. (see https://github.com/tensorflow/tensorflow/issues/3047)
i wrote up a long version of my workaround at https://github.com/mariochampion/roboflow/issues/3 and would love any suggestions or pointers for the better way of not tweaking someone else's file, but capturing its output properly.
thanks!"
"Interesting mathematics challenge from a recent calc course - can machine learning scope out ""exquisite"" solutions?",2,4,False,False,False,learnmachinelearning,1514058082,True,"About a year ago, I took a calc course from a now-retired professor. A recurring extra credit assignment was to find solutions to problems on his website [here](http://www.milefoot.com/math/integermania/). I'm just barely starting to dive into machine learning, so this might have no relevance, but the question of automating these solutions and training a computer to find ""exquisite"" solutions (defined on the site) has interested me since he introduced it. Since he's now retired this wouldn't benefit any current or future students, but I think he'd appreciate the prospect of training a computer to discover solutions not even he would've thought of.

The goal is essentially to take four predetermined integers and, through various operations, generate another specific integer from them, rewarding lower-level operations as more exquisite (he goes into complete detail at the link above). What do you guys think?"
What are some other sites like kaggle?,1,13,False,False,False,learnmachinelearning,1514058595,True,"Just curious, are there any sites similar to kaggle?  Especially those focused on education?"
Lesson 45 – Time to ‘r’th arrival: The language of Gamma distribution,0,9,False,False,False,learnmachinelearning,1514082475,False, 
The LION Way: Machine Learning and Intelligent Optimization [pdf],0,1,False,False,False,learnmachinelearning,1514105040,False, 
"2018 could be the year AI kills Spam and Redefine Data Science. So what’s there for the aspiring data scientists, and how to get a job in the Big Data and Machine Learning/AI domains?",4,13,False,False,False,learnmachinelearning,1514117584,False, 
Getting Hands-On Machine Learning with Scikit-Learn and TensorFlow by Geron?,10,9,False,False,False,learnmachinelearning,1514119550,True,"Hi, I am a beginner when it comes to Machine Learning. I prefer a more hands-on approach, learning the theory along when I go through the material. Does anybody have the book and could recommend it to me?

Thanks for any help!"
Why Softmaxlayers?,4,2,False,False,False,learnmachinelearning,1514122309,True,"So I understand that we use them to normalize the activation in the output layer to the interval [0,1] but why exactly is that necessary? I figure that when we are training our model we need it to correctly calculate the error. But when we are predicting couldn't we neglect it? I mean all activations are divided by the same constant. And thus, the neuron with the highest activation will also have the highest probability. So, the class we chose will be the same. Or am I missing something?"
noob question about loading image data in pytorch,0,2,False,False,False,learnmachinelearning,1514140541,True,"hello all, 

I'm very familiar with sklearn work and currently getting my feet wet with neural nets.  I'd like to use skorch as a wrapper to have a familiar .fit(X,y) syntax with my work.

What I'm trying now is transfer learning and fine tuning pretrained nets like alexnet and resnet.  I understand from tutorials how to reset the final layer and such.  I have a few questions.

* Can I load images in such a way that I can just have an X, y format?

* Can I also replace the input layer of image-trained net to take a 1D, 1 channel array instead of an image, per sample?

What I'm doing now is just resizing my input arrays of 0,1,2 categorical data into RGB square images, with each pixel being a categorical feature."
Why is RMSProp often preferred for RNNs over Adam?,1,2,False,False,False,learnmachinelearning,1514141015,True,A lot of sources recommend relying on RMSProp when training RNNs. Why is this? Is it something to do with momentum being a bad idea for BPTT? When would using Adam with LSTMs be noticeably worse than RMSProp?
"""Transfer learn"" or start from scratch",2,4,False,False,False,learnmachinelearning,1514152151,True,"Let's say I don't know how many residual blocks to use but I want to start small. After I trained my initial net, is it better to append zero res blocks to the end and keep training (assume I have infinite data) or just reinitialize with random weights?"
Making an AI for match 3 games,2,5,False,False,False,learnmachinelearning,1514152543,True,"I'm just getting my hands wet in machine learning and trying to take in all the information. I set as my final goal to make an AI that can beat a match 3 game like Candy Crush Saga or Homescapes.
I was just wondering how could it be implemented. Like every tile corresponds to an input neuron but what about the output neurons? Every possible move from every tile corresponds to an output node?"
Visualizing Convolutional Filters from a CNN,0,0,False,False,False,learnmachinelearning,1514158489,False, 
MIT Sloan: Intro to Machine Learning (in 360/VR),0,49,False,False,False,learnmachinelearning,1514166876,False, 
elitedatascience.com's guide to learning machine learning?,1,17,False,False,False,learnmachinelearning,1514175276,True,"https://elitedatascience.com/learn-machine-learning

Does this seem like a good path to take if I'm a complete beginner to machine learning? I've programmed in C++ and Java before, and I've taken a linear algebra class, and that's all. I started at step 0 (""prerequisites: python, statistics, math"") and learned the basics of python and got to the step where it tells me to start doing projects (such as on Kaggle) based on datasets/making models etc. However, should I be doing that before I learn anything about statistics and stuff? I feel very unprepared for getting anything done and it seems like everything is a prerequisite for each other/very impossible to learn.

Thank you :)"
Training a ANN on a value which is not the output,0,1,False,False,False,learnmachinelearning,1514201453,True,[deleted]
Loss function for inversely proportional regression,2,6,False,False,False,learnmachinelearning,1514204714,True,"What is a good loss function for a inversely proportional regression model?

For example, I have an estimate function which looks like estimation= 3 / (input−5) + 6 , how should I calculate the loss?

(I'm not a native speaker, sorry if I have got the terminologies wrong)"
Stochastic Gradient ascent for Logistic Regression,13,3,False,False,False,learnmachinelearning,1514217987,True,"Hey there,

I want to implement a version of stochastic gradient ascent algorithm for logistic regression.

I have watched Andrew Ng's [tutorial](https://www.youtube.com/watch?v=W9iWNJNFzQI), which explains clearly how the descent version works. How would it be changed, since I want the ascent version of this?"
Finding good words for Scrabble,2,3,False,False,False,learnmachinelearning,1514232273,True,"I've built my own simple autocorrection and a racer pilot AI and those seemed fairly straightforward, but how would I go about building an AI for Scrabble. I want to do this mainly because my quite optimized algorithm that bruteforces the best combination already takes a few minutes for one word (!) without even considering if it's a good move in the long term.

I struggle the most with understanding how could I constrain the network only to provide output that don't break any of the game's rules, like all the examples I've found just tie to a specific output, but there's millions of different possible layout states. I tried Googling but I clearly lack the vocabulary in English to find a solution for it. Could you please guide me in the right direction?"
"Are you interested in AI and want to learn more through tutorials? Check out our new Subreddit called AITutorials here, and make sure to subscribe if you're interested.",2,53,False,False,False,learnmachinelearning,1514263958,False, 
Top 10 skills needed to Become Data Scientist in 2018,0,1,False,False,False,learnmachinelearning,1514275371,False, 
Neural Network learns XOR function | Hidden Layer Output Visualization |,1,1,False,False,False,learnmachinelearning,1514275694,False, 
Understanding the Hidden Layer output as Neural Network learns XOR function,1,8,False,False,False,learnmachinelearning,1514278839,False, 
Visual Analytics: Exploring #KendrickLamar on Instagram,0,1,False,False,False,learnmachinelearning,1514278862,False, 
How to train a Deep Neural Network using only TensorFlow C++,0,6,False,False,False,learnmachinelearning,1514294634,False, 
How do modern search engines implement spelling correction?,4,11,False,False,False,learnmachinelearning,1514295257,True,"A naive approach would be to use fuzzy string matching bw a misspelled word and all existing words, then select the closest match. That's...inefficient though. "
[Help] Using Sklearn for SGD Regression. Having trouble with label encoders,0,1,False,False,False,learnmachinelearning,1514301506,True,"Hi, I'm new to machine learning and my only experience is with Sklearn and Python. I have a data set which is 10 columns, 9 of them are for the training and 1 is the target. 3 of the training columns are strings and the target is also a string (it's a Genre), so I used a label encoder to convert strings to numbers and then I can convert them back again after a prediction.

However, the predictions don't have any values which can be converted back to strings (which I think is to be expected). Because for example I have 10 Genres so any values in the Genre column are 0-9. But after prediction I end up with values like 1.3209472e+16 instead of 1 or 5 or 3 that are associated with a genre.

Am I on the right track with this or is there options/different algorithms which make it so it choose from the data that's already there and not predict what doesn't exist?

Thank you!"
How to convert Naive Bayesian spam classifier to pure Bayesian?,3,2,False,False,False,learnmachinelearning,1514302432,True,"I understand in naive Bayesian classifier we assume that all words and their occurrence is independent to each other but how can we not assume independence and still solve this problem (spam classification) using Bayesian/Baye's theorem?

Please suggest!"
Question about Keras ImageDataGenerator,0,1,False,False,False,learnmachinelearning,1514309616,True,"I have been experimenting with some cats and dogs in Keras, looking at data augmentation. I have a working pipeline but I'm a little bit confused about the *steps_per_epoch* argument in the *fit_generator* method.

I am under the impression that ImageDataGenerator lets me artificially increase the number of training samples by applying random transformations. Does the value *steps_per_epoch* determine how many extra training samples I am training with?

For example, for N training samples, if my *steps_per_epoch* = N / batch_size (so in each epoch I use exactly N samples), I am not actually generating any extra data? And if I set *steps_per_epoch* to some value greater than N / batch_size, all of those ""extra"" training examples will be generated by my generator?

Thanks a lot for any help"
"Want to learn how to create your own BlockChain in 10 Minutes using JavaScript? Check this out, and if you enjoy the video, make sure to Subscribe! :)",1,0,False,False,False,learnmachinelearning,1514324163,False, 
What to do after finishing Coursera course?,5,17,False,False,False,learnmachinelearning,1514328112,True,"I am doing the guide that is linked in Wiki for engineers. Right now, I have 2 more weeks to go to finish the Coursera class. I understood the theory and did all the assignments as best as I can (using vectorized implementation etc, doing ungraded assignments etc). 

Now, I want to plan what to do next; so, I don't fly blind once I am done with the course. Coursera recommends me a course called [Neural Networks for Machine Learning by University of Toronto](https://www.coursera.org/learn/neural-networks) (I am in Deep Learning path). Is this course worth it? There is also the following courses: https://www.deeplearning.ai.

Or should I ignore these and go straight to reading The Deep Learning book?"
Where to next?,1,8,False,False,False,learnmachinelearning,1514328386,True,"I'm hoping to work in quant/FinTech in the near future, and I've gained familiarity with different Machine Learning algorithms.

I know the basics: neural networks, random forests, SVMs, regression, K-means, gradient boosting, etc. I have a solid understanding of these ideas but a weaker understanding of the math behind them. I learned the math behind them, but the math doesn't stick with me as well as the ideas.

I wanted to ask some of the more experienced users here, what do I do next? Should I work on projects? Contribute to open source? 

Thanks. 
"
Question about the REINFORCE algorithm,0,11,False,False,False,learnmachinelearning,1514343308,True,"So I've recently been playing around with implementing the REINFORCE algorithm to help my understanding of it. However, I have a question about how REINFORCE works with deterministic actions (I'm guessing this is for continuous action spaces) rather than outputting a probability distribution over discrete actions. From [here](http://www.scholarpedia.org/article/Policy_gradient_methods):

&gt;**Disadvantages of this approach:** When used with a deterministic policy, likelihood ratio gradients have to maintain a system model. Such a model can be very hard to obtain for continuous states and actions, hence, the simpler finite difference gradients are often superior in this scenario. Similarly, finite difference gradients can still be more useful than likelihood ratio gradients if the system is deterministic and very repetitive. Also, the practical implementation of a likelihood ratio gradient method is much more demanding than the one of a finite difference method. 

I haven't been able to find too much info on how to use a model in conjunction with likelihood ratios for the continuous action case. Assuming that we have a good model of the system's dynamics, is anyone here able to explain to me how this is typically combined with REINFORCE in order to help my own understanding?

Thanks"
TWIL (This Week I Learned) - Share something new that you have learned this week!,3,5,False,False,False,learnmachinelearning,1514358314,True,"It doesn't matter if it's something trivial. As long as it's new information about machine learning you didn't know until this week, feel free to share!
"
[HELP] need recommendation on training data,4,2,False,False,False,learnmachinelearning,1514380965,True,"
hi r/learnmachinelearning !

I had an idea on recognizing the number plates of cars that are passing by on a road, but i'm not able to find any suitable video on youtube that I can train/test my program on.

Any suggestions ?

Thanks !"
A few questions on a ML tutorial,4,2,False,False,False,learnmachinelearning,1514388139,True,"I'm adapting [this] (https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html) tutorial, but I'm a bit fuzzy on what the author is doing.

First of all, his sample data is structured as follows 

    train/
        dogs/
            dog001.jpg
            dog002.jpg
            ...
        cats/
            cat001.jpg
            cat002.jpg
            ...
    validation/
        dogs/
            dog001.jpg
            dog002.jpg
            ...
        cats/
            cat001.jpg
            cat002.jpg
            ...

Does he have different data in his train and validation classes, or are the same pictures used twice? I would imagine its different but he uses the same file names

Also, the author spends the first portion of his article discussing data augmentation, running a bunch of obfuscations to increase the variability of his data set. However, when he actually implements his ML algorithm he forgoes this step. Why wouldn't he include this in his implementation? 

Also, the author purposefully restricted the size of both his data sets because he was mimicking a situation where obtaining a large data set would be impossible. For my project, its hard to find data for my positive class but very easy to find data for my negative class. Should I include more negative examples in my training and validation classes? "
"24 M - Data scientists, WWYD?",9,11,False,False,False,learnmachinelearning,1514404002,True,"Hi Everyone,

If you'd like to get to the point, please read below. If you'd like the backstory, please see below the opening point. Thank you!

How realistic is it for a newbie (no python, strong at math but never took university-level courses since I couldn't go) to create an income from something machine-learning or algo related. I really just want to discover a way to earn 50-60k a year without me getting heavily involved so I can pursue more ventures like this. Is my best bet learning algo-trading for forex since I have low capital? 

In short - IF YOU COULD ONLY MAKE MONEY WITH MACHINE LEARNING SKILLS AS A SIDE JOB IN ORDER TO EVENTUALLY MAKE IT YOUR FULL-TIME, HOW COULD/WOULD YOU DO IT ENTREPRENUERLY? (not a word, but I'll risk it as I think it gets the message across. 

If you're reading this far, I really appreciate you taking time out of your day to even consider helping me.

Long story short, I come from an underprivileged family (things could always be worse! but we had tough times/still do) and because of this, needed a high-income job outside the gates after high school. 

So its been 4-5 years now, and I'm stuck making between 50k-60k while working to the bone at my new role which has proven to be VERY, very challenging. 

Anyways, I've been feeling miserable because I'm not doing what I love, and I want to follow my passions! 

I cannot explain why, or what got me into the concept of machine learning - but holy fuck (excuse my french), Reddit. Machine learning blew my mind. My mind is consumed all day by things that could be solved using machine learning algorithms, and really wish I had the skillset/capability to do so.

Sorry in advance for any spelling errors. Thank you all for reading!"
Callbacks in Keras,2,2,False,False,False,learnmachinelearning,1514407029,False, 
Assignment - recommendations on what to do with this csv,1,0,False,False,False,learnmachinelearning,1514410012,True,"Hey folks,

I received an assignment for class the day after Christmas(Brutal.). I've been given a dataset which is a collection of documents, which are all mini-reviews of machine learning in the public eye (on news sites etc). I've been told to do 'something' with the data. That's it really, 'something' relating to machine learning. I've been at it for easily over 20 hours now and I'm struggling. 

What I did do however, was strip the documents of all punctuation and applied applied TFIDF, which I've turned into this CSV. The word is on the left with its weight on the right. In this example 'source' and 'agent' are weighted highly due to them appearing in every document. 

My question is - what can I do with this csv now? I have weighted values so I presume I should be able to do something. A great deal of complexity isn't required for this, but ideally I would like to output this information into a graph of some sort. I've been working on this so long that right now I'm just burned out on ideas, ideally I'd like some sort of tutorial I can walk through.

My initial thought on all of this was using K-means. Unfortunately the only example I can find seems to rely on using categorical information from a newsgroup and I can't understand how to convert it to my case.

Any suggestions/help would be appreciated!


EDIT: Forgot CSV [example](https://imgur.com/qjxyIXA) 


EDIT 2: On second though, I may be done here. TFIDF seems to be considered related to ML, so I could be finished! Still though, if anybody has ideas on what to do with it, much appreciated. "
Autoencoder inputs data valued between [-1 1] and only returns values between [0 1].,2,1,False,False,False,learnmachinelearning,1514416697,True,"I'm trying to learn to use an autoencoder to de-noise a data stream using TensorFlow. I have loosely followed the example [given with tensorflow](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/autoencoder.py). The key points are:

* My data has the truth (no noise) and the input (truth + noise) and I use the truth as y_true.
* Cost function is the mean of the error squared
* I am using the RMSPropOptimizer
* Sigmoid activation functions

It works very well, except it does not allow for any of the output values to be negative, essentially forcing them to zero. You can see and example of the data, truth, and result [here](https://imgur.com/a/6vJhE). Can anybody point me into a direction that would help me understand how to allow for negative output from the autoencoder? I can't image it is my minimization algorithm, and the sigmoid allows for negative values.

Any pointers are appreciated. Thanks!

edit: bullets are hard"
"Want to learn how to make your own Artificial Intelligence-Run CRYPTOCURRENCY CHATBOT in just 5 MINUTES? Check this video out, and make sure to subscribe to the channel if you like the content. :)",0,0,False,False,False,learnmachinelearning,1514426578,False, 
Is there any platform where I can practice Machine learning tools everyday?,8,34,False,False,False,learnmachinelearning,1514439992,True,"I'm a beginner in Machine learning and Data Science. I'm looking for a perfect partner place where I can spend 3-4 hours a day. Based on my research, everywhere It is advised to take Post Graduation in Stat. Is there any platform where I can dwell with machine learning models and visualization tools. Any suggestions would be highly appreciated."
"Is it possible for a non-student to get some sort of internship in machine learning? If so, how?",3,3,False,False,False,learnmachinelearning,1514444217,True,"I'm not a student but have hopes of switching my career over to machine learning. Doing lots of self studying, and then going to start a project soon. 

I like the idea of doing an internship on my road to a full career in ML, but those are usually reserved for students. 

Is it possible to have some sort of similar program for a non-student?"
Some help with imitation learning,1,10,False,False,False,learnmachinelearning,1514455051,True,"I am thinking of using imitation learning for atari games (more like game) or a game(such as mario or car simulator) as a project for university.
Now, my questions are these:

-How should I approach gathering data? (images or data such as position of player, position of enemies, action taken) for every frame

-What algorithm should I approach and try to understand in such a situation? (dagger, searn, smile) 
I've looked into Dagger algorithm and I've got confused (because of mathematics) and don't seem to understand it that well (maybe because I wasn't able to actually find an example of its usage)

-What game should I try it for? (an atari game such as pong, space ivaders, pacman or something like tork?)

Now, I get that those questions may be...a bit stupid. But I've got a bit confused after not understanding that much about imitation learning.

Thank you for taking your time into reading this."
Help on how to get started with a text analysis problem,0,2,False,False,False,learnmachinelearning,1514464573,True,"So I have two set of texts, A and B: 
[A^1 , A^2 , ... , A^n ] and [B^1 , B^2 , ... , B^m ]

Assuming we've already removed stop words and done normalization. How do I find the words most common among texts in A and simultaneously uncommon in B. 

For example, if A are biological texts on sharks and B are biological texts on lions, I'd like to sort out words like shark, fish and sea for A, but **not** words like predator, hunting and wildlife (since these are common in both texts).

I'd also like it if it could emphasis on words that are common in all texts in A, thus if one text in A *love* to call sharks ""sharkiefishies"", to the degree that it's mentioned more than the combined occurrences of the word ""hammerhead"" I'd like to sort that out, since it doesn't occur in the other texts. While if every single text mentions ""hammerhead"" (while not being mentioned even once in the texts in B) I'd like to somehow see that.

Now it feels like I'm a spoiled brat writing a wish list on what my ""magical algorithm"" should du, it's just that I'm thinking there might be some standard methods/algorithms/models for this this that I'm just not aware of since I have no experience with text-analysis."
Odd outputs in my home-brewn LSTM network,4,3,False,False,False,learnmachinelearning,1514466330,True,"I've made my own LSTM network for my final school year project however it is producing some overly consistent outputs in the early stages of training. It always seems to output very similar values despite the fact that it should be random seeing as the weights are also random at the beginning of training.

For a bit of context, I am making a network to generate music for me and I am basing my network off the paper ""LSTM: A Search Space Odyssey"" but it always outputs the same two notes in the early stages of training. Is there a reason why it is so consistent in doing this or is my code just bad?

[Imgur](https://i.imgur.com/FGUpbnl.png) is an example of one output.

EDIT: Bit more detail about the network: uses RMSProp and Momentum to update the weights with gamma value of 0.9 and momentum value of 0.6. Training rate is 0.0001, any higher leads to exploding weights."
Tensorflow - Aerial Image Segmentation for identifying buildings - help needed,0,2,False,False,False,learnmachinelearning,1514470106,True,"Hello 

I am just getting started on my master's thesis, where I will be working with TensorFlow. The goal is to create a convolutional neural network that will be able to identify buildings on aerial imagery. Furthermore, these identified buildings should be compared to the ground truth / buildings identified on older imagery to determine whether the building geometry has been changed (e.g. the building has been expanded or torn down).

However, I am not sure if this is possible to do with a TensorFlow-model or if I will also have to use some other tools/models? 

I am completely new to Deep Learning and Machine Learning in general. I have done a bit of research on the topic and found other models with similar functionality e.g. SegNet. However, these only partially solve my problem. 

Do you have any ideas as to how to go about this? Some good beginner literature or tutorials on the subject would also be much appreciated."
Taking the next step with an ML program,0,3,False,False,False,learnmachinelearning,1514475364,True,"[I just completed this tutorial on my custom dataset](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)

I'd like to take the ML weights I generated and actually use them to classify a large dataset. Does anyone know of a guide that shows something like this? "
What's the status of Julia?,2,7,False,False,False,learnmachinelearning,1514480362,True,"How far along is Julia for ML/Data Science compared to the usual suspects (Python, R, ...)? Especially compared to the functionality of sklearn, numpy, pandas, etc. I don't know if I can take some time learning it atm or not."
Looking for companies with internships for those pursuing a BS in CS,6,13,False,False,False,learnmachinelearning,1514480818,True,"I'm working through the Deep Learning specialization by deeplearning.ai and Andrew on Coursera. Super interested, and now I find myself looking for a summer internship to learn more, get good mentorship, and apply what I've learnt.       
Does anyone have any suggestions?"
Does anyone know what happened to the CUDA Intro to Parallel Programming class on Udacity?,1,4,False,False,False,learnmachinelearning,1514492956,True,When I click on enroll it just takes me to the udacity course search page https://developer.nvidia.com/udacity-cs344-intro-parallel-programming.
Can you explain how a matrix translates into machine learning to someone who barely understands NN at all,5,14,False,False,False,learnmachinelearning,1514508819,True,"I have learned how to build a GA and now I'm trying to learn NN to be able to combine them and create a ML AI for video games that I build.

As far as I've gotten I still haven't picked up how a matrix of floating point numbers that equate to either +1 or -1 translate into some form of behaviour change.  
I think if I understood that I'd have a better idea of what I should be looking for on my learning path."
"As a game developer, am I on the right track to acquire the skills to create improved AI?",4,2,False,False,False,learnmachinelearning,1514510683,True,"I am by profession an experienced Web Developer and growing as a Game Developer in my free time. I've learned how to build basic genetic algorithms and I've been trying to learn how to build simple but useful neural networks as well.

I'm in progress with my BSc in Computer Science, but I've had a rough history with studying math in general even though I really like it in my hobbies. I think this is what is making my entry into ML so slow and tough, but I think I'm progressing. The guide I've found that works for me from ground up has been [this one](http://karpathy.github.io/neuralnets/).

I realise that ML is a field too large for me to dive into if I want to mainly dive into another field like Game Development, but my reason for getting into this was to be able to build smart AI.

My current goal project is to learn GA and NN enough to be able to build a simple AI in a tiny 2D sandbox game scenario where there is one or a few enemies that constantly battle each other or the player and with every attack and every respawn learn how to use the abilities they possess more skillfully based on how the player tends to fight and dodge or how the opposing AI learned to use their skills.

My question is about direction I think. I'm not sure if I'm on the right track to achieve my goal or if I'm more like falling into a different world where I'll get lost quickly if I haven't already..."
School project with neural networks,8,5,False,False,False,learnmachinelearning,1514513949,True,"Hi reddit, I am a student from Switzerland and I have to do a school project for this school year.

I decided to pick up a project related to neural networks ( I have already some more accurate ideas).
I've never had programming on my syllabus though, so I started  to learn it on my spare time.
I think I'm gonna use python for this project because I saw that it was a good first programming langage and also great for machine learning.

Do you have any recommendations on websites or books that I should use about python or machine learning/neural network in general for this kind of project ? "
Neural networks and deep learning online book,0,1,False,False,False,learnmachinelearning,1514527976,False,[deleted]
Neural Networks and Deep Learning (Online Tutorial/Book) | Michael Nielsen,3,45,False,False,False,learnmachinelearning,1514528638,False, 
Weekly Show-off!,1,1,False,False,False,learnmachinelearning,1514531120,True,"Show off the machine learning projects that you have been working on! Whether big or small, any projects that you have built could be shared here.
"
RNN from scratch by fast.ai from keras dense layers.,0,2,False,False,False,learnmachinelearning,1514539833,False, 
[NLP] Bag of words for sentiment analysis.,3,2,False,False,False,learnmachinelearning,1514558283,True,Me and my friends are working on an NLP system for analyzing sentiments of mobile phone reviews. We need bag of words based on which we can classify the data into positive and negative sentence(s). Is there any source where I can get such collection of words which we can use? Please help!
Create new images from an existing set?,2,1,False,False,False,learnmachinelearning,1514560799,True,"Greetings! I'm new to machine learning, and my google-fu has failed me.

I have a large library of images with a similar style. They aren't abstract art, but the color scheme and images are all pretty similar. Is it possible to take this library of images and generate something novel?"
Looks for a study companion,20,12,False,False,False,learnmachinelearning,1514562379,True,"Hello guys, 
I'm a design student. With fair amount of experience in programming and math. And now I'm planning to learn machine learning on my own. Since I don't really have a good peer group in my place, was wondering if anyone would like to join in the learning process, or guide through it, as I feel it works better that way. 
Thanks. Looking forward for cool studymates. "
How would you go about this problem: Matching users to houses based on expressed preferences and historical data. (I'm a noob),2,1,False,False,False,learnmachinelearning,1514565029,True,"Can someone lead me down the right rabbit hole?

Given we have zillow.com, how would one use machine learning (as they do) to determine if a property is recommendable to a user.

To be clear, I'm not attempting to generate recommendations, I'd just like to extract features from a user, and a listing, and infer if they'd be a good match based on historical interactions.

**How I'm currently doing it**

 Currently, I'm taking all of the historical analytics events, extracting the useful features of the listing (price, bedrooms, location), and the features of the user (price preference, bedroom preference, location), combining them into a single feature vector, and then indicating whether the user was interested (viewed/clicked), or if they ignored it (just an impression but did not engage). Then I query the model to predict: ""given a new property with a list of features, would a user with be interested (based on their features)"". 

Is this a sane approach? Here's an example row of the data I use to train the model:

Interested: yes, 

User Prefers 1BR: yes, 

User Prefers 2BR: no, 

Property is 1BR: yes, 

Property is 2BR: no

Property is 3BR: no

Property is 4BR: no

"
Are Word Vectors Used by Chatbots? Are the Contextual Meanings of Vectorized Words Ever Used to Make Sentences?,2,1,False,False,False,learnmachinelearning,1514565411,True,"I know all about what word vectors are and the whole 'king - man + woman = queen' thing, but how exactly are they used?  

Do any content generating algos make use of them?  

Do they work in conjunction with other Neural Networks?  
Would Generative Adversarial Networks be able come up with sentences with them?  
Could an LSTM model make use of them?"
What does this community think about Intel's AI Academy?,0,6,False,False,False,learnmachinelearning,1514566831,True,"Here is the [link](https://software.intel.com/en-us/ai-academy/basics), they have a few into videos and two courses:

 - Machine Learning 101
 
 - Deep Learning 101

If anyone has any experience with this I'd like to hear your thoughts, as well as any recommendations for a n00b. It's cool to see big companies releasing this stuff and trying to build a wider community in this field. "
Why is it in tensor flow everything is loaded into the tensor but not calculated until its told to?,9,19,False,False,False,learnmachinelearning,1514574606,True,"I never understood this concept can some one please explain? 

Eg defining an array in numpy gives you back the array but if I do it in tensorflow I just get a tensor operation with no actual computation?"
Popularity Bias in Recommender System using User-Based Collaborated Filtern?,0,1,False,False,False,learnmachinelearning,1514580862,True,"Hello there.

I built my first recommender system based on user-based collaborated filtering using the MovieLens database. It uses a [simple approach](https://buildingrecommenders.files.wordpress.com/2015/11/user-based-generation.png?w=900) taken from [this blog post] (https://buildingrecommenders.wordpress.com/2015/11/18/overview-of-recommender-algorithms-part-2/). I didn't want to add too much complexity in the beginning for the sake of learning about the different approaches.

Now I read about popularity bias when using collaborative filtering and therefore I tried something with my algorithm. In the beginning, I pretended to be a user with the following ratings:

    {
    movieId: '155', // The Dark Knight
    rating: '5.0',
    },
    {
    movieId: '49026', // The Dark Knight Rises
    rating: '4.0',
    },
    {
    movieId: '40662', // Batman: Under the Red Hood
    rating: '3.0',
    },
    {
    movieId: '58574', // Sherlock Holmes: A Game of Shadows
    rating: '4.0',
    },
    {
    movieId: '44038', // Lovecraft: Fear of the Unknown
    rating: '3.0',
    },
    {
    movieId: '415', // Batman &amp; Robin
    rating: '4.0',
    },
    {
    movieId: '1726', // Iron Man
    rating: '5.0',
    },

The predictions for similar movies were okay-ish. However, what stood out for me was that there were two not really fitting movies in the list of the top 30th recommendations: Sissi and Titanic. So I tried to add those two movies to my ratings but with a low rating.

    ...
    {
    movieId: '457', // Sissi
    rating: '1.0',
    },
    {
    movieId: '597', // Titanic
    rating: '1.0',
    },

What happened next was unexpected. Sissi and Titanic made it from top 30th to the top 10th. Sissi was even the 1st recommended movie. **Is that popularity bias, because too many people rated those movies related to the other movies in my list? Can it happen or did I screw up my code?**

I know that the used algorithm is the simplest approach so far. If I am right and it is popularity bias, **what's the simplest improvement to get rid of it?** I am just learning about those things, so I want to improve the algorithm step by step. Appreciating any help on this subject! Thank you very much."
Keyword Extraction With Machine Learning,2,11,False,False,False,learnmachinelearning,1514591894,False, 
I studied hard for a year and now I have an AI ML job building robots,0,1,False,False,False,learnmachinelearning,1514613538,False, 
"Weekly Status Check Meeting - Share your progress, your goals, and whatever is stopping you from achieving those goals!",2,2,False,False,False,learnmachinelearning,1514617510,True,"Let's have a  meeting!

1. What have you accomplished since last week?
2. What are your goals for next week?
3. Do you have any blockers that need helps from the /r/LearnMachineLearning community?

Don't be pressured to fill out all three questions! If you just want to celebrate your progress, just share that. If you have been planning something, you can make this meeting your first step towards your goal. If you are stuck from making a progress, feel free to just ask a question. 
"
need help with minmax algorithm - connect 4,3,3,False,False,False,learnmachinelearning,1514627272,True,"This is what I have so far:

https://pastebin.com/fj7bgipF

I think the node class successfully does it's job in creating the game tree. I am confused about implementing minmax on this game tree. I am aware the the minmax function is totally messed up. But I don't know where to start"
What's the best place to learn about Kullback-Leibler divergence and how cross-entropy is derived from it?,4,17,False,False,False,learnmachinelearning,1514630545,True,"I would like to know how the cross entropy function loss is derived. It look like I have to go deep into KL theory, but I'm down for that. "
Statistical Computing | University of Notre Dame course for Computer Scientists and Engineers,2,6,False,False,False,learnmachinelearning,1514639113,False, 
Categorical integer features; do they need encoded,2,2,False,False,False,learnmachinelearning,1514642114,True,"Just making sure I’m thinking about this right. Let’s say I’m building a nn to try and predict a customers part buying history (number of days to refill). I have the customer id which is an integer, but to be used in the calculation I’d need to one-hot encode the customer id since the actual numeric value for the id field itself is meaningless. Because otherwise the impact a customer has on part buying would have to be a function of the customer id which it wouldn’t be since they are just randomly assigned (well not randomly assigned, but the number is not important). "
Looking for advice on how to proceed with neural networks,5,3,False,False,False,learnmachinelearning,1514649329,True,"Trying to pick up how to program neural networks over winter break. I've been doing a lot of research into how they function, and have begun work on creating one from scratch (with tutorials) in python to recognize handwritten digits.
My question is whether or not it is better for me to proceed this way than to simply install tensorflow and Keras and learn how to use those systems, as they will be far more powerful and more widely applicable than whatever I string together. On the other hand, even though I have done a lot of reading, using these tools from the start might leave me with less knowledge of how everything works. Which approach should I take?"
How to do this sentiment analysis? [Python],1,16,False,False,False,learnmachinelearning,1514655708,True,"I have a list of stop words (Which I would like to add to default stopwords list of any python sentiment analyze package).

I have a list of Positive, negative words (Which I have to use to analyze polarity).

How I can do it with any python package (NLTK or TextBlob)

Note: I am thinking about to write a small function which will calculate and decide polarity. But, is this the best way? 

Thank you."
"I'm unable to find any Big Data reference architectures, pls help?[x-post /r/datascience",4,5,False,False,False,learnmachinelearning,1514659389,False, 
Help with Logistic Regression Model. Trying to implement from Andrew Ng's ML Specialization Week 2. Still very new to this!,0,1,False,False,False,learnmachinelearning,1514665177,False,[deleted]
RL with distribution actions instead of argmax action selection?,0,2,False,False,False,learnmachinelearning,1514666508,True,"Hello there,
I'm currently doing some RL research as it is a semi-new concept to me when I came across an environment where you can command a fleet of ships to go to separate planets in the environment. I've decided that it's best to use an algorithm that distributes the fleet across all 28 planets based on what the model decides is best, but I have failed to see a reinforcement algorithm that supports this type of action state. Is there any information out there that could help me adapt existing RL algorithms to my solution? Feel free to ask any questions that may help you as I'm aware that I haven't given significant detail in this post. Thanks in advance!"
Lesson 46 - Convolution of independent random variables: The basics.,0,3,False,False,False,learnmachinelearning,1514673876,False, 
The State of Decentralized AI in 2018 [Infographic],0,1,False,False,False,learnmachinelearning,1514686921,False,[deleted]
Checking my understanding of Convolution network.,5,2,False,False,False,learnmachinelearning,1514695911,True,"Hello, can someone please check my comments for the code given. I just want to make sure i understand correctly the code. And i have a question of what does Dropout layer do in case of convolution.

In case of regular layer, it switches off one neuron. What does it do in case of convolution?


    model = Sequential()
    model.add(Conv2D(30, (5, 5), input_shape=(1, 28, 28), activation='relu'))
*output going to be 24x24x30*

    model.add(MaxPooling2D(pool_size=(2, 2)))
*output going to be 12x12x30*

    model.add(Conv2D(15, (3, 3), activation='relu'))
*output going to be 10x10x15*

    model.add(MaxPooling2D(pool_size=(2, 2)))
*output going to be 5x5x15*

    model.add(Dropout(0.2))
**Not sure what drop out does here. Does it drop one layer (out of 15) with probability 20%?**

    model.add(Flatten())
*output 375 neurons layer.*

thanks a bunch."
Artificial Intelligence for beginners,0,11,False,False,False,learnmachinelearning,1514713300,False, 
Would you still recommend Andrew Ng course of Coursera?,19,31,False,False,False,learnmachinelearning,1514727031,True,"I've started watching Andrew Ng course before watching sentdex playlist on YouTube but I'm beginning to think that it is way too much low level nowadays, I'm not doing programming assignments because I'm not interested in Octave/MATLAB and because I don't find it necessary since we have libraries that are already written to do the computations, I just wanted to learn a little bit more about what happens behind the curtains.  

On this matter I was thinking that maybe I don't even need to worry about the low level stuff, I should instead focus on learning libraries such as scikit or tensorflow or keras. I'm doing ML for my high school final year project which will be a virtual self driving car so that's also why I'm not spending too much time on Andrew's course.

I'm so confused, what do you suggest? Should I start watching sentdex playlist right away?"
Understanding Neural Machine Translation,3,2,False,False,False,learnmachinelearning,1514747272,True,I can understand how the encoder of a encoder-decoder system works. Encoder takes in a sequence of word vectors through a RNN/LSTM layer and encodes it into a state vector. This state vector is passed to another LSTM which is decoder which produces vector outputs that are words. I am confused as to how do we get words from outputs of the decoder LSTM. Does it treat decoding as a classification problem and give us the best translated word or does it simply outputs a vector in output embedding space and we match the closest word vector to the output to get the new sequence word. Any clarification/help is appreciated.
